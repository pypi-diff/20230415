# Comparing `tmp/polars_lts_cpu-0.17.2.tar.gz` & `tmp/polars_lts_cpu-0.17.3.tar.gz`

## Comparing `polars_lts_cpu-0.17.2.tar` & `polars_lts_cpu-0.17.3.tar`

### file list

```diff
@@ -1,1081 +1,1096 @@
--rw-r--r--   0        0        0     1411 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/LICENSE
--rw-r--r--   0     1001      123     4012 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/README.md
--rw-r--r--   0     1001      123     9096 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/assets/SQL.sublime-syntax
--rw-r--r--   0     1001      123    21158 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/assets/theme
--rw-r--r--   0     1001      123     1450 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/cli/highlighter.rs
--rw-r--r--   0     1001      123     5052 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/cli/mod.rs
--rw-r--r--   0     1001      123     1043 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/cli/prompt.rs
--rw-r--r--   0     1001      123    13598 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/context.rs
--rw-r--r--   0     1001      123    16610 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/functions.rs
--rw-r--r--   0     1001      123    26950 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/lib.rs
--rw-r--r--   0     1001      123      342 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/main.rs
--rw-r--r--   0     1001      123    13264 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/sql_expr.rs
--rw-r--r--   0     1001      123     3386 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/table_functions.rs
--rw-r--r--   0        0        0     5945 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/LICENSE
--rw-r--r--   0     1001      123     1796 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dot.rs
--rw-r--r--   0     1001      123     4359 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/eval.rs
--rw-r--r--   0     1001      123     4505 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/functions.rs
--rw-r--r--   0     1001      123      164 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/into.rs
--rw-r--r--   0     1001      123     4674 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/list.rs
--rw-r--r--   0     1001      123     2831 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/mod.rs
--rw-r--r--   0     1001      123     1182 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs
--rw-r--r--   0     1001      123     9288 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/csv.rs
--rw-r--r--   0     1001      123     4309 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/file_list_reader.rs
--rw-r--r--   0     1001      123     2261 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/ipc.rs
--rw-r--r--   0     1001      123    47120 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/mod.rs
--rw-r--r--   0     1001      123     3414 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/ndjson.rs
--rw-r--r--   0     1001      123     3440 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/parquet.rs
--rw-r--r--   0     1001      123     2892 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/pivot.rs
--rw-r--r--   0     1001      123      416 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/python.rs
--rw-r--r--   0     1001      123     6376 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/lib.rs
--rw-r--r--   0     1001      123      764 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs
--rw-r--r--   0     1001      123      776 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs
--rw-r--r--   0     1001      123      670 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs
--rw-r--r--   0     1001      123     1284 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs
--rw-r--r--   0     1001      123     3908 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs
--rw-r--r--   0     1001      123     3577 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs
--rw-r--r--   0     1001      123    13592 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs
--rw-r--r--   0     1001      123     4335 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs
--rw-r--r--   0     1001      123     6058 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs
--rw-r--r--   0     1001      123     7074 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs
--rw-r--r--   0     1001      123     2045 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs
--rw-r--r--   0     1001      123     1677 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs
--rw-r--r--   0     1001      123     2986 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs
--rw-r--r--   0     1001      123     1963 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs
--rw-r--r--   0     1001      123     4184 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs
--rw-r--r--   0     1001      123     1211 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs
--rw-r--r--   0     1001      123     2421 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs
--rw-r--r--   0     1001      123      548 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs
--rw-r--r--   0     1001      123     2197 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs
--rw-r--r--   0     1001      123     1922 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs
--rw-r--r--   0     1001      123      663 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs
--rw-r--r--   0     1001      123     3702 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs
--rw-r--r--   0     1001      123      838 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs
--rw-r--r--   0     1001      123     1284 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/exotic.rs
--rw-r--r--   0     1001      123    22402 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs
--rw-r--r--   0     1001      123     2689 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs
--rw-r--r--   0     1001      123    17409 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs
--rw-r--r--   0     1001      123    18847 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs
--rw-r--r--   0     1001      123     3153 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs
--rw-r--r--   0     1001      123     6326 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs
--rw-r--r--   0     1001      123     2003 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs
--rw-r--r--   0     1001      123     5804 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs
--rw-r--r--   0     1001      123     3670 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs
--rw-r--r--   0     1001      123     5304 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs
--rw-r--r--   0     1001      123    20940 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs
--rw-r--r--   0     1001      123    10091 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs
--rw-r--r--   0     1001      123     3929 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs
--rw-r--r--   0     1001      123    11541 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs
--rw-r--r--   0     1001      123     8331 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs
--rw-r--r--   0     1001      123    14345 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs
--rw-r--r--   0     1001      123    31804 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs
--rw-r--r--   0     1001      123     2044 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs
--rw-r--r--   0     1001      123      419 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/mod.rs
--rw-r--r--   0     1001      123     2005 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs
--rw-r--r--   0     1001      123    27332 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs
--rw-r--r--   0     1001      123    18867 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs
--rw-r--r--   0     1001      123       87 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/planner/mod.rs
--rw-r--r--   0     1001      123     9563 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/state.rs
--rw-r--r--   0     1001      123    20901 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/streaming/convert.rs
--rw-r--r--   0     1001      123      219 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/streaming/mod.rs
--rw-r--r--   0     1001      123     3333 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs
--rw-r--r--   0     1001      123      722 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/prelude.rs
--rw-r--r--   0     1001      123    14987 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/aggregations.rs
--rw-r--r--   0     1001      123     2339 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/arity.rs
--rw-r--r--   0     1001      123     7031 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/cse.rs
--rw-r--r--   0     1001      123    12749 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/io.rs
--rw-r--r--   0     1001      123     4207 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/logical.rs
--rw-r--r--   0     1001      123     4293 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/mod.rs
--rw-r--r--   0     1001      123    14819 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/optimization_checks.rs
--rw-r--r--   0     1001      123     6799 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/predicate_queries.rs
--rw-r--r--   0     1001      123     3158 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/projection_queries.rs
--rw-r--r--   0     1001      123    47889 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/queries.rs
--rw-r--r--   0     1001      123     8358 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/streaming.rs
--rw-r--r--   0     1001      123     2953 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/tpch.rs
--rw-r--r--   0     1001      123     1033 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/utils.rs
--rw-r--r--   0        0        0     1780 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/LICENSE
--rw-r--r--   0     1001      123       98 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/mod.rs
--rw-r--r--   0     1001      123     1219 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/filter.rs
--rw-r--r--   0     1001      123     4103 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/function.rs
--rw-r--r--   0     1001      123      229 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/mod.rs
--rw-r--r--   0     1001      123      548 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs
--rw-r--r--   0     1001      123     3247 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/projection.rs
--rw-r--r--   0     1001      123     2324 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/reproject.rs
--rw-r--r--   0     1001      123     6501 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs
--rw-r--r--   0     1001      123    10473 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs
--rw-r--r--   0     1001      123     1207 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs
--rw-r--r--   0     1001      123     1888 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs
--rw-r--r--   0     1001      123     4555 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs
--rw-r--r--   0     1001      123     1746 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs
--rw-r--r--   0     1001      123     5413 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs
--rw-r--r--   0     1001      123     4951 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs
--rw-r--r--   0     1001      123      211 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mod.rs
--rw-r--r--   0     1001      123      856 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs
--rw-r--r--   0     1001      123     4294 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs
--rw-r--r--   0     1001      123    24282 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic.rs
--rw-r--r--   0     1001      123     2150 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs
--rw-r--r--   0     1001      123     4666 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs
--rw-r--r--   0     1001      123     3906 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs
--rw-r--r--   0     1001      123    20859 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs
--rw-r--r--   0     1001      123    23521 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs
--rw-r--r--   0     1001      123     2457 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs
--rw-r--r--   0     1001      123     7893 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/io.rs
--rw-r--r--   0     1001      123     5485 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs
--rw-r--r--   0     1001      123    14279 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs
--rw-r--r--   0     1001      123    11824 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs
--rw-r--r--   0     1001      123      178 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/mod.rs
--rw-r--r--   0     1001      123     2002 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/memory.rs
--rw-r--r--   0     1001      123      567 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/mod.rs
--rw-r--r--   0     1001      123     1492 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs
--rw-r--r--   0     1001      123     1824 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs
--rw-r--r--   0     1001      123     3108 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/slice.rs
--rw-r--r--   0     1001      123      130 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/mod.rs
--rw-r--r--   0     1001      123     3808 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs
--rw-r--r--   0     1001      123     6295 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs
--rw-r--r--   0     1001      123     5953 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs
--rw-r--r--   0     1001      123     3801 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs
--rw-r--r--   0     1001      123      600 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/utils.rs
--rw-r--r--   0     1001      123     5076 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/csv.rs
--rw-r--r--   0     1001      123     1231 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/frame.rs
--rw-r--r--   0     1001      123      987 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs
--rw-r--r--   0     1001      123      376 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/mod.rs
--rw-r--r--   0     1001      123     3387 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/parquet.rs
--rw-r--r--   0     1001      123     1146 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/reproject.rs
--rw-r--r--   0     1001      123     1022 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/union.rs
--rw-r--r--   0     1001      123      448 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/expressions.rs
--rw-r--r--   0     1001      123      272 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/lib.rs
--rw-r--r--   0     1001      123      719 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/chunks.rs
--rw-r--r--   0     1001      123      474 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/context.rs
--rw-r--r--   0     1001      123      223 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/mod.rs
--rw-r--r--   0     1001      123      430 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/operator.rs
--rw-r--r--   0     1001      123      626 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/sink.rs
--rw-r--r--   0     1001      123      241 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/source.rs
--rw-r--r--   0     1001      123        1 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/config.rs
--rw-r--r--   0     1001      123    19550 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/convert.rs
--rw-r--r--   0     1001      123    13982 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs
--rw-r--r--   0     1001      123     1237 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/mod.rs
--rw-r--r--   0        0        0      823 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-algo/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-algo/LICENSE
--rw-r--r--   0     1001      123     7265 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-algo/src/algo.rs
--rw-r--r--   0     1001      123       88 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-algo/src/lib.rs
--rw-r--r--   0     1001      123       28 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-algo/src/prelude.rs
--rw-r--r--   0        0        0     2055 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/LICENSE
--rw-r--r--   0     1001      123     3565 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/date.rs
--rw-r--r--   0     1001      123     6465 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/datetime.rs
--rw-r--r--   0     1001      123     3305 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/duration.rs
--rw-r--r--   0     1001      123     5607 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/kernels.rs
--rw-r--r--   0     1001      123     1062 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/mod.rs
--rw-r--r--   0     1001      123     7302 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs
--rw-r--r--   0     1001      123     2582 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs
--rw-r--r--   0     1001      123    10476 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs
--rw-r--r--   0     1001      123      428 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/mod.rs
--rw-r--r--   0     1001      123     7368 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs
--rw-r--r--   0     1001      123     4125 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/time.rs
--rw-r--r--   0     1001      123    15873 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs
--rw-r--r--   0     1001      123    20048 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs
--rw-r--r--   0     1001      123     5808 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs
--rw-r--r--   0     1001      123     9585 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs
--rw-r--r--   0     1001      123     2960 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/date_range.rs
--rw-r--r--   0     1001      123    31306 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/groupby/dynamic.rs
--rw-r--r--   0     1001      123       88 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/groupby/mod.rs
--rw-r--r--   0     1001      123      535 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/lib.rs
--rw-r--r--   0     1001      123      320 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/prelude.rs
--rw-r--r--   0     1001      123     1568 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/round.rs
--rw-r--r--   0     1001      123     4028 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/_trait.rs
--rw-r--r--   0     1001      123      136 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/boolean.rs
--rw-r--r--   0     1001      123      140 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/categoricals.rs
--rw-r--r--   0     1001      123      133 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/date.rs
--rw-r--r--   0     1001      123      137 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/datetime.rs
--rw-r--r--   0     1001      123      137 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/duration.rs
--rw-r--r--   0     1001      123     1863 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/floats.rs
--rw-r--r--   0     1001      123     1792 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/integers.rs
--rw-r--r--   0     1001      123      133 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/list.rs
--rw-r--r--   0     1001      123      486 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/mod.rs
--rw-r--r--   0     1001      123      155 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/object.rs
--rw-r--r--   0     1001      123      135 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/struct_.rs
--rw-r--r--   0     1001      123      133 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/time.rs
--rw-r--r--   0     1001      123      133 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/utf8.rs
--rw-r--r--   0     1001      123    12448 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/mod.rs
--rw-r--r--   0     1001      123     1630 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/truncate.rs
--rw-r--r--   0     1001      123     7059 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/upsample.rs
--rw-r--r--   0     1001      123     2567 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/utils.rs
--rw-r--r--   0     1001      123     1524 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/bounds.rs
--rw-r--r--   0     1001      123     2008 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/calendar.rs
--rw-r--r--   0     1001      123    23538 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/duration.rs
--rw-r--r--   0     1001      123    20089 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/groupby.rs
--rw-r--r--   0     1001      123      503 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/mod.rs
--rw-r--r--   0     1001      123    24202 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/test.rs
--rw-r--r--   0     1001      123    11624 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/window.rs
--rw-r--r--   0        0        0      476 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/LICENSE
--rw-r--r--   0     1001      123     2645 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/arena.rs
--rw-r--r--   0     1001      123     1373 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/atomic.rs
--rw-r--r--   0     1001      123     2659 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/cell.rs
--rw-r--r--   0     1001      123     1015 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/contention_pool.rs
--rw-r--r--   0     1001      123      509 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/error.rs
--rw-r--r--   0     1001      123      271 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/fmt.rs
--rw-r--r--   0     1001      123      763 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/functions.rs
--rw-r--r--   0     1001      123      514 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/hash.rs
--rw-r--r--   0     1001      123     2709 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/iter/enumerate_idx.rs
--rw-r--r--   0     1001      123       61 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/iter/mod.rs
--rw-r--r--   0     1001      123      583 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/lib.rs
--rw-r--r--   0     1001      123      353 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/macros.rs
--rw-r--r--   0     1001      123      282 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/mem.rs
--rw-r--r--   0     1001      123     1792 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/slice.rs
--rw-r--r--   0     1001      123     2467 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/sort.rs
--rw-r--r--   0     1001      123     1114 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/sync.rs
--rw-r--r--   0     1001      123      504 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/sys.rs
--rw-r--r--   0     1001      123      697 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/unwrap.rs
--rw-r--r--   0     1001      123      616 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/wasm.rs
--rw-r--r--   0        0        0     5407 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/LICENSE
--rw-r--r--   0     1001      123    19606 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/arithmetic.rs
--rw-r--r--   0     1001      123     8679 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/bitwise.rs
--rw-r--r--   0     1001      123     2298 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/binary.rs
--rw-r--r--   0     1001      123     1179 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs
--rw-r--r--   0     1001      123     1556 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/from.rs
--rw-r--r--   0     1001      123    20729 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/list.rs
--rw-r--r--   0     1001      123     8845 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/mod.rs
--rw-r--r--   0     1001      123     1382 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs
--rw-r--r--   0     1001      123     2263 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs
--rw-r--r--   0     1001      123    13129 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/cast.rs
--rw-r--r--   0     1001      123    48300 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs
--rw-r--r--   0     1001      123     9463 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs
--rw-r--r--   0     1001      123      551 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/drop.rs
--rw-r--r--   0     1001      123      963 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/float.rs
--rw-r--r--   0     1001      123     5150 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/from.rs
--rw-r--r--   0     1001      123    38411 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs
--rw-r--r--   0     1001      123     1395 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs
--rw-r--r--   0     1001      123       28 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/par/mod.rs
--rw-r--r--   0     1001      123     1129 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs
--rw-r--r--   0     1001      123       21 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/kernels/mod.rs
--rw-r--r--   0     1001      123     2986 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/kernels/take.rs
--rw-r--r--   0     1001      123     7001 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/list/iterator.rs
--rw-r--r--   0     1001      123     2802 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/list/mod.rs
--rw-r--r--   0     1001      123    19456 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs
--rw-r--r--   0     1001      123     3688 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs
--rw-r--r--   0     1001      123     4270 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs
--rw-r--r--   0     1001      123    10220 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs
--rw-r--r--   0     1001      123     1400 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs
--rw-r--r--   0     1001      123      358 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/full.rs
--rw-r--r--   0     1001      123      192 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/mod.rs
--rw-r--r--   0     1001      123     2731 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs
--rw-r--r--   0     1001      123     2172 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs
--rw-r--r--   0     1001      123      925 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs
--rw-r--r--   0     1001      123     6453 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs
--rw-r--r--   0     1001      123     1604 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/date.rs
--rw-r--r--   0     1001      123     4105 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs
--rw-r--r--   0     1001      123     3567 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs
--rw-r--r--   0     1001      123     2434 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/duration.rs
--rw-r--r--   0     1001      123     2549 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/mod.rs
--rw-r--r--   0     1001      123      476 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/struct_/from.rs
--rw-r--r--   0     1001      123    13166 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs
--rw-r--r--   0     1001      123     1182 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/time.rs
--rw-r--r--   0     1001      123    23438 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/mod.rs
--rw-r--r--   0     1001      123     7200 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ndarray.rs
--rw-r--r--   0     1001      123     4484 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/builder.rs
--rw-r--r--   0     1001      123     1547 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs
--rw-r--r--   0     1001      123     3124 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs
--rw-r--r--   0     1001      123     7054 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs
--rw-r--r--   0     1001      123     3410 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs
--rw-r--r--   0     1001      123      137 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/is_valid.rs
--rw-r--r--   0     1001      123     4419 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/iterator.rs
--rw-r--r--   0     1001      123     4826 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/mod.rs
--rw-r--r--   0     1001      123     2517 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/registry.rs
--rw-r--r--   0     1001      123      272 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/abs.rs
--rw-r--r--   0     1001      123    32120 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs
--rw-r--r--   0     1001      123     9946 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs
--rw-r--r--   0     1001      123     2875 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs
--rw-r--r--   0     1001      123     9391 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs
--rw-r--r--   0     1001      123     2365 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/append.rs
--rw-r--r--   0     1001      123    27269 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/apply.rs
--rw-r--r--   0     1001      123    12799 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs
--rw-r--r--   0     1001      123     6295 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs
--rw-r--r--   0     1001      123    11537 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs
--rw-r--r--   0     1001      123     1737 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs
--rw-r--r--   0     1001      123     4801 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs
--rw-r--r--   0     1001      123     6264 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs
--rw-r--r--   0     1001      123    24977 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/explode.rs
--rw-r--r--   0     1001      123     8339 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/extend.rs
--rw-r--r--   0     1001      123    13777 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs
--rw-r--r--   0     1001      123     5308 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/filter.rs
--rw-r--r--   0     1001      123     4436 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/full.rs
--rw-r--r--   0     1001      123        1 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/interpolate.rs
--rw-r--r--   0     1001      123    15089 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs
--rw-r--r--   0     1001      123        1 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/len.rs
--rw-r--r--   0     1001      123    22261 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/mod.rs
--rw-r--r--   0     1001      123     2403 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs
--rw-r--r--   0     1001      123      593 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs
--rw-r--r--   0     1001      123     2585 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs
--rw-r--r--   0     1001      123     1539 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs
--rw-r--r--   0     1001      123    10234 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs
--rw-r--r--   0     1001      123    12518 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/set.rs
--rw-r--r--   0     1001      123     6151 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/shift.rs
--rw-r--r--   0     1001      123     2299 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs
--rw-r--r--   0     1001      123     5467 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs
--rw-r--r--   0     1001      123     7430 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs
--rw-r--r--   0     1001      123    30762 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs
--rw-r--r--   0     1001      123      380 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/slice.rs
--rw-r--r--   0     1001      123    20472 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs
--rw-r--r--   0     1001      123     6630 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs
--rw-r--r--   0     1001      123     1859 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs
--rw-r--r--   0     1001      123    16256 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs
--rw-r--r--   0     1001      123     5041 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs
--rw-r--r--   0     1001      123     6064 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs
--rw-r--r--   0     1001      123    11229 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs
--rw-r--r--   0     1001      123    14620 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs
--rw-r--r--   0     1001      123     7753 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/zip.rs
--rw-r--r--   0     1001      123     9093 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/random.rs
--rw-r--r--   0     1001      123     1959 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs
--rw-r--r--   0     1001      123     2489 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/date.rs
--rw-r--r--   0     1001      123    11559 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs
--rw-r--r--   0     1001      123     3201 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs
--rw-r--r--   0     1001      123      533 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs
--rw-r--r--   0     1001      123     1592 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/time.rs
--rw-r--r--   0     1001      123      872 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/to_vec.rs
--rw-r--r--   0     1001      123     8113 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/trusted_len.rs
--rw-r--r--   0     1001      123    29283 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs
--rw-r--r--   0     1001      123     7689 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/cloud.rs
--rw-r--r--   0     1001      123     1549 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/config.rs
--rw-r--r--   0     1001      123     3946 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/_serde.rs
--rw-r--r--   0     1001      123     2701 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/aliases.rs
--rw-r--r--   0     1001      123    42068 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/any_value.rs
--rw-r--r--   0     1001      123    11442 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/dtype.rs
--rw-r--r--   0     1001      123     5532 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/field.rs
--rw-r--r--   0     1001      123     7644 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/mod.rs
--rw-r--r--   0     1001      123     2016 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/time_unit.rs
--rw-r--r--   0     1001      123      118 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/mod.rs
--rw-r--r--   0     1001      123      898 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs
--rw-r--r--   0     1001      123      481 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_3.rs
--rw-r--r--   0     1001      123      293 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_4.rs
--rw-r--r--   0     1001      123      499 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_5.rs
--rw-r--r--   0     1001      123      288 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_6.rs
--rw-r--r--   0     1001      123     1071 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_7.rs
--rw-r--r--   0     1001      123      819 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_8.rs
--rw-r--r--   0     1001      123      596 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_9.rs
--rw-r--r--   0     1001      123       43 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/mod.rs
--rw-r--r--   0     1001      123       25 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/error.rs
--rw-r--r--   0     1001      123      433 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/export.rs
--rw-r--r--   0     1001      123    37711 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/fmt.rs
--rw-r--r--   0     1001      123     5177 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/arithmetic.rs
--rw-r--r--   0     1001      123     7874 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/asof_join/asof.rs
--rw-r--r--   0     1001      123    33715 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/asof_join/groups.rs
--rw-r--r--   0     1001      123     6561 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/asof_join/mod.rs
--rw-r--r--   0     1001      123      559 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/chunks.rs
--rw-r--r--   0     1001      123     5179 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/cross_join.rs
--rw-r--r--   0     1001      123    16609 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/explode.rs
--rw-r--r--   0     1001      123     1019 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/from.rs
--rw-r--r--   0     1001      123    16518 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs
--rw-r--r--   0     1001      123     7643 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs
--rw-r--r--   0     1001      123    47350 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs
--rw-r--r--   0     1001      123      218 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/expr.rs
--rw-r--r--   0     1001      123    12291 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/hashing.rs
--rw-r--r--   0     1001      123    14048 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/into_groups.rs
--rw-r--r--   0     1001      123    39434 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/mod.rs
--rw-r--r--   0     1001      123    10535 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/perfect.rs
--rw-r--r--   0     1001      123    17027 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/proxy.rs
--rw-r--r--   0     1001      123    18264 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/mod.rs
--rw-r--r--   0     1001      123    22392 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs
--rw-r--r--   0     1001      123     2413 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs
--rw-r--r--   0     1001      123    16303 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs
--rw-r--r--   0     1001      123     2953 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs
--rw-r--r--   0     1001      123     6076 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs
--rw-r--r--   0     1001      123     4247 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs
--rw-r--r--   0     1001      123     3913 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs
--rw-r--r--   0     1001      123    11583 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs
--rw-r--r--   0     1001      123   124249 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/mod.rs
--rw-r--r--   0     1001      123    20041 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/av_buffer.rs
--rw-r--r--   0     1001      123     3732 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/dataframe.rs
--rw-r--r--   0     1001      123     5950 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/mod.rs
--rw-r--r--   0     1001      123     8778 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/transpose.rs
--rw-r--r--   0     1001      123     2149 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/top_k.rs
--rw-r--r--   0     1001      123     1388 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/upstream_traits.rs
--rw-r--r--   0     1001      123    10935 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/functions.rs
--rw-r--r--   0     1001      123     2149 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/fx.rs
--rw-r--r--   0     1001      123     1503 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/identity.rs
--rw-r--r--   0     1001      123      453 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/mod.rs
--rw-r--r--   0     1001      123     2707 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/partition.rs
--rw-r--r--   0     1001      123    17653 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/vector_hasher.rs
--rw-r--r--   0     1001      123     1903 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/lib.rs
--rw-r--r--   0     1001      123    15766 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/named_from.rs
--rw-r--r--   0     1001      123     2411 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/prelude.rs
--rw-r--r--   0     1001      123     8247 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/schema.rs
--rw-r--r--   0     1001      123     4218 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/serde/chunked_array.rs
--rw-r--r--   0     1001      123     6551 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/serde/mod.rs
--rw-r--r--   0     1001      123     9929 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/serde/series.rs
--rw-r--r--   0     1001      123    17338 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/any_value.rs
--rw-r--r--   0     1001      123    28511 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs
--rw-r--r--   0     1001      123      222 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/arithmetic/mod.rs
--rw-r--r--   0     1001      123     3546 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/arithmetic/owned.rs
--rw-r--r--   0     1001      123    13187 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/comparison.rs
--rw-r--r--   0     1001      123    24117 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/from.rs
--rw-r--r--   0     1001      123     9318 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/binary.rs
--rw-r--r--   0     1001      123    10951 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/boolean.rs
--rw-r--r--   0     1001      123    13039 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/categorical.rs
--rw-r--r--   0     1001      123    18120 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/dates_time.rs
--rw-r--r--   0     1001      123    15344 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/datetime.rs
--rw-r--r--   0     1001      123     5718 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/decimal.rs
--rw-r--r--   0     1001      123    14668 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/duration.rs
--rw-r--r--   0     1001      123    14348 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/floats.rs
--rw-r--r--   0     1001      123     6308 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/list.rs
--rw-r--r--   0     1001      123    18430 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/mod.rs
--rw-r--r--   0     1001      123     5191 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/null.rs
--rw-r--r--   0     1001      123     7851 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/object.rs
--rw-r--r--   0     1001      123    11097 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/struct_.rs
--rw-r--r--   0     1001      123     9836 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/utf8.rs
--rw-r--r--   0     1001      123     4062 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/into.rs
--rw-r--r--   0     1001      123     6297 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/iterator.rs
--rw-r--r--   0     1001      123    36305 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/mod.rs
--rw-r--r--   0     1001      123      853 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/diff.rs
--rw-r--r--   0     1001      123     5204 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/downcast.rs
--rw-r--r--   0     1001      123     3601 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/ewm.rs
--rw-r--r--   0     1001      123      413 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/extend.rs
--rw-r--r--   0     1001      123      562 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/mod.rs
--rw-r--r--   0     1001      123     5974 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/moment.rs
--rw-r--r--   0     1001      123     2908 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/null.rs
--rw-r--r--   0     1001      123     1347 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/pct_change.rs
--rw-r--r--   0     1001      123     4247 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/round.rs
--rw-r--r--   0     1001      123     5072 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/to_list.rs
--rw-r--r--   0     1001      123     1476 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/unique.rs
--rw-r--r--   0     1001      123    18378 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/series_trait.rs
--rw-r--r--   0     1001      123     2840 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/unstable.rs
--rw-r--r--   0     1001      123     8117 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/testing.rs
--rw-r--r--   0     1001      123      508 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/tests.rs
--rw-r--r--   0     1001      123    32703 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/utils/mod.rs
--rw-r--r--   0     1001      123     1181 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/utils/series.rs
--rw-r--r--   0     1001      123    13773 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/utils/supertype.rs
--rw-r--r--   0        0        0    10379 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/LICENSE
--rw-r--r--   0     1001      123     3269 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/Makefile
--rw-r--r--   0     1001      123      215 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/build.rs
--rw-r--r--   0     1001      123       78 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/clippy.toml
--rw-r--r--   0     1001      123    17602 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/eager.rs
--rw-r--r--   0     1001      123     8778 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/lazy.rs
--rw-r--r--   0     1001      123       50 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/mod.rs
--rw-r--r--   0     1001      123     3797 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/performance.rs
--rw-r--r--   0     1001      123       59 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/export.rs
--rw-r--r--   0     1001      123    20419 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/lib.rs
--rw-r--r--   0     1001      123      387 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/prelude.rs
--rw-r--r--   0     1001      123       32 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/src/sql.rs
--rw-r--r--   0     1001      123     4272 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/date_like.rs
--rw-r--r--   0     1001      123     2401 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/groupby.rs
--rw-r--r--   0     1001      123    17826 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/joins.rs
--rw-r--r--   0     1001      123      545 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/list.rs
--rw-r--r--   0     1001      123      189 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/mod.rs
--rw-r--r--   0     1001      123     6258 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/pivot.rs
--rw-r--r--   0     1001      123     1102 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/random.rs
--rw-r--r--   0     1001      123    10844 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/rolling_window.rs
--rw-r--r--   0     1001      123     1093 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/series.rs
--rw-r--r--   0     1001      123      370 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/utils.rs
--rw-r--r--   0     1001      123    30146 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/csv.rs
--rw-r--r--   0     1001      123     4490 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/ipc_stream.rs
--rw-r--r--   0     1001      123     7044 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/json.rs
--rw-r--r--   0     1001      123      378 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/mod.rs
--rw-r--r--   0     1001      123      988 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/parquet.rs
--rw-r--r--   0     1001      123     1530 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/joins.rs
--rw-r--r--   0     1001      123     2452 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/aggregation.rs
--rw-r--r--   0     1001      123      702 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/cse.rs
--rw-r--r--   0     1001      123      500 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/explodes.rs
--rw-r--r--   0     1001      123     2279 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/apply.rs
--rw-r--r--   0     1001      123    10815 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/arity.rs
--rw-r--r--   0     1001      123     1064 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/expand.rs
--rw-r--r--   0     1001      123     1008 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/filter.rs
--rw-r--r--   0     1001      123      428 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/is_in.rs
--rw-r--r--   0     1001      123      121 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/mod.rs
--rw-r--r--   0     1001      123      659 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/slice.rs
--rw-r--r--   0     1001      123    10121 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/window.rs
--rw-r--r--   0     1001      123      579 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/folds.rs
--rw-r--r--   0     1001      123      557 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/functions.rs
--rw-r--r--   0     1001      123     4482 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/groupby.rs
--rw-r--r--   0     1001      123     1655 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs
--rw-r--r--   0     1001      123      691 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/mod.rs
--rw-r--r--   0     1001      123     5381 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/predicate_queries.rs
--rw-r--r--   0     1001      123     4476 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/projection_queries.rs
--rw-r--r--   0     1001      123     6441 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/queries.rs
--rw-r--r--   0     1001      123      141 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/main.rs
--rw-r--r--   0     1001      123      552 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/schema.rs
--rw-r--r--   0        0        0     3133 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/LICENSE
--rw-r--r--   0     1001      123      234 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/binary/mod.rs
--rw-r--r--   0     1001      123     3549 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs
--rw-r--r--   0     1001      123    11023 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/interpolate.rs
--rw-r--r--   0     1001      123     1679 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/count.rs
--rw-r--r--   0     1001      123     2452 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/hash.rs
--rw-r--r--   0     1001      123     7861 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs
--rw-r--r--   0     1001      123      511 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/mod.rs
--rw-r--r--   0     1001      123    22005 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs
--rw-r--r--   0     1001      123     5269 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs
--rw-r--r--   0     1001      123     2435 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs
--rw-r--r--   0     1001      123      489 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/mod.rs
--rw-r--r--   0     1001      123     9380 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs
--rw-r--r--   0     1001      123     6795 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/set.rs
--rw-r--r--   0     1001      123     7490 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/case.rs
--rw-r--r--   0     1001      123     8251 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs
--rw-r--r--   0     1001      123     2345 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs
--rw-r--r--   0     1001      123      514 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs
--rw-r--r--   0     1001      123    14731 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs
--rw-r--r--   0     1001      123     4053 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs
--rw-r--r--   0     1001      123     2486 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/top_k.rs
--rw-r--r--   0     1001      123     7727 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs
--rw-r--r--   0     1001      123    18025 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/join/mod.rs
--rw-r--r--   0     1001      123     4174 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/mod.rs
--rw-r--r--   0     1001      123    10257 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/pivot/mod.rs
--rw-r--r--   0     1001      123    13483 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/pivot/positioning.rs
--rw-r--r--   0     1001      123      217 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/lib.rs
--rw-r--r--   0     1001      123      290 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/prelude.rs
--rw-r--r--   0     1001      123       25 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/mod.rs
--rw-r--r--   0     1001      123     7231 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs
--rw-r--r--   0     1001      123     3680 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/floor_divide.rs
--rw-r--r--   0     1001      123     3413 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/is_first.rs
--rw-r--r--   0     1001      123     2975 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/is_unique.rs
--rw-r--r--   0     1001      123     3626 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/log.rs
--rw-r--r--   0     1001      123      952 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/mod.rs
--rw-r--r--   0     1001      123     1769 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/rolling.rs
--rw-r--r--   0     1001      123     7642 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/search_sorted.rs
--rw-r--r--   0     1001      123     2500 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/to_dummies.rs
--rw-r--r--   0     1001      123     2067 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/various.rs
--rw-r--r--   0        0        0      879 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-error/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-error/LICENSE
--rw-r--r--   0     1001      123     6297 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-error/src/lib.rs
--rw-r--r--   0        0        0     4346 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/LICENSE
--rw-r--r--   0     1001      123     2383 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/avro/mod.rs
--rw-r--r--   0     1001      123     3604 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/avro/read.rs
--rw-r--r--   0     1001      123     2622 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/avro/write.rs
--rw-r--r--   0     1001      123     4505 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/cloud/adaptors.rs
--rw-r--r--   0     1001      123     9506 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/cloud/glob.rs
--rw-r--r--   0     1001      123     3089 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/cloud/mod.rs
--rw-r--r--   0     1001      123    28016 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/buffer.rs
--rw-r--r--   0     1001      123     1898 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/mod.rs
--rw-r--r--   0     1001      123    19430 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/parser.rs
--rw-r--r--   0     1001      123    21349 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read.rs
--rw-r--r--   0     1001      123    10817 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs
--rw-r--r--   0     1001      123    13909 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs
--rw-r--r--   0     1001      123    31233 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read_impl/mod.rs
--rw-r--r--   0     1001      123    11466 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/splitfields.rs
--rw-r--r--   0     1001      123    25209 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/utils.rs
--rw-r--r--   0     1001      123     2796 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/write.rs
--rw-r--r--   0     1001      123    12866 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/write_impl.rs
--rw-r--r--   0     1001      123      184 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/export.rs
--rw-r--r--   0     1001      123     7580 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/ipc_file.rs
--rw-r--r--   0     1001      123     9245 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/ipc_stream.rs
--rw-r--r--   0     1001      123     3253 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/mmap.rs
--rw-r--r--   0     1001      123      401 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/mod.rs
--rw-r--r--   0     1001      123     8282 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/write.rs
--rw-r--r--   0     1001      123     1471 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/write_async.rs
--rw-r--r--   0     1001      123     9974 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/json.rs
--rw-r--r--   0     1001      123     4892 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/lib.rs
--rw-r--r--   0     1001      123     1969 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/mmap.rs
--rw-r--r--   0     1001      123     7215 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ndjson_core/buffer.rs
--rw-r--r--   0     1001      123       39 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ndjson_core/mod.rs
--rw-r--r--   0     1001      123    12177 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ndjson_core/ndjson.rs
--rw-r--r--   0     1001      123      273 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/options.rs
--rw-r--r--   0     1001      123     7354 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/async_impl.rs
--rw-r--r--   0     1001      123     3093 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/mmap.rs
--rw-r--r--   0     1001      123     3132 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/mod.rs
--rw-r--r--   0     1001      123     4790 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/predicates.rs
--rw-r--r--   0     1001      123     9629 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/read.rs
--rw-r--r--   0     1001      123    16886 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/read_impl.rs
--rw-r--r--   0     1001      123    10106 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/write.rs
--rw-r--r--   0     1001      123     5334 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/partition.rs
--rw-r--r--   0     1001      123     1455 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/predicates.rs
--rw-r--r--   0     1001      123      633 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/prelude.rs
--rw-r--r--   0     1001      123      417 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/tests.rs
--rw-r--r--   0     1001      123     4467 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/utils.rs
--rw-r--r--   0        0        0     5211 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/LICENSE
--rw-r--r--   0     1001      123    17253 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dot.rs
--rw-r--r--   0     1001      123     4171 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/arithmetic.rs
--rw-r--r--   0     1001      123      935 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/binary.rs
--rw-r--r--   0     1001      123      969 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/cat.rs
--rw-r--r--   0     1001      123     9323 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/dt.rs
--rw-r--r--   0     1001      123    13163 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/expr.rs
--rw-r--r--   0     1001      123      753 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/from.rs
--rw-r--r--   0     1001      123       85 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/abs.rs
--rw-r--r--   0     1001      123     1431 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs
--rw-r--r--   0     1001      123     1327 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs
--rw-r--r--   0     1001      123     4169 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs
--rw-r--r--   0     1001      123      344 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/clip.rs
--rw-r--r--   0     1001      123     1593 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs
--rw-r--r--   0     1001      123    13120 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs
--rw-r--r--   0     1001      123      665 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs
--rw-r--r--   0     1001      123     1364 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs
--rw-r--r--   0     1001      123     8119 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/list.rs
--rw-r--r--   0     1001      123      581 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/log.rs
--rw-r--r--   0     1001      123    17430 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs
--rw-r--r--   0     1001      123      462 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/nan.rs
--rw-r--r--   0     1001      123     3132 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs
--rw-r--r--   0     1001      123      152 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/rolling.rs
--rw-r--r--   0     1001      123      200 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/row_hash.rs
--rw-r--r--   0     1001      123    12740 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs
--rw-r--r--   0     1001      123      306 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/search_sorted.rs
--rw-r--r--   0     1001      123     3812 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs
--rw-r--r--   0     1001      123     1238 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs
--rw-r--r--   0     1001      123      972 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs
--rw-r--r--   0     1001      123    18280 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs
--rw-r--r--   0     1001      123     1017 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs
--rw-r--r--   0     1001      123     2627 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs
--rw-r--r--   0     1001      123     5122 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs
--rw-r--r--   0     1001      123      170 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/unique.rs
--rw-r--r--   0     1001      123    38368 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/functions.rs
--rw-r--r--   0     1001      123    10196 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/list.rs
--rw-r--r--   0     1001      123     2181 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/meta.rs
--rw-r--r--   0     1001      123    67107 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/mod.rs
--rw-r--r--   0     1001      123       40 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/names.rs
--rw-r--r--   0     1001      123     2094 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/options.rs
--rw-r--r--   0     1001      123    14993 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/string.rs
--rw-r--r--   0     1001      123     2715 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/struct_.rs
--rw-r--r--   0     1001      123       38 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/frame/mod.rs
--rw-r--r--   0     1001      123      933 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/frame/opt_state.rs
--rw-r--r--   0     1001      123      466 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/global.rs
--rw-r--r--   0     1001      123      156 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/lib.rs
--rw-r--r--   0     1001      123     6819 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs
--rw-r--r--   0     1001      123    11390 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs
--rw-r--r--   0     1001      123    25701 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/alp.rs
--rw-r--r--   0     1001      123     1622 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs
--rw-r--r--   0     1001      123     1428 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/apply.rs
--rw-r--r--   0     1001      123    25056 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/builder.rs
--rw-r--r--   0     1001      123    29650 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/conversion.rs
--rw-r--r--   0     1001      123      301 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/debug.rs
--rw-r--r--   0     1001      123    15193 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/format.rs
--rw-r--r--   0     1001      123      895 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs
--rw-r--r--   0     1001      123      137 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/explode.rs
--rw-r--r--   0     1001      123     1169 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs
--rw-r--r--   0     1001      123    12019 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs
--rw-r--r--   0     1001      123     1330 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs
--rw-r--r--   0     1001      123     9746 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/iterator.rs
--rw-r--r--   0     1001      123    10463 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/lit.rs
--rw-r--r--   0     1001      123     8148 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/mod.rs
--rw-r--r--   0     1001      123     7416 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs
--rw-r--r--   0     1001      123    15287 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs
--rw-r--r--   0     1001      123     3260 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs
--rw-r--r--   0     1001      123     3236 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs
--rw-r--r--   0     1001      123     3994 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs
--rw-r--r--   0     1001      123    14494 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs
--rw-r--r--   0     1001      123     1556 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs
--rw-r--r--   0     1001      123     6715 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs
--rw-r--r--   0     1001      123     1222 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs
--rw-r--r--   0     1001      123    28281 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs
--rw-r--r--   0     1001      123     2571 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs
--rw-r--r--   0     1001      123    15130 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs
--rw-r--r--   0     1001      123     1755 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs
--rw-r--r--   0     1001      123     3930 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs
--rw-r--r--   0     1001      123     1799 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs
--rw-r--r--   0     1001      123     3269 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs
--rw-r--r--   0     1001      123     2638 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs
--rw-r--r--   0     1001      123    15747 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs
--rw-r--r--   0     1001      123    26507 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs
--rw-r--r--   0     1001      123     2692 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs
--rw-r--r--   0     1001      123     2639 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs
--rw-r--r--   0     1001      123     3501 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs
--rw-r--r--   0     1001      123    27332 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs
--rw-r--r--   0     1001      123     3492 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs
--rw-r--r--   0     1001      123    13850 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs
--rw-r--r--   0     1001      123     3161 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs
--rw-r--r--   0     1001      123     9725 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs
--rw-r--r--   0     1001      123    19819 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs
--rw-r--r--   0     1001      123    10197 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/options.rs
--rw-r--r--   0     1001      123    15273 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/projection.rs
--rw-r--r--   0     1001      123     4615 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs
--rw-r--r--   0     1001      123    13048 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/schema.rs
--rw-r--r--   0     1001      123      809 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/prelude.rs
--rw-r--r--   0     1001      123    11955 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/utils.rs
--rw-r--r--   0        0        0      940 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/LICENSE
--rw-r--r--   0     1001      123     8985 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encode.rs
--rw-r--r--   0     1001      123     4591 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encodings/fixed.rs
--rw-r--r--   0     1001      123       47 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encodings/mod.rs
--rw-r--r--   0     1001      123     4508 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encodings/variable.rs
--rw-r--r--   0     1001      123    13678 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/lib.rs
--rw-r--r--   0     1001      123     2079 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/row.rs
--rw-r--r--   0     1001      123      682 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/utils.rs
--rw-r--r--   0        0        0     1431 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/LICENSE
--rw-r--r--   0     1001      123     1975 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/default_arrays.rs
--rw-r--r--   0     1001      123     3160 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/get.rs
--rw-r--r--   0     1001      123     2986 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/list.rs
--rw-r--r--   0     1001      123     7771 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/mod.rs
--rw-r--r--   0     1001      123      878 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/null.rs
--rw-r--r--   0     1001      123     1125 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/slice.rs
--rw-r--r--   0     1001      123     1807 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/utf8.rs
--rw-r--r--   0     1001      123     2294 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/bit_util.rs
--rw-r--r--   0     1001      123       17 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/bitmap/mod.rs
--rw-r--r--   0     1001      123      819 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/bitmap/mutable.rs
--rw-r--r--   0     1001      123      232 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/compute/cast.rs
--rw-r--r--   0     1001      123       56 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/compute/mod.rs
--rw-r--r--   0     1001      123     2962 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/compute/take/boolean.rs
--rw-r--r--   0     1001      123    24907 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/compute/take/mod.rs
--rw-r--r--   0     1001      123     1042 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/conversion.rs
--rw-r--r--   0     1001      123     1609 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/data_types.rs
--rw-r--r--   0     1001      123       25 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/error.rs
--rw-r--r--   0     1001      123       28 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/export.rs
--rw-r--r--   0     1001      123       26 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/floats/mod.rs
--rw-r--r--   0     1001      123     2066 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/floats/ord.rs
--rw-r--r--   0     1001      123     1273 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/index.rs
--rw-r--r--   0     1001      123      915 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/is_valid.rs
--rw-r--r--   0     1001      123     4740 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/agg_mean.rs
--rw-r--r--   0     1001      123     1015 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/concatenate.rs
--rw-r--r--   0     1001      123     5161 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/ewm/average.rs
--rw-r--r--   0     1001      123     1808 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs
--rw-r--r--   0     1001      123    25065 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs
--rw-r--r--   0     1001      123     1406 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/float.rs
--rw-r--r--   0     1001      123     4907 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/list.rs
--rw-r--r--   0     1001      123     1895 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs
--rw-r--r--   0     1001      123     9731 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/mod.rs
--rw-r--r--   0     1001      123     3703 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs
--rw-r--r--   0     1001      123     2022 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs
--rw-r--r--   0     1001      123    18684 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs
--rw-r--r--   0     1001      123     3924 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs
--rw-r--r--   0     1001      123    11659 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs
--rw-r--r--   0     1001      123     5504 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs
--rw-r--r--   0     1001      123     8683 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs
--rw-r--r--   0     1001      123     1749 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs
--rw-r--r--   0     1001      123    14367 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs
--rw-r--r--   0     1001      123     9070 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs
--rw-r--r--   0     1001      123    11609 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs
--rw-r--r--   0     1001      123     4698 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs
--rw-r--r--   0     1001      123     8335 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs
--rw-r--r--   0     1001      123     8109 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/window.rs
--rw-r--r--   0     1001      123     4752 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/set.rs
--rw-r--r--   0     1001      123     4529 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sort_partition.rs
--rw-r--r--   0     1001      123     2948 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs
--rw-r--r--   0     1001      123     5974 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs
--rw-r--r--   0     1001      123      231 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sorted_join/mod.rs
--rw-r--r--   0     1001      123      841 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/string.rs
--rw-r--r--   0     1001      123     4292 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/take_agg.rs
--rw-r--r--   0     1001      123     3897 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/time.rs
--rw-r--r--   0     1001      123      341 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/lib.rs
--rw-r--r--   0     1001      123      434 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/prelude.rs
--rw-r--r--   0     1001      123      534 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/slice.rs
--rw-r--r--   0     1001      123      762 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/time_zone.rs
--rw-r--r--   0     1001      123      998 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/boolean.rs
--rw-r--r--   0     1001      123     2716 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/mod.rs
--rw-r--r--   0     1001      123     2533 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs
--rw-r--r--   0     1001      123      158 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/rev.rs
--rw-r--r--   0     1001      123     5020 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/utils.rs
--rw-r--r--   0        0        0     4381 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/Cargo.toml
--rw-r--r--   0     1001      123       76 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/.gitignore
--rw-r--r--   0     1001      123     1055 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/LICENSE
--rw-r--r--   0     1001      123     2414 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/Makefile
--rw-r--r--   0     1001      123    10844 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/README.md
--rw-r--r--   0     1001      123      651 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/build.rs
--rw-r--r--   0     1001      123       32 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/.gitignore
--rw-r--r--   0     1001      123      679 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/Makefile
--rw-r--r--   0     1001      123      318 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/api_redirect.html
--rw-r--r--   0     1001      123      151 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/autosummary/accessor.rst
--rw-r--r--   0     1001      123      160 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/autosummary/accessor_attribute.rst
--rw-r--r--   0     1001      123      168 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/autosummary/accessor_callable.rst
--rw-r--r--   0     1001      123      157 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/autosummary/accessor_method.rst
--rw-r--r--   0     1001      123      836 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/autosummary/class.rst
--rw-r--r--   0     1001      123       94 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/autosummary/class_without_autosummary.rst
--rw-r--r--   0     1001      123      406 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/_templates/sidebar-nav-bs.html
--rw-r--r--   0     1001      123      450 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/requirements-docs.txt
--rw-r--r--   0     1001      123     1567 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/_static/css/custom.css
--rw-r--r--   0     1001      123     7302 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/conf.py
--rw-r--r--   0     1001      123       51 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/index.rst
--rw-r--r--   0     1001      123     6767 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/api.rst
--rw-r--r--   0     1001      123     1339 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/config.rst
--rw-r--r--   0     1001      123      274 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/aggregation.rst
--rw-r--r--   0     1001      123      221 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/attributes.rst
--rw-r--r--   0     1001      123      142 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/computation.rst
--rw-r--r--   0     1001      123      319 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/descriptive.rst
--rw-r--r--   0     1001      123      319 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/export.rst
--rw-r--r--   0     1001      123      464 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/groupby.rst
--rw-r--r--   0     1001      123      379 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/index.rst
--rw-r--r--   0     1001      123      189 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/miscellaneous.rst
--rw-r--r--   0     1001      123     1513 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/dataframe/modify_select.rst
--rw-r--r--   0     1001      123      663 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/datatypes.rst
--rw-r--r--   0     1001      123      421 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/exceptions.rst
--rw-r--r--   0     1001      123      388 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/aggregation.rst
--rw-r--r--   0     1001      123      309 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/binary.rst
--rw-r--r--   0     1001      123      338 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/boolean.rst
--rw-r--r--   0     1001      123      237 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/categories.rst
--rw-r--r--   0     1001      123      221 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/columns.rst
--rw-r--r--   0     1001      123     1038 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/computation.rst
--rw-r--r--   0     1001      123     1072 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/functions.rst
--rw-r--r--   0     1001      123      461 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/index.rst
--rw-r--r--   0     1001      123      695 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/list.rst
--rw-r--r--   0     1001      123      374 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/meta.rst
--rw-r--r--   0     1001      123      125 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/miscellaneous.rst
--rw-r--r--   0     1001      123      977 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/modify_select.rst
--rw-r--r--   0     1001      123      639 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/operators.rst
--rw-r--r--   0     1001      123      860 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/string.rst
--rw-r--r--   0     1001      123      254 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/struct.rst
--rw-r--r--   0     1001      123      968 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/temporal.rst
--rw-r--r--   0     1001      123       98 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/expressions/window.rst
--rw-r--r--   0     1001      123      692 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/functions.rst
--rw-r--r--   0     1001      123      392 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/index.rst
--rw-r--r--   0     1001      123     1269 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/io.rst
--rw-r--r--   0     1001      123      252 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/aggregation.rst
--rw-r--r--   0     1001      123      179 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/attributes.rst
--rw-r--r--   0     1001      123      146 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/descriptive.rst
--rw-r--r--   0     1001      123      497 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/groupby.rst
--rw-r--r--   0     1001      123      354 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/index.rst
--rw-r--r--   0     1001      123      455 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/miscellaneous.rst
--rw-r--r--   0     1001      123      988 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/modify_select.rst
--rw-r--r--   0     1001      123      339 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/aggregation.rst
--rw-r--r--   0     1001      123      256 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/attributes.rst
--rw-r--r--   0     1001      123      321 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/binary.rst
--rw-r--r--   0     1001      123      117 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/boolean.rst
--rw-r--r--   0     1001      123      241 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/categories.rst
--rw-r--r--   0     1001      123     1103 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/computation.rst
--rw-r--r--   0     1001      123      722 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/descriptive.rst
--rw-r--r--   0     1001      123      240 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/export.rst
--rw-r--r--   0     1001      123      428 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/index.rst
--rw-r--r--   0     1001      123      749 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/list.rst
--rw-r--r--   0     1001      123      236 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/miscellaneous.rst
--rw-r--r--   0     1001      123     1077 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/modify_select.rst
--rw-r--r--   0     1001      123      922 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/string.rst
--rw-r--r--   0     1001      123      396 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/struct.rst
--rw-r--r--   0     1001      123     1118 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/series/temporal.rst
--rw-r--r--   0     1001      123      302 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/sql.rst
--rw-r--r--   0     1001      123      647 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/testing.rst
--rw-r--r--   0     1001      123      168 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/docs/source/reference/utils.rst
--rw-r--r--   0     1001      123     5941 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/__init__.py
--rw-r--r--   0     1001      123    13396 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/api.py
--rw-r--r--   0     1001      123    24553 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/config.py
--rw-r--r--   0     1001      123    25409 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/convert.py
--rw-r--r--   0     1001      123       77 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/dataframe/__init__.py
--rw-r--r--   0     1001      123     5057 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/dataframe/_html.py
--rw-r--r--   0     1001      123   301542 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/dataframe/frame.py
--rw-r--r--   0     1001      123    33240 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/dataframe/groupby.py
--rw-r--r--   0     1001      123     2524 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/datatypes/__init__.py
--rw-r--r--   0     1001      123    11189 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/datatypes/classes.py
--rw-r--r--   0     1001      123     1356 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/datatypes/constants.py
--rw-r--r--   0     1001      123     4430 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/datatypes/constructor.py
--rw-r--r--   0     1001      123    14468 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/datatypes/convert.py
--rw-r--r--   0     1001      123     7049 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/dependencies.py
--rw-r--r--   0     1001      123     2954 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/exceptions.py
--rw-r--r--   0     1001      123       61 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/__init__.py
--rw-r--r--   0     1001      123     2730 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/binary.py
--rw-r--r--   0     1001      123     1708 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/categorical.py
--rw-r--r--   0     1001      123    65759 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/datetime.py
--rw-r--r--   0     1001      123   250561 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/expr.py
--rw-r--r--   0     1001      123    22899 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/list.py
--rw-r--r--   0     1001      123     2059 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/meta.py
--rw-r--r--   0     1001      123    44215 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/string.py
--rw-r--r--   0     1001      123     5436 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/expr/struct.py
--rw-r--r--   0     1001      123     1941 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/functions/__init__.py
--rw-r--r--   0     1001      123    29688 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/functions/eager.py
--rw-r--r--   0     1001      123    88870 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/functions/lazy.py
--rw-r--r--   0     1001      123     6293 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/functions/whenthen.py
--rw-r--r--   0     1001      123      280 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/internals.py
--rw-r--r--   0     1001      123      978 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/__init__.py
--rw-r--r--   0     1001      123     6264 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/_utils.py
--rw-r--r--   0     1001      123      878 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/avro.py
--rw-r--r--   0     1001      123      144 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/csv/__init__.py
--rw-r--r--   0     1001      123     1082 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/csv/_utils.py
--rw-r--r--   0     1001      123     4691 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/csv/batched_reader.py
--rw-r--r--   0     1001      123    35533 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/csv/functions.py
--rw-r--r--   0     1001      123     8655 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/database.py
--rw-r--r--   0     1001      123    10988 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/delta.py
--rw-r--r--   0     1001      123       75 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/excel/__init__.py
--rw-r--r--   0     1001      123    18459 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/excel/_write_utils.py
--rw-r--r--   0     1001      123     5309 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/excel/functions.py
--rw-r--r--   0     1001      123      142 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/ipc/__init__.py
--rw-r--r--   0     1001      123     1271 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/ipc/anonymous_scan.py
--rw-r--r--   0     1001      123     5840 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/ipc/functions.py
--rw-r--r--   0     1001      123      519 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/json.py
--rw-r--r--   0     1001      123     2257 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/ndjson.py
--rw-r--r--   0     1001      123      170 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/parquet/__init__.py
--rw-r--r--   0     1001      123     1299 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/parquet/anonymous_scan.py
--rw-r--r--   0     1001      123     7212 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/parquet/functions.py
--rw-r--r--   0     1001      123      136 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/pyarrow_dataset/__init__.py
--rw-r--r--   0     1001      123     2331 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/pyarrow_dataset/anonymous_scan.py
--rw-r--r--   0     1001      123     3611 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/io/pyarrow_dataset/functions.py
--rw-r--r--   0     1001      123       77 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/lazyframe/__init__.py
--rw-r--r--   0     1001      123   165937 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/lazyframe/frame.py
--rw-r--r--   0     1001      123    24010 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/lazyframe/groupby.py
--rw-r--r--   0     1001      123        0 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/py.typed
--rw-r--r--   0     1001      123       69 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/__init__.py
--rw-r--r--   0     1001      123     1579 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/_numpy.py
--rw-r--r--   0     1001      123     1920 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/binary.py
--rw-r--r--   0     1001      123     1699 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/categorical.py
--rw-r--r--   0     1001      123    43693 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/datetime.py
--rw-r--r--   0     1001      123    12385 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/list.py
--rw-r--r--   0     1001      123   160680 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/series.py
--rw-r--r--   0     1001      123    26584 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/string.py
--rw-r--r--   0     1001      123     2287 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/struct.py
--rw-r--r--   0     1001      123     5375 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/series/utils.py
--rw-r--r--   0     1001      123     7638 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/slice.py
--rw-r--r--   0     1001      123       75 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/sql/__init__.py
--rw-r--r--   0     1001      123     1351 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/sql/context.py
--rw-r--r--   0     1001      123     4764 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/string_cache.py
--rw-r--r--   0     1001      123      362 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/testing/__init__.py
--rw-r--r--   0     1001      123    25164 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/testing/_parametric.py
--rw-r--r--   0     1001      123      929 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/testing/_private.py
--rw-r--r--   0     1001      123    13264 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/testing/asserts.py
--rw-r--r--   0     1001      123      551 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/testing/parametric.py
--rw-r--r--   0     1001      123     5681 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/type_aliases.py
--rw-r--r--   0     1001      123     1035 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/__init__.py
--rw-r--r--   0     1001      123    47827 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/_construction.py
--rw-r--r--   0     1001      123     2782 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/_parse_expr_input.py
--rw-r--r--   0     1001      123      721 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/_scan.py
--rw-r--r--   0     1001      123      687 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/_wrap.py
--rw-r--r--   0     1001      123      683 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/build_info.py
--rw-r--r--   0     1001      123     8948 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/convert.py
--rw-r--r--   0     1001      123     5789 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/decorators.py
--rw-r--r--   0     1001      123     1660 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/meta.py
--rw-r--r--   0     1001      123      514 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/polars_version.py
--rw-r--r--   0     1001      123     2339 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/show_versions.py
--rw-r--r--   0     1001      123    11592 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/polars/utils/various.py
--rw-r--r--   0     1001      123     5299 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/pyproject.toml
--rw-r--r--   0     1001      123      690 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/requirements-dev.txt
--rw-r--r--   0     1001      123       70 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/requirements-lint.txt
--rw-r--r--   0     1001      123     1610 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/scripts/check_stacklevels.py
--rw-r--r--   0     1001      123    10959 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/apply/dataframe.rs
--rw-r--r--   0     1001      123     8388 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/apply/mod.rs
--rw-r--r--   0     1001      123    71436 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/apply/series.rs
--rw-r--r--   0     1001      123       32 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/arrow_interop/mod.rs
--rw-r--r--   0     1001      123     1306 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/arrow_interop/to_py.rs
--rw-r--r--   0     1001      123     3906 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/arrow_interop/to_rust.rs
--rw-r--r--   0     1001      123     5214 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/batched_csv.rs
--rw-r--r--   0     1001      123    48063 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/conversion.rs
--rw-r--r--   0     1001      123    45496 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/dataframe.rs
--rw-r--r--   0     1001      123     3799 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/datatypes.rs
--rw-r--r--   0     1001      123     3288 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/error.rs
--rw-r--r--   0     1001      123     9482 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/file.rs
--rw-r--r--   0     1001      123     7468 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lazy/apply.rs
--rw-r--r--   0     1001      123    32660 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lazy/dataframe.rs
--rw-r--r--   0     1001      123    62357 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lazy/dsl.rs
--rw-r--r--   0     1001      123     1082 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lazy/meta.rs
--rw-r--r--   0     1001      123      727 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lazy/mod.rs
--rw-r--r--   0     1001      123      212 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lazy/utils.rs
--rw-r--r--   0     1001      123    20790 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/lib.rs
--rw-r--r--   0     1001      123     4050 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/list_construction.rs
--rw-r--r--   0     1001      123     7902 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/npy.rs
--rw-r--r--   0     1001      123     1022 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/object.rs
--rw-r--r--   0     1001      123      122 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/prelude.rs
--rw-r--r--   0     1001      123      435 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/py_modules.rs
--rw-r--r--   0     1001      123    54555 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/series.rs
--rw-r--r--   0     1001      123     3478 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/set.rs
--rw-r--r--   0     1001      123      843 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/sql.rs
--rw-r--r--   0     1001      123     2335 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/src/utils.rs
--rw-r--r--   0     1001      123     6165 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/README.md
--rw-r--r--   0     1001      123     2189 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/benchmark/groupby-datagen.R
--rw-r--r--   0     1001      123     7945 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/benchmark/run_h2oai_benchmark.py
--rw-r--r--   0     1001      123     5018 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/benchmark/test_release.py
--rw-r--r--   0     1001      123     4589 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/docs/run_doctest.py
--rw-r--r--   0     1001      123     3707 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/parametric/test_dataframe.py
--rw-r--r--   0     1001      123     1692 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/parametric/test_lazyframe.py
--rw-r--r--   0     1001      123     5709 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/parametric/test_series.py
--rw-r--r--   0     1001      123     7584 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/parametric/test_testing.py
--rw-r--r--   0     1001      123        0 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/__init__.py
--rw-r--r--   0     1001      123     3394 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/conftest.py
--rw-r--r--   0     1001      123       86 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/__init__.py
--rw-r--r--   0     1001      123      351 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_binary.py
--rw-r--r--   0     1001      123     1420 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_bool.py
--rw-r--r--   0     1001      123    11514 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_categorical.py
--rw-r--r--   0     1001      123     2552 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_decimal.py
--rw-r--r--   0     1001      123    14169 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_list.py
--rw-r--r--   0     1001      123      284 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_null.py
--rw-r--r--   0     1001      123     2801 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_object.py
--rw-r--r--   0     1001      123    27448 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_struct.py
--rw-r--r--   0     1001      123    89703 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/datatypes/test_temporal.py
--rw-r--r--   0     1001      123      218 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/conftest.py
--rw-r--r--   0     1001      123       16 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/.part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet.crc
--rw-r--r--   0     1001      123       16 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/.part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet.crc
--rw-r--r--   0     1001      123       16 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/_delta_log/.00000000000000000000.json.crc
--rw-r--r--   0     1001      123       16 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/_delta_log/.00000000000000000001.json.crc
--rw-r--r--   0     1001      123      905 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json
--rw-r--r--   0     1001      123      936 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json
--rw-r--r--   0     1001      123      972 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet
--rw-r--r--   0     1001      123      690 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet
--rw-r--r--   0     1001      123        0 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/empty.csv
--rw-r--r--   0     1001      123     5959 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/example.xlsx
--rw-r--r--   0     1001      123      457 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.csv
--rw-r--r--   0     1001      123     2351 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.ipc
--rw-r--r--   0     1001      123     1713 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.ndjson
--rw-r--r--   0     1001      123     1427 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.parquet
--rw-r--r--   0     1001      123      455 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.csv
--rw-r--r--   0     1001      123     2351 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.ipc
--rw-r--r--   0     1001      123     1711 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.ndjson
--rw-r--r--   0     1001      123     1916 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.parquet
--rw-r--r--   0     1001      123      455 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods3.csv
--rw-r--r--   0     1001      123      457 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods4.csv
--rw-r--r--   0     1001      123      452 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/foods5.csv
--rw-r--r--   0     1001      123       49 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/gzipped.csv
--rw-r--r--   0     1001      123       57 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/small.csv
--rw-r--r--   0     1001      123      756 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/files/small.parquet
--rw-r--r--   0     1001      123     1907 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_avro.py
--rw-r--r--   0     1001      123    38970 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_csv.py
--rw-r--r--   0     1001      123     7127 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_database.py
--rw-r--r--   0     1001      123     3456 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_delta.py
--rw-r--r--   0     1001      123    11067 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_excel.py
--rw-r--r--   0     1001      123     5916 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_ipc.py
--rw-r--r--   0     1001      123     3361 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_json.py
--rw-r--r--   0     1001      123     6828 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_csv.py
--rw-r--r--   0     1001      123     2060 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_ipc.py
--rw-r--r--   0     1001      123     2851 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_json.py
--rw-r--r--   0     1001      123    11918 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_parquet.py
--rw-r--r--   0     1001      123     2012 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_other.py
--rw-r--r--   0     1001      123    13357 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_parquet.py
--rw-r--r--   0     1001      123      612 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_pickle.py
--rw-r--r--   0     1001      123     3229 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/io/test_pyarrow_dataset.py
--rw-r--r--   0     1001      123      509 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/__init__.py
--rw-r--r--   0     1001      123     3218 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_binary.py
--rw-r--r--   0     1001      123     2489 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_categorical.py
--rw-r--r--   0     1001      123    13569 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_datetime.py
--rw-r--r--   0     1001      123    12741 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_list.py
--rw-r--r--   0     1001      123     1748 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_meta.py
--rw-r--r--   0     1001      123    23698 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_string.py
--rw-r--r--   0     1001      123    15640 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_strptime.py
--rw-r--r--   0     1001      123      982 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/namespaces/test_struct.py
--rw-r--r--   0     1001      123       85 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/__init__.py
--rw-r--r--   0     1001      123     4637 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_aggregations.py
--rw-r--r--   0     1001      123     9412 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_apply.py
--rw-r--r--   0     1001      123     3952 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_arithmetic.py
--rw-r--r--   0     1001      123      956 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_comparison.py
--rw-r--r--   0     1001      123     2906 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_drop.py
--rw-r--r--   0     1001      123     7840 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_explode.py
--rw-r--r--   0     1001      123     3881 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_filter.py
--rw-r--r--   0     1001      123     1801 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_folds.py
--rw-r--r--   0     1001      123    22696 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_groupby.py
--rw-r--r--   0     1001      123    16263 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_join.py
--rw-r--r--   0     1001      123    10467 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_join_asof.py
--rw-r--r--   0     1001      123      643 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_melt.py
--rw-r--r--   0     1001      123    10253 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_pivot.py
--rw-r--r--   0     1001      123    18639 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_rolling.py
--rw-r--r--   0     1001      123    19137 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_sort.py
--rw-r--r--   0     1001      123     3643 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_statistics.py
--rw-r--r--   0     1001      123     3631 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_transpose.py
--rw-r--r--   0     1001      123      771 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_unique.py
--rw-r--r--   0     1001      123     9805 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/operations/test_window.py
--rw-r--r--   0     1001      123     4775 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_api.py
--rw-r--r--   0     1001      123     1077 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_arity.py
--rw-r--r--   0     1001      123    19916 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_cfg.py
--rw-r--r--   0     1001      123    32653 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_constructors.py
--rw-r--r--   0     1001      123      454 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_context.py
--rw-r--r--   0     1001      123     1628 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_cse.py
--rw-r--r--   0     1001      123     3497 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_datatypes.py
--rw-r--r--   0     1001      123   118730 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_df.py
--rw-r--r--   0     1001      123     1009 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_empty.py
--rw-r--r--   0     1001      123    15839 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_errors.py
--rw-r--r--   0     1001      123     2387 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_expr_multi_cols.py
--rw-r--r--   0     1001      123    32643 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_exprs.py
--rw-r--r--   0     1001      123     3305 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_fmt.py
--rw-r--r--   0     1001      123    10759 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_functions.py
--rw-r--r--   0     1001      123     3763 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_interchange.py
--rw-r--r--   0     1001      123    32596 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_interop.py
--rw-r--r--   0     1001      123    48110 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_lazy.py
--rw-r--r--   0     1001      123     2369 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_polars_import.py
--rw-r--r--   0     1001      123     4008 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_predicates.py
--rw-r--r--   0     1001      123     6995 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_projections.py
--rw-r--r--   0     1001      123    11550 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_queries.py
--rw-r--r--   0     1001      123     4743 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_rows.py
--rw-r--r--   0     1001      123    10976 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_schema.py
--rw-r--r--   0     1001      123     2226 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_serde.py
--rw-r--r--   0     1001      123    83595 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_series.py
--rw-r--r--   0     1001      123     2561 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_sql.py
--rw-r--r--   0     1001      123    13877 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_streaming.py
--rw-r--r--   0     1001      123    10344 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/test_testing.py
--rw-r--r--   0     1001      123       41 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/utils/__init__.py
--rw-r--r--   0     1001      123      306 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/utils/test_build_info.py
--rw-r--r--   0     1001      123      247 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/utils/test_show_versions.py
--rw-r--r--   0     1001      123     4307 2023-04-11 14:48:58.000000 polars_lts_cpu-0.17.2/tests/unit/utils/test_utils.py
--rw-r--r--   0     1001      123    63097 2023-04-11 14:50:04.000000 polars_lts_cpu-0.17.2/Cargo.lock
--rw-r--r--   0        0        0    13382 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.2/PKG-INFO
+-rw-r--r--   0        0        0     2055 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/LICENSE
+-rw-r--r--   0     1001      123     3565 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/date.rs
+-rw-r--r--   0     1001      123     6465 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/datetime.rs
+-rw-r--r--   0     1001      123     3305 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/duration.rs
+-rw-r--r--   0     1001      123     5607 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/kernels.rs
+-rw-r--r--   0     1001      123     1062 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/mod.rs
+-rw-r--r--   0     1001      123     7302 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs
+-rw-r--r--   0     1001      123     2582 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs
+-rw-r--r--   0     1001      123    10476 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs
+-rw-r--r--   0     1001      123      428 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/mod.rs
+-rw-r--r--   0     1001      123     7368 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs
+-rw-r--r--   0     1001      123     4143 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/time.rs
+-rw-r--r--   0     1001      123    21192 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs
+-rw-r--r--   0     1001      123    20108 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs
+-rw-r--r--   0     1001      123     4115 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs
+-rw-r--r--   0     1001      123     9692 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs
+-rw-r--r--   0     1001      123     2960 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/date_range.rs
+-rw-r--r--   0     1001      123    31306 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/groupby/dynamic.rs
+-rw-r--r--   0     1001      123       88 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/groupby/mod.rs
+-rw-r--r--   0     1001      123      535 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/lib.rs
+-rw-r--r--   0     1001      123      320 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/prelude.rs
+-rw-r--r--   0     1001      123     1568 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/round.rs
+-rw-r--r--   0     1001      123     4028 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/_trait.rs
+-rw-r--r--   0     1001      123      136 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/boolean.rs
+-rw-r--r--   0     1001      123      140 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/categoricals.rs
+-rw-r--r--   0     1001      123      133 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/date.rs
+-rw-r--r--   0     1001      123      137 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/datetime.rs
+-rw-r--r--   0     1001      123      137 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/duration.rs
+-rw-r--r--   0     1001      123     1863 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/floats.rs
+-rw-r--r--   0     1001      123     1792 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/integers.rs
+-rw-r--r--   0     1001      123      133 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/list.rs
+-rw-r--r--   0     1001      123      486 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/mod.rs
+-rw-r--r--   0     1001      123      155 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/object.rs
+-rw-r--r--   0     1001      123      135 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/struct_.rs
+-rw-r--r--   0     1001      123      133 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/time.rs
+-rw-r--r--   0     1001      123      133 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/utf8.rs
+-rw-r--r--   0     1001      123    12466 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/mod.rs
+-rw-r--r--   0     1001      123     1630 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/truncate.rs
+-rw-r--r--   0     1001      123     7059 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/upsample.rs
+-rw-r--r--   0     1001      123     2567 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/utils.rs
+-rw-r--r--   0     1001      123     1524 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/bounds.rs
+-rw-r--r--   0     1001      123     2008 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/calendar.rs
+-rw-r--r--   0     1001      123    23538 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/duration.rs
+-rw-r--r--   0     1001      123    20089 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/groupby.rs
+-rw-r--r--   0     1001      123      503 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/mod.rs
+-rw-r--r--   0     1001      123    24202 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/test.rs
+-rw-r--r--   0     1001      123    11624 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/window.rs
+-rw-r--r--   0        0        0     1411 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/LICENSE
+-rw-r--r--   0     1001      123     4012 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/README.md
+-rw-r--r--   0     1001      123     9096 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/assets/SQL.sublime-syntax
+-rw-r--r--   0     1001      123    21158 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/assets/theme
+-rw-r--r--   0     1001      123     1450 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/cli/highlighter.rs
+-rw-r--r--   0     1001      123     5052 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/cli/mod.rs
+-rw-r--r--   0     1001      123     1043 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/cli/prompt.rs
+-rw-r--r--   0     1001      123    14453 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/context.rs
+-rw-r--r--   0     1001      123    16610 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/functions.rs
+-rw-r--r--   0     1001      123    27444 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/lib.rs
+-rw-r--r--   0     1001      123      342 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/main.rs
+-rw-r--r--   0     1001      123    13269 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/sql_expr.rs
+-rw-r--r--   0     1001      123     3386 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/table_functions.rs
+-rw-r--r--   0        0        0      879 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-error/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-error/LICENSE
+-rw-r--r--   0     1001      123     6297 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-error/src/lib.rs
+-rw-r--r--   0        0        0     1780 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/LICENSE
+-rw-r--r--   0     1001      123       98 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/mod.rs
+-rw-r--r--   0     1001      123     1219 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/filter.rs
+-rw-r--r--   0     1001      123     4103 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/function.rs
+-rw-r--r--   0     1001      123      229 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/mod.rs
+-rw-r--r--   0     1001      123      548 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs
+-rw-r--r--   0     1001      123     3247 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/projection.rs
+-rw-r--r--   0     1001      123     2324 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/reproject.rs
+-rw-r--r--   0     1001      123     6479 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs
+-rw-r--r--   0     1001      123    10473 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs
+-rw-r--r--   0     1001      123     1207 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs
+-rw-r--r--   0     1001      123     1888 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs
+-rw-r--r--   0     1001      123     4554 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs
+-rw-r--r--   0     1001      123     1746 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs
+-rw-r--r--   0     1001      123     5413 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs
+-rw-r--r--   0     1001      123     4951 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs
+-rw-r--r--   0     1001      123      211 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mod.rs
+-rw-r--r--   0     1001      123      856 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs
+-rw-r--r--   0     1001      123     4294 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs
+-rw-r--r--   0     1001      123     3030 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs
+-rw-r--r--   0     1001      123     6275 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs
+-rw-r--r--   0     1001      123    13665 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs
+-rw-r--r--   0     1001      123     2681 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs
+-rw-r--r--   0     1001      123     2534 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs
+-rw-r--r--   0     1001      123     5961 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs
+-rw-r--r--   0     1001      123    10613 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs
+-rw-r--r--   0     1001      123     2164 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs
+-rw-r--r--   0     1001      123     4666 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs
+-rw-r--r--   0     1001      123     3906 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs
+-rw-r--r--   0     1001      123    20856 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs
+-rw-r--r--   0     1001      123    23518 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs
+-rw-r--r--   0     1001      123     2457 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs
+-rw-r--r--   0     1001      123     8395 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/io.rs
+-rw-r--r--   0     1001      123     5485 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs
+-rw-r--r--   0     1001      123    14279 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs
+-rw-r--r--   0     1001      123    11824 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs
+-rw-r--r--   0     1001      123      178 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/mod.rs
+-rw-r--r--   0     1001      123     2002 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/memory.rs
+-rw-r--r--   0     1001      123      589 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/mod.rs
+-rw-r--r--   0     1001      123     1492 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs
+-rw-r--r--   0     1001      123     1824 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs
+-rw-r--r--   0     1001      123     3108 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/slice.rs
+-rw-r--r--   0     1001      123      130 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/mod.rs
+-rw-r--r--   0     1001      123     3808 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs
+-rw-r--r--   0     1001      123     6295 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs
+-rw-r--r--   0     1001      123     5953 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs
+-rw-r--r--   0     1001      123     3801 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs
+-rw-r--r--   0     1001      123      635 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/utils.rs
+-rw-r--r--   0     1001      123     5076 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/csv.rs
+-rw-r--r--   0     1001      123     1231 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/frame.rs
+-rw-r--r--   0     1001      123      987 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs
+-rw-r--r--   0     1001      123      376 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/mod.rs
+-rw-r--r--   0     1001      123     3387 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/parquet.rs
+-rw-r--r--   0     1001      123     1146 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/reproject.rs
+-rw-r--r--   0     1001      123     1022 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/union.rs
+-rw-r--r--   0     1001      123      448 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/expressions.rs
+-rw-r--r--   0     1001      123      272 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/lib.rs
+-rw-r--r--   0     1001      123      719 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/chunks.rs
+-rw-r--r--   0     1001      123      474 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/context.rs
+-rw-r--r--   0     1001      123      223 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/mod.rs
+-rw-r--r--   0     1001      123      430 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/operator.rs
+-rw-r--r--   0     1001      123      626 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/sink.rs
+-rw-r--r--   0     1001      123      241 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/source.rs
+-rw-r--r--   0     1001      123        1 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/config.rs
+-rw-r--r--   0     1001      123    20488 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/convert.rs
+-rw-r--r--   0     1001      123    13982 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs
+-rw-r--r--   0     1001      123     1237 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/mod.rs
+-rw-r--r--   0        0        0     1431 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/LICENSE
+-rw-r--r--   0     1001      123     1975 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/default_arrays.rs
+-rw-r--r--   0     1001      123     3160 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/get.rs
+-rw-r--r--   0     1001      123     3277 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/list.rs
+-rw-r--r--   0     1001      123     7771 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/mod.rs
+-rw-r--r--   0     1001      123      878 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/null.rs
+-rw-r--r--   0     1001      123     1125 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/slice.rs
+-rw-r--r--   0     1001      123     1807 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/utf8.rs
+-rw-r--r--   0     1001      123     2294 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/bit_util.rs
+-rw-r--r--   0     1001      123       17 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/bitmap/mod.rs
+-rw-r--r--   0     1001      123      819 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/bitmap/mutable.rs
+-rw-r--r--   0     1001      123      232 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/compute/cast.rs
+-rw-r--r--   0     1001      123       56 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/compute/mod.rs
+-rw-r--r--   0     1001      123     2962 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/compute/take/boolean.rs
+-rw-r--r--   0     1001      123    24907 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/compute/take/mod.rs
+-rw-r--r--   0     1001      123     1042 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/conversion.rs
+-rw-r--r--   0     1001      123     1609 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/data_types.rs
+-rw-r--r--   0     1001      123       25 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/error.rs
+-rw-r--r--   0     1001      123       28 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/export.rs
+-rw-r--r--   0     1001      123       26 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/floats/mod.rs
+-rw-r--r--   0     1001      123     2066 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/floats/ord.rs
+-rw-r--r--   0     1001      123     1273 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/index.rs
+-rw-r--r--   0     1001      123      915 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/is_valid.rs
+-rw-r--r--   0     1001      123     4740 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/agg_mean.rs
+-rw-r--r--   0     1001      123     1015 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/concatenate.rs
+-rw-r--r--   0     1001      123     5161 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/ewm/average.rs
+-rw-r--r--   0     1001      123     1808 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs
+-rw-r--r--   0     1001      123    25065 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs
+-rw-r--r--   0     1001      123     1406 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/float.rs
+-rw-r--r--   0     1001      123     4907 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/list.rs
+-rw-r--r--   0     1001      123     1895 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs
+-rw-r--r--   0     1001      123     9731 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/mod.rs
+-rw-r--r--   0     1001      123     3703 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs
+-rw-r--r--   0     1001      123     2022 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs
+-rw-r--r--   0     1001      123    18684 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs
+-rw-r--r--   0     1001      123     3924 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs
+-rw-r--r--   0     1001      123    11659 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs
+-rw-r--r--   0     1001      123     5504 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs
+-rw-r--r--   0     1001      123     8683 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs
+-rw-r--r--   0     1001      123     1749 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs
+-rw-r--r--   0     1001      123    14367 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs
+-rw-r--r--   0     1001      123     9070 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs
+-rw-r--r--   0     1001      123    11609 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs
+-rw-r--r--   0     1001      123     4698 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs
+-rw-r--r--   0     1001      123     8335 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs
+-rw-r--r--   0     1001      123     8109 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/window.rs
+-rw-r--r--   0     1001      123     4752 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/set.rs
+-rw-r--r--   0     1001      123     4529 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sort_partition.rs
+-rw-r--r--   0     1001      123     2948 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs
+-rw-r--r--   0     1001      123     5974 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs
+-rw-r--r--   0     1001      123      231 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sorted_join/mod.rs
+-rw-r--r--   0     1001      123      841 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/string.rs
+-rw-r--r--   0     1001      123     4292 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/take_agg.rs
+-rw-r--r--   0     1001      123     4417 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/time.rs
+-rw-r--r--   0     1001      123      341 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/lib.rs
+-rw-r--r--   0     1001      123      434 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/prelude.rs
+-rw-r--r--   0     1001      123      534 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/slice.rs
+-rw-r--r--   0     1001      123      762 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/time_zone.rs
+-rw-r--r--   0     1001      123      998 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/boolean.rs
+-rw-r--r--   0     1001      123     2716 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/mod.rs
+-rw-r--r--   0     1001      123     2533 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs
+-rw-r--r--   0     1001      123      158 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/rev.rs
+-rw-r--r--   0     1001      123     5020 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/utils.rs
+-rw-r--r--   0        0        0      476 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/LICENSE
+-rw-r--r--   0     1001      123     2645 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/arena.rs
+-rw-r--r--   0     1001      123     1373 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/atomic.rs
+-rw-r--r--   0     1001      123     2659 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/cell.rs
+-rw-r--r--   0     1001      123     1015 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/contention_pool.rs
+-rw-r--r--   0     1001      123      509 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/error.rs
+-rw-r--r--   0     1001      123      271 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/fmt.rs
+-rw-r--r--   0     1001      123      763 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/functions.rs
+-rw-r--r--   0     1001      123      514 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/hash.rs
+-rw-r--r--   0     1001      123     2709 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/iter/enumerate_idx.rs
+-rw-r--r--   0     1001      123       61 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/iter/mod.rs
+-rw-r--r--   0     1001      123      583 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/lib.rs
+-rw-r--r--   0     1001      123      573 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/macros.rs
+-rw-r--r--   0     1001      123      282 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/mem.rs
+-rw-r--r--   0     1001      123     1792 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/slice.rs
+-rw-r--r--   0     1001      123     2467 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/sort.rs
+-rw-r--r--   0     1001      123     1114 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/sync.rs
+-rw-r--r--   0     1001      123      504 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/sys.rs
+-rw-r--r--   0     1001      123      697 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/unwrap.rs
+-rw-r--r--   0     1001      123      616 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/wasm.rs
+-rw-r--r--   0        0        0      940 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/LICENSE
+-rw-r--r--   0     1001      123     8985 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encode.rs
+-rw-r--r--   0     1001      123     4591 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encodings/fixed.rs
+-rw-r--r--   0     1001      123       47 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encodings/mod.rs
+-rw-r--r--   0     1001      123     4508 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encodings/variable.rs
+-rw-r--r--   0     1001      123    13678 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/lib.rs
+-rw-r--r--   0     1001      123     2079 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/row.rs
+-rw-r--r--   0     1001      123      682 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/utils.rs
+-rw-r--r--   0        0        0     4346 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/LICENSE
+-rw-r--r--   0     1001      123     2383 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/avro/mod.rs
+-rw-r--r--   0     1001      123     3604 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/avro/read.rs
+-rw-r--r--   0     1001      123     2622 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/avro/write.rs
+-rw-r--r--   0     1001      123     4505 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/cloud/adaptors.rs
+-rw-r--r--   0     1001      123     9506 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/cloud/glob.rs
+-rw-r--r--   0     1001      123     3089 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/cloud/mod.rs
+-rw-r--r--   0     1001      123    28675 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/buffer.rs
+-rw-r--r--   0     1001      123     1898 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/mod.rs
+-rw-r--r--   0     1001      123    19709 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/parser.rs
+-rw-r--r--   0     1001      123    21349 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read.rs
+-rw-r--r--   0     1001      123    10817 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs
+-rw-r--r--   0     1001      123    13909 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs
+-rw-r--r--   0     1001      123    31233 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read_impl/mod.rs
+-rw-r--r--   0     1001      123    11466 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/splitfields.rs
+-rw-r--r--   0     1001      123    25218 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/utils.rs
+-rw-r--r--   0     1001      123     2796 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/write.rs
+-rw-r--r--   0     1001      123    12866 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/write_impl.rs
+-rw-r--r--   0     1001      123      184 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/export.rs
+-rw-r--r--   0     1001      123     7580 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/ipc_file.rs
+-rw-r--r--   0     1001      123     9218 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/ipc_stream.rs
+-rw-r--r--   0     1001      123     3253 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/mmap.rs
+-rw-r--r--   0     1001      123      401 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/mod.rs
+-rw-r--r--   0     1001      123     8282 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/write.rs
+-rw-r--r--   0     1001      123     1471 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/write_async.rs
+-rw-r--r--   0     1001      123     9974 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/json.rs
+-rw-r--r--   0     1001      123     4879 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/lib.rs
+-rw-r--r--   0     1001      123     1969 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/mmap.rs
+-rw-r--r--   0     1001      123     7215 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ndjson_core/buffer.rs
+-rw-r--r--   0     1001      123       39 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ndjson_core/mod.rs
+-rw-r--r--   0     1001      123    12177 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ndjson_core/ndjson.rs
+-rw-r--r--   0     1001      123      273 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/options.rs
+-rw-r--r--   0     1001      123     7354 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/async_impl.rs
+-rw-r--r--   0     1001      123     3093 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/mmap.rs
+-rw-r--r--   0     1001      123     3132 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/mod.rs
+-rw-r--r--   0     1001      123     4790 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/predicates.rs
+-rw-r--r--   0     1001      123     9629 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/read.rs
+-rw-r--r--   0     1001      123    16886 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/read_impl.rs
+-rw-r--r--   0     1001      123    10106 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/write.rs
+-rw-r--r--   0     1001      123     5334 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/partition.rs
+-rw-r--r--   0     1001      123     1455 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/predicates.rs
+-rw-r--r--   0     1001      123      633 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/prelude.rs
+-rw-r--r--   0     1001      123      417 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/tests.rs
+-rw-r--r--   0     1001      123     4467 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/utils.rs
+-rw-r--r--   0        0        0     3268 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/LICENSE
+-rw-r--r--   0     1001      123      234 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/binary/mod.rs
+-rw-r--r--   0     1001      123     3549 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs
+-rw-r--r--   0     1001      123    11023 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/interpolate.rs
+-rw-r--r--   0     1001      123     1679 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/count.rs
+-rw-r--r--   0     1001      123     2452 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/hash.rs
+-rw-r--r--   0     1001      123     7861 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs
+-rw-r--r--   0     1001      123      511 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/mod.rs
+-rw-r--r--   0     1001      123    22005 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs
+-rw-r--r--   0     1001      123     5269 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs
+-rw-r--r--   0     1001      123     2435 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs
+-rw-r--r--   0     1001      123      489 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/mod.rs
+-rw-r--r--   0     1001      123     9380 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs
+-rw-r--r--   0     1001      123     6795 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/set.rs
+-rw-r--r--   0     1001      123     7490 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/case.rs
+-rw-r--r--   0     1001      123     8251 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs
+-rw-r--r--   0     1001      123     2345 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs
+-rw-r--r--   0     1001      123      514 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs
+-rw-r--r--   0     1001      123    14731 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs
+-rw-r--r--   0     1001      123     4053 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs
+-rw-r--r--   0     1001      123     2486 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/top_k.rs
+-rw-r--r--   0     1001      123     7727 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs
+-rw-r--r--   0     1001      123    18025 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/join/mod.rs
+-rw-r--r--   0     1001      123     4174 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/mod.rs
+-rw-r--r--   0     1001      123    10257 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/pivot/mod.rs
+-rw-r--r--   0     1001      123    13486 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/pivot/positioning.rs
+-rw-r--r--   0     1001      123      217 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/lib.rs
+-rw-r--r--   0     1001      123      290 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/prelude.rs
+-rw-r--r--   0     1001      123       25 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/mod.rs
+-rw-r--r--   0     1001      123     9623 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs
+-rw-r--r--   0     1001      123      118 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/approx_algo/mod.rs
+-rw-r--r--   0     1001      123     2016 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/approx_unique.rs
+-rw-r--r--   0     1001      123    11872 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs
+-rw-r--r--   0     1001      123     3680 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/floor_divide.rs
+-rw-r--r--   0     1001      123     3423 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/is_first.rs
+-rw-r--r--   0     1001      123     2975 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/is_unique.rs
+-rw-r--r--   0     1001      123     3626 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/log.rs
+-rw-r--r--   0     1001      123     1106 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/mod.rs
+-rw-r--r--   0     1001      123     1769 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/rolling.rs
+-rw-r--r--   0     1001      123     7642 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/search_sorted.rs
+-rw-r--r--   0     1001      123     2500 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/to_dummies.rs
+-rw-r--r--   0     1001      123     2067 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/various.rs
+-rw-r--r--   0        0        0    10472 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/LICENSE
+-rw-r--r--   0     1001      123     3276 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/Makefile
+-rw-r--r--   0     1001      123      215 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/build.rs
+-rw-r--r--   0     1001      123       78 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/clippy.toml
+-rw-r--r--   0     1001      123    17602 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/eager.rs
+-rw-r--r--   0     1001      123     8778 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/lazy.rs
+-rw-r--r--   0     1001      123       50 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/mod.rs
+-rw-r--r--   0     1001      123     3797 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/performance.rs
+-rw-r--r--   0     1001      123       59 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/export.rs
+-rw-r--r--   0     1001      123    20212 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/lib.rs
+-rw-r--r--   0     1001      123      387 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/prelude.rs
+-rw-r--r--   0     1001      123       32 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/src/sql.rs
+-rw-r--r--   0     1001      123     4272 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/date_like.rs
+-rw-r--r--   0     1001      123     2401 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/groupby.rs
+-rw-r--r--   0     1001      123    17826 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/joins.rs
+-rw-r--r--   0     1001      123      545 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/list.rs
+-rw-r--r--   0     1001      123      189 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/mod.rs
+-rw-r--r--   0     1001      123     6258 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/pivot.rs
+-rw-r--r--   0     1001      123     1102 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/random.rs
+-rw-r--r--   0     1001      123    10844 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/rolling_window.rs
+-rw-r--r--   0     1001      123     1093 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/series.rs
+-rw-r--r--   0     1001      123      370 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/utils.rs
+-rw-r--r--   0     1001      123    30142 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/csv.rs
+-rw-r--r--   0     1001      123     4490 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/ipc_stream.rs
+-rw-r--r--   0     1001      123     7044 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/json.rs
+-rw-r--r--   0     1001      123      378 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/mod.rs
+-rw-r--r--   0     1001      123      988 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/parquet.rs
+-rw-r--r--   0     1001      123     1530 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/joins.rs
+-rw-r--r--   0     1001      123     2452 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/aggregation.rs
+-rw-r--r--   0     1001      123      702 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/cse.rs
+-rw-r--r--   0     1001      123      500 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/explodes.rs
+-rw-r--r--   0     1001      123     2279 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/apply.rs
+-rw-r--r--   0     1001      123    10815 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/arity.rs
+-rw-r--r--   0     1001      123     1064 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/expand.rs
+-rw-r--r--   0     1001      123     1008 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/filter.rs
+-rw-r--r--   0     1001      123      428 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/is_in.rs
+-rw-r--r--   0     1001      123      121 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/mod.rs
+-rw-r--r--   0     1001      123      659 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/slice.rs
+-rw-r--r--   0     1001      123    10139 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/window.rs
+-rw-r--r--   0     1001      123      579 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/folds.rs
+-rw-r--r--   0     1001      123      557 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/functions.rs
+-rw-r--r--   0     1001      123     4482 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/groupby.rs
+-rw-r--r--   0     1001      123     1655 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs
+-rw-r--r--   0     1001      123      691 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/mod.rs
+-rw-r--r--   0     1001      123     5381 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/predicate_queries.rs
+-rw-r--r--   0     1001      123     4476 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/projection_queries.rs
+-rw-r--r--   0     1001      123     6444 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/queries.rs
+-rw-r--r--   0     1001      123      141 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/main.rs
+-rw-r--r--   0     1001      123      552 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/schema.rs
+-rw-r--r--   0        0        0     6007 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/LICENSE
+-rw-r--r--   0     1001      123     1796 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dot.rs
+-rw-r--r--   0     1001      123     4359 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/eval.rs
+-rw-r--r--   0     1001      123     4505 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/functions.rs
+-rw-r--r--   0     1001      123      164 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/into.rs
+-rw-r--r--   0     1001      123     6768 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/list.rs
+-rw-r--r--   0     1001      123     2899 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/mod.rs
+-rw-r--r--   0     1001      123     1182 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs
+-rw-r--r--   0     1001      123     9288 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/csv.rs
+-rw-r--r--   0     1001      123     4309 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/file_list_reader.rs
+-rw-r--r--   0     1001      123     2261 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/ipc.rs
+-rw-r--r--   0     1001      123    47120 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/mod.rs
+-rw-r--r--   0     1001      123     3414 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/ndjson.rs
+-rw-r--r--   0     1001      123     3440 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/parquet.rs
+-rw-r--r--   0     1001      123     2892 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/pivot.rs
+-rw-r--r--   0     1001      123      416 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/python.rs
+-rw-r--r--   0     1001      123     6376 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/lib.rs
+-rw-r--r--   0     1001      123     1049 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs
+-rw-r--r--   0     1001      123      776 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs
+-rw-r--r--   0     1001      123      670 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs
+-rw-r--r--   0     1001      123     1284 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs
+-rw-r--r--   0     1001      123     3908 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs
+-rw-r--r--   0     1001      123     3577 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs
+-rw-r--r--   0     1001      123    13439 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs
+-rw-r--r--   0     1001      123     4335 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs
+-rw-r--r--   0     1001      123     6058 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs
+-rw-r--r--   0     1001      123     7074 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs
+-rw-r--r--   0     1001      123     2045 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs
+-rw-r--r--   0     1001      123     1677 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs
+-rw-r--r--   0     1001      123     2986 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs
+-rw-r--r--   0     1001      123     1963 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs
+-rw-r--r--   0     1001      123     4184 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs
+-rw-r--r--   0     1001      123     1211 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs
+-rw-r--r--   0     1001      123     2421 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs
+-rw-r--r--   0     1001      123      548 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs
+-rw-r--r--   0     1001      123     2197 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs
+-rw-r--r--   0     1001      123     1922 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs
+-rw-r--r--   0     1001      123      663 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs
+-rw-r--r--   0     1001      123     3702 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs
+-rw-r--r--   0     1001      123      838 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs
+-rw-r--r--   0     1001      123     1284 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/exotic.rs
+-rw-r--r--   0     1001      123    21864 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs
+-rw-r--r--   0     1001      123     2689 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs
+-rw-r--r--   0     1001      123    17409 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs
+-rw-r--r--   0     1001      123    18847 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs
+-rw-r--r--   0     1001      123     3153 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs
+-rw-r--r--   0     1001      123     6326 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs
+-rw-r--r--   0     1001      123     2003 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs
+-rw-r--r--   0     1001      123     5804 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs
+-rw-r--r--   0     1001      123     3670 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs
+-rw-r--r--   0     1001      123     5304 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs
+-rw-r--r--   0     1001      123    21103 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs
+-rw-r--r--   0     1001      123    10091 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs
+-rw-r--r--   0     1001      123     3929 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs
+-rw-r--r--   0     1001      123    11541 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs
+-rw-r--r--   0     1001      123     8331 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs
+-rw-r--r--   0     1001      123    14345 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs
+-rw-r--r--   0     1001      123    31819 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs
+-rw-r--r--   0     1001      123     2044 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs
+-rw-r--r--   0     1001      123      419 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/mod.rs
+-rw-r--r--   0     1001      123     2005 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs
+-rw-r--r--   0     1001      123    27335 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs
+-rw-r--r--   0     1001      123    18867 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs
+-rw-r--r--   0     1001      123       87 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/planner/mod.rs
+-rw-r--r--   0     1001      123     9470 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/state.rs
+-rw-r--r--   0     1001      123    20901 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/streaming/convert.rs
+-rw-r--r--   0     1001      123      219 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/streaming/mod.rs
+-rw-r--r--   0     1001      123     3333 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs
+-rw-r--r--   0     1001      123      722 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/prelude.rs
+-rw-r--r--   0     1001      123    14990 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/aggregations.rs
+-rw-r--r--   0     1001      123     2339 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/arity.rs
+-rw-r--r--   0     1001      123     7031 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/cse.rs
+-rw-r--r--   0     1001      123    12749 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/io.rs
+-rw-r--r--   0     1001      123     4207 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/logical.rs
+-rw-r--r--   0     1001      123     4293 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/mod.rs
+-rw-r--r--   0     1001      123    14819 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/optimization_checks.rs
+-rw-r--r--   0     1001      123     6799 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/predicate_queries.rs
+-rw-r--r--   0     1001      123     3158 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/projection_queries.rs
+-rw-r--r--   0     1001      123    47907 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/queries.rs
+-rw-r--r--   0     1001      123     8358 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/streaming.rs
+-rw-r--r--   0     1001      123     2953 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/tpch.rs
+-rw-r--r--   0     1001      123     1033 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/utils.rs
+-rw-r--r--   0        0        0      823 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-algo/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-algo/LICENSE
+-rw-r--r--   0     1001      123     7265 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-algo/src/algo.rs
+-rw-r--r--   0     1001      123       88 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-algo/src/lib.rs
+-rw-r--r--   0     1001      123       28 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-algo/src/prelude.rs
+-rw-r--r--   0        0        0     5407 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/LICENSE
+-rw-r--r--   0     1001      123    19606 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/arithmetic.rs
+-rw-r--r--   0     1001      123     8679 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/bitwise.rs
+-rw-r--r--   0     1001      123     2298 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/binary.rs
+-rw-r--r--   0     1001      123     1207 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs
+-rw-r--r--   0     1001      123     1556 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/from.rs
+-rw-r--r--   0     1001      123    19782 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/list.rs
+-rw-r--r--   0     1001      123     8845 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/mod.rs
+-rw-r--r--   0     1001      123     1410 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs
+-rw-r--r--   0     1001      123     2291 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs
+-rw-r--r--   0     1001      123    13129 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/cast.rs
+-rw-r--r--   0     1001      123    48300 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs
+-rw-r--r--   0     1001      123     9463 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs
+-rw-r--r--   0     1001      123      551 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/drop.rs
+-rw-r--r--   0     1001      123      963 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/float.rs
+-rw-r--r--   0     1001      123     5150 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/from.rs
+-rw-r--r--   0     1001      123    38411 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs
+-rw-r--r--   0     1001      123     1395 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs
+-rw-r--r--   0     1001      123       28 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/par/mod.rs
+-rw-r--r--   0     1001      123     1129 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs
+-rw-r--r--   0     1001      123       21 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/kernels/mod.rs
+-rw-r--r--   0     1001      123     2986 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/kernels/take.rs
+-rw-r--r--   0     1001      123     7001 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/list/iterator.rs
+-rw-r--r--   0     1001      123     2802 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/list/mod.rs
+-rw-r--r--   0     1001      123    19456 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs
+-rw-r--r--   0     1001      123     3688 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs
+-rw-r--r--   0     1001      123     4270 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs
+-rw-r--r--   0     1001      123    10220 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs
+-rw-r--r--   0     1001      123     1400 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs
+-rw-r--r--   0     1001      123      358 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/full.rs
+-rw-r--r--   0     1001      123      192 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/mod.rs
+-rw-r--r--   0     1001      123     2731 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs
+-rw-r--r--   0     1001      123     2172 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs
+-rw-r--r--   0     1001      123      925 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs
+-rw-r--r--   0     1001      123     6453 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs
+-rw-r--r--   0     1001      123     1604 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/date.rs
+-rw-r--r--   0     1001      123     4105 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs
+-rw-r--r--   0     1001      123     4443 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs
+-rw-r--r--   0     1001      123     2434 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/duration.rs
+-rw-r--r--   0     1001      123     2549 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/mod.rs
+-rw-r--r--   0     1001      123      476 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/struct_/from.rs
+-rw-r--r--   0     1001      123    14266 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs
+-rw-r--r--   0     1001      123     1182 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/time.rs
+-rw-r--r--   0     1001      123    23609 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/mod.rs
+-rw-r--r--   0     1001      123     7200 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ndarray.rs
+-rw-r--r--   0     1001      123     4484 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/builder.rs
+-rw-r--r--   0     1001      123     1547 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs
+-rw-r--r--   0     1001      123     3124 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs
+-rw-r--r--   0     1001      123     7054 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs
+-rw-r--r--   0     1001      123     3410 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs
+-rw-r--r--   0     1001      123      137 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/is_valid.rs
+-rw-r--r--   0     1001      123     4419 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/iterator.rs
+-rw-r--r--   0     1001      123     4826 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/mod.rs
+-rw-r--r--   0     1001      123     2517 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/registry.rs
+-rw-r--r--   0     1001      123      272 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/abs.rs
+-rw-r--r--   0     1001      123    32120 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs
+-rw-r--r--   0     1001      123     9946 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs
+-rw-r--r--   0     1001      123     2875 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs
+-rw-r--r--   0     1001      123     9391 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs
+-rw-r--r--   0     1001      123     2365 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/append.rs
+-rw-r--r--   0     1001      123    27269 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/apply.rs
+-rw-r--r--   0     1001      123    12799 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs
+-rw-r--r--   0     1001      123     6295 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs
+-rw-r--r--   0     1001      123    11537 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs
+-rw-r--r--   0     1001      123     1737 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs
+-rw-r--r--   0     1001      123     4801 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs
+-rw-r--r--   0     1001      123     6264 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs
+-rw-r--r--   0     1001      123    24977 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/explode.rs
+-rw-r--r--   0     1001      123     8339 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/extend.rs
+-rw-r--r--   0     1001      123    13777 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs
+-rw-r--r--   0     1001      123     5308 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/filter.rs
+-rw-r--r--   0     1001      123     4436 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/full.rs
+-rw-r--r--   0     1001      123        1 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/interpolate.rs
+-rw-r--r--   0     1001      123    15089 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs
+-rw-r--r--   0     1001      123        1 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/len.rs
+-rw-r--r--   0     1001      123    22261 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/mod.rs
+-rw-r--r--   0     1001      123     2403 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs
+-rw-r--r--   0     1001      123      593 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs
+-rw-r--r--   0     1001      123     2585 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs
+-rw-r--r--   0     1001      123     1539 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs
+-rw-r--r--   0     1001      123    10234 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs
+-rw-r--r--   0     1001      123    12518 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/set.rs
+-rw-r--r--   0     1001      123     6151 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/shift.rs
+-rw-r--r--   0     1001      123     2299 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs
+-rw-r--r--   0     1001      123     5467 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs
+-rw-r--r--   0     1001      123     7430 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs
+-rw-r--r--   0     1001      123    30762 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs
+-rw-r--r--   0     1001      123      380 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/slice.rs
+-rw-r--r--   0     1001      123    20472 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs
+-rw-r--r--   0     1001      123     6630 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs
+-rw-r--r--   0     1001      123     1859 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs
+-rw-r--r--   0     1001      123    16256 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs
+-rw-r--r--   0     1001      123     5041 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs
+-rw-r--r--   0     1001      123     6064 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs
+-rw-r--r--   0     1001      123    11229 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs
+-rw-r--r--   0     1001      123    14620 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs
+-rw-r--r--   0     1001      123     7753 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/zip.rs
+-rw-r--r--   0     1001      123     9093 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/random.rs
+-rw-r--r--   0     1001      123     1959 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs
+-rw-r--r--   0     1001      123     2501 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/date.rs
+-rw-r--r--   0     1001      123    11998 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs
+-rw-r--r--   0     1001      123     3201 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs
+-rw-r--r--   0     1001      123      533 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs
+-rw-r--r--   0     1001      123     1592 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/time.rs
+-rw-r--r--   0     1001      123      872 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/to_vec.rs
+-rw-r--r--   0     1001      123     8113 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/trusted_len.rs
+-rw-r--r--   0     1001      123    25934 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs
+-rw-r--r--   0     1001      123     7689 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/cloud.rs
+-rw-r--r--   0     1001      123     1549 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/config.rs
+-rw-r--r--   0     1001      123     3946 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/_serde.rs
+-rw-r--r--   0     1001      123     2701 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/aliases.rs
+-rw-r--r--   0     1001      123    42068 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/any_value.rs
+-rw-r--r--   0     1001      123    11748 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/dtype.rs
+-rw-r--r--   0     1001      123     5532 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/field.rs
+-rw-r--r--   0     1001      123     7675 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/mod.rs
+-rw-r--r--   0     1001      123     2016 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/time_unit.rs
+-rw-r--r--   0     1001      123      118 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/mod.rs
+-rw-r--r--   0     1001      123      898 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs
+-rw-r--r--   0     1001      123      481 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_3.rs
+-rw-r--r--   0     1001      123      293 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_4.rs
+-rw-r--r--   0     1001      123      499 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_5.rs
+-rw-r--r--   0     1001      123      288 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_6.rs
+-rw-r--r--   0     1001      123     1071 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_7.rs
+-rw-r--r--   0     1001      123      819 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_8.rs
+-rw-r--r--   0     1001      123      596 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_9.rs
+-rw-r--r--   0     1001      123       43 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/mod.rs
+-rw-r--r--   0     1001      123       25 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/error.rs
+-rw-r--r--   0     1001      123      433 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/export.rs
+-rw-r--r--   0     1001      123    36116 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/fmt.rs
+-rw-r--r--   0     1001      123     5177 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/arithmetic.rs
+-rw-r--r--   0     1001      123     7874 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/asof_join/asof.rs
+-rw-r--r--   0     1001      123    33715 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/asof_join/groups.rs
+-rw-r--r--   0     1001      123     6561 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/asof_join/mod.rs
+-rw-r--r--   0     1001      123      559 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/chunks.rs
+-rw-r--r--   0     1001      123     5179 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/cross_join.rs
+-rw-r--r--   0     1001      123    16609 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/explode.rs
+-rw-r--r--   0     1001      123     1019 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/from.rs
+-rw-r--r--   0     1001      123    16518 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs
+-rw-r--r--   0     1001      123     7643 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs
+-rw-r--r--   0     1001      123    47356 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs
+-rw-r--r--   0     1001      123      218 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/expr.rs
+-rw-r--r--   0     1001      123    12291 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/hashing.rs
+-rw-r--r--   0     1001      123    14048 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/into_groups.rs
+-rw-r--r--   0     1001      123    39434 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/mod.rs
+-rw-r--r--   0     1001      123    10535 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/perfect.rs
+-rw-r--r--   0     1001      123    17027 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/proxy.rs
+-rw-r--r--   0     1001      123    18264 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/mod.rs
+-rw-r--r--   0     1001      123    22392 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs
+-rw-r--r--   0     1001      123     2413 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs
+-rw-r--r--   0     1001      123    16303 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs
+-rw-r--r--   0     1001      123     2953 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs
+-rw-r--r--   0     1001      123     6076 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs
+-rw-r--r--   0     1001      123     4247 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs
+-rw-r--r--   0     1001      123     3913 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs
+-rw-r--r--   0     1001      123    11583 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs
+-rw-r--r--   0     1001      123   124249 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/mod.rs
+-rw-r--r--   0     1001      123    27393 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/av_buffer.rs
+-rw-r--r--   0     1001      123     3732 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/dataframe.rs
+-rw-r--r--   0     1001      123     5950 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/mod.rs
+-rw-r--r--   0     1001      123     8795 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/transpose.rs
+-rw-r--r--   0     1001      123     2149 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/top_k.rs
+-rw-r--r--   0     1001      123     1388 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/upstream_traits.rs
+-rw-r--r--   0     1001      123    10935 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/functions.rs
+-rw-r--r--   0     1001      123     2149 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/fx.rs
+-rw-r--r--   0     1001      123     1503 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/identity.rs
+-rw-r--r--   0     1001      123      457 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/mod.rs
+-rw-r--r--   0     1001      123     2684 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/partition.rs
+-rw-r--r--   0     1001      123    17653 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/vector_hasher.rs
+-rw-r--r--   0     1001      123     1896 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/lib.rs
+-rw-r--r--   0     1001      123    15766 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/named_from.rs
+-rw-r--r--   0     1001      123     2411 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/prelude.rs
+-rw-r--r--   0     1001      123     8247 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/schema.rs
+-rw-r--r--   0     1001      123     4218 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/serde/chunked_array.rs
+-rw-r--r--   0     1001      123     6551 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/serde/mod.rs
+-rw-r--r--   0     1001      123     9929 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/serde/series.rs
+-rw-r--r--   0     1001      123    17701 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/any_value.rs
+-rw-r--r--   0     1001      123    28511 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs
+-rw-r--r--   0     1001      123      222 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/arithmetic/mod.rs
+-rw-r--r--   0     1001      123     3546 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/arithmetic/owned.rs
+-rw-r--r--   0     1001      123    13187 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/comparison.rs
+-rw-r--r--   0     1001      123    24386 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/from.rs
+-rw-r--r--   0     1001      123     9217 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/binary.rs
+-rw-r--r--   0     1001      123    10850 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/boolean.rs
+-rw-r--r--   0     1001      123    12938 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/categorical.rs
+-rw-r--r--   0     1001      123    17994 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/dates_time.rs
+-rw-r--r--   0     1001      123    15242 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/datetime.rs
+-rw-r--r--   0     1001      123     5718 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/decimal.rs
+-rw-r--r--   0     1001      123    15106 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/duration.rs
+-rw-r--r--   0     1001      123    14223 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/floats.rs
+-rw-r--r--   0     1001      123     6207 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/list.rs
+-rw-r--r--   0     1001      123    18305 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/mod.rs
+-rw-r--r--   0     1001      123     5246 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/null.rs
+-rw-r--r--   0     1001      123     7817 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/object.rs
+-rw-r--r--   0     1001      123    11029 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/struct_.rs
+-rw-r--r--   0     1001      123     9735 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/utf8.rs
+-rw-r--r--   0     1001      123     4257 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/into.rs
+-rw-r--r--   0     1001      123     6297 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/iterator.rs
+-rw-r--r--   0     1001      123    37171 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/mod.rs
+-rw-r--r--   0     1001      123      853 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/diff.rs
+-rw-r--r--   0     1001      123     5204 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/downcast.rs
+-rw-r--r--   0     1001      123     3601 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/ewm.rs
+-rw-r--r--   0     1001      123      413 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/extend.rs
+-rw-r--r--   0     1001      123      562 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/mod.rs
+-rw-r--r--   0     1001      123     5974 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/moment.rs
+-rw-r--r--   0     1001      123     2908 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/null.rs
+-rw-r--r--   0     1001      123     1347 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/pct_change.rs
+-rw-r--r--   0     1001      123     4247 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/round.rs
+-rw-r--r--   0     1001      123     5072 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/to_list.rs
+-rw-r--r--   0     1001      123     1476 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/unique.rs
+-rw-r--r--   0     1001      123    18263 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/series_trait.rs
+-rw-r--r--   0     1001      123     2840 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/unstable.rs
+-rw-r--r--   0     1001      123     8117 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/testing.rs
+-rw-r--r--   0     1001      123      508 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/tests.rs
+-rw-r--r--   0     1001      123    32703 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/utils/mod.rs
+-rw-r--r--   0     1001      123     1181 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/utils/series.rs
+-rw-r--r--   0     1001      123    13773 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/utils/supertype.rs
+-rw-r--r--   0        0        0     5256 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/LICENSE
+-rw-r--r--   0     1001      123       45 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/constants.rs
+-rw-r--r--   0     1001      123    17253 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dot.rs
+-rw-r--r--   0     1001      123     4171 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/arithmetic.rs
+-rw-r--r--   0     1001      123      935 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/binary.rs
+-rw-r--r--   0     1001      123      650 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/cat.rs
+-rw-r--r--   0     1001      123     9424 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/dt.rs
+-rw-r--r--   0     1001      123    13169 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/expr.rs
+-rw-r--r--   0     1001      123      753 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/from.rs
+-rw-r--r--   0     1001      123       85 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/abs.rs
+-rw-r--r--   0     1001      123     1431 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs
+-rw-r--r--   0     1001      123     1327 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs
+-rw-r--r--   0     1001      123     4221 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs
+-rw-r--r--   0     1001      123     1910 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs
+-rw-r--r--   0     1001      123     1216 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs
+-rw-r--r--   0     1001      123      344 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/clip.rs
+-rw-r--r--   0     1001      123     1593 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs
+-rw-r--r--   0     1001      123    13227 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs
+-rw-r--r--   0     1001      123      810 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs
+-rw-r--r--   0     1001      123     1364 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs
+-rw-r--r--   0     1001      123     8119 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/list.rs
+-rw-r--r--   0     1001      123      581 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/log.rs
+-rw-r--r--   0     1001      123    19145 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs
+-rw-r--r--   0     1001      123      462 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/nan.rs
+-rw-r--r--   0     1001      123     3132 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs
+-rw-r--r--   0     1001      123      152 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/rolling.rs
+-rw-r--r--   0     1001      123      260 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/round.rs
+-rw-r--r--   0     1001      123      200 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/row_hash.rs
+-rw-r--r--   0     1001      123    13066 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs
+-rw-r--r--   0     1001      123      306 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/search_sorted.rs
+-rw-r--r--   0     1001      123     3812 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs
+-rw-r--r--   0     1001      123     1238 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs
+-rw-r--r--   0     1001      123      972 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs
+-rw-r--r--   0     1001      123    19590 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs
+-rw-r--r--   0     1001      123     1017 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs
+-rw-r--r--   0     1001      123     2195 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs
+-rw-r--r--   0     1001      123     5122 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs
+-rw-r--r--   0     1001      123      170 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/unique.rs
+-rw-r--r--   0     1001      123    42498 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/functions.rs
+-rw-r--r--   0     1001      123    10196 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/list.rs
+-rw-r--r--   0     1001      123     2181 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/meta.rs
+-rw-r--r--   0     1001      123    64804 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/mod.rs
+-rw-r--r--   0     1001      123       40 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/names.rs
+-rw-r--r--   0     1001      123     2094 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/options.rs
+-rw-r--r--   0     1001      123    14993 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/string.rs
+-rw-r--r--   0     1001      123     2715 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/struct_.rs
+-rw-r--r--   0     1001      123       38 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/frame/mod.rs
+-rw-r--r--   0     1001      123      933 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/frame/opt_state.rs
+-rw-r--r--   0     1001      123      466 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/global.rs
+-rw-r--r--   0     1001      123      175 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/lib.rs
+-rw-r--r--   0     1001      123     6825 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs
+-rw-r--r--   0     1001      123    11393 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs
+-rw-r--r--   0     1001      123    25701 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/alp.rs
+-rw-r--r--   0     1001      123     1622 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs
+-rw-r--r--   0     1001      123     1428 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/apply.rs
+-rw-r--r--   0     1001      123    25056 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/builder.rs
+-rw-r--r--   0     1001      123    29662 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/conversion.rs
+-rw-r--r--   0     1001      123      301 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/debug.rs
+-rw-r--r--   0     1001      123    15196 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/format.rs
+-rw-r--r--   0     1001      123      895 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs
+-rw-r--r--   0     1001      123      137 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/explode.rs
+-rw-r--r--   0     1001      123     1169 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs
+-rw-r--r--   0     1001      123    12019 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs
+-rw-r--r--   0     1001      123     1330 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs
+-rw-r--r--   0     1001      123     9752 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/iterator.rs
+-rw-r--r--   0     1001      123    10463 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/lit.rs
+-rw-r--r--   0     1001      123     8148 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/mod.rs
+-rw-r--r--   0     1001      123     7416 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs
+-rw-r--r--   0     1001      123    15287 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs
+-rw-r--r--   0     1001      123     3260 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs
+-rw-r--r--   0     1001      123     3236 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs
+-rw-r--r--   0     1001      123     3994 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs
+-rw-r--r--   0     1001      123    14494 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs
+-rw-r--r--   0     1001      123     1556 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs
+-rw-r--r--   0     1001      123     6715 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs
+-rw-r--r--   0     1001      123     1222 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs
+-rw-r--r--   0     1001      123    28281 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs
+-rw-r--r--   0     1001      123     2571 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs
+-rw-r--r--   0     1001      123    15130 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs
+-rw-r--r--   0     1001      123     1755 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs
+-rw-r--r--   0     1001      123     3930 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs
+-rw-r--r--   0     1001      123     1799 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs
+-rw-r--r--   0     1001      123     3269 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs
+-rw-r--r--   0     1001      123     2638 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs
+-rw-r--r--   0     1001      123    15747 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs
+-rw-r--r--   0     1001      123    26507 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs
+-rw-r--r--   0     1001      123     2692 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs
+-rw-r--r--   0     1001      123     2639 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs
+-rw-r--r--   0     1001      123     3501 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs
+-rw-r--r--   0     1001      123    27332 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs
+-rw-r--r--   0     1001      123     3492 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs
+-rw-r--r--   0     1001      123    13850 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs
+-rw-r--r--   0     1001      123     3161 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs
+-rw-r--r--   0     1001      123     9725 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs
+-rw-r--r--   0     1001      123    19819 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs
+-rw-r--r--   0     1001      123    10197 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/options.rs
+-rw-r--r--   0     1001      123    15273 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/projection.rs
+-rw-r--r--   0     1001      123     4615 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs
+-rw-r--r--   0     1001      123    13048 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/schema.rs
+-rw-r--r--   0     1001      123      809 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/prelude.rs
+-rw-r--r--   0     1001      123    11955 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/utils.rs
+-rw-r--r--   0        0        0     4403 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/Cargo.toml
+-rw-r--r--   0     1001      123       76 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/.gitignore
+-rw-r--r--   0     1001      123     1055 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/LICENSE
+-rw-r--r--   0     1001      123     2414 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/Makefile
+-rw-r--r--   0     1001      123    10844 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/README.md
+-rw-r--r--   0     1001      123      651 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/build.rs
+-rw-r--r--   0     1001      123       32 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/.gitignore
+-rw-r--r--   0     1001      123      679 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/Makefile
+-rw-r--r--   0     1001      123      318 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/api_redirect.html
+-rw-r--r--   0     1001      123      151 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/autosummary/accessor.rst
+-rw-r--r--   0     1001      123      160 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/autosummary/accessor_attribute.rst
+-rw-r--r--   0     1001      123      168 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/autosummary/accessor_callable.rst
+-rw-r--r--   0     1001      123      157 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/autosummary/accessor_method.rst
+-rw-r--r--   0     1001      123      836 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/autosummary/class.rst
+-rw-r--r--   0     1001      123       94 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/autosummary/class_without_autosummary.rst
+-rw-r--r--   0     1001      123      406 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/_templates/sidebar-nav-bs.html
+-rw-r--r--   0     1001      123      450 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/requirements-docs.txt
+-rw-r--r--   0     1001      123     1567 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/_static/css/custom.css
+-rw-r--r--   0     1001      123     7302 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/conf.py
+-rw-r--r--   0     1001      123       51 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/index.rst
+-rw-r--r--   0     1001      123     6767 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/api.rst
+-rw-r--r--   0     1001      123     1339 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/config.rst
+-rw-r--r--   0     1001      123      274 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/aggregation.rst
+-rw-r--r--   0     1001      123      221 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/attributes.rst
+-rw-r--r--   0     1001      123      142 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/computation.rst
+-rw-r--r--   0     1001      123      319 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/descriptive.rst
+-rw-r--r--   0     1001      123      319 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/export.rst
+-rw-r--r--   0     1001      123      464 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/groupby.rst
+-rw-r--r--   0     1001      123      379 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/index.rst
+-rw-r--r--   0     1001      123      189 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/miscellaneous.rst
+-rw-r--r--   0     1001      123     1513 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/dataframe/modify_select.rst
+-rw-r--r--   0     1001      123      663 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/datatypes.rst
+-rw-r--r--   0     1001      123      421 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/exceptions.rst
+-rw-r--r--   0     1001      123      391 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/aggregation.rst
+-rw-r--r--   0     1001      123      309 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/binary.rst
+-rw-r--r--   0     1001      123      338 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/boolean.rst
+-rw-r--r--   0     1001      123      237 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/categories.rst
+-rw-r--r--   0     1001      123      221 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/columns.rst
+-rw-r--r--   0     1001      123     1061 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/computation.rst
+-rw-r--r--   0     1001      123     1114 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/functions.rst
+-rw-r--r--   0     1001      123      461 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/index.rst
+-rw-r--r--   0     1001      123      695 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/list.rst
+-rw-r--r--   0     1001      123      374 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/meta.rst
+-rw-r--r--   0     1001      123      125 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/miscellaneous.rst
+-rw-r--r--   0     1001      123      977 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/modify_select.rst
+-rw-r--r--   0     1001      123      639 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/operators.rst
+-rw-r--r--   0     1001      123      860 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/string.rst
+-rw-r--r--   0     1001      123      254 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/struct.rst
+-rw-r--r--   0     1001      123      968 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/temporal.rst
+-rw-r--r--   0     1001      123       98 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/expressions/window.rst
+-rw-r--r--   0     1001      123      692 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/functions.rst
+-rw-r--r--   0     1001      123      392 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/index.rst
+-rw-r--r--   0     1001      123     1269 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/io.rst
+-rw-r--r--   0     1001      123      252 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/aggregation.rst
+-rw-r--r--   0     1001      123      179 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/attributes.rst
+-rw-r--r--   0     1001      123      146 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/descriptive.rst
+-rw-r--r--   0     1001      123      497 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/groupby.rst
+-rw-r--r--   0     1001      123      354 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/index.rst
+-rw-r--r--   0     1001      123      455 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/miscellaneous.rst
+-rw-r--r--   0     1001      123      988 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/modify_select.rst
+-rw-r--r--   0     1001      123      339 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/aggregation.rst
+-rw-r--r--   0     1001      123      256 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/attributes.rst
+-rw-r--r--   0     1001      123      321 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/binary.rst
+-rw-r--r--   0     1001      123      117 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/boolean.rst
+-rw-r--r--   0     1001      123      241 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/categories.rst
+-rw-r--r--   0     1001      123     1103 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/computation.rst
+-rw-r--r--   0     1001      123      722 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/descriptive.rst
+-rw-r--r--   0     1001      123      240 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/export.rst
+-rw-r--r--   0     1001      123      428 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/index.rst
+-rw-r--r--   0     1001      123      749 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/list.rst
+-rw-r--r--   0     1001      123      236 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/miscellaneous.rst
+-rw-r--r--   0     1001      123     1077 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/modify_select.rst
+-rw-r--r--   0     1001      123      922 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/string.rst
+-rw-r--r--   0     1001      123      396 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/struct.rst
+-rw-r--r--   0     1001      123     1118 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/series/temporal.rst
+-rw-r--r--   0     1001      123      302 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/sql.rst
+-rw-r--r--   0     1001      123      647 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/testing.rst
+-rw-r--r--   0     1001      123      168 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/docs/source/reference/utils.rst
+-rw-r--r--   0     1001      123     6283 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/__init__.py
+-rw-r--r--   0     1001      123    13396 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/api.py
+-rw-r--r--   0     1001      123    24553 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/config.py
+-rw-r--r--   0     1001      123    25409 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/convert.py
+-rw-r--r--   0     1001      123       77 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/dataframe/__init__.py
+-rw-r--r--   0     1001      123     5057 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/dataframe/_html.py
+-rw-r--r--   0     1001      123   303363 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/dataframe/frame.py
+-rw-r--r--   0     1001      123    33240 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/dataframe/groupby.py
+-rw-r--r--   0     1001      123     2588 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/datatypes/__init__.py
+-rw-r--r--   0     1001      123    11189 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/datatypes/classes.py
+-rw-r--r--   0     1001      123     1541 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/datatypes/constants.py
+-rw-r--r--   0     1001      123     4430 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/datatypes/constructor.py
+-rw-r--r--   0     1001      123    12688 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/datatypes/convert.py
+-rw-r--r--   0     1001      123     7338 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/dependencies.py
+-rw-r--r--   0     1001      123     2954 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/exceptions.py
+-rw-r--r--   0     1001      123       61 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/__init__.py
+-rw-r--r--   0     1001      123     2730 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/binary.py
+-rw-r--r--   0     1001      123     1708 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/categorical.py
+-rw-r--r--   0     1001      123    69359 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/datetime.py
+-rw-r--r--   0     1001      123   251184 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/expr.py
+-rw-r--r--   0     1001      123    22899 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/list.py
+-rw-r--r--   0     1001      123     2059 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/meta.py
+-rw-r--r--   0     1001      123    44707 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/string.py
+-rw-r--r--   0     1001      123     5436 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/expr/struct.py
+-rw-r--r--   0     1001      123     1981 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/functions/__init__.py
+-rw-r--r--   0     1001      123    29688 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/functions/eager.py
+-rw-r--r--   0     1001      123    90019 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/functions/lazy.py
+-rw-r--r--   0     1001      123     6293 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/functions/whenthen.py
+-rw-r--r--   0     1001      123      280 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/internals.py
+-rw-r--r--   0     1001      123      978 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/__init__.py
+-rw-r--r--   0     1001      123     6264 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/_utils.py
+-rw-r--r--   0     1001      123      878 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/avro.py
+-rw-r--r--   0     1001      123      144 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/csv/__init__.py
+-rw-r--r--   0     1001      123     1082 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/csv/_utils.py
+-rw-r--r--   0     1001      123     4691 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/csv/batched_reader.py
+-rw-r--r--   0     1001      123    35533 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/csv/functions.py
+-rw-r--r--   0     1001      123     8655 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/database.py
+-rw-r--r--   0     1001      123    10988 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/delta.py
+-rw-r--r--   0     1001      123       75 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/excel/__init__.py
+-rw-r--r--   0     1001      123    18459 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/excel/_write_utils.py
+-rw-r--r--   0     1001      123     5309 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/excel/functions.py
+-rw-r--r--   0     1001      123      142 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/ipc/__init__.py
+-rw-r--r--   0     1001      123     1271 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/ipc/anonymous_scan.py
+-rw-r--r--   0     1001      123     5840 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/ipc/functions.py
+-rw-r--r--   0     1001      123      519 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/json.py
+-rw-r--r--   0     1001      123     2257 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/ndjson.py
+-rw-r--r--   0     1001      123      170 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/parquet/__init__.py
+-rw-r--r--   0     1001      123     1299 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/parquet/anonymous_scan.py
+-rw-r--r--   0     1001      123     7212 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/parquet/functions.py
+-rw-r--r--   0     1001      123      136 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/pyarrow_dataset/__init__.py
+-rw-r--r--   0     1001      123     2331 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/pyarrow_dataset/anonymous_scan.py
+-rw-r--r--   0     1001      123     3611 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/io/pyarrow_dataset/functions.py
+-rw-r--r--   0     1001      123       77 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/lazyframe/__init__.py
+-rw-r--r--   0     1001      123   166918 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/lazyframe/frame.py
+-rw-r--r--   0     1001      123    24010 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/lazyframe/groupby.py
+-rw-r--r--   0     1001      123        0 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/py.typed
+-rw-r--r--   0     1001      123       69 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/__init__.py
+-rw-r--r--   0     1001      123     1579 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/_numpy.py
+-rw-r--r--   0     1001      123     1920 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/binary.py
+-rw-r--r--   0     1001      123     1699 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/categorical.py
+-rw-r--r--   0     1001      123    47287 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/datetime.py
+-rw-r--r--   0     1001      123    12385 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/list.py
+-rw-r--r--   0     1001      123   162618 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/series.py
+-rw-r--r--   0     1001      123    27401 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/string.py
+-rw-r--r--   0     1001      123     2287 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/struct.py
+-rw-r--r--   0     1001      123     5375 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/series/utils.py
+-rw-r--r--   0     1001      123     7638 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/slice.py
+-rw-r--r--   0     1001      123       75 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/sql/__init__.py
+-rw-r--r--   0     1001      123     1351 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/sql/context.py
+-rw-r--r--   0     1001      123     4764 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/string_cache.py
+-rw-r--r--   0     1001      123      362 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/__init__.py
+-rw-r--r--   0     1001      123      929 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/_private.py
+-rw-r--r--   0     1001      123     3689 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/_tempdir.py
+-rw-r--r--   0     1001      123    13597 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/asserts.py
+-rw-r--r--   0     1001      123     1380 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/parametric/__init__.py
+-rw-r--r--   0     1001      123    23137 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/parametric/primitives.py
+-rw-r--r--   0     1001      123     2811 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/testing/parametric/strategies.py
+-rw-r--r--   0     1001      123     5681 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/type_aliases.py
+-rw-r--r--   0     1001      123     1167 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/__init__.py
+-rw-r--r--   0     1001      123    50687 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/_construction.py
+-rw-r--r--   0     1001      123     2782 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/_parse_expr_input.py
+-rw-r--r--   0     1001      123      721 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/_scan.py
+-rw-r--r--   0     1001      123      687 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/_wrap.py
+-rw-r--r--   0     1001      123      683 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/build_info.py
+-rw-r--r--   0     1001      123     9483 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/convert.py
+-rw-r--r--   0     1001      123     5789 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/decorators.py
+-rw-r--r--   0     1001      123     1660 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/meta.py
+-rw-r--r--   0     1001      123      514 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/polars_version.py
+-rw-r--r--   0     1001      123     2339 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/show_versions.py
+-rw-r--r--   0     1001      123    11592 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/polars/utils/various.py
+-rw-r--r--   0     1001      123     5325 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/pyproject.toml
+-rw-r--r--   0     1001      123      699 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/requirements-dev.txt
+-rw-r--r--   0     1001      123       70 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/requirements-lint.txt
+-rw-r--r--   0     1001      123     1640 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/scripts/check_stacklevels.py
+-rw-r--r--   0     1001      123    10959 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/apply/dataframe.rs
+-rw-r--r--   0     1001      123     8388 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/apply/mod.rs
+-rw-r--r--   0     1001      123    71436 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/apply/series.rs
+-rw-r--r--   0     1001      123       32 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/arrow_interop/mod.rs
+-rw-r--r--   0     1001      123     1306 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/arrow_interop/to_py.rs
+-rw-r--r--   0     1001      123     3906 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/arrow_interop/to_rust.rs
+-rw-r--r--   0     1001      123     5214 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/batched_csv.rs
+-rw-r--r--   0     1001      123    47168 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/conversion.rs
+-rw-r--r--   0     1001      123    45433 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/dataframe.rs
+-rw-r--r--   0     1001      123     3799 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/datatypes.rs
+-rw-r--r--   0     1001      123     3288 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/error.rs
+-rw-r--r--   0     1001      123     9482 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/file.rs
+-rw-r--r--   0     1001      123     7468 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lazy/apply.rs
+-rw-r--r--   0     1001      123    33479 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lazy/dataframe.rs
+-rw-r--r--   0     1001      123    62595 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lazy/dsl.rs
+-rw-r--r--   0     1001      123     1082 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lazy/meta.rs
+-rw-r--r--   0     1001      123      727 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lazy/mod.rs
+-rw-r--r--   0     1001      123      212 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lazy/utils.rs
+-rw-r--r--   0     1001      123    21002 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/lib.rs
+-rw-r--r--   0     1001      123     7902 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/npy.rs
+-rw-r--r--   0     1001      123     1029 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/object.rs
+-rw-r--r--   0     1001      123      122 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/prelude.rs
+-rw-r--r--   0     1001      123      435 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/py_modules.rs
+-rw-r--r--   0     1001      123    54504 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/series.rs
+-rw-r--r--   0     1001      123     3478 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/set.rs
+-rw-r--r--   0     1001      123      843 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/sql.rs
+-rw-r--r--   0     1001      123     2335 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/src/utils.rs
+-rw-r--r--   0     1001      123     6165 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/README.md
+-rw-r--r--   0     1001      123     2189 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/benchmark/groupby-datagen.R
+-rw-r--r--   0     1001      123     7945 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/benchmark/run_h2oai_benchmark.py
+-rw-r--r--   0     1001      123     5018 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/benchmark/test_release.py
+-rw-r--r--   0     1001      123     4589 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/docs/run_doctest.py
+-rw-r--r--   0     1001      123     3707 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/parametric/test_dataframe.py
+-rw-r--r--   0     1001      123     1692 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/parametric/test_lazyframe.py
+-rw-r--r--   0     1001      123     5709 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/parametric/test_series.py
+-rw-r--r--   0     1001      123     7395 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/parametric/test_testing.py
+-rw-r--r--   0     1001      123        0 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/__init__.py
+-rw-r--r--   0     1001      123     3382 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/conftest.py
+-rw-r--r--   0     1001      123       86 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/__init__.py
+-rw-r--r--   0     1001      123      351 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_binary.py
+-rw-r--r--   0     1001      123     1420 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_bool.py
+-rw-r--r--   0     1001      123    11514 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_categorical.py
+-rw-r--r--   0     1001      123     2766 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_decimal.py
+-rw-r--r--   0     1001      123      280 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_duration.py
+-rw-r--r--   0     1001      123    14355 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_list.py
+-rw-r--r--   0     1001      123      284 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_null.py
+-rw-r--r--   0     1001      123     2801 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_object.py
+-rw-r--r--   0     1001      123    28043 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_struct.py
+-rw-r--r--   0     1001      123    91453 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/datatypes/test_temporal.py
+-rw-r--r--   0     1001      123      218 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/conftest.py
+-rw-r--r--   0     1001      123       16 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/.part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet.crc
+-rw-r--r--   0     1001      123       16 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/.part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet.crc
+-rw-r--r--   0     1001      123       16 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/_delta_log/.00000000000000000000.json.crc
+-rw-r--r--   0     1001      123       16 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/_delta_log/.00000000000000000001.json.crc
+-rw-r--r--   0     1001      123      905 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json
+-rw-r--r--   0     1001      123      936 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json
+-rw-r--r--   0     1001      123      972 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet
+-rw-r--r--   0     1001      123      690 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet
+-rw-r--r--   0     1001      123        0 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/empty.csv
+-rw-r--r--   0     1001      123     5959 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/example.xlsx
+-rw-r--r--   0     1001      123      457 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.csv
+-rw-r--r--   0     1001      123     2351 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.ipc
+-rw-r--r--   0     1001      123     1713 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.ndjson
+-rw-r--r--   0     1001      123     1427 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.parquet
+-rw-r--r--   0     1001      123      455 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.csv
+-rw-r--r--   0     1001      123     2351 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.ipc
+-rw-r--r--   0     1001      123     1711 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.ndjson
+-rw-r--r--   0     1001      123     1916 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.parquet
+-rw-r--r--   0     1001      123      455 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods3.csv
+-rw-r--r--   0     1001      123      457 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods4.csv
+-rw-r--r--   0     1001      123      452 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/foods5.csv
+-rw-r--r--   0     1001      123       49 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/gzipped.csv
+-rw-r--r--   0     1001      123       57 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/small.csv
+-rw-r--r--   0     1001      123      756 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/files/small.parquet
+-rw-r--r--   0     1001      123     1937 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_avro.py
+-rw-r--r--   0     1001      123    39029 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_csv.py
+-rw-r--r--   0     1001      123     6360 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_database.py
+-rw-r--r--   0     1001      123     3456 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_delta.py
+-rw-r--r--   0     1001      123    11067 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_excel.py
+-rw-r--r--   0     1001      123     5919 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_ipc.py
+-rw-r--r--   0     1001      123     3391 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_json.py
+-rw-r--r--   0     1001      123     6849 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_csv.py
+-rw-r--r--   0     1001      123     2060 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_ipc.py
+-rw-r--r--   0     1001      123     2881 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_json.py
+-rw-r--r--   0     1001      123    11849 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_parquet.py
+-rw-r--r--   0     1001      123     2012 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_other.py
+-rw-r--r--   0     1001      123    13315 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_parquet.py
+-rw-r--r--   0     1001      123      612 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_pickle.py
+-rw-r--r--   0     1001      123     3259 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/io/test_pyarrow_dataset.py
+-rw-r--r--   0     1001      123      509 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/__init__.py
+-rw-r--r--   0     1001      123     3218 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_binary.py
+-rw-r--r--   0     1001      123     2489 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_categorical.py
+-rw-r--r--   0     1001      123    13578 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_datetime.py
+-rw-r--r--   0     1001      123    12750 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_list.py
+-rw-r--r--   0     1001      123     1748 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_meta.py
+-rw-r--r--   0     1001      123    23698 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_string.py
+-rw-r--r--   0     1001      123    15767 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_strptime.py
+-rw-r--r--   0     1001      123      982 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/namespaces/test_struct.py
+-rw-r--r--   0     1001      123       85 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/__init__.py
+-rw-r--r--   0     1001      123     5851 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_aggregations.py
+-rw-r--r--   0     1001      123     9412 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_apply.py
+-rw-r--r--   0     1001      123     4390 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_arithmetic.py
+-rw-r--r--   0     1001      123      956 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_comparison.py
+-rw-r--r--   0     1001      123     2906 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_drop.py
+-rw-r--r--   0     1001      123     7840 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_explode.py
+-rw-r--r--   0     1001      123     3908 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_filter.py
+-rw-r--r--   0     1001      123     1801 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_folds.py
+-rw-r--r--   0     1001      123    22696 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_groupby.py
+-rw-r--r--   0     1001      123    16263 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_join.py
+-rw-r--r--   0     1001      123    10467 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_join_asof.py
+-rw-r--r--   0     1001      123      643 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_melt.py
+-rw-r--r--   0     1001      123    10253 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_pivot.py
+-rw-r--r--   0     1001      123    18639 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_rolling.py
+-rw-r--r--   0     1001      123    19140 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_sort.py
+-rw-r--r--   0     1001      123     3643 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_statistics.py
+-rw-r--r--   0     1001      123     3631 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_transpose.py
+-rw-r--r--   0     1001      123      771 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_unique.py
+-rw-r--r--   0     1001      123     9814 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/operations/test_window.py
+-rw-r--r--   0     1001      123     4775 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_api.py
+-rw-r--r--   0     1001      123     1077 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_arity.py
+-rw-r--r--   0     1001      123    19908 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_cfg.py
+-rw-r--r--   0     1001      123    38697 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_constructors.py
+-rw-r--r--   0     1001      123      454 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_context.py
+-rw-r--r--   0     1001      123     1628 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_cse.py
+-rw-r--r--   0     1001      123     3497 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_datatypes.py
+-rw-r--r--   0     1001      123   120351 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_df.py
+-rw-r--r--   0     1001      123     1009 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_empty.py
+-rw-r--r--   0     1001      123    15839 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_errors.py
+-rw-r--r--   0     1001      123     2387 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_expr_multi_cols.py
+-rw-r--r--   0     1001      123    32643 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_exprs.py
+-rw-r--r--   0     1001      123     3305 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_fmt.py
+-rw-r--r--   0     1001      123    11301 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_functions.py
+-rw-r--r--   0     1001      123     3763 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_interchange.py
+-rw-r--r--   0     1001      123    32596 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_interop.py
+-rw-r--r--   0     1001      123    49534 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_lazy.py
+-rw-r--r--   0     1001      123     2369 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_polars_import.py
+-rw-r--r--   0     1001      123     4014 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_predicates.py
+-rw-r--r--   0     1001      123     6995 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_projections.py
+-rw-r--r--   0     1001      123    11550 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_queries.py
+-rw-r--r--   0     1001      123     4743 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_rows.py
+-rw-r--r--   0     1001      123    10976 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_schema.py
+-rw-r--r--   0     1001      123     2441 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_serde.py
+-rw-r--r--   0     1001      123    83973 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_series.py
+-rw-r--r--   0     1001      123     2561 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_sql.py
+-rw-r--r--   0     1001      123    13877 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_streaming.py
+-rw-r--r--   0     1001      123    10700 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/test_testing.py
+-rw-r--r--   0     1001      123       41 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/utils/__init__.py
+-rw-r--r--   0     1001      123      306 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/utils/test_build_info.py
+-rw-r--r--   0     1001      123      247 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/utils/test_show_versions.py
+-rw-r--r--   0     1001      123     4307 2023-04-15 18:45:31.000000 polars_lts_cpu-0.17.3/tests/unit/utils/test_utils.py
+-rw-r--r--   0     1001      123    64028 2023-04-15 18:46:31.000000 polars_lts_cpu-0.17.3/Cargo.lock
+-rw-r--r--   0        0        0    13382 1970-01-01 00:00:00.000000 polars_lts_cpu-0.17.3/PKG-INFO
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/Cargo.toml`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/README.md` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/README.md`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/assets/SQL.sublime-syntax` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/assets/SQL.sublime-syntax`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/assets/theme` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/assets/theme`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/cli/highlighter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/cli/highlighter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/cli/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/cli/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/cli/prompt.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/cli/prompt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/context.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/context.rs`

 * *Files 7% similar despite different names*

```diff
@@ -18,57 +18,74 @@
 
 thread_local! {pub(crate) static TABLES: RefCell<Vec<String>> = RefCell::new(vec![])}
 
 /// The SQLContext is the main entry point for executing SQL queries.
 #[derive(Default, Clone)]
 pub struct SQLContext {
     pub(crate) table_map: PlHashMap<String, LazyFrame>,
-    pub(crate) tables: Vec<String>,
+    cte_map: RefCell<PlHashMap<String, LazyFrame>>,
 }
 
 impl SQLContext {
     /// Create a new SQLContext
     pub fn new() -> Self {
         Self {
             table_map: PlHashMap::new(),
-            tables: vec![],
+            cte_map: RefCell::new(PlHashMap::new()),
         }
     }
     /// Register a DataFrame as a table in the SQLContext.
     pub fn register(&mut self, name: &str, lf: LazyFrame) {
-        self.tables.push(name.to_owned());
         self.table_map.insert(name.to_owned(), lf);
     }
+
+    fn register_cte(&mut self, name: &str, lf: LazyFrame) {
+        self.cte_map.borrow_mut().insert(name.to_owned(), lf);
+    }
+
+    fn get_table_from_current_scope(&mut self, name: &str) -> Option<LazyFrame> {
+        if let Some(lf) = self.table_map.get(name) {
+            Some(lf.clone())
+        } else {
+            self.cte_map.borrow().get(name).cloned()
+        }
+    }
 }
 
 impl SQLContext {
     /// Execute a sql query and return the result as a LazyFrame.
     pub fn execute(&mut self, query: &str) -> PolarsResult<LazyFrame> {
         let ast = Parser::parse_sql(&GenericDialect::default(), query).map_err(to_compute_err)?;
         polars_ensure!(ast.len() == 1, ComputeError: "One and only one statement at a time please");
-        self.execute_statement(ast.get(0).unwrap())
+        let res = self.execute_statement(ast.get(0).unwrap());
+        // every execution should clear the cte map
+        self.cte_map.borrow_mut().clear();
+        res
     }
 
     pub(crate) fn execute_statement(&mut self, stmt: &Statement) -> PolarsResult<LazyFrame> {
         let ast = stmt;
         Ok(match ast {
             Statement::Query(query) => self.execute_query(query)?,
+
             stmt @ Statement::ShowTables { .. } => self.execute_show_tables(stmt)?,
             stmt @ Statement::CreateTable { .. } => self.execute_create_table(stmt)?,
             _ => polars_bail!(
                 ComputeError: "SQL statement type {:?} is not supported", ast,
             ),
         })
     }
 
     pub(crate) fn execute_query(&mut self, query: &Query) -> PolarsResult<LazyFrame> {
+        self.register_ctes(query)?;
         let mut lf = match &query.body.as_ref() {
             SetExpr::Select(select_stmt) => self.execute_select(select_stmt)?,
             _ => polars_bail!(ComputeError: "INSERT, UPDATE is not supported"),
         };
+
         if !query.order_by.is_empty() {
             lf = self.process_order_by(lf, &query.order_by)?;
         }
         match &query.limit {
             Some(SqlExpr::Value(SQLValue::Number(nrow, _))) => {
                 let nrow = nrow
                     .parse()
@@ -79,19 +96,36 @@
             _ => polars_bail!(
                 ComputeError: "non-number arguments to LIMIT clause are not supported",
             ),
         }
     }
 
     fn execute_show_tables(&mut self, _: &Statement) -> PolarsResult<LazyFrame> {
-        let tables = Series::new("name", self.tables.clone());
+        let tables = Series::new(
+            "name",
+            self.table_map.clone().into_keys().collect::<Vec<_>>(),
+        );
         let df = DataFrame::new(vec![tables])?;
         Ok(df.lazy())
     }
 
+    fn register_ctes(&mut self, query: &Query) -> PolarsResult<()> {
+        if let Some(with) = &query.with {
+            if with.recursive {
+                polars_bail!(ComputeError: "Recursive CTEs are not supported")
+            }
+            for cte in &with.cte_tables {
+                let cte_name = cte.alias.name.to_string();
+                let cte_lf = self.execute_query(&cte.query)?;
+                self.register_cte(&cte_name, cte_lf);
+            }
+        }
+        Ok(())
+    }
+
     /// execute the 'FROM' part of the query
     fn execute_from_statement(&mut self, tbl_expr: &TableWithJoins) -> PolarsResult<LazyFrame> {
         let (tbl_name, mut lf) = self.get_table(&tbl_expr.relation)?;
         if !tbl_expr.joins.is_empty() {
             for tbl in &tbl_expr.joins {
                 let (join_tbl_name, join_tbl) = self.get_table(&tbl.relation)?;
                 match &tbl.join_operator {
@@ -231,39 +265,32 @@
             TableFactor::Table {
                 name, alias, args, ..
             } => {
                 if let Some(args) = args {
                     return self.execute_tbl_function(name, alias, args);
                 }
                 let tbl_name = name.0.get(0).unwrap().value.as_str();
-
-                if self.table_map.contains_key(tbl_name) {
-                    let lf = self.table_map.get(tbl_name).cloned().ok_or_else(|| {
-                        polars_err!(
-                            ComputeError: "table '{}' was not registered in the SQLContext", name,
-                        )
-                    })?;
+                if let Some(lf) = self.get_table_from_current_scope(tbl_name) {
                     Ok((tbl_name.to_string(), lf))
                 } else {
-                    polars_bail!(ComputeError: "relation {} was not found", tbl_name);
+                    polars_bail!(ComputeError: "relation '{}' was not found", tbl_name);
                 }
             }
             // Support bare table, optional with alias for now
             _ => polars_bail!(ComputeError: "not implemented"),
         }
     }
 
     fn execute_tbl_function(
         &mut self,
         name: &ObjectName,
         alias: &Option<TableAlias>,
         args: &[FunctionArg],
     ) -> PolarsResult<(String, LazyFrame)> {
         let tbl_fn = name.0.get(0).unwrap().value.as_str();
-
         let read_fn = tbl_fn.parse::<PolarsTableFunctions>()?;
         let (tbl_name, lf) = read_fn.execute(args)?;
         let tbl_name = alias
             .as_ref()
             .map(|a| a.name.value.clone())
             .unwrap_or_else(|| tbl_name);
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/lib.rs`

 * *Files 4% similar despite different names*

```diff
@@ -105,18 +105,18 @@
 
     #[test]
     fn test_cast_exprs() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                cast(a as FLOAT) as floats, 
-                cast(a as INT) as ints, 
-                cast(a as BIGINT) as bigints, 
+            SELECT
+                cast(a as FLOAT) as floats,
+                cast(a as INT) as ints,
+                cast(a as BIGINT) as bigints,
                 cast(a as STRING) as strings
             FROM df"#;
         let df_sql = context.execute(sql).unwrap().collect().unwrap();
         let df_pl = df
             .lazy()
             .select(&[
                 col("a").cast(DataType::Float32).alias("floats"),
@@ -131,17 +131,17 @@
 
     #[test]
     fn test_literal_exprs() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                1 as int_lit, 
-                1.0 as float_lit, 
+            SELECT
+                1 as int_lit,
+                1.0 as float_lit,
                 'foo' as string_lit,
                 true as bool_lit,
                 null as null_lit
             FROM df"#;
         let df_sql = context.execute(sql).unwrap().collect().unwrap();
         let df_pl = df
             .lazy()
@@ -159,16 +159,16 @@
 
     #[test]
     fn test_prefixed_column_names() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                df.a as a, 
+            SELECT
+                df.a as a,
                 df.b as b
             FROM df"#;
         let df_sql = context.execute(sql).unwrap().collect().unwrap();
         let df_pl = df
             .lazy()
             .select(&[col("a").alias("a"), col("b").alias("b")])
             .collect()
@@ -178,39 +178,40 @@
 
     #[test]
     fn test_prefixed_column_names_2() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                "df"."a" as a, 
+            SELECT
+                "df"."a" as a,
                 "df"."b" as b
             FROM df"#;
         let df_sql = context.execute(sql).unwrap().collect().unwrap();
         let df_pl = df
             .lazy()
             .select(&[col("a").alias("a"), col("b").alias("b")])
             .collect()
             .unwrap();
         assert!(df_sql.frame_equal(&df_pl));
     }
+
     #[test]
     fn test_binary_functions() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                a, 
-                b, 
-                a + b as add, 
-                a - b as sub, 
-                a * b as mul, 
-                a / b as div, 
+            SELECT
+                a,
+                b,
+                a + b as add,
+                a - b as sub,
+                a * b as mul,
+                a / b as div,
                 a % b as rem,
                 a <> b as neq,
                 a = b as eq,
                 a > b as gt,
                 a < b as lt,
                 a >= b as gte,
                 a <= b as lte,
@@ -245,21 +246,21 @@
 
     #[test]
     fn test_null_exprs() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                a, 
+            SELECT
+                a,
                 b,
-                a is null as isnull_a, 
-                b is null as isnull_b, 
+                a is null as isnull_a,
+                b is null as isnull_b,
                 a is not null as isnotnull_a,
-                b is not null as isnotnull_b 
+                b is not null as isnotnull_b
             FROM df"#;
         let df_sql = context.execute(sql).unwrap().collect().unwrap();
         let df_pl = df
             .lazy()
             .select(&[
                 col("a"),
                 col("b"),
@@ -280,16 +281,16 @@
             "b" => &[Some(1), Some(2), None]
         }
         .unwrap();
 
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                a, 
+            SELECT
+                a,
                 b
             FROM df
             WHERE a is null and b is not null"#;
         let df_sql = context.execute(sql).unwrap().collect().unwrap();
         let df_pl = df
             .lazy()
             .filter(col("a").is_null().and(col("b").is_not_null()))
@@ -304,16 +305,16 @@
         let df = df! {
             "a" => [1.0]
         }
         .unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                a, 
+            SELECT
+                a,
                 ABS(a) AS abs,
                 ACOS(a) AS acos,
                 ASIN(a) AS asin,
                 ATAN(a) AS atan,
                 CEIL(a) AS ceil,
                 EXP(a) AS exp,
                 FLOOR(a) AS floor,
@@ -367,25 +368,26 @@
                 col("a").floor().alias("floor"),
                 col("a").ceil().alias("ceil"),
             ])
             .collect()
             .unwrap();
         assert!(df_sql.frame_equal_missing(&df_pl));
     }
+
     #[test]
     fn test_string_functions() {
         let df = df! {
             "a" => &["foo", "xxxbarxxx", "---bazyyy"]
         }
         .unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
-                a, 
+            SELECT
+                a,
                 lower('LITERAL') as lower_literal,
                 lower(a) as lower_a,
                 lower("a") as lower_a2,
                 lower(df.a) as lower_a_df,
                 lower("df".a) as lower_a_df2,
                 lower("df"."a") as lower_a_df3,
                 upper(a) as upper_a,
@@ -445,21 +447,23 @@
                     .rstrip(Some("xyz".into()))
                     .alias("rtrim_a_xyz"),
             ])
             .collect()
             .unwrap();
         assert!(df_sql.frame_equal_missing(&df_pl));
     }
+
     #[test]
+    #[ignore = "TODO: non deterministic"]
     fn test_agg_functions() {
         let df = create_sample_df().unwrap();
         let mut context = SQLContext::new();
         context.register("df", df.clone().lazy());
         let sql = r#"
-            SELECT 
+            SELECT
                 sum(a) as sum_a,
                 first(a) as first_a,
                 last(a) as last_a,
                 avg(a) as avg_a,
                 max(a) as max_a,
                 min(a) as min_a,
                 atan(a) as atan_a,
@@ -558,41 +562,41 @@
 
     #[test]
     fn test_arr_agg() {
         let df = create_sample_df().unwrap();
         let exprs = vec![
             (
                 "SELECT ARRAY_AGG(a) AS a FROM df",
-                vec![col("a").list().alias("a")],
+                vec![col("a").implode().alias("a")],
             ),
             (
                 "SELECT ARRAY_AGG(a) AS a, ARRAY_AGG(b) as b FROM df",
-                vec![col("a").list().alias("a"), col("b").list().alias("b")],
+                vec![col("a").implode().alias("a"), col("b").implode().alias("b")],
             ),
             (
                 "SELECT ARRAY_AGG(a ORDER BY a) AS a FROM df",
                 vec![col("a")
                     .sort_by(vec![col("a")], vec![false])
-                    .list()
+                    .implode()
                     .alias("a")],
             ),
             (
                 "SELECT ARRAY_AGG(a) AS a FROM df",
-                vec![col("a").list().alias("a")],
+                vec![col("a").implode().alias("a")],
             ),
             (
                 "SELECT unnest(ARRAY_AGG(DISTINCT a)) FROM df",
-                vec![col("a").unique_stable().list().explode().alias("a")],
+                vec![col("a").unique_stable().implode().explode().alias("a")],
             ),
             (
                 "SELECT ARRAY_AGG(a ORDER BY b LIMIT 2) FROM df",
                 vec![col("a")
                     .sort_by(vec![col("b")], vec![false])
                     .head(Some(2))
-                    .list()],
+                    .implode()],
             ),
         ];
 
         for (sql, expr) in exprs {
             assert_sql_to_polars(&df, sql, |df| df.select(&expr));
         }
     }
@@ -707,15 +711,15 @@
             CREATE TABLE foods AS
             SELECT *
             FROM read_csv('../../examples/datasets/foods1.csv')"#;
         context.execute(sql).unwrap().collect().unwrap();
         let df_sql = context
             .execute(
                 r#"
-            SELECT 
+            SELECT
                 "fats_g" AS fats,
                 AVG(calories) OVER (PARTITION BY "category") AS avg_calories_by_category
             FROM foods
             LIMIT 5
             "#,
             )
             .unwrap()
@@ -774,15 +778,15 @@
         let mut context = SQLContext::new();
         let sql = r#"
         CREATE TABLE foods AS
         SELECT *
         FROM read_ipc('../../examples/datasets/foods1.ipc')"#;
 
         context.execute(sql)?.collect()?;
-        let sql = r#"   
+        let sql = r#"
         SELECT
             category,
             count(category) as count,
             max(calories),
             min(fats_g)
         FROM foods
         GROUP BY category
@@ -807,8 +811,26 @@
                 )
                 .limit(2);
         let lp = expected.clone().describe_optimized_plan()?;
         let expected = expected.collect()?;
         assert!(df_sql.frame_equal(&expected));
         Ok(())
     }
+
+    #[test]
+    #[cfg(feature = "csv")]
+    fn test_ctes() -> PolarsResult<()> {
+        let mut context = SQLContext::new();
+        let sql = r#"
+        with foods as (
+            SELECT *
+            FROM read_csv('../../examples/datasets/foods1.csv')
+        )
+        select * from foods "#;
+        assert!(context.execute(sql).is_ok());
+
+        let sql = r#"select * from foods"#;
+        assert!(context.execute(sql).is_err());
+
+        Ok(())
+    }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/sql_expr.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/sql_expr.rs`

 * *Files 0% similar despite different names*

```diff
@@ -89,15 +89,15 @@
     fn visit_compound_identifier(&self, idents: &[sqlparser::ast::Ident]) -> PolarsResult<Expr> {
         polars_ensure!(
             idents.len() == 2,
             ComputeError: "compound identifier {:?} is not yet supported", idents,
         );
         let tbl_name = &idents[0].value;
         let refers_main_table =
-            { self.ctx.tables.len() == 1 && self.ctx.tables.contains(&tbl_name) };
+            { self.ctx.table_map.len() == 1 && self.ctx.table_map.contains_key(tbl_name) };
         polars_ensure!(
             refers_main_table, ComputeError:
             "compound identifier {:?} is not yet supported if multiple tables are registered",
             idents
         );
         Ok(col(&idents[1].value))
     }
@@ -268,29 +268,29 @@
             base = base.unique_stable();
         }
 
         polars_ensure!(
             !expr.within_group,
             ComputeError: "ARRAY_AGG WITHIN GROUP is not yet supported"
         );
-        Ok(base.list())
+        Ok(base.implode())
     }
 
     fn visit_order_by(&self, order_by: &OrderByExpr) -> PolarsResult<(Expr, bool)> {
         let expr = self.visit_expr(&order_by.expr)?;
         let descending = order_by.asc.unwrap_or(false);
         Ok((expr, descending))
     }
 
     fn err(&self, expr: &Expr) -> PolarsResult<Expr> {
         polars_bail!(ComputeError: "SQL expression {:?} is not yet supported", expr);
     }
 }
 
-pub(crate) fn parse_sql_expr<'a>(expr: &SqlExpr, ctx: &'a SQLContext) -> PolarsResult<Expr> {
+pub(crate) fn parse_sql_expr(expr: &SqlExpr, ctx: &SQLContext) -> PolarsResult<Expr> {
     let visitor = SqlExprVisitor { ctx };
     visitor.visit_expr(expr)
 }
 
 pub(super) fn process_join_constraint(
     constraint: &JoinConstraint,
     left_name: &str,
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-sql/src/table_functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/src/table_functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 [dev-dependencies]
 serde_json = "1"
 
 [dependencies]
 ahash= "0.8"
 bitflags= "1.3"
 glob = "0.3"
+once_cell = "1"
 polars-arrow = { version = "0.28.0", path = "../polars-arrow" }
 polars-core = { version = "0.28.0", path = "../polars-core", features = ["lazy", "private", "zip_with", "random"], default-features = false }
 polars-io = { version = "0.28.0", path = "../polars-io", features = ["lazy", "csv-file", "private"], default-features = false }
 polars-ops = { version = "0.28.0", path = "../polars-ops", default-features = false }
 polars-pipe = { version = "0.28.0", path = "../polars-pipe", optional = true }
 polars-plan = { version = "0.28.0", path = "../polars-plan" }
 polars-time = { version = "0.28.0", path = "../polars-time", optional = true }
@@ -66,14 +67,15 @@
 timezones = ["polars-plan/timezones"]
 list_take = ["polars-ops/list_take", "polars-plan/list_take"]
 list_count = ["polars-ops/list_count", "polars-plan/list_count"]
 
 true_div = ["polars-plan/true_div"]
 
 # operations
+approx_unique = ["polars-plan/approx_unique"]
 is_in = ["polars-plan/is_in"]
 repeat_by = ["polars-plan/repeat_by"]
 round_series = ["polars-plan/round_series", "polars-ops/round_series"]
 is_first = ["polars-plan/is_first"]
 is_unique = ["polars-plan/is_unique"]
 cross_join = ["polars-plan/cross_join", "polars-pipe/cross_join"]
 asof_join = ["polars-plan/asof_join", "polars-time"]
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-sql/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dot.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/eval.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/eval.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/dsl/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/dsl/mod.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,10 @@
-//! Domain specific language for the Lazy API. This DSL revolves around the [`Expr`] type, which represents an abstract
+//! Domain specific language for the Lazy API.
+//!
+//! This DSL revolves around the [`Expr`] type, which represents an abstract
 //! operation on a DataFrame, such as mapping over a column, filtering, groupby, or aggregation.
 //! In general, functions on [`LazyFrame`](crate::frame::LazyFrame)s consume the LazyFrame and produce a new LazyFrame representing
 //! the result of applying the function and passed expressions to the consumed LazyFrame.
 //! At runtime, when [`LazyFrame::collect`](crate::frame::LazyFrame::collect) is called, the expressions that comprise
 //! the LazyFrame's logical plan are materialized on the actual underlying Series.
 //! For instance, `let expr = col("x").pow(lit(2)).alias("x2");` would produce an expression representing the abstract
 //! operation of squaring the column `"x"` and naming the resulting column `"x2"`, and to apply this operation to a
@@ -28,17 +30,19 @@
 //! These kinds of invalid operations will only yield an error at runtime, when
 //! [`collect`](crate::frame::LazyFrame::collect) is called on the LazyFrame.
 
 #[cfg(any(feature = "cumulative_eval", feature = "list_eval"))]
 mod eval;
 pub mod functions;
 mod into;
+#[cfg(feature = "list_eval")]
 mod list;
 
 #[cfg(any(feature = "cumulative_eval", feature = "list_eval"))]
 pub use eval::*;
 pub use functions::*;
 #[cfg(any(feature = "cumulative_eval", feature = "list_eval"))]
 use into::IntoExpr;
+#[cfg(feature = "list_eval")]
 pub use list::*;
 pub use polars_plan::dsl::*;
 pub use polars_plan::logical_plan::UdfSchema;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/csv.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/file_list_reader.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/file_list_reader.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/ipc.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/ipc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/ndjson.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/ndjson.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/parquet.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/frame/pivot.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/frame/pivot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs`

 * *Files 2% similar despite different names*

```diff
@@ -122,22 +122,22 @@
     // ui: groups with single unique value counted in sample
     let set_size = keys[0].len();
     if set_size < sample_size {
         sample_size = set_size;
     }
 
     let finish = |groups: &GroupsProxy| {
-        let u = groups.len() as f32;
+        let u = groups.len() as f64;
         let ui = if groups.len() == sample_size {
             u
         } else {
-            groups.iter().filter(|g| g.len() == 1).count() as f32
+            groups.iter().filter(|g| g.len() == 1).count() as f64
         };
 
-        (u + (ui / sample_size as f32) * (set_size - sample_size) as f32) as usize
+        (u + (ui / sample_size as f64) * (set_size - sample_size) as f64) as usize
     };
 
     if keys.len() == 1 {
         // we sample as that will work also with sorted data.
         // not that sampling without replacement is very very expensive. don't do that.
         let s = keys[0].sample_n(sample_size, true, false, None).unwrap();
         // fast multi-threaded way to get unique.
@@ -185,21 +185,18 @@
             .map(|s| s.parse::<usize>().unwrap())
             .unwrap_or(1000);
 
         let (unique_estimate, sampled_method) = match (keys.len(), keys[0].dtype()) {
             #[cfg(feature = "dtype-categorical")]
             (1, DataType::Categorical(Some(rev_map))) => (rev_map.len(), "known"),
             _ => {
-                let sample_frac = std::env::var("POLARS_PARTITION_SAMPLE_FRAC")
-                    .map(|s| s.parse::<f32>().unwrap())
-                    .unwrap_or(0.001);
-                let sample_size = (original_df.height() as f32 * sample_frac) as usize;
+                // sqrt(N) is a good sample size as it remains low on large numbers
+                // it is better than taking a fraction as it saturates
+                let sample_size = (original_df.height() as f64).powf(0.5) as usize;
 
-                // we never sample more than 1k data points
-                let sample_size = std::cmp::min(sample_size, 1_000);
                 // we never sample less than 100 data points.
                 let sample_size = std::cmp::max(100, sample_size);
                 (estimate_unique_count(keys, sample_size)?, "estimated")
             }
         };
         if state.verbose() {
             eprintln!("{sampled_method} unique values: {unique_estimate}");
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/exotic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/exotic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs`

 * *Files 1% similar despite different names*

```diff
@@ -184,16 +184,15 @@
                         // a list per group.
                         let s = match ac.agg_state() {
                             // mean agg:
                             // -> f64 -> list<f64>
                             AggState::AggregatedFlat(s) => s.reshape(&[-1, 1]).unwrap(),
                             _ => {
                                 let agg = ac.aggregated();
-                                let ca = agg.list().unwrap();
-                                run_list_agg(ca)
+                                agg.as_list().into_series()
                             }
                         };
                         rename_series(s, &keep_name)
                     }
                 }
                 GroupByMethod::Groups => {
                     let mut column: ListChunked = ac.groups().as_list_chunked();
@@ -450,15 +449,15 @@
                         None,
                     )) as ArrayRef
                 };
                 let mut ca = unsafe { ListChunked::from_chunks(&new_name, vec![arr]) };
                 if can_fast_explode {
                     ca.set_fast_explode()
                 }
-                Ok(run_list_agg(&ca))
+                Ok(ca.into_series().as_list().into_series())
             }
             GroupByMethod::First => {
                 let mut agg = unsafe { partitioned.agg_first(groups) };
                 agg.rename(partitioned.name());
                 Ok(agg)
             }
             GroupByMethod::Last => {
@@ -548,23 +547,7 @@
         self.input.to_field(input_schema)
     }
 
     fn is_valid_aggregation(&self) -> bool {
         true
     }
 }
-
-fn run_list_agg(ca: &ListChunked) -> Series {
-    assert_eq!(ca.chunks().len(), 1);
-    let arr = ca.chunks()[0].clone();
-
-    let offsets = (0i64..(ca.len() as i64 + 1)).collect::<Vec<_>>();
-    let offsets = unsafe { Offsets::new_unchecked(offsets) };
-
-    let new_arr = LargeListArray::new(
-        DataType::List(Box::new(ca.dtype().clone())).to_arrow(),
-        offsets.into(),
-        arr,
-        None,
-    );
-    unsafe { ListChunked::from_chunks(ca.name(), vec![Box::new(new_arr)]).into_series() }
-}
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -339,20 +339,21 @@
                         fmt_expr, series.len(), self.groups.len(),
                     );
                 }
                 AggState::AggregatedList(series)
             }
             (true, _) => AggState::AggregatedFlat(series),
             _ => {
-                // already aggregated to sum, min even this series was flattened it never could
-                // retrieve the length before grouping, so it stays  in this state.
-                if let AggState::AggregatedFlat(_) = self.state {
-                    AggState::AggregatedFlat(series)
-                } else {
-                    AggState::NotAggregated(series)
+                match self.state {
+                    // already aggregated to sum, min even this series was flattened it never could
+                    // retrieve the length before grouping, so it stays  in this state.
+                    AggState::AggregatedFlat(_) => AggState::AggregatedFlat(series),
+                    // applying a function on a literal, keeps the literal state
+                    AggState::Literal(_) if series.len() == 1 => AggState::Literal(series),
+                    _ => AggState::NotAggregated(series),
                 }
             }
         };
         Ok(self)
     }
 
     pub(crate) fn with_literal(&mut self, series: Series) -> &mut Self {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs`

 * *Files 1% similar despite different names*

```diff
@@ -206,31 +206,31 @@
         let ac = self
             .phys_function
             .evaluate_on_groups(df, gb.get_groups(), state)?;
         Ok(ac)
     }
 
     fn is_explicit_list_agg(&self) -> bool {
-        // col("foo").list()
-        // col("foo").list().alias()
+        // col("foo").implode()
+        // col("foo").implode().alias()
         // ..
-        // col("foo").list().alias().alias()
+        // col("foo").implode().alias().alias()
         //
         // but not:
-        // col("foo").list().sum().alias()
+        // col("foo").implode().sum().alias()
         // ..
         // col("foo").min()
         let mut explicit_list = false;
         for e in &self.expr {
             if let Expr::Window { function, .. } = e {
                 // or list().alias
                 let mut finishes_list = false;
                 for e in &**function {
                     match e {
-                        Expr::Agg(AggExpr::List(_)) => {
+                        Expr::Agg(AggExpr::Implode(_)) => {
                             finishes_list = true;
                         }
                         Expr::Alias(_, _) => {}
                         _ => break,
                     }
                 }
                 explicit_list = finishes_list;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs`

 * *Files 0% similar despite different names*

```diff
@@ -396,15 +396,15 @@
                                 function,
                                 node_to_expr(expression, expr_arena),
                                 ApplyOptions::ApplyFlat,
                             )))
                         }
                     }
                 }
-                AAggExpr::List(expr) => {
+                AAggExpr::Implode(expr) => {
                     let input = create_physical_expr(expr, ctxt, expr_arena, schema)?;
                     match ctxt {
                         Context::Aggregation => {
                             Ok(Arc::new(AggregationExpr::new(input, GroupByMethod::List)))
                         }
                         Context::Default => {
                             let function = SpecialEq::new(Arc::new(move |s: &mut [Series]| {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/state.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/state.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use std::borrow::Cow;
 use std::sync::atomic::{AtomicU8, Ordering};
 use std::sync::{Mutex, RwLock};
 
 use bitflags::bitflags;
+use once_cell::sync::OnceCell;
 use polars_core::config::verbose;
 use polars_core::frame::groupby::GroupsProxy;
 use polars_core::frame::hash_join::JoinOptIds;
 use polars_core::prelude::*;
 #[cfg(any(feature = "parquet", feature = "csv-file", feature = "ipc"))]
 use polars_plan::logical_plan::FileFingerPrint;
 
@@ -59,15 +60,15 @@
         unsafe { std::mem::transmute(value) }
     }
 }
 
 /// State/ cache that is maintained during the Execution of the physical plan.
 pub struct ExecutionState {
     // cached by a `.cache` call and kept in memory for the duration of the plan.
-    df_cache: Arc<Mutex<PlHashMap<usize, DataFrame>>>,
+    df_cache: Arc<Mutex<PlHashMap<usize, Arc<OnceCell<DataFrame>>>>>,
     // cache file reads until all branches got there file, then we delete it
     #[cfg(any(feature = "ipc", feature = "parquet", feature = "csv-file"))]
     pub(crate) file_cache: FileCache,
     pub(super) schema_cache: RwLock<Option<SchemaRef>>,
     /// Used by Window Expression to prevent redundant grouping
     pub(super) group_tuples: GroupsProxyCache,
     /// Used by Window Expression to prevent redundant joins
@@ -189,24 +190,20 @@
 
     /// Get the schema.
     pub(crate) fn get_schema(&self) -> Option<SchemaRef> {
         let lock = self.schema_cache.read().unwrap();
         lock.clone()
     }
 
-    /// Check if we have DataFrame in cache
-    pub(crate) fn cache_hit(&self, key: &usize) -> Option<DataFrame> {
-        let guard = self.df_cache.lock().unwrap();
-        guard.get(key).cloned()
-    }
-
-    /// Store DataFrame in cache.
-    pub(crate) fn store_cache(&self, key: usize, df: DataFrame) {
+    pub(crate) fn get_df_cache(&self, key: usize) -> Arc<OnceCell<DataFrame>> {
         let mut guard = self.df_cache.lock().unwrap();
-        guard.insert(key, df);
+        guard
+            .entry(key)
+            .or_insert_with(|| Arc::new(OnceCell::new()))
+            .clone()
     }
 
     /// Clear the cache used by the Window expressions
     pub(crate) fn clear_expr_cache(&self) {
         {
             let mut lock = self.group_tuples.lock().unwrap();
             lock.clear();
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/streaming/convert.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/streaming/convert.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/prelude.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/aggregations.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/aggregations.rs`

 * *Files 0% similar despite different names*

```diff
@@ -30,15 +30,15 @@
 
     let out = df
         .lazy()
         .groupby_stable([col("g")])
         .agg([
             col("v").unique().first().alias("v_first"),
             col("v").unique().sort(false).first().alias("true_first"),
-            col("v").unique().list(),
+            col("v").unique().implode(),
         ])
         .collect()?;
 
     let a = out.column("v_first").unwrap();
     let a = a.sum::<i32>().unwrap();
     // can be both because unique does not guarantee order
     assert!(a == 10 || a == 11);
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/arity.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/cse.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/io.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/logical.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/logical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/optimization_checks.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/optimization_checks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/predicate_queries.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/predicate_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/projection_queries.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/projection_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/queries.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/queries.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1124,15 +1124,15 @@
     let df = df![
         "a" => ["a", "b", "a"],
         "b" => [Some(1), None, None]
     ]?;
 
     let out = df
         .lazy()
-        .select([col("b").forward_fill(None).list().over([col("a")])])
+        .select([col("b").forward_fill(None).implode().over([col("a")])])
         .collect()?;
     let agg = out.column("b")?.list()?;
 
     let a: Series = agg.get(0).unwrap();
     assert!(a.series_equal(&Series::new("b", &[1, 1])));
     let a: Series = agg.get(2).unwrap();
     assert!(a.series_equal(&Series::new("b", &[1, 1])));
@@ -1284,15 +1284,15 @@
     let out = df
         .lazy()
         .select([
             col("fruits"),
             col("B")
                 .shift(1)
                 .filter(col("B").shift(1).gt(lit(4)))
-                .list()
+                .implode()
                 .over([col("fruits")])
                 .alias("filtered"),
         ])
         .collect()?;
 
     assert_eq!(
         out.column("filtered")?
@@ -1435,15 +1435,15 @@
 #[test]
 fn test_sort_by_suffix() -> PolarsResult<()> {
     let df = fruits_cars();
     let out = df
         .lazy()
         .select([col("*")
             .sort_by([col("A")], [false])
-            .list()
+            .implode()
             .over([col("fruits")])
             .flatten()
             .suffix("_sorted")])
         .collect()?;
 
     let expected = df!(
             "A_sorted"=> [1, 2, 5, 3, 4],
@@ -1461,15 +1461,15 @@
     let s = Series::new("a", &[1, 2, 3]);
     let mut builder = get_list_builder(s.dtype(), s.len(), 1, s.name()).unwrap();
     builder.append_series(&s);
     let expected = builder.finish().into_series();
 
     let df = DataFrame::new(vec![s])?;
 
-    let out = df.lazy().select([col("a").list()]).collect()?;
+    let out = df.lazy().select([col("a").implode()]).collect()?;
 
     let s = out.column("a")?;
     assert!(s.series_equal(&expected));
 
     Ok(())
 }
 
@@ -1636,15 +1636,15 @@
         .lazy()
         .select([col("a")
             .arg_sort(SortOptions {
                 descending: false,
                 nulls_last: false,
                 multithreaded: true,
             })
-            .list()
+            .implode()
             .over([col("a")])
             .flatten()])
         .collect()?;
 
     let a = out.column("a")?.idx()?;
     assert_eq!(Vec::from(a), &[Some(0), Some(0)]);
 
@@ -1665,15 +1665,15 @@
             .rank(
                 RankOptions {
                     method: RankMethod::Average,
                     ..Default::default()
                 },
                 None,
             )
-            .list()
+            .implode()
             .over([col("group")])])
         .collect()?;
 
     let out = out.column("value")?.explode()?;
     let out = out.f32()?;
     assert_eq!(
         Vec::from(out),
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/streaming.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/streaming.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/tests/tpch.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/tests/tpch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-lazy/src/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/Cargo.toml`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-error/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/filter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/function.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/function.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/projection.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/operators/reproject.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/operators/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs`

 * *Files 1% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 
 #[cfg(any(feature = "parquet", feature = "ipc"))]
 trait SinkWriter {
     fn _write_batch(&mut self, df: &DataFrame) -> PolarsResult<()>;
     fn _finish(&mut self) -> PolarsResult<()>;
 }
 
-#[cfg(any(feature = "parquet", feature = "ipc"))]
+#[cfg(feature = "parquet")]
 impl SinkWriter for polars_io::parquet::BatchedWriter<std::fs::File> {
     fn _write_batch(&mut self, df: &DataFrame) -> PolarsResult<()> {
         self.write_batch(df)
     }
 
     fn _finish(&mut self) -> PolarsResult<()> {
         self.finish()?;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs`

 * *Files 0% similar despite different names*

```diff
@@ -92,15 +92,15 @@
     MinMaxI8(MinMaxAgg<i8, fn(&i8, &i8) -> Ordering>),
     MinMaxI16(MinMaxAgg<i16, fn(&i16, &i16) -> Ordering>),
     MinMaxI32(MinMaxAgg<i32, fn(&i32, &i32) -> Ordering>),
     MinMaxI64(MinMaxAgg<i64, fn(&i64, &i64) -> Ordering>),
 }
 
 impl AggregateFunction {
-    pub(crate) fn split2(&self) -> Self {
+    pub(crate) fn split(&self) -> Self {
         use AggregateFunction::*;
         match self {
             First(agg) => First(FirstAgg::new(agg.dtype.clone())),
             Last(agg) => Last(LastAgg::new(agg.dtype.clone())),
             SumF32(_) => SumF32(SumAgg::new()),
             SumF64(_) => SumF64(SumAgg::new()),
             SumU32(_) => SumU32(SumAgg::new()),
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs`

 * *Files 12% similar despite different names*

```diff
@@ -1,547 +1,471 @@
 use std::any::Any;
-use std::hash::{Hash, Hasher};
 use std::sync::Mutex;
 
 use hashbrown::hash_map::RawEntryMut;
 use num_traits::NumCast;
-use polars_arrow::trusted_len::PushUnchecked;
 use polars_core::export::ahash::RandomState;
 use polars_core::frame::row::AnyValueBuffer;
 use polars_core::prelude::*;
-use polars_core::series::SeriesPhysIter;
 use polars_core::utils::_set_partition_size;
 use polars_core::{IdBuildHasher, POOL};
 use polars_utils::hash_to_partition;
 use polars_utils::slice::GetSaferUnchecked;
 use polars_utils::unwrap::UnwrapUncheckedRelease;
 use rayon::prelude::*;
 
 use super::aggregates::AggregateFn;
+use super::generic::Key;
 use crate::executors::sinks::groupby::aggregates::AggregateFunction;
 use crate::executors::sinks::groupby::ooc_state::OocState;
 use crate::executors::sinks::groupby::physical_agg_to_logical;
+use crate::executors::sinks::groupby::primitive::apply_aggregation;
 use crate::executors::sinks::groupby::utils::{compute_slices, finalize_groupby};
 use crate::executors::sinks::io::IOThread;
-use crate::executors::sinks::utils::{hash_series, load_vec};
+use crate::executors::sinks::utils::load_vec;
 use crate::executors::sinks::HASHMAP_INIT_SIZE;
 use crate::expressions::PhysicalPipedExpr;
 use crate::operators::{DataChunk, FinalizedSink, PExecutionContext, Sink, SinkResult};
 use crate::pipeline::FORCE_OOC_GROUPBY;
 
-// This is the hash and the Index offset in the linear buffer
-#[derive(Copy, Clone)]
-pub(super) struct Key {
-    pub(super) hash: u64,
-    pub(super) idx: IdxSize,
-}
-
-impl Key {
-    #[inline]
-    pub(super) fn new(hash: u64, idx: IdxSize) -> Self {
-        Self { hash, idx }
-    }
-}
-
-impl Hash for Key {
-    #[inline]
-    fn hash<H: Hasher>(&self, state: &mut H) {
-        state.write_u64(self.hash)
-    }
-}
-
 // we store a hashmap per partition (partitioned by hash)
 // the hashmap contains indexes as keys and as values
 // those indexes point into the keys buffer and the values buffer
 // the keys buffer are buffers of AnyValue per partition
 // and the values are buffer of Aggregation functions per partition
-pub struct GenericGroupbySink {
+pub struct Utf8GroupbySink {
     thread_no: usize,
     // idx is the offset in the array with keys
     // idx is the offset in the array with aggregators
     pre_agg_partitions: Vec<PlIdHashMap<Key, IdxSize>>,
     // the aggregations/keys are all tightly packed
     // the aggregation function of a group can be found
     // by:
-    // first get the correct vec by the partition index
     //      * offset = (idx)
-    //      * end = (offset + n_aggs)
-    keys: Vec<Vec<AnyValue<'static>>>,
-    aggregators: Vec<Vec<AggregateFunction>>,
-    // the keys that will be aggregated on
-    key_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
+    //      * end = (offset + 1)
+    keys: Vec<Option<smartstring::alias::String>>,
+    aggregators: Vec<AggregateFunction>,
+    // the key that will be aggregated on
+    key_column: Arc<dyn PhysicalPipedExpr>,
     // the columns that will be aggregated
     aggregation_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
     hb: RandomState,
     // Initializing Aggregation functions. If we aggregate by 2 columns
     // this vec will have two functions. We will use these functions
     // to populate the buffer where the hashmap points to
     agg_fns: Vec<AggregateFunction>,
     input_schema: SchemaRef,
     output_schema: SchemaRef,
     // amortize allocations
     aggregation_series: Vec<Series>,
-    keys_series: Vec<Series>,
     hashes: Vec<u64>,
     slice: Option<(i64, usize)>,
+
     ooc_state: OocState,
 }
 
-impl GenericGroupbySink {
+impl Utf8GroupbySink {
     pub(crate) fn new(
-        key_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
+        key_column: Arc<dyn PhysicalPipedExpr>,
         aggregation_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
         agg_fns: Vec<AggregateFunction>,
         input_schema: SchemaRef,
         output_schema: SchemaRef,
         slice: Option<(i64, usize)>,
     ) -> Self {
         let ooc = std::env::var(FORCE_OOC_GROUPBY).is_ok();
         Self::new_inner(
-            key_columns,
+            key_column,
             aggregation_columns,
             agg_fns,
             input_schema,
             output_schema,
             slice,
             None,
             ooc,
         )
     }
 
     #[allow(clippy::too_many_arguments)]
-    pub(crate) fn new_inner(
-        key_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
+    fn new_inner(
+        key_column: Arc<dyn PhysicalPipedExpr>,
         aggregation_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
         agg_fns: Vec<AggregateFunction>,
         input_schema: SchemaRef,
         output_schema: SchemaRef,
         slice: Option<(i64, usize)>,
         io_thread: Option<Arc<Mutex<Option<IOThread>>>>,
         ooc: bool,
     ) -> Self {
-        let hb = RandomState::default();
+        let hb = Default::default();
         let partitions = _set_partition_size();
 
         let pre_agg = load_vec(partitions, || PlIdHashMap::with_capacity(HASHMAP_INIT_SIZE));
-        let keys = load_vec(partitions, || {
-            Vec::with_capacity(HASHMAP_INIT_SIZE * key_columns.len())
-        });
-        let aggregators = load_vec(partitions, || {
-            Vec::with_capacity(HASHMAP_INIT_SIZE * aggregation_columns.len())
-        });
+        let keys = Vec::with_capacity(HASHMAP_INIT_SIZE * partitions);
+        let aggregators =
+            Vec::with_capacity(HASHMAP_INIT_SIZE * aggregation_columns.len() * partitions);
 
         let mut out = Self {
             thread_no: 0,
             pre_agg_partitions: pre_agg,
             keys,
             aggregators,
-            key_columns,
+            key_column,
             aggregation_columns,
             hb,
             agg_fns,
             input_schema,
             output_schema,
             aggregation_series: vec![],
-            keys_series: vec![],
             hashes: vec![],
             slice,
             ooc_state: OocState::new(io_thread, ooc),
         };
         if ooc {
             out.ooc_state.init_ooc(out.input_schema.clone()).unwrap();
         }
         out
     }
 
     #[inline]
     fn number_of_aggs(&self) -> usize {
         self.aggregation_columns.len()
     }
-    #[inline]
-    fn number_of_keys(&self) -> usize {
-        self.key_columns.len()
-    }
 
     fn pre_finalize(&mut self) -> PolarsResult<Vec<DataFrame>> {
-        let mut aggregators = std::mem::take(&mut self.aggregators);
-        let n_keys = self.number_of_keys();
+        // we create a pointer to the aggregation functions buffer
+        // we will deref *mut on every partition thread
+        // this will be safe, as the partitions guarantee that access don't alias.
+        let aggregators = self.aggregators.as_ptr() as usize;
+        let aggregators_len = self.aggregators.len();
+
         let slices = compute_slices(&self.pre_agg_partitions, self.slice);
 
         POOL.install(|| {
             let dfs =
                 self.pre_agg_partitions
                     .par_iter()
-                    .zip(aggregators.par_iter_mut())
-                    .zip(self.keys.par_iter())
                     .zip(slices.par_iter())
-                    .filter_map(|(((agg_map, agg_fns), current_keys), slice)| {
+                    .filter_map(|(agg_map, slice)| {
+                        let ptr = aggregators as *mut AggregateFunction;
+                        // safety:
+                        // we will not alias.
+                        let aggregators =
+                            unsafe { std::slice::from_raw_parts_mut(ptr, aggregators_len) };
+
                         let (offset, slice_len) = (*slice)?;
                         if agg_map.is_empty() {
                             return None;
                         }
-                        let mut key_builders = self
-                            .output_schema
-                            .iter_dtypes()
-                            .take(n_keys)
-                            .map(|dtype| AnyValueBuffer::new(&dtype.to_physical(), agg_map.len()))
-                            .collect::<Vec<_>>();
-                        let dtypes = agg_fns
+                        let dtypes = aggregators
                             .iter()
                             .take(self.number_of_aggs())
                             .map(|func| func.dtype())
                             .collect::<Vec<_>>();
 
                         let mut buffers = dtypes
                             .iter()
                             .map(|dtype| AnyValueBuffer::new(dtype, slice_len))
                             .collect::<Vec<_>>();
 
+                        let cap = std::cmp::min(slice_len, agg_map.len());
+                        let mut key_builder = Utf8ChunkedBuilder::new("", cap, cap * 8);
                         agg_map.into_iter().skip(offset).take(slice_len).for_each(
                             |(k, &offset)| {
-                                let keys_offset = k.idx as usize;
-                                let keys = unsafe {
-                                    current_keys
-                                        .get_unchecked_release(keys_offset..keys_offset + n_keys)
+                                let key_offset = k.idx as usize;
+                                let key = unsafe {
+                                    self.keys.get_unchecked_release(key_offset).as_deref()
                                 };
-
-                                for (key, key_builder) in keys.iter().zip(key_builders.iter_mut()) {
-                                    key_builder.add(key.as_borrowed());
-                                }
+                                key_builder.append_option(key);
 
                                 for (i, buffer) in (offset as usize
                                     ..offset as usize + self.aggregation_columns.len())
                                     .zip(buffers.iter_mut())
                                 {
                                     unsafe {
-                                        let agg_fn = agg_fns.get_unchecked_release_mut(i);
+                                        let agg_fn = aggregators.get_unchecked_release_mut(i);
                                         let av = agg_fn.finalize();
                                         buffer.add(av);
                                     }
                                 }
                             },
                         );
 
-                        let mut cols = Vec::with_capacity(n_keys + self.number_of_aggs());
-                        for key_builder in key_builders {
-                            cols.push(key_builder.into_series());
-                        }
+                        let mut cols = Vec::with_capacity(1 + self.number_of_aggs());
+                        cols.push(key_builder.finish().into_series());
                         cols.extend(buffers.into_iter().map(|buf| buf.into_series()));
                         physical_agg_to_logical(&mut cols, &self.output_schema);
                         Some(DataFrame::new_no_checks(cols))
                     })
                     .collect::<Vec<_>>();
 
             Ok(dfs)
         })
     }
-
-    fn evaluate_keys_aggs_and_hashes(
+    fn prepare_key_and_aggregation_series(
         &mut self,
         context: &PExecutionContext,
         chunk: &DataChunk,
-    ) -> PolarsResult<()> {
-        // todo! amortize allocation
+    ) -> PolarsResult<Series> {
+        let s = self
+            .key_column
+            .evaluate(chunk, context.execution_state.as_any())?;
+        let s = s.to_physical_repr();
+        let s = s.rechunk();
+
+        // todo! ammortize allocation
         for phys_e in self.aggregation_columns.iter() {
             let s = phys_e.evaluate(chunk, context.execution_state.as_any())?;
             let s = s.to_physical_repr();
             self.aggregation_series.push(s.rechunk());
         }
-        for phys_e in self.key_columns.iter() {
-            let s = phys_e.evaluate(chunk, context.execution_state.as_any())?;
-            let s = s.to_physical_repr();
-            self.keys_series.push(s.rechunk());
-        }
-
-        // write the hashes to self.hashes buffer
-        hash_series(&self.keys_series, &mut self.hashes, &self.hb);
-        Ok(())
+        s.vec_hash(self.hb.clone(), &mut self.hashes).unwrap();
+        Ok(s)
     }
-
     #[inline]
-    fn get_partitions(
-        &mut self,
-        h: u64,
-    ) -> (
-        &mut PlIdHashMap<Key, IdxSize>,
-        &mut Vec<AggregateFunction>,
-        &mut Vec<AnyValue<'static>>,
-    ) {
+    fn get_partitions(&mut self, h: u64) -> &mut PlIdHashMap<Key, IdxSize> {
         let partition = hash_to_partition(h, self.pre_agg_partitions.len());
         let current_partition =
             unsafe { self.pre_agg_partitions.get_unchecked_release_mut(partition) };
-        let current_aggregators = unsafe { self.aggregators.get_unchecked_release_mut(partition) };
-        let current_key_values = unsafe { self.keys.get_unchecked_release_mut(partition) };
 
-        (current_partition, current_aggregators, current_key_values)
+        current_partition
     }
 
     fn sink_ooc(
         &mut self,
         context: &PExecutionContext,
         chunk: DataChunk,
     ) -> PolarsResult<SinkResult> {
-        let num_aggs = self.number_of_aggs();
-        let num_keys = self.number_of_keys();
-        self.evaluate_keys_aggs_and_hashes(context, &chunk)?;
+        let s = self.prepare_key_and_aggregation_series(context, &chunk)?;
 
         // take containers to please bchk
         // we put them back once done
-        let keys_series = std::mem::take(&mut self.keys_series);
-        let aggregation_series = std::mem::take(&mut self.aggregation_series);
         let mut hashes = std::mem::take(&mut self.hashes);
+        let keys = std::mem::take(&mut self.keys);
         let agg_fns = std::mem::take(&mut self.agg_fns);
+        let mut aggregators = std::mem::take(&mut self.aggregators);
 
-        let (mut key_iters, mut agg_iters) = get_iters(&keys_series, &aggregation_series);
-
-        // a small buffer that holds the current key values
-        // if we groupby 2 keys, this holds 2 anyvalues.
-        let mut current_tuple = Vec::with_capacity(num_keys);
+        // write the hashes to self.hashes buffer
+        // s.vec_hash(self.hb.clone(), &mut self.hashes).unwrap();
+        // now we have written hashes, we take the pointer to this buffer
+        // we will write the aggregation_function indexes in the same buffer
+        // this is unsafe and we must check that we only write the hashes that
+        // already read/taken. So we write on the slots we just read
+        let agg_idx_ptr = hashes.as_ptr() as *mut u64 as *mut IdxSize;
+        // array of the keys
+        let keys_arr = s.utf8().unwrap().downcast_iter().next().unwrap().clone();
 
         // set all bits to false
         self.ooc_state.reset_ooc_filter_rows(chunk.data.height());
 
-        for (iteration_idx, &h) in hashes.iter().enumerate() {
-            // load the keys in the buffer
-            current_tuple.clear();
-            for key_iter in key_iters.iter_mut() {
-                unsafe { current_tuple.push_unchecked(key_iter.next().unwrap_unchecked_release()) }
-            }
-
-            let (current_partition, current_aggregators, current_key_values) =
-                self.get_partitions(h);
-            let entry = get_entry(
-                h,
-                &mut current_tuple,
-                current_partition,
-                current_key_values,
-                num_keys,
-            );
+        let mut processed = 0;
+        for (iteration_idx, (key_val, &h)) in keys_arr.iter().zip(&hashes).enumerate() {
+            let current_partition = self.get_partitions(h);
+            let entry = get_entry(key_val, h, current_partition, &keys);
 
             match entry {
-                // if the slot does not exist, we do not add it but instead
-                // we sink these rows to disk
                 RawEntryMut::Vacant(_) => {
                     // set this row to true: e.g. processed ooc
                     // safety: we correctly set the length with `reset_ooc_filter_rows`
                     unsafe {
                         self.ooc_state.set_row_as_ooc(iteration_idx);
                     }
                 }
                 RawEntryMut::Occupied(entry) => {
                     let agg_idx = *entry.get();
-
-                    apply_aggregation(
-                        agg_idx,
-                        num_aggs,
-                        chunk.chunk_index,
-                        &mut agg_iters,
-                        current_aggregators,
-                    );
+                    // # Safety
+                    // we write to the hashes buffer we iterate over at the moment.
+                    // this is sound because we writes are trailing from iteration
+                    unsafe { write_agg_idx(agg_idx_ptr, processed, agg_idx) };
+                    processed += 1;
                 }
             };
         }
+
+        // note that this slice looks into the self.hashes buffer
+        let agg_idxs = unsafe { std::slice::from_raw_parts(agg_idx_ptr, processed) };
+
+        apply_aggregation(
+            agg_idxs,
+            &chunk,
+            self.number_of_aggs(),
+            &self.aggregation_series,
+            &agg_fns,
+            &mut aggregators,
+        );
         self.ooc_state.dump(chunk.data, &mut hashes);
-        drop(agg_iters);
-        drop(key_iters);
-        self.aggregation_series = aggregation_series;
-        self.keys_series = keys_series;
+
+        self.aggregation_series.clear();
         self.hashes = hashes;
+        self.keys = keys;
         self.agg_fns = agg_fns;
-        self.aggregation_series.clear();
-        self.keys_series.clear();
+        self.aggregators = aggregators;
         self.hashes.clear();
+        self.ooc_state.check_memory_usage(&self.input_schema)?;
         Ok(SinkResult::CanHaveMoreInput)
     }
 }
 
-impl Sink for GenericGroupbySink {
+impl Sink for Utf8GroupbySink {
     fn sink(&mut self, context: &PExecutionContext, chunk: DataChunk) -> PolarsResult<SinkResult> {
         if self.ooc_state.ooc {
             return self.sink_ooc(context, chunk);
         }
-        let num_aggs = self.number_of_aggs();
-        let num_keys = self.number_of_keys();
-        self.evaluate_keys_aggs_and_hashes(context, &chunk)?;
+        let s = self.prepare_key_and_aggregation_series(context, &chunk)?;
 
         // take containers to please bchk
         // we put them back once done
-        let keys_series = std::mem::take(&mut self.keys_series);
-        let aggregation_series = std::mem::take(&mut self.aggregation_series);
         let hashes = std::mem::take(&mut self.hashes);
+        let mut keys = std::mem::take(&mut self.keys);
         let agg_fns = std::mem::take(&mut self.agg_fns);
+        let mut aggregators = std::mem::take(&mut self.aggregators);
 
-        let (mut key_iters, mut agg_iters) = get_iters(&keys_series, &aggregation_series);
-
-        // a small buffer that holds the current key values
-        // if we groupby 2 keys, this holds 2 anyvalues.
-        let mut current_tuple = Vec::with_capacity(self.key_columns.len());
-
-        for &h in &hashes {
-            // load the keys in the buffer
-            current_tuple.clear();
-            for key_iter in key_iters.iter_mut() {
-                unsafe { current_tuple.push_unchecked(key_iter.next().unwrap_unchecked_release()) }
-            }
-
-            let (current_partition, current_aggregators, current_key_values) =
-                self.get_partitions(h);
-            let entry = get_entry(
-                h,
-                &mut current_tuple,
-                current_partition,
-                current_key_values,
-                num_keys,
-            );
+        // write the hashes to self.hashes buffer
+        // s.vec_hash(self.hb.clone(), &mut self.hashes).unwrap();
+        // now we have written hashes, we take the pointer to this buffer
+        // we will write the aggregation_function indexes in the same buffer
+        // this is unsafe and we must check that we only write the hashes that
+        // already read/taken. So we write on the slots we just read
+        let agg_idx_ptr = hashes.as_ptr() as *mut u64 as *mut IdxSize;
+        // array of the keys
+        let keys_arr = s.utf8().unwrap().downcast_iter().next().unwrap().clone();
+
+        for (iteration_idx, (key_val, &h)) in keys_arr.iter().zip(&hashes).enumerate() {
+            let current_partition = self.get_partitions(h);
+            let entry = get_entry(key_val, h, current_partition, &keys);
 
             let agg_idx = match entry {
                 RawEntryMut::Vacant(entry) => {
-                    let value_offset = unsafe {
-                        NumCast::from(current_aggregators.len()).unwrap_unchecked_release()
-                    };
+                    let value_offset =
+                        unsafe { NumCast::from(aggregators.len()).unwrap_unchecked_release() };
                     let keys_offset = unsafe {
-                        Key::new(
-                            h,
-                            NumCast::from(current_key_values.len()).unwrap_unchecked_release(),
-                        )
+                        Key::new(h, NumCast::from(keys.len()).unwrap_unchecked_release())
                     };
                     entry.insert(keys_offset, value_offset);
 
-                    unsafe {
-                        current_key_values.extend(
-                            current_tuple
-                                .iter()
-                                .map(|av| av.clone().into_static().unwrap_unchecked_release()),
-                        )
-                    };
+                    keys.push(key_val.map(|s| s.into()));
+
                     // initialize the aggregators
                     for agg_fn in &agg_fns {
-                        current_aggregators.push(agg_fn.split2())
+                        aggregators.push(agg_fn.split())
                     }
                     value_offset
                 }
                 RawEntryMut::Occupied(entry) => *entry.get(),
             };
-            apply_aggregation(
-                agg_idx,
-                num_aggs,
-                chunk.chunk_index,
-                &mut agg_iters,
-                current_aggregators,
-            );
+            // # Safety
+            // we write to the hashes buffer we iterate over at the moment.
+            // this is sound because we writes are trailing from iteration
+            unsafe { write_agg_idx(agg_idx_ptr, iteration_idx, agg_idx) };
         }
-        drop(agg_iters);
-        drop(key_iters);
-        self.aggregation_series = aggregation_series;
-        self.keys_series = keys_series;
+
+        // note that this slice looks into the self.hashes buffer
+        let agg_idxs = unsafe { std::slice::from_raw_parts(agg_idx_ptr, keys_arr.len()) };
+
+        apply_aggregation(
+            agg_idxs,
+            &chunk,
+            self.number_of_aggs(),
+            &self.aggregation_series,
+            &agg_fns,
+            &mut aggregators,
+        );
+        self.aggregation_series.clear();
         self.hashes = hashes;
+        self.keys = keys;
         self.agg_fns = agg_fns;
-        self.aggregation_series.clear();
-        self.keys_series.clear();
+        self.aggregators = aggregators;
         self.hashes.clear();
         self.ooc_state.check_memory_usage(&self.input_schema)?;
         Ok(SinkResult::CanHaveMoreInput)
     }
 
     fn combine(&mut self, other: &mut dyn Sink) {
         // don't parallelize this as this is already done in parallel.
 
         let other = other.as_any().downcast_ref::<Self>().unwrap();
         let n_partitions = self.pre_agg_partitions.len();
         debug_assert_eq!(n_partitions, other.pre_agg_partitions.len());
-        let n_keys = self.number_of_keys();
 
         self.pre_agg_partitions
             .iter_mut()
             .zip(other.pre_agg_partitions.iter())
-            .zip(self.aggregators.iter_mut())
-            .zip(other.aggregators.iter())
-            .for_each(
-                |(((map_self, map_other), aggregators_self), aggregators_other)| {
-                    for (k_other, &agg_idx_other) in map_other.iter() {
-                        // the hash value
-                        let h = k_other.hash;
-                        // the partition where all keys and maps are located
-                        let partition = hash_to_partition(h, n_partitions);
-                        // get the key buffers
-                        let keys_buffer_self =
-                            unsafe { self.keys.get_unchecked_release_mut(partition) };
-                        let keys_buffer_other =
-                            unsafe { other.keys.get_unchecked_release(partition) };
-
-                        // the offset in the keys of other
-                        let idx_other = k_other.idx as usize;
-                        // slice to the keys of other
-                        let keys_other = unsafe {
-                            keys_buffer_other.get_unchecked_release(idx_other..idx_other + n_keys)
-                        };
+            .for_each(|(map_self, map_other)| {
+                for (k_other, &agg_idx_other) in map_other.iter() {
+                    // the hash value
+                    let h = k_other.hash;
+
+                    // the offset in the keys of other
+                    let idx_other = k_other.idx as usize;
+                    // slice to the keys of other
+                    let key_other = unsafe { other.keys.get_unchecked_release(idx_other) };
 
-                        let entry = map_self.raw_entry_mut().from_hash(h, |k_self| {
+                    let entry = map_self.raw_entry_mut().from_hash(h, |k_self| {
+                        h == k_self.hash && {
                             // the offset in the keys of self
                             let idx_self = k_self.idx as usize;
                             // slice to the keys of self
                             // safety:
                             // in bounds
-                            let keys_self = unsafe {
-                                keys_buffer_self.get_unchecked_release(idx_self..idx_self + n_keys)
-                            };
+                            let key_self = unsafe { self.keys.get_unchecked_release(idx_self) };
                             // compare the keys
-                            keys_self == keys_other
-                        });
+                            key_self == key_other
+                        }
+                    });
 
-                        let agg_idx_self = match entry {
-                            // the keys of other are not in this table, so we must update this table
-                            RawEntryMut::Vacant(entry) => {
-                                // get the current offset in the values buffer
-                                let values_offset = unsafe {
-                                    NumCast::from(aggregators_self.len()).unwrap_unchecked_release()
-                                };
-                                // get the key, comprised of the hash and the current offset in the keys buffer
-                                let key = unsafe {
-                                    Key::new(
-                                        h,
-                                        NumCast::from(keys_buffer_self.len())
-                                            .unwrap_unchecked_release(),
-                                    )
-                                };
+                    let agg_idx_self = match entry {
+                        // the keys of other are not in this table, so we must update this table
+                        RawEntryMut::Vacant(entry) => {
+                            // get the current offset in the values buffer
+                            let values_offset = unsafe {
+                                NumCast::from(self.aggregators.len()).unwrap_unchecked_release()
+                            };
+                            // get the key, comprised of the hash and the current offset in the keys buffer
+                            let key = unsafe {
+                                Key::new(
+                                    h,
+                                    NumCast::from(self.keys.len()).unwrap_unchecked_release(),
+                                )
+                            };
 
-                                // extend the keys buffer with the new keys from other
-                                keys_buffer_self.extend_from_slice(keys_other);
+                            // extend the keys buffer with the new key from other
+                            self.keys.push(key_other.clone());
 
-                                // insert the keys and values_offset
-                                entry.insert(key, values_offset);
-                                // initialize the new aggregators
-                                for agg_fn in &self.agg_fns {
-                                    aggregators_self.push(agg_fn.split2())
-                                }
-                                values_offset
+                            // insert the keys and values_offset
+                            entry.insert(key, values_offset);
+                            // initialize the new aggregators
+                            for agg_fn in &self.agg_fns {
+                                self.aggregators.push(agg_fn.split())
                             }
-                            RawEntryMut::Occupied(entry) => *entry.get(),
-                        };
+                            values_offset
+                        }
+                        RawEntryMut::Occupied(entry) => *entry.get(),
+                    };
 
-                        // combine the aggregation functions
-                        for i in 0..self.aggregation_columns.len() {
-                            unsafe {
-                                let agg_fn_other = aggregators_other
-                                    .get_unchecked_release(agg_idx_other as usize + i);
-                                let agg_fn_self = aggregators_self
-                                    .get_unchecked_release_mut(agg_idx_self as usize + i);
-                                agg_fn_self.combine(agg_fn_other.as_any())
-                            }
+                    // combine the aggregation functions
+                    for i in 0..self.aggregation_columns.len() {
+                        unsafe {
+                            let agg_fn_other = other
+                                .aggregators
+                                .get_unchecked_release(agg_idx_other as usize + i);
+                            let agg_fn_self = self
+                                .aggregators
+                                .get_unchecked_release_mut(agg_idx_self as usize + i);
+                            agg_fn_self.combine(agg_fn_other.as_any())
                         }
                     }
-                },
-            );
+                }
+            });
     }
 
     fn split(&self, thread_no: usize) -> Box<dyn Sink> {
         let mut new = Self::new_inner(
-            self.key_columns.clone(),
+            self.key_column.clone(),
             self.aggregation_columns.clone(),
-            self.agg_fns.iter().map(|func| func.split2()).collect(),
+            self.agg_fns.iter().map(|func| func.split()).collect(),
             self.input_schema.clone(),
             self.output_schema.clone(),
             self.slice,
             Some(self.ooc_state.io_thread.clone()),
             self.ooc_state.ooc,
         );
         new.hb = self.hb.clone();
@@ -566,63 +490,86 @@
         finalize_groupby(dfs, &self.output_schema, self.slice, payload)
     }
 
     fn as_any(&mut self) -> &mut dyn Any {
         self
     }
     fn fmt(&self) -> &str {
-        "generic_groupby"
+        "utf8_groupby"
+    }
+}
+
+// write agg_idx to the hashes buffer.
+pub(super) unsafe fn write_agg_idx(h: *mut IdxSize, i: usize, agg_idx: IdxSize) {
+    h.add(i).write(agg_idx)
+}
+
+pub(super) fn apply_aggregate(
+    agg_i: usize,
+    chunk_idx: IdxSize,
+    agg_idxs: &[IdxSize],
+    aggregation_s: &Series,
+    has_physical_agg: bool,
+    aggregators: &mut [AggregateFunction],
+) {
+    macro_rules! apply_agg {
+                ($self:expr, $macro:ident $(, $opt_args:expr)*) => {{
+                    match $self.dtype() {
+                        #[cfg(feature = "dtype-u8")]
+                        DataType::UInt8 => $macro!($self.u8().unwrap(), pre_agg_u8 $(, $opt_args)*),
+                        #[cfg(feature = "dtype-u16")]
+                        DataType::UInt16 => $macro!($self.u16().unwrap(), pre_agg_u16 $(, $opt_args)*),
+                        DataType::UInt32 => $macro!($self.u32().unwrap(), pre_agg_u32 $(, $opt_args)*),
+                        DataType::UInt64 => $macro!($self.u64().unwrap(), pre_agg_u64 $(, $opt_args)*),
+                        #[cfg(feature = "dtype-i8")]
+                        DataType::Int8 => $macro!($self.i8().unwrap(), pre_agg_i8 $(, $opt_args)*),
+                        #[cfg(feature = "dtype-i16")]
+                        DataType::Int16 => $macro!($self.i16().unwrap(), pre_agg_i16 $(, $opt_args)*),
+                        DataType::Int32 => $macro!($self.i32().unwrap(), pre_agg_i32 $(, $opt_args)*),
+                        DataType::Int64 => $macro!($self.i64().unwrap(), pre_agg_i64 $(, $opt_args)*),
+                        DataType::Float32 => $macro!($self.f32().unwrap(), pre_agg_f32 $(, $opt_args)*),
+                        DataType::Float64 => $macro!($self.f64().unwrap(), pre_agg_f64 $(, $opt_args)*),
+                        dt => panic!("not implemented for {:?}", dt),
+                    }
+                }};
+            }
+
+    if has_physical_agg && aggregation_s.dtype().is_numeric() {
+        macro_rules! dispatch {
+            ($ca:expr, $name:ident) => {{
+                let arr = $ca.downcast_iter().next().unwrap();
+
+                for (&agg_idx, av) in agg_idxs.iter().zip(arr.into_iter()) {
+                    let i = agg_idx as usize + agg_i;
+                    let agg_fn = unsafe { aggregators.get_unchecked_release_mut(i) };
+
+                    agg_fn.$name(chunk_idx, av.copied())
+                }
+            }};
+        }
+
+        apply_agg!(aggregation_s, dispatch);
+    } else {
+        let mut iter = aggregation_s.phys_iter();
+        for &agg_idx in agg_idxs.iter() {
+            let i = agg_idx as usize + agg_i;
+            let agg_fn = unsafe { aggregators.get_unchecked_release_mut(i) };
+            agg_fn.pre_agg(chunk_idx, &mut iter)
+        }
     }
 }
 
 #[inline]
 fn get_entry<'a>(
+    key_val: Option<&str>,
     h: u64,
-    current_tuple: &mut Vec<AnyValue>,
     current_partition: &'a mut PlIdHashMap<Key, IdxSize>,
-    current_key_values: &Vec<AnyValue>,
-    n_keys: usize,
+    keys: &[Option<smartstring::alias::String>],
 ) -> RawEntryMut<'a, Key, IdxSize, IdBuildHasher> {
     current_partition.raw_entry_mut().from_hash(h, |key| {
+        // first compare the hash before we incur the cache miss
         key.hash == h && {
             let idx = key.idx as usize;
-            if n_keys > 1 {
-                current_tuple.iter().enumerate().all(|(i, key)| unsafe {
-                    current_key_values.get_unchecked_release(i + idx) == key
-                })
-            } else {
-                unsafe {
-                    current_key_values.get_unchecked_release(idx)
-                        == current_tuple.get_unchecked_release(0)
-                }
-            }
+            unsafe { keys.get_unchecked_release(idx).as_deref() == key_val }
         }
     })
 }
-fn get_iters<'a>(
-    key_series: &'a [Series],
-    aggregation_series: &'a [Series],
-) -> (Vec<SeriesPhysIter<'a>>, Vec<SeriesPhysIter<'a>>) {
-    (
-        key_series.iter().map(|s| s.phys_iter()).collect::<Vec<_>>(),
-        aggregation_series
-            .iter()
-            .map(|s| s.phys_iter())
-            .collect::<Vec<_>>(),
-    )
-}
-
-#[inline]
-fn apply_aggregation(
-    agg_idx: IdxSize,
-    num_aggs: usize,
-    chunk_index: IdxSize,
-    agg_iters: &mut [SeriesPhysIter],
-    current_aggregators: &mut [AggregateFunction],
-) {
-    for (i, agg_iter) in (0..num_aggs).zip(agg_iters.iter_mut()) {
-        let i = agg_idx as usize + i;
-        let agg_fn = unsafe { current_aggregators.get_unchecked_release_mut(i) };
-
-        agg_fn.pre_agg(chunk_index, agg_iter.as_mut())
-    }
-}
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 mod generic;
 mod ooc;
 mod ooc_state;
 mod primitive;
 mod string;
 mod utils;
 
-pub(crate) use generic::*;
+pub(crate) use generic::GenericGroupby2;
 use polars_core::prelude::*;
 #[cfg(feature = "dtype-categorical")]
 use polars_core::using_string_cache;
 pub(crate) use primitive::*;
 pub(crate) use string::*;
 
 const MEMORY_FRACTION_THRESHOLD: f64 = 0.3;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -414,15 +414,15 @@
 
                     let agg_idx_self = match entry {
                         RawEntryMut::Vacant(entry) => {
                             let offset = NumCast::from(self.aggregators.len()).unwrap();
                             entry.insert(*key, offset);
                             // initialize the aggregators
                             for agg_fn in &self.agg_fns {
-                                self.aggregators.push(agg_fn.split2())
+                                self.aggregators.push(agg_fn.split())
                             }
                             offset
                         }
                         RawEntryMut::Occupied(entry) => *entry.get(),
                     };
                     // combine the aggregation functions
                     for i in 0..self.aggregation_columns.len() {
@@ -457,15 +457,15 @@
         finalize_groupby(dfs, &self.output_schema, self.slice, payload)
     }
 
     fn split(&self, thread_no: usize) -> Box<dyn Sink> {
         let mut new = Self::new_inner(
             self.key.clone(),
             self.aggregation_columns.clone(),
-            self.agg_fns.iter().map(|func| func.split2()).collect(),
+            self.agg_fns.iter().map(|func| func.split()).collect(),
             self.input_schema.clone(),
             self.output_schema.clone(),
             self.slice,
             Some(self.ooc_state.io_thread.clone()),
             self.ooc_state.ooc,
         );
         new.hb = self.hb.clone();
@@ -505,15 +505,15 @@
             let key = Key {
                 hash: h,
                 value: opt_v,
             };
             entry.insert(key, offset);
             // initialize the aggregators
             for agg_fn in agg_fns {
-                current_aggregators.push(agg_fn.split2())
+                current_aggregators.push(agg_fn.split())
             }
             offset
         }
         RawEntryMut::Occupied(entry) => *entry.get(),
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/mod.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,575 +1,765 @@
-use std::any::Any;
-use std::sync::Mutex;
+//! The typed heart of every Series column.
+use std::iter::Map;
+use std::marker::PhantomData;
+use std::sync::Arc;
+
+use arrow::array::*;
+use arrow::bitmap::Bitmap;
+use polars_arrow::prelude::ValueSize;
+
+use crate::prelude::*;
+
+pub mod ops;
+#[macro_use]
+pub mod arithmetic;
+pub mod builder;
+pub mod cast;
+pub mod comparison;
+pub mod float;
+pub mod iterator;
+pub mod kernels;
+#[cfg(feature = "ndarray")]
+mod ndarray;
+
+mod bitwise;
+#[cfg(feature = "object")]
+mod drop;
+mod from;
+pub(crate) mod list;
+pub(crate) mod logical;
+#[cfg(feature = "object")]
+pub mod object;
+#[cfg(feature = "random")]
+mod random;
+#[cfg(any(
+    feature = "temporal",
+    feature = "dtype-datetime",
+    feature = "dtype-date"
+))]
+pub mod temporal;
+mod to_vec;
+mod trusted_len;
+pub mod upstream_traits;
+
+use std::mem;
+use std::slice::Iter;
+
+use bitflags::bitflags;
+use polars_arrow::prelude::*;
+
+use crate::series::IsSorted;
+use crate::utils::{first_non_null, last_non_null, CustomIterTools};
+
+#[cfg(not(feature = "dtype-categorical"))]
+pub struct RevMapping {}
+
+pub type ChunkIdIter<'a> = std::iter::Map<std::slice::Iter<'a, ArrayRef>, fn(&ArrayRef) -> usize>;
+
+/// # ChunkedArray
+///
+/// Every Series contains a `ChunkedArray<T>`. Unlike Series, ChunkedArray's are typed. This allows
+/// us to apply closures to the data and collect the results to a `ChunkedArray` of the same type `T`.
+/// Below we use an apply to use the cosine function to the values of a `ChunkedArray`.
+///
+/// ```rust
+/// # use polars_core::prelude::*;
+/// fn apply_cosine(ca: &Float32Chunked) -> Float32Chunked {
+///     ca.apply(|v| v.cos())
+/// }
+/// ```
+///
+/// If we would like to cast the result we could use a Rust Iterator instead of an `apply` method.
+/// Note that Iterators are slightly slower as the null values aren't ignored implicitly.
+///
+/// ```rust
+/// # use polars_core::prelude::*;
+/// fn apply_cosine_and_cast(ca: &Float32Chunked) -> Float64Chunked {
+///     ca.into_iter()
+///         .map(|opt_v| {
+///         opt_v.map(|v| v.cos() as f64)
+///     }).collect()
+/// }
+/// ```
+///
+/// Another option is to first cast and then use an apply.
+///
+/// ```rust
+/// # use polars_core::prelude::*;
+/// fn apply_cosine_and_cast(ca: &Float32Chunked) -> Float64Chunked {
+///     ca.apply_cast_numeric(|v| v.cos() as f64)
+/// }
+/// ```
+///
+/// ## Conversion between Series and ChunkedArray's
+/// Conversion from a `Series` to a `ChunkedArray` is effortless.
+///
+/// ```rust
+/// # use polars_core::prelude::*;
+/// fn to_chunked_array(series: &Series) -> PolarsResult<&Int32Chunked>{
+///     series.i32()
+/// }
+///
+/// fn to_series(ca: Int32Chunked) -> Series {
+///     ca.into_series()
+/// }
+/// ```
+///
+/// # Iterators
+///
+/// `ChunkedArrays` fully support Rust native [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html)
+/// and [DoubleEndedIterator](https://doc.rust-lang.org/std/iter/trait.DoubleEndedIterator.html) traits, thereby
+/// giving access to all the excellent methods available for [Iterators](https://doc.rust-lang.org/std/iter/trait.Iterator.html).
+///
+/// ```rust
+/// # use polars_core::prelude::*;
+///
+/// fn iter_forward(ca: &Float32Chunked) {
+///     ca.into_iter()
+///         .for_each(|opt_v| println!("{:?}", opt_v))
+/// }
+///
+/// fn iter_backward(ca: &Float32Chunked) {
+///     ca.into_iter()
+///         .rev()
+///         .for_each(|opt_v| println!("{:?}", opt_v))
+/// }
+/// ```
+///
+/// # Memory layout
+///
+/// `ChunkedArray`'s use [Apache Arrow](https://github.com/apache/arrow) as backend for the memory layout.
+/// Arrows memory is immutable which makes it possible to make multiple zero copy (sub)-views from a single array.
+///
+/// To be able to append data, Polars uses chunks to append new memory locations, hence the `ChunkedArray<T>` data structure.
+/// Appends are cheap, because it will not lead to a full reallocation of the whole array (as could be the case with a Rust Vec).
+///
+/// However, multiple chunks in a `ChunkArray` will slow down many operations that need random access because we have an extra indirection
+/// and indexes need to be mapped to the proper chunk. Arithmetic may also be slowed down by this.
+/// When multiplying two `ChunkArray'`s with different chunk sizes they cannot utilize [SIMD](https://en.wikipedia.org/wiki/SIMD) for instance.
+///
+/// If you want to have predictable performance
+/// (no unexpected re-allocation of memory), it is advised to call the [ChunkedArray::rechunk] after
+/// multiple append operations.
+///
+/// See also [`ChunkedArray::extend`] for appends within a chunk.
+pub struct ChunkedArray<T: PolarsDataType> {
+    pub(crate) field: Arc<Field>,
+    pub(crate) chunks: Vec<ArrayRef>,
+    phantom: PhantomData<T>,
+    pub(crate) bit_settings: Settings,
+    length: IdxSize,
+}
 
-use hashbrown::hash_map::RawEntryMut;
-use num_traits::NumCast;
-use polars_core::export::ahash::RandomState;
-use polars_core::frame::row::AnyValueBuffer;
-use polars_core::prelude::*;
-use polars_core::utils::_set_partition_size;
-use polars_core::{IdBuildHasher, POOL};
-use polars_utils::hash_to_partition;
-use polars_utils::slice::GetSaferUnchecked;
-use polars_utils::unwrap::UnwrapUncheckedRelease;
-use rayon::prelude::*;
-
-use super::aggregates::AggregateFn;
-use super::generic::Key;
-use crate::executors::sinks::groupby::aggregates::AggregateFunction;
-use crate::executors::sinks::groupby::ooc_state::OocState;
-use crate::executors::sinks::groupby::physical_agg_to_logical;
-use crate::executors::sinks::groupby::primitive::apply_aggregation;
-use crate::executors::sinks::groupby::utils::{compute_slices, finalize_groupby};
-use crate::executors::sinks::io::IOThread;
-use crate::executors::sinks::utils::load_vec;
-use crate::executors::sinks::HASHMAP_INIT_SIZE;
-use crate::expressions::PhysicalPipedExpr;
-use crate::operators::{DataChunk, FinalizedSink, PExecutionContext, Sink, SinkResult};
-use crate::pipeline::FORCE_OOC_GROUPBY;
-
-// we store a hashmap per partition (partitioned by hash)
-// the hashmap contains indexes as keys and as values
-// those indexes point into the keys buffer and the values buffer
-// the keys buffer are buffers of AnyValue per partition
-// and the values are buffer of Aggregation functions per partition
-pub struct Utf8GroupbySink {
-    thread_no: usize,
-    // idx is the offset in the array with keys
-    // idx is the offset in the array with aggregators
-    pre_agg_partitions: Vec<PlIdHashMap<Key, IdxSize>>,
-    // the aggregations/keys are all tightly packed
-    // the aggregation function of a group can be found
-    // by:
-    //      * offset = (idx)
-    //      * end = (offset + 1)
-    keys: Vec<Option<smartstring::alias::String>>,
-    aggregators: Vec<AggregateFunction>,
-    // the key that will be aggregated on
-    key_column: Arc<dyn PhysicalPipedExpr>,
-    // the columns that will be aggregated
-    aggregation_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
-    hb: RandomState,
-    // Initializing Aggregation functions. If we aggregate by 2 columns
-    // this vec will have two functions. We will use these functions
-    // to populate the buffer where the hashmap points to
-    agg_fns: Vec<AggregateFunction>,
-    input_schema: SchemaRef,
-    output_schema: SchemaRef,
-    // amortize allocations
-    aggregation_series: Vec<Series>,
-    hashes: Vec<u64>,
-    slice: Option<(i64, usize)>,
-
-    ooc_state: OocState,
-}
-
-impl Utf8GroupbySink {
-    pub(crate) fn new(
-        key_column: Arc<dyn PhysicalPipedExpr>,
-        aggregation_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
-        agg_fns: Vec<AggregateFunction>,
-        input_schema: SchemaRef,
-        output_schema: SchemaRef,
-        slice: Option<(i64, usize)>,
-    ) -> Self {
-        let ooc = std::env::var(FORCE_OOC_GROUPBY).is_ok();
-        Self::new_inner(
-            key_column,
-            aggregation_columns,
-            agg_fns,
-            input_schema,
-            output_schema,
-            slice,
-            None,
-            ooc,
-        )
+bitflags! {
+    #[derive(Default)]
+    pub(crate) struct Settings: u8 {
+    const SORTED_ASC = 0x01;
+    const SORTED_DSC = 0x02;
+    const FAST_EXPLODE_LIST = 0x04;
+}}
+
+impl<T: PolarsDataType> ChunkedArray<T> {
+    pub(crate) fn is_sorted_ascending_flag(&self) -> bool {
+        self.bit_settings.contains(Settings::SORTED_ASC)
     }
 
-    #[allow(clippy::too_many_arguments)]
-    fn new_inner(
-        key_column: Arc<dyn PhysicalPipedExpr>,
-        aggregation_columns: Arc<Vec<Arc<dyn PhysicalPipedExpr>>>,
-        agg_fns: Vec<AggregateFunction>,
-        input_schema: SchemaRef,
-        output_schema: SchemaRef,
-        slice: Option<(i64, usize)>,
-        io_thread: Option<Arc<Mutex<Option<IOThread>>>>,
-        ooc: bool,
-    ) -> Self {
-        let hb = Default::default();
-        let partitions = _set_partition_size();
+    pub(crate) fn is_sorted_descending_flag(&self) -> bool {
+        self.bit_settings.contains(Settings::SORTED_DSC)
+    }
 
-        let pre_agg = load_vec(partitions, || PlIdHashMap::with_capacity(HASHMAP_INIT_SIZE));
-        let keys = Vec::with_capacity(HASHMAP_INIT_SIZE * partitions);
-        let aggregators =
-            Vec::with_capacity(HASHMAP_INIT_SIZE * aggregation_columns.len() * partitions);
-
-        let mut out = Self {
-            thread_no: 0,
-            pre_agg_partitions: pre_agg,
-            keys,
-            aggregators,
-            key_column,
-            aggregation_columns,
-            hb,
-            agg_fns,
-            input_schema,
-            output_schema,
-            aggregation_series: vec![],
-            hashes: vec![],
-            slice,
-            ooc_state: OocState::new(io_thread, ooc),
-        };
-        if ooc {
-            out.ooc_state.init_ooc(out.input_schema.clone()).unwrap();
+    pub fn unset_fast_explode_list(&mut self) {
+        self.bit_settings.remove(Settings::FAST_EXPLODE_LIST)
+    }
+
+    pub fn is_sorted_flag2(&self) -> IsSorted {
+        if self.is_sorted_ascending_flag() {
+            IsSorted::Ascending
+        } else if self.is_sorted_descending_flag() {
+            IsSorted::Descending
+        } else {
+            IsSorted::Not
         }
-        out
     }
 
-    #[inline]
-    fn number_of_aggs(&self) -> usize {
-        self.aggregation_columns.len()
+    /// Set the 'sorted' bit meta info.
+    pub fn set_sorted_flag(&mut self, sorted: IsSorted) {
+        match sorted {
+            IsSorted::Not => {
+                self.bit_settings
+                    .remove(Settings::SORTED_ASC | Settings::SORTED_DSC);
+            }
+            IsSorted::Ascending => {
+                // // unset descending sorted
+                self.bit_settings.remove(Settings::SORTED_DSC);
+                // set ascending sorted
+                self.bit_settings.insert(Settings::SORTED_ASC)
+            }
+            IsSorted::Descending => {
+                // unset ascending sorted
+                self.bit_settings.remove(Settings::SORTED_ASC);
+                // set descending sorted
+                self.bit_settings.insert(Settings::SORTED_DSC)
+            }
+        }
     }
 
-    fn pre_finalize(&mut self) -> PolarsResult<Vec<DataFrame>> {
-        // we create a pointer to the aggregation functions buffer
-        // we will deref *mut on every partition thread
-        // this will be safe, as the partitions guarantee that access don't alias.
-        let aggregators = self.aggregators.as_ptr() as usize;
-        let aggregators_len = self.aggregators.len();
-
-        let slices = compute_slices(&self.pre_agg_partitions, self.slice);
-
-        POOL.install(|| {
-            let dfs =
-                self.pre_agg_partitions
-                    .par_iter()
-                    .zip(slices.par_iter())
-                    .filter_map(|(agg_map, slice)| {
-                        let ptr = aggregators as *mut AggregateFunction;
-                        // safety:
-                        // we will not alias.
-                        let aggregators =
-                            unsafe { std::slice::from_raw_parts_mut(ptr, aggregators_len) };
-
-                        let (offset, slice_len) = (*slice)?;
-                        if agg_map.is_empty() {
-                            return None;
-                        }
-                        let dtypes = aggregators
-                            .iter()
-                            .take(self.number_of_aggs())
-                            .map(|func| func.dtype())
-                            .collect::<Vec<_>>();
-
-                        let mut buffers = dtypes
-                            .iter()
-                            .map(|dtype| AnyValueBuffer::new(dtype, slice_len))
-                            .collect::<Vec<_>>();
-
-                        let cap = std::cmp::min(slice_len, agg_map.len());
-                        let mut key_builder = Utf8ChunkedBuilder::new("", cap, cap * 8);
-                        agg_map.into_iter().skip(offset).take(slice_len).for_each(
-                            |(k, &offset)| {
-                                let key_offset = k.idx as usize;
-                                let key = unsafe {
-                                    self.keys.get_unchecked_release(key_offset).as_deref()
-                                };
-                                key_builder.append_option(key);
-
-                                for (i, buffer) in (offset as usize
-                                    ..offset as usize + self.aggregation_columns.len())
-                                    .zip(buffers.iter_mut())
-                                {
-                                    unsafe {
-                                        let agg_fn = aggregators.get_unchecked_release_mut(i);
-                                        let av = agg_fn.finalize();
-                                        buffer.add(av);
-                                    }
-                                }
-                            },
-                        );
-
-                        let mut cols = Vec::with_capacity(1 + self.number_of_aggs());
-                        cols.push(key_builder.finish().into_series());
-                        cols.extend(buffers.into_iter().map(|buf| buf.into_series()));
-                        physical_agg_to_logical(&mut cols, &self.output_schema);
-                        Some(DataFrame::new_no_checks(cols))
-                    })
-                    .collect::<Vec<_>>();
-
-            Ok(dfs)
-        })
-    }
-    fn prepare_key_and_aggregation_series(
-        &mut self,
-        context: &PExecutionContext,
-        chunk: &DataChunk,
-    ) -> PolarsResult<Series> {
-        let s = self
-            .key_column
-            .evaluate(chunk, context.execution_state.as_any())?;
-        let s = s.to_physical_repr();
-        let s = s.rechunk();
-
-        // todo! ammortize allocation
-        for phys_e in self.aggregation_columns.iter() {
-            let s = phys_e.evaluate(chunk, context.execution_state.as_any())?;
-            let s = s.to_physical_repr();
-            self.aggregation_series.push(s.rechunk());
+    /// Get the index of the first non null value in this ChunkedArray.
+    pub fn first_non_null(&self) -> Option<usize> {
+        if self.is_empty() {
+            None
+        } else {
+            first_non_null(self.iter_validities())
         }
-        s.vec_hash(self.hb.clone(), &mut self.hashes).unwrap();
-        Ok(s)
     }
+
+    /// Get the index of the last non null value in this ChunkedArray.
+    pub fn last_non_null(&self) -> Option<usize> {
+        last_non_null(self.iter_validities(), self.length as usize)
+    }
+
+    /// Get the buffer of bits representing null values
     #[inline]
-    fn get_partitions(&mut self, h: u64) -> &mut PlIdHashMap<Key, IdxSize> {
-        let partition = hash_to_partition(h, self.pre_agg_partitions.len());
-        let current_partition =
-            unsafe { self.pre_agg_partitions.get_unchecked_release_mut(partition) };
-
-        current_partition
-    }
-
-    fn sink_ooc(
-        &mut self,
-        context: &PExecutionContext,
-        chunk: DataChunk,
-    ) -> PolarsResult<SinkResult> {
-        let s = self.prepare_key_and_aggregation_series(context, &chunk)?;
-
-        // take containers to please bchk
-        // we put them back once done
-        let mut hashes = std::mem::take(&mut self.hashes);
-        let keys = std::mem::take(&mut self.keys);
-        let agg_fns = std::mem::take(&mut self.agg_fns);
-        let mut aggregators = std::mem::take(&mut self.aggregators);
-
-        // write the hashes to self.hashes buffer
-        // s.vec_hash(self.hb.clone(), &mut self.hashes).unwrap();
-        // now we have written hashes, we take the pointer to this buffer
-        // we will write the aggregation_function indexes in the same buffer
-        // this is unsafe and we must check that we only write the hashes that
-        // already read/taken. So we write on the slots we just read
-        let agg_idx_ptr = hashes.as_ptr() as *mut u64 as *mut IdxSize;
-        // array of the keys
-        let keys_arr = s.utf8().unwrap().downcast_iter().next().unwrap().clone();
-
-        // set all bits to false
-        self.ooc_state.reset_ooc_filter_rows(chunk.data.height());
-
-        let mut processed = 0;
-        for (iteration_idx, (key_val, &h)) in keys_arr.iter().zip(&hashes).enumerate() {
-            let current_partition = self.get_partitions(h);
-            let entry = get_entry(key_val, h, current_partition, &keys);
-
-            match entry {
-                RawEntryMut::Vacant(_) => {
-                    // set this row to true: e.g. processed ooc
-                    // safety: we correctly set the length with `reset_ooc_filter_rows`
-                    unsafe {
-                        self.ooc_state.set_row_as_ooc(iteration_idx);
-                    }
-                }
-                RawEntryMut::Occupied(entry) => {
-                    let agg_idx = *entry.get();
-                    // # Safety
-                    // we write to the hashes buffer we iterate over at the moment.
-                    // this is sound because we writes are trailing from iteration
-                    unsafe { write_agg_idx(agg_idx_ptr, processed, agg_idx) };
-                    processed += 1;
-                }
-            };
+    #[allow(clippy::type_complexity)]
+    pub fn iter_validities(&self) -> Map<Iter<'_, ArrayRef>, fn(&ArrayRef) -> Option<&Bitmap>> {
+        fn to_validity(arr: &ArrayRef) -> Option<&Bitmap> {
+            arr.validity()
         }
+        self.chunks.iter().map(to_validity)
+    }
+
+    #[inline]
+    /// Return if any the chunks in this `[ChunkedArray]` have a validity bitmap.
+    /// no bitmap means no null values.
+    pub fn has_validity(&self) -> bool {
+        self.iter_validities().any(|valid| valid.is_some())
+    }
+
+    /// Shrink the capacity of this array to fit its length.
+    pub fn shrink_to_fit(&mut self) {
+        self.chunks = vec![arrow::compute::concatenate::concatenate(
+            self.chunks
+                .iter()
+                .map(|a| &**a)
+                .collect::<Vec<_>>()
+                .as_slice(),
+        )
+        .unwrap()];
+    }
 
-        // note that this slice looks into the self.hashes buffer
-        let agg_idxs = unsafe { std::slice::from_raw_parts(agg_idx_ptr, processed) };
+    /// Unpack a Series to the same physical type.
+    ///
+    /// # Safety
+    ///
+    /// This is unsafe as the dtype may be incorrect and
+    /// is assumed to be correct in other safe code.
+    pub(crate) unsafe fn unpack_series_matching_physical_type(
+        &self,
+        series: &Series,
+    ) -> &ChunkedArray<T> {
+        let series_trait = &**series;
+        if self.dtype() == series.dtype() {
+            &*(series_trait as *const dyn SeriesTrait as *const ChunkedArray<T>)
+        } else {
+            use DataType::*;
+            match (self.dtype(), series.dtype()) {
+                (Int64, Datetime(_, _)) | (Int64, Duration(_)) | (Int32, Date) => {
+                    &*(series_trait as *const dyn SeriesTrait as *const ChunkedArray<T>)
+                }
+                _ => panic!(
+                    "cannot unpack series {:?} into matching type {:?}",
+                    series,
+                    self.dtype()
+                ),
+            }
+        }
+    }
 
-        apply_aggregation(
-            agg_idxs,
-            &chunk,
-            self.number_of_aggs(),
-            &self.aggregation_series,
-            &agg_fns,
-            &mut aggregators,
+    /// Series to ChunkedArray<T>
+    pub fn unpack_series_matching_type(&self, series: &Series) -> PolarsResult<&ChunkedArray<T>> {
+        polars_ensure!(
+            self.dtype() == series.dtype(),
+            SchemaMismatch: "cannot unpack series of type `{}` into `{}`",
+            series.dtype(),
+            self.dtype(),
         );
-        self.ooc_state.dump(chunk.data, &mut hashes);
+        // Safety
+        // dtype will be correct.
+        Ok(unsafe { self.unpack_series_matching_physical_type(series) })
+    }
+
+    /// Unique id representing the number of chunks
+    pub fn chunk_id(&self) -> ChunkIdIter {
+        self.chunks.iter().map(|chunk| chunk.len())
+    }
+
+    /// A reference to the chunks
+    #[inline]
+    pub fn chunks(&self) -> &Vec<ArrayRef> {
+        &self.chunks
+    }
+
+    /// A mutable reference to the chunks
+    ///
+    /// # Safety
+    /// The caller must ensure to not change the `DataType` or `length` of any of the chunks.
+    #[inline]
+    pub unsafe fn chunks_mut(&mut self) -> &mut Vec<ArrayRef> {
+        &mut self.chunks
+    }
+
+    /// Returns true if contains a single chunk and has no null values
+    pub fn is_optimal_aligned(&self) -> bool {
+        self.chunks.len() == 1 && self.null_count() == 0
+    }
+
+    /// Count the null values.
+    #[inline]
+    pub fn null_count(&self) -> usize {
+        self.chunks.iter().map(|arr| arr.null_count()).sum()
+    }
+
+    /// Create a new ChunkedArray from self, where the chunks are replaced.
+    fn copy_with_chunks(
+        &self,
+        chunks: Vec<ArrayRef>,
+        keep_sorted: bool,
+        keep_fast_explode: bool,
+    ) -> Self {
+        let mut out = ChunkedArray {
+            field: self.field.clone(),
+            chunks,
+            phantom: PhantomData,
+            bit_settings: self.bit_settings,
+            length: 0,
+        };
+        out.compute_len();
+        if !keep_sorted {
+            out.set_sorted_flag(IsSorted::Not);
+        }
+        if !keep_fast_explode {
+            out.unset_fast_explode_list()
+        }
+        out
+    }
+
+    /// Get data type of ChunkedArray.
+    pub fn dtype(&self) -> &DataType {
+        self.field.data_type()
+    }
+
+    #[cfg(feature = "dtype-struct")]
+    pub(crate) unsafe fn set_dtype(&mut self, dtype: DataType) {
+        self.field = Arc::new(Field::new(self.name(), dtype))
+    }
 
-        self.aggregation_series.clear();
-        self.hashes = hashes;
-        self.keys = keys;
-        self.agg_fns = agg_fns;
-        self.aggregators = aggregators;
-        self.hashes.clear();
-        self.ooc_state.check_memory_usage(&self.input_schema)?;
-        Ok(SinkResult::CanHaveMoreInput)
+    /// Name of the ChunkedArray.
+    pub fn name(&self) -> &str {
+        self.field.name()
+    }
+
+    /// Get a reference to the field.
+    pub fn ref_field(&self) -> &Field {
+        &self.field
+    }
+
+    /// Rename this ChunkedArray.
+    pub fn rename(&mut self, name: &str) {
+        self.field = Arc::new(Field::new(name, self.field.data_type().clone()))
     }
 }
 
-impl Sink for Utf8GroupbySink {
-    fn sink(&mut self, context: &PExecutionContext, chunk: DataChunk) -> PolarsResult<SinkResult> {
-        if self.ooc_state.ooc {
-            return self.sink_ooc(context, chunk);
-        }
-        let s = self.prepare_key_and_aggregation_series(context, &chunk)?;
-
-        // take containers to please bchk
-        // we put them back once done
-        let hashes = std::mem::take(&mut self.hashes);
-        let mut keys = std::mem::take(&mut self.keys);
-        let agg_fns = std::mem::take(&mut self.agg_fns);
-        let mut aggregators = std::mem::take(&mut self.aggregators);
-
-        // write the hashes to self.hashes buffer
-        // s.vec_hash(self.hb.clone(), &mut self.hashes).unwrap();
-        // now we have written hashes, we take the pointer to this buffer
-        // we will write the aggregation_function indexes in the same buffer
-        // this is unsafe and we must check that we only write the hashes that
-        // already read/taken. So we write on the slots we just read
-        let agg_idx_ptr = hashes.as_ptr() as *mut u64 as *mut IdxSize;
-        // array of the keys
-        let keys_arr = s.utf8().unwrap().downcast_iter().next().unwrap().clone();
-
-        for (iteration_idx, (key_val, &h)) in keys_arr.iter().zip(&hashes).enumerate() {
-            let current_partition = self.get_partitions(h);
-            let entry = get_entry(key_val, h, current_partition, &keys);
-
-            let agg_idx = match entry {
-                RawEntryMut::Vacant(entry) => {
-                    let value_offset =
-                        unsafe { NumCast::from(aggregators.len()).unwrap_unchecked_release() };
-                    let keys_offset = unsafe {
-                        Key::new(h, NumCast::from(keys.len()).unwrap_unchecked_release())
-                    };
-                    entry.insert(keys_offset, value_offset);
-
-                    keys.push(key_val.map(|s| s.into()));
-
-                    // initialize the aggregators
-                    for agg_fn in &agg_fns {
-                        aggregators.push(agg_fn.split2())
-                    }
-                    value_offset
-                }
-                RawEntryMut::Occupied(entry) => *entry.get(),
-            };
-            // # Safety
-            // we write to the hashes buffer we iterate over at the moment.
-            // this is sound because we writes are trailing from iteration
-            unsafe { write_agg_idx(agg_idx_ptr, iteration_idx, agg_idx) };
-        }
-
-        // note that this slice looks into the self.hashes buffer
-        let agg_idxs = unsafe { std::slice::from_raw_parts(agg_idx_ptr, keys_arr.len()) };
-
-        apply_aggregation(
-            agg_idxs,
-            &chunk,
-            self.number_of_aggs(),
-            &self.aggregation_series,
-            &agg_fns,
-            &mut aggregators,
-        );
-        self.aggregation_series.clear();
-        self.hashes = hashes;
-        self.keys = keys;
-        self.agg_fns = agg_fns;
-        self.aggregators = aggregators;
-        self.hashes.clear();
-        self.ooc_state.check_memory_usage(&self.input_schema)?;
-        Ok(SinkResult::CanHaveMoreInput)
-    }
-
-    fn combine(&mut self, other: &mut dyn Sink) {
-        // don't parallelize this as this is already done in parallel.
-
-        let other = other.as_any().downcast_ref::<Self>().unwrap();
-        let n_partitions = self.pre_agg_partitions.len();
-        debug_assert_eq!(n_partitions, other.pre_agg_partitions.len());
-
-        self.pre_agg_partitions
-            .iter_mut()
-            .zip(other.pre_agg_partitions.iter())
-            .for_each(|(map_self, map_other)| {
-                for (k_other, &agg_idx_other) in map_other.iter() {
-                    // the hash value
-                    let h = k_other.hash;
-
-                    // the offset in the keys of other
-                    let idx_other = k_other.idx as usize;
-                    // slice to the keys of other
-                    let key_other = unsafe { other.keys.get_unchecked_release(idx_other) };
-
-                    let entry = map_self.raw_entry_mut().from_hash(h, |k_self| {
-                        h == k_self.hash && {
-                            // the offset in the keys of self
-                            let idx_self = k_self.idx as usize;
-                            // slice to the keys of self
-                            // safety:
-                            // in bounds
-                            let key_self = unsafe { self.keys.get_unchecked_release(idx_self) };
-                            // compare the keys
-                            key_self == key_other
-                        }
-                    });
-
-                    let agg_idx_self = match entry {
-                        // the keys of other are not in this table, so we must update this table
-                        RawEntryMut::Vacant(entry) => {
-                            // get the current offset in the values buffer
-                            let values_offset = unsafe {
-                                NumCast::from(self.aggregators.len()).unwrap_unchecked_release()
-                            };
-                            // get the key, comprised of the hash and the current offset in the keys buffer
-                            let key = unsafe {
-                                Key::new(
-                                    h,
-                                    NumCast::from(self.keys.len()).unwrap_unchecked_release(),
-                                )
-                            };
-
-                            // extend the keys buffer with the new key from other
-                            self.keys.push(key_other.clone());
-
-                            // insert the keys and values_offset
-                            entry.insert(key, values_offset);
-                            // initialize the new aggregators
-                            for agg_fn in &self.agg_fns {
-                                self.aggregators.push(agg_fn.split2())
-                            }
-                            values_offset
-                        }
-                        RawEntryMut::Occupied(entry) => *entry.get(),
-                    };
-
-                    // combine the aggregation functions
-                    for i in 0..self.aggregation_columns.len() {
-                        unsafe {
-                            let agg_fn_other = other
-                                .aggregators
-                                .get_unchecked_release(agg_idx_other as usize + i);
-                            let agg_fn_self = self
-                                .aggregators
-                                .get_unchecked_release_mut(agg_idx_self as usize + i);
-                            agg_fn_self.combine(agg_fn_other.as_any())
-                        }
-                    }
-                }
-            });
+impl<T> ChunkedArray<T>
+where
+    T: PolarsDataType,
+{
+    /// Should be used to match the chunk_id of another ChunkedArray.
+    /// # Panics
+    /// It is the callers responsibility to ensure that this ChunkedArray has a single chunk.
+    pub(crate) fn match_chunks<I>(&self, chunk_id: I) -> Self
+    where
+        I: Iterator<Item = usize>,
+    {
+        debug_assert!(self.chunks.len() == 1);
+        // Takes a ChunkedArray containing a single chunk
+        let slice = |ca: &Self| {
+            let array = &ca.chunks[0];
+
+            let mut offset = 0;
+            let chunks = chunk_id
+                .map(|len| {
+                    // safety:
+                    // within bounds
+                    debug_assert!((offset + len) <= array.len());
+                    let out = unsafe { array.sliced_unchecked(offset, len) };
+                    offset += len;
+                    out
+                })
+                .collect();
+
+            unsafe { Self::from_chunks(self.name(), chunks) }
+        };
+
+        if self.chunks.len() != 1 {
+            let out = self.rechunk();
+            slice(&out)
+        } else {
+            slice(self)
+        }
+    }
+}
+
+impl<T: PolarsDataType> AsRefDataType for ChunkedArray<T> {
+    fn as_ref_dtype(&self) -> &DataType {
+        self.dtype()
     }
+}
+
+pub(crate) trait AsSinglePtr: AsRefDataType {
+    /// Rechunk and return a ptr to the start of the array
+    fn as_single_ptr(&mut self) -> PolarsResult<usize> {
+        polars_bail!(opq = as_single_ptr, self.as_ref_dtype());
+    }
+}
 
-    fn split(&self, thread_no: usize) -> Box<dyn Sink> {
-        let mut new = Self::new_inner(
-            self.key_column.clone(),
-            self.aggregation_columns.clone(),
-            self.agg_fns.iter().map(|func| func.split2()).collect(),
-            self.input_schema.clone(),
-            self.output_schema.clone(),
-            self.slice,
-            Some(self.ooc_state.io_thread.clone()),
-            self.ooc_state.ooc,
+impl<T> AsSinglePtr for ChunkedArray<T>
+where
+    T: PolarsNumericType,
+{
+    fn as_single_ptr(&mut self) -> PolarsResult<usize> {
+        let mut ca = self.rechunk();
+        mem::swap(&mut ca, self);
+        let a = self.data_views().next().unwrap();
+        let ptr = a.as_ptr();
+        Ok(ptr as usize)
+    }
+}
+
+impl AsSinglePtr for BooleanChunked {}
+impl AsSinglePtr for ListChunked {}
+impl AsSinglePtr for Utf8Chunked {}
+impl AsSinglePtr for BinaryChunked {}
+#[cfg(feature = "object")]
+impl<T: PolarsObject> AsSinglePtr for ObjectChunked<T> {}
+
+impl<T> ChunkedArray<T>
+where
+    T: PolarsNumericType,
+{
+    /// Contiguous slice
+    pub fn cont_slice(&self) -> PolarsResult<&[T::Native]> {
+        polars_ensure!(
+            self.chunks.len() == 1 && self.chunks[0].null_count() == 0,
+            ComputeError: "chunked array is not contiguous"
         );
-        new.hb = self.hb.clone();
-        new.thread_no = thread_no;
-        Box::new(new)
-    }
-
-    fn finalize(&mut self, _context: &PExecutionContext) -> PolarsResult<FinalizedSink> {
-        let dfs = self.pre_finalize()?;
-        let payload = if self.ooc_state.ooc {
-            let mut iot = self.ooc_state.io_thread.lock().unwrap();
-            // make sure that we reset the shared states
-            // the OOC groupby will call split as well and it should
-            // not send continue spilling to disk
-            let iot = iot.take().unwrap();
-            self.ooc_state.ooc = false;
+        Ok(self.downcast_iter().next().map(|arr| arr.values()).unwrap())
+    }
 
-            Some((iot, self.split(0)))
+    /// Contiguous mutable slice
+    pub(crate) fn cont_slice_mut(&mut self) -> Option<&mut [T::Native]> {
+        if self.chunks.len() == 1 && self.chunks[0].null_count() == 0 {
+            // Safety, we will not swap the PrimitiveArray.
+            let arr = unsafe { self.downcast_iter_mut().next().unwrap() };
+            arr.get_mut_values()
         } else {
             None
-        };
-        finalize_groupby(dfs, &self.output_schema, self.slice, payload)
+        }
+    }
+
+    /// Get slices of the underlying arrow data.
+    /// NOTE: null values should be taken into account by the user of these slices as they are handled
+    /// separately
+    pub fn data_views(&self) -> impl Iterator<Item = &[T::Native]> + DoubleEndedIterator {
+        self.downcast_iter().map(|arr| arr.values().as_slice())
+    }
+
+    #[allow(clippy::wrong_self_convention)]
+    pub fn into_no_null_iter(
+        &self,
+    ) -> impl Iterator<Item = T::Native>
+           + '_
+           + Send
+           + Sync
+           + ExactSizeIterator
+           + DoubleEndedIterator
+           + TrustedLen {
+        // .copied was significantly slower in benchmark, next call did not inline?
+        #[allow(clippy::map_clone)]
+        // we know the iterators len
+        unsafe {
+            self.data_views()
+                .flatten()
+                .map(|v| *v)
+                .trust_my_length(self.len())
+        }
+    }
+}
+
+impl<T: PolarsDataType> Clone for ChunkedArray<T> {
+    fn clone(&self) -> Self {
+        ChunkedArray {
+            field: self.field.clone(),
+            chunks: self.chunks.clone(),
+            phantom: PhantomData,
+            bit_settings: self.bit_settings,
+            length: self.length,
+        }
     }
+}
 
-    fn as_any(&mut self) -> &mut dyn Any {
+impl<T: PolarsDataType> AsRef<ChunkedArray<T>> for ChunkedArray<T> {
+    fn as_ref(&self) -> &ChunkedArray<T> {
         self
     }
-    fn fmt(&self) -> &str {
-        "utf8_groupby"
+}
+
+impl ValueSize for ListChunked {
+    fn get_values_size(&self) -> usize {
+        self.chunks
+            .iter()
+            .fold(0usize, |acc, arr| acc + arr.get_values_size())
     }
 }
 
-// write agg_idx to the hashes buffer.
-pub(super) unsafe fn write_agg_idx(h: *mut IdxSize, i: usize, agg_idx: IdxSize) {
-    h.add(i).write(agg_idx)
-}
-
-pub(super) fn apply_aggregate(
-    agg_i: usize,
-    chunk_idx: IdxSize,
-    agg_idxs: &[IdxSize],
-    aggregation_s: &Series,
-    has_physical_agg: bool,
-    aggregators: &mut [AggregateFunction],
-) {
-    macro_rules! apply_agg {
-                ($self:expr, $macro:ident $(, $opt_args:expr)*) => {{
-                    match $self.dtype() {
-                        #[cfg(feature = "dtype-u8")]
-                        DataType::UInt8 => $macro!($self.u8().unwrap(), pre_agg_u8 $(, $opt_args)*),
-                        #[cfg(feature = "dtype-u16")]
-                        DataType::UInt16 => $macro!($self.u16().unwrap(), pre_agg_u16 $(, $opt_args)*),
-                        DataType::UInt32 => $macro!($self.u32().unwrap(), pre_agg_u32 $(, $opt_args)*),
-                        DataType::UInt64 => $macro!($self.u64().unwrap(), pre_agg_u64 $(, $opt_args)*),
-                        #[cfg(feature = "dtype-i8")]
-                        DataType::Int8 => $macro!($self.i8().unwrap(), pre_agg_i8 $(, $opt_args)*),
-                        #[cfg(feature = "dtype-i16")]
-                        DataType::Int16 => $macro!($self.i16().unwrap(), pre_agg_i16 $(, $opt_args)*),
-                        DataType::Int32 => $macro!($self.i32().unwrap(), pre_agg_i32 $(, $opt_args)*),
-                        DataType::Int64 => $macro!($self.i64().unwrap(), pre_agg_i64 $(, $opt_args)*),
-                        DataType::Float32 => $macro!($self.f32().unwrap(), pre_agg_f32 $(, $opt_args)*),
-                        DataType::Float64 => $macro!($self.f64().unwrap(), pre_agg_f64 $(, $opt_args)*),
-                        dt => panic!("not implemented for {:?}", dt),
-                    }
-                }};
-            }
+impl ValueSize for Utf8Chunked {
+    fn get_values_size(&self) -> usize {
+        self.chunks
+            .iter()
+            .fold(0usize, |acc, arr| acc + arr.get_values_size())
+    }
+}
 
-    if has_physical_agg && aggregation_s.dtype().is_numeric() {
-        macro_rules! dispatch {
-            ($ca:expr, $name:ident) => {{
-                let arr = $ca.downcast_iter().next().unwrap();
-
-                for (&agg_idx, av) in agg_idxs.iter().zip(arr.into_iter()) {
-                    let i = agg_idx as usize + agg_i;
-                    let agg_fn = unsafe { aggregators.get_unchecked_release_mut(i) };
+impl ValueSize for BinaryChunked {
+    fn get_values_size(&self) -> usize {
+        self.chunks
+            .iter()
+            .fold(0usize, |acc, arr| acc + arr.get_values_size())
+    }
+}
 
-                    agg_fn.$name(chunk_idx, av.copied())
-                }
-            }};
+impl ListChunked {
+    /// Get the inner data type of the list.
+    pub fn inner_dtype(&self) -> DataType {
+        match self.dtype() {
+            DataType::List(dt) => *dt.clone(),
+            _ => unreachable!(),
         }
+    }
 
-        apply_agg!(aggregation_s, dispatch);
-    } else {
-        let mut iter = aggregation_s.phys_iter();
-        for &agg_idx in agg_idxs.iter() {
-            let i = agg_idx as usize + agg_i;
-            let agg_fn = unsafe { aggregators.get_unchecked_release_mut(i) };
-            agg_fn.pre_agg(chunk_idx, &mut iter)
-        }
+    pub fn set_inner_dtype(&mut self, dtype: DataType) {
+        assert_eq!(dtype.to_physical(), self.inner_dtype().to_physical());
+        let field = Arc::make_mut(&mut self.field);
+        field.coerce(DataType::List(Box::new(dtype)));
     }
 }
 
-#[inline]
-fn get_entry<'a>(
-    key_val: Option<&str>,
-    h: u64,
-    current_partition: &'a mut PlIdHashMap<Key, IdxSize>,
-    keys: &[Option<smartstring::alias::String>],
-) -> RawEntryMut<'a, Key, IdxSize, IdBuildHasher> {
-    current_partition.raw_entry_mut().from_hash(h, |key| {
-        // first compare the hash before we incur the cache miss
-        key.hash == h && {
-            let idx = key.idx as usize;
-            unsafe { keys.get_unchecked_release(idx).as_deref() == key_val }
-        }
-    })
+pub(crate) fn to_primitive<T: PolarsNumericType>(
+    values: Vec<T::Native>,
+    validity: Option<Bitmap>,
+) -> PrimitiveArray<T::Native> {
+    PrimitiveArray::new(T::get_dtype().to_arrow(), values.into(), validity)
+}
+
+pub(crate) fn to_array<T: PolarsNumericType>(
+    values: Vec<T::Native>,
+    validity: Option<Bitmap>,
+) -> ArrayRef {
+    Box::new(to_primitive::<T>(values, validity))
+}
+
+impl<T: PolarsNumericType> From<PrimitiveArray<T::Native>> for ChunkedArray<T> {
+    fn from(a: PrimitiveArray<T::Native>) -> Self {
+        unsafe { ChunkedArray::from_chunks("", vec![Box::new(a)]) }
+    }
+}
+
+#[cfg(test)]
+pub(crate) mod test {
+    use crate::prelude::*;
+
+    pub(crate) fn get_chunked_array() -> Int32Chunked {
+        ChunkedArray::new("a", &[1, 2, 3])
+    }
+
+    #[test]
+    fn test_sort() {
+        let a = Int32Chunked::new("a", &[1, 9, 3, 2]);
+        let b = a
+            .sort(false)
+            .into_iter()
+            .map(|opt| opt.unwrap())
+            .collect::<Vec<_>>();
+        assert_eq!(b, [1, 2, 3, 9]);
+        let a = Utf8Chunked::new("a", &["b", "a", "c"]);
+        let a = a.sort(false);
+        let b = a.into_iter().collect::<Vec<_>>();
+        assert_eq!(b, [Some("a"), Some("b"), Some("c")]);
+        assert!(a.is_sorted_ascending_flag());
+    }
+
+    #[test]
+    fn arithmetic() {
+        let a = &Int32Chunked::new("a", &[1, 100, 6, 40]);
+        let b = &Int32Chunked::new("b", &[-1, 2, 3, 4]);
+
+        // Not really asserting anything here but shill making sure the code is exercised
+        // This (and more) is properly tested from the integration test suite and Python bindings.
+        println!("{:?}", a + b);
+        println!("{:?}", a - b);
+        println!("{:?}", a * b);
+        println!("{:?}", a / b);
+    }
+
+    #[test]
+    fn iter() {
+        let s1 = get_chunked_array();
+        // sum
+        assert_eq!(s1.into_iter().fold(0, |acc, val| { acc + val.unwrap() }), 6)
+    }
+
+    #[test]
+    fn limit() {
+        let a = get_chunked_array();
+        let b = a.limit(2);
+        println!("{:?}", b);
+        assert_eq!(b.len(), 2)
+    }
+
+    #[test]
+    fn filter() {
+        let a = get_chunked_array();
+        let b = a
+            .filter(&BooleanChunked::new("filter", &[true, false, false]))
+            .unwrap();
+        assert_eq!(b.len(), 1);
+        assert_eq!(b.into_iter().next(), Some(Some(1)));
+    }
+
+    #[test]
+    fn aggregates() {
+        let a = &Int32Chunked::new("a", &[1, 100, 10, 9]);
+        assert_eq!(a.max(), Some(100));
+        assert_eq!(a.min(), Some(1));
+        assert_eq!(a.sum(), Some(120))
+    }
+
+    #[test]
+    fn take() {
+        let a = get_chunked_array();
+        let new = a.take([0usize, 1].iter().copied().into()).unwrap();
+        assert_eq!(new.len(), 2)
+    }
+
+    #[test]
+    fn cast() {
+        let a = get_chunked_array();
+        let b = a.cast(&DataType::Int64).unwrap();
+        assert_eq!(b.dtype(), &ArrowDataType::Int64)
+    }
+
+    fn assert_slice_equal<T>(ca: &ChunkedArray<T>, eq: &[T::Native])
+    where
+        T: PolarsNumericType,
+    {
+        assert_eq!(
+            ca.into_iter().map(|opt| opt.unwrap()).collect::<Vec<_>>(),
+            eq
+        )
+    }
+
+    #[test]
+    fn slice() {
+        let mut first = UInt32Chunked::new("first", &[0, 1, 2]);
+        let second = UInt32Chunked::new("second", &[3, 4, 5]);
+        first.append(&second);
+        assert_slice_equal(&first.slice(0, 3), &[0, 1, 2]);
+        assert_slice_equal(&first.slice(0, 4), &[0, 1, 2, 3]);
+        assert_slice_equal(&first.slice(1, 4), &[1, 2, 3, 4]);
+        assert_slice_equal(&first.slice(3, 2), &[3, 4]);
+        assert_slice_equal(&first.slice(3, 3), &[3, 4, 5]);
+        assert_slice_equal(&first.slice(-3, 3), &[3, 4, 5]);
+        assert_slice_equal(&first.slice(-6, 6), &[0, 1, 2, 3, 4, 5]);
+
+        assert_eq!(first.slice(-7, 2).len(), 2);
+        assert_eq!(first.slice(-3, 4).len(), 3);
+        assert_eq!(first.slice(3, 4).len(), 3);
+        assert_eq!(first.slice(10, 4).len(), 0);
+    }
+
+    #[test]
+    fn sorting() {
+        let s = UInt32Chunked::new("", &[9, 2, 4]);
+        let sorted = s.sort(false);
+        assert_slice_equal(&sorted, &[2, 4, 9]);
+        let sorted = s.sort(true);
+        assert_slice_equal(&sorted, &[9, 4, 2]);
+
+        let s: Utf8Chunked = ["b", "a", "z"].iter().collect();
+        let sorted = s.sort(false);
+        assert_eq!(
+            sorted.into_iter().collect::<Vec<_>>(),
+            &[Some("a"), Some("b"), Some("z")]
+        );
+        let sorted = s.sort(true);
+        assert_eq!(
+            sorted.into_iter().collect::<Vec<_>>(),
+            &[Some("z"), Some("b"), Some("a")]
+        );
+        let s: Utf8Chunked = [Some("b"), None, Some("z")].iter().copied().collect();
+        let sorted = s.sort(false);
+        assert_eq!(
+            sorted.into_iter().collect::<Vec<_>>(),
+            &[None, Some("b"), Some("z")]
+        );
+    }
+
+    #[test]
+    fn reverse() {
+        let s = UInt32Chunked::new("", &[1, 2, 3]);
+        // path with continuous slice
+        assert_slice_equal(&s.reverse(), &[3, 2, 1]);
+        // path with options
+        let s = UInt32Chunked::new("", &[Some(1), None, Some(3)]);
+        assert_eq!(Vec::from(&s.reverse()), &[Some(3), None, Some(1)]);
+        let s = BooleanChunked::new("", &[true, false]);
+        assert_eq!(Vec::from(&s.reverse()), &[Some(false), Some(true)]);
+
+        let s = Utf8Chunked::new("", &["a", "b", "c"]);
+        assert_eq!(Vec::from(&s.reverse()), &[Some("c"), Some("b"), Some("a")]);
+
+        let s = Utf8Chunked::new("", &[Some("a"), None, Some("c")]);
+        assert_eq!(Vec::from(&s.reverse()), &[Some("c"), None, Some("a")]);
+    }
+
+    #[test]
+    #[cfg(feature = "dtype-categorical")]
+    fn test_iter_categorical() {
+        use crate::{reset_string_cache, SINGLE_LOCK};
+        let _lock = SINGLE_LOCK.lock();
+        reset_string_cache();
+        let ca = Utf8Chunked::new("", &[Some("foo"), None, Some("bar"), Some("ham")]);
+        let ca = ca.cast(&DataType::Categorical(None)).unwrap();
+        let ca = ca.categorical().unwrap();
+        let v: Vec<_> = ca.logical().into_iter().collect();
+        assert_eq!(v, &[Some(0), None, Some(1), Some(2)]);
+    }
+
+    #[test]
+    #[ignore]
+    fn test_shrink_to_fit() {
+        let mut builder = Utf8ChunkedBuilder::new("foo", 2048, 100 * 2048);
+        builder.append_value("foo");
+        let mut arr = builder.finish();
+        let before = arr
+            .chunks()
+            .iter()
+            .map(|arr| arrow::compute::aggregate::estimated_bytes_size(arr.as_ref()))
+            .sum::<usize>();
+        arr.shrink_to_fit();
+        let after = arr
+            .chunks()
+            .iter()
+            .map(|arr| arrow::compute::aggregate::estimated_bytes_size(arr.as_ref()))
+            .sum::<usize>();
+        assert!(before > after);
+    }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/io.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/io.rs`

 * *Files 7% similar despite different names*

```diff
@@ -106,14 +106,20 @@
         let lockfile2 = lockfile.clone();
         std::thread::spawn(move || {
             // this moves the lockfile in the thread
             // we keep one in the thread and one in the `IoThread` struct
             let _keep_hold_on_lockfile = lockfile2;
 
             let mut count = 0usize;
+
+            // We accept 2 cases. E.g.
+            // 1. (None, DfIter):
+            //    This will dump to `dir/count.ipc`
+            // 2. (Some(partitions), DfIter)
+            //    This will dump to `dir/partition/count.ipc`
             while let Ok((partitions, iter)) = receiver.recv() {
                 if let Some(partitions) = partitions {
                     for (part, df) in partitions.into_no_null_iter().zip(iter) {
                         let mut path = dir2.clone();
                         path.push(format!("{part}"));
 
                         let _ = std::fs::create_dir(&path);
@@ -170,14 +176,20 @@
             writer.finish(&mut df).unwrap();
         } else {
             let iter = Box::new(std::iter::once(df));
             self.dump_iter(None, iter)
         }
     }
 
+    pub(in crate::executors::sinks) fn dump_partition(&self, partition_no: IdxSize, df: DataFrame) {
+        let partition = Some(IdxCa::from_vec("", vec![partition_no]));
+        let iter = Box::new(std::iter::once(df));
+        self.dump_iter(partition, iter)
+    }
+
     pub(in crate::executors::sinks) fn dump_iter(&self, partition: Option<IdxCa>, iter: DfIter) {
         let add = iter.size_hint().1.unwrap();
         self.sender.send((partition, iter)).unwrap();
         self.sent.fetch_add(add, Ordering::Relaxed);
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/memory.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/memory.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/mod.rs`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-#[cfg(feature = "parquet")]
+#[cfg(any(feature = "parquet", feature = "ipc"))]
 mod file_sink;
 pub(crate) mod groupby;
 mod io;
 mod joins;
 mod memory;
 mod ordered;
 mod reproject;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sinks/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sinks/utils.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 use polars_core::export::ahash::RandomState;
 use polars_core::prelude::*;
 
 pub(super) fn hash_series(columns: &[Series], buf: &mut Vec<u64>, hb: &RandomState) {
+    debug_assert!(buf.is_empty());
     let mut col_iter = columns.iter();
     let first_key = col_iter.next().unwrap();
     first_key.vec_hash(hb.clone(), buf).unwrap();
     for other_key in col_iter {
         other_key.vec_hash_combine(hb.clone(), buf).unwrap();
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/csv.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/frame.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/frame.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/parquet.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/reproject.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/executors/sources/union.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/executors/sources/union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/chunks.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/chunks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/operators/sink.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/operators/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/convert.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/convert.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 use std::sync::Arc;
 
 use polars_core::prelude::*;
 use polars_core::with_match_physical_integer_polars_type;
 use polars_plan::prelude::*;
 
 use crate::executors::sinks::groupby::aggregates::convert_to_hash_agg;
+use crate::executors::sinks::groupby::GenericGroupby2;
 use crate::executors::sinks::*;
 use crate::executors::{operators, sources};
 use crate::expressions::PhysicalPipedExpr;
 use crate::operators::{Operator, Sink, Source};
 use crate::pipeline::PipeLine;
 
 fn exprs_to_physical<F>(
@@ -220,20 +221,20 @@
                 Box::new(sort_sink) as Box<dyn Sink>
             }
         }
         Distinct { input, options } => {
             // We create a Groupby.agg_first()/agg_last (depending on the keep strategy
             let input_schema = lp_arena.get(*input).schema(lp_arena).into_owned();
 
-            let (keys, aggs, schema) = match &options.subset {
+            let (keys, aggs, output_schema) = match &options.subset {
                 None => {
                     let keys = input_schema
                         .iter_names()
                         .map(|name| expr_arena.add(AExpr::Column(Arc::from(name.as_str()))))
-                        .collect();
+                        .collect::<Vec<_>>();
                     let aggs = vec![];
                     (keys, aggs, input_schema.clone())
                 }
                 Some(keys) => {
                     let mut groupby_out_schema = Schema::with_capacity(input_schema.len());
                     let key_names = PlHashSet::from_iter(keys.iter().map(|s| s.as_ref()));
                     let keys = keys
@@ -268,28 +269,41 @@
                                 })
                             }
                         })
                         .collect();
                     (keys, aggs, groupby_out_schema.into())
                 }
             };
-            let lp = Aggregate {
-                input: *input,
-                keys,
-                aggs,
-                schema,
-                apply: None,
-                maintain_order: false,
-                options: GroupbyOptions {
-                    slice: options.slice,
-                    ..Default::default()
-                },
-            };
-            let node = lp_arena.add(lp);
-            let groupby_sink = get_sink(node, lp_arena, expr_arena, to_physical)?;
+
+            let key_columns = Arc::new(exprs_to_physical(
+                &keys,
+                expr_arena,
+                to_physical,
+                Some(&input_schema),
+            )?);
+
+            let mut aggregation_columns = Vec::with_capacity(aggs.len());
+            let mut agg_fns = Vec::with_capacity(aggs.len());
+
+            for node in &aggs {
+                let (index, agg_fn) =
+                    convert_to_hash_agg(*node, expr_arena, &input_schema, &to_physical);
+                aggregation_columns.push(index);
+                agg_fns.push(agg_fn)
+            }
+            let aggregation_columns = Arc::new(aggregation_columns);
+
+            let groupby_sink = Box::new(GenericGroupby2::new(
+                key_columns,
+                aggregation_columns,
+                Arc::from(agg_fns),
+                output_schema,
+                options.slice,
+            ));
+
             Box::new(ReProjectSink::new(input_schema, groupby_sink))
         }
         Aggregate {
             input,
             keys,
             aggs,
             schema: output_schema,
@@ -311,46 +325,55 @@
                 let (index, agg_fn) =
                     convert_to_hash_agg(*node, expr_arena, &input_schema, &to_physical);
                 aggregation_columns.push(index);
                 agg_fns.push(agg_fn)
             }
             let aggregation_columns = Arc::new(aggregation_columns);
 
-            match (
-                output_schema.get_index(0).unwrap().1.to_physical(),
-                keys.len(),
-            ) {
-                (dt, 1) if dt.is_integer() => {
-                    with_match_physical_integer_polars_type!(dt, |$T| {
-                        Box::new(groupby::PrimitiveGroupbySink::<$T>::new(
-                            key_columns[0].clone(),
-                            aggregation_columns,
-                            agg_fns,
-                            input_schema,
-                            output_schema.clone(),
-                            options.slice,
-                        )) as Box<dyn Sink>
-                    })
-                }
-                (DataType::Utf8, 1) => Box::new(groupby::Utf8GroupbySink::new(
-                    key_columns[0].clone(),
-                    aggregation_columns,
-                    agg_fns,
-                    input_schema,
-                    output_schema.clone(),
-                    options.slice,
-                )) as Box<dyn Sink>,
-                _ => Box::new(groupby::GenericGroupbySink::new(
+            if std::env::var("POLARS_STREAMING_GB2").as_deref() == Ok("1") {
+                Box::new(GenericGroupby2::new(
                     key_columns,
                     aggregation_columns,
-                    agg_fns,
-                    input_schema,
+                    Arc::from(agg_fns),
                     output_schema.clone(),
                     options.slice,
-                )) as Box<dyn Sink>,
+                ))
+            } else {
+                match (
+                    output_schema.get_index(0).unwrap().1.to_physical(),
+                    keys.len(),
+                ) {
+                    (dt, 1) if dt.is_integer() => {
+                        with_match_physical_integer_polars_type!(dt, |$T| {
+                            Box::new(groupby::PrimitiveGroupbySink::<$T>::new(
+                                key_columns[0].clone(),
+                                aggregation_columns,
+                                agg_fns,
+                                input_schema,
+                                output_schema.clone(),
+                                options.slice,
+                            )) as Box<dyn Sink>
+                        })
+                    }
+                    (DataType::Utf8, 1) => Box::new(groupby::Utf8GroupbySink::new(
+                        key_columns[0].clone(),
+                        aggregation_columns,
+                        agg_fns,
+                        input_schema,
+                        output_schema.clone(),
+                        options.slice,
+                    )) as Box<dyn Sink>,
+                    _ => Box::new(GenericGroupby2::new(
+                        key_columns,
+                        aggregation_columns,
+                        Arc::from(agg_fns),
+                        output_schema.clone(),
+                        options.slice,
+                    )),
+                }
             }
         }
         lp => {
             panic!("{lp:?} not implemented")
         }
     };
     Ok(out)
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-pipe/src/pipeline/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/src/pipeline/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-algo/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-algo/Cargo.toml`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-algo/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-pipe/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-algo/src/algo.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-algo/src/algo.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/Cargo.toml`

 * *Files 6% similar despite different names*

```diff
@@ -36,17 +36,17 @@
 
 default = ["private"]
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/date.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/datetime.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/duration.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/kernels.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/kernels.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/time.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/time.rs`

 * *Files 6% similar despite different names*

```diff
@@ -14,16 +14,16 @@
         + time.minute() as i64 * SECONDS_IN_MINUTE
         + time.second() as i64)
         * NANOSECONDS
         + time.nanosecond() as i64
 }
 
 pub trait TimeMethods {
-    /// Format Date with a `fmt` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
-    fn strftime(&self, fmt: &str) -> Utf8Chunked;
+    /// Format Date with a `format` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
+    fn strftime(&self, format: &str) -> Utf8Chunked;
 
     /// Extract hour from underlying NaiveDateTime representation.
     /// Returns the hour number from 0 to 23.
     fn hour(&self) -> UInt32Chunked;
 
     /// Extract minute from underlying NaiveDateTime representation.
     /// Returns the minute number from 0 to 59.
@@ -38,30 +38,30 @@
     /// The range from 1,000,000,000 to 1,999,999,999 represents the leap second.
     fn nanosecond(&self) -> UInt32Chunked;
 
     fn parse_from_str_slice(name: &str, v: &[&str], fmt: &str) -> TimeChunked;
 }
 
 impl TimeMethods for TimeChunked {
-    /// Format Date with a `fmt` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
-    fn strftime(&self, fmt: &str) -> Utf8Chunked {
+    /// Format Date with a `format` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
+    fn strftime(&self, format: &str) -> Utf8Chunked {
         let time = NaiveTime::from_hms_opt(0, 0, 0).unwrap();
-        let fmted = format!("{}", time.format(fmt));
+        let fmted = format!("{}", time.format(format));
 
         let mut ca: Utf8Chunked = self.apply_kernel_cast(&|arr| {
             let mut buf = String::new();
             let mut mutarr =
                 MutableUtf8Array::with_capacities(arr.len(), arr.len() * fmted.len() + 1);
 
             for opt in arr.into_iter() {
                 match opt {
                     None => mutarr.push_null(),
                     Some(v) => {
                         buf.clear();
-                        let timefmt = time64ns_to_time(*v).format(fmt);
+                        let timefmt = time64ns_to_time(*v).format(format);
                         write!(buf, "{timefmt}").unwrap();
                         mutarr.push(Some(&buf))
                     }
                 }
             }
 
             let arr: Utf8Array<i64> = mutarr.into();
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs`

 * *Files 27% similar despite different names*

```diff
@@ -1,19 +1,146 @@
 use chrono::{DateTime, FixedOffset, NaiveDate, NaiveDateTime};
+use once_cell::sync::Lazy;
 use polars_arrow::export::arrow::array::PrimitiveArray;
 use polars_core::prelude::*;
 use polars_core::utils::arrow::types::NativeType;
+use regex::Regex;
 
 use super::patterns::{self, PatternWithOffset};
 #[cfg(feature = "dtype-date")]
 use crate::chunkedarray::date::naive_date_to_date;
 use crate::chunkedarray::utf8::patterns::Pattern;
 use crate::chunkedarray::utf8::strptime;
 use crate::prelude::utf8::strptime::StrpTimeState;
 
+const DATETIME_DMY_PATTERN: &str = r#"(?x)
+        ^
+        ['"]?                        # optional quotes
+        (?:\d{1,2})                  # day
+        [-/]                         # separator
+        (?P<month>[01]?\d{1})        # month
+        [-/]                         # separator
+        (?:\d{4,})                   # year
+        (?:
+            [T\ ]                    # separator
+            (?:\d{2})                # hour
+            :?                       # separator
+            (?:\d{2})                # minute
+            (?:
+                :?                   # separator
+                (?:\d{2})            # second
+                (?:
+                    \.(?:\d{1,9})    # subsecond
+                )?
+            )?
+        )?
+        ['"]?                        # optional quotes
+        $
+        "#;
+
+static DATETIME_DMY_RE: Lazy<Regex> = Lazy::new(|| Regex::new(DATETIME_DMY_PATTERN).unwrap());
+const DATETIME_YMD_PATTERN: &str = r#"(?x)
+        ^
+        ['"]?                      # optional quotes
+        (?:\d{4,})                 # year
+        [-/]                       # separator
+        (?P<month>[01]?\d{1})      # month
+        [-/]                       # separator
+        (?:\d{1,2})                # day
+        (?:
+            [T\ ]                  # separator
+            (?:\d{2})              # hour
+            :?                     # separator
+            (?:\d{2})              # minute
+            (?:
+                :?                 # separator
+                (?:\d{2})          # seconds
+                (?:
+                    \.(?:\d{1,9})  # subsecond
+                )?
+            )?
+        )?
+        ['"]?                      # optional quotes
+        $
+        "#;
+static DATETIME_YMD_RE: Lazy<Regex> = Lazy::new(|| Regex::new(DATETIME_YMD_PATTERN).unwrap());
+const DATETIME_YMDZ_PATTERN: &str = r#"(?x)
+        ^
+        ['"]?                  # optional quotes
+        (?:\d{4,})             # year
+        [-/]                   # separator
+        (?P<month>[01]?\d{1})  # month
+        [-/]                   # separator
+        (?:\d{1,2})            # year
+        [T\ ]                  # separator
+        (?:\d{2})              # hour
+        :?                     # separator
+        (?:\d{2})              # minute
+        (?:
+            :?                 # separator
+            (?:\d{2})          # second
+            (?:
+                \.(?:\d{1,9})  # subsecond
+            )?
+        )?
+        (?:
+            # offset (e.g. +01:00)
+            [+-](?:\d{2})
+            :?
+            (?:\d{2})
+            # or Zulu suffix
+            |Z
+        )
+        ['"]?                  # optional quotes
+        $
+        "#;
+static DATETIME_YMDZ_RE: Lazy<Regex> = Lazy::new(|| Regex::new(DATETIME_YMDZ_PATTERN).unwrap());
+
+impl Pattern {
+    pub fn is_inferable(&self, val: &str) -> bool {
+        match self {
+            Pattern::DateDMY => true, // there are very few Date patterns, so it's cheaper
+            Pattern::DateYMD => true, // to just try them
+            Pattern::DatetimeDMY => match DATETIME_DMY_RE.captures(val) {
+                Some(search) => (1..=12).contains(
+                    &search
+                        .name("month")
+                        .unwrap()
+                        .as_str()
+                        .parse::<u8>()
+                        .unwrap(),
+                ),
+                None => false,
+            },
+            Pattern::DatetimeYMD => match DATETIME_YMD_RE.captures(val) {
+                Some(search) => (1..=12).contains(
+                    &search
+                        .name("month")
+                        .unwrap()
+                        .as_str()
+                        .parse::<u8>()
+                        .unwrap(),
+                ),
+                None => false,
+            },
+            Pattern::DatetimeYMDZ => match DATETIME_YMDZ_RE.captures(val) {
+                Some(search) => (1..=12).contains(
+                    &search
+                        .name("month")
+                        .unwrap()
+                        .as_str()
+                        .parse::<u8>()
+                        .unwrap(),
+                ),
+                None => false,
+            },
+        }
+    }
+}
+
 pub trait StrpTimeParser<T> {
     fn parse_bytes(&mut self, val: &[u8]) -> Option<T>;
 }
 
 #[cfg(feature = "dtype-datetime")]
 impl StrpTimeParser<i64> for DatetimeInfer<i64> {
     fn parse_bytes(&mut self, val: &[u8]) -> Option<i64> {
@@ -76,14 +203,15 @@
                 })
         }
     }
 }
 
 #[derive(Clone)]
 pub struct DatetimeInfer<T> {
+    pub pattern_with_offset: PatternWithOffset,
     patterns: &'static [&'static str],
     latest_fmt: &'static str,
     transform: fn(&str, &str, Option<FixedOffset>, bool) -> Option<T>,
     transform_bytes: StrpTimeState,
     fmt_len: u16,
     pub logical_type: DataType,
     utc: bool,
@@ -92,32 +220,44 @@
 #[cfg(feature = "dtype-datetime")]
 impl TryFrom<Pattern> for DatetimeInfer<i64> {
     type Error = PolarsError;
 
     fn try_from(value: Pattern) -> PolarsResult<Self> {
         match value {
             Pattern::DatetimeDMY => Ok(DatetimeInfer {
+                pattern_with_offset: PatternWithOffset {
+                    pattern: Pattern::DatetimeDMY,
+                    offset: None,
+                },
                 patterns: patterns::DATETIME_D_M_Y,
                 latest_fmt: patterns::DATETIME_D_M_Y[0],
                 transform: transform_datetime_us,
                 transform_bytes: StrpTimeState::default(),
                 fmt_len: 0,
                 logical_type: DataType::Datetime(TimeUnit::Microseconds, None),
                 utc: false,
             }),
             Pattern::DatetimeYMD => Ok(DatetimeInfer {
+                pattern_with_offset: PatternWithOffset {
+                    pattern: Pattern::DatetimeYMD,
+                    offset: None,
+                },
                 patterns: patterns::DATETIME_Y_M_D,
                 latest_fmt: patterns::DATETIME_Y_M_D[0],
                 transform: transform_datetime_us,
                 transform_bytes: StrpTimeState::default(),
                 fmt_len: 0,
                 logical_type: DataType::Datetime(TimeUnit::Microseconds, None),
                 utc: false,
             }),
             Pattern::DatetimeYMDZ => Ok(DatetimeInfer {
+                pattern_with_offset: PatternWithOffset {
+                    pattern: Pattern::DatetimeYMDZ,
+                    offset: None,
+                },
                 patterns: patterns::DATETIME_Y_M_D_Z,
                 latest_fmt: patterns::DATETIME_Y_M_D_Z[0],
                 transform: transform_tzaware_datetime_us,
                 transform_bytes: StrpTimeState::default(),
                 fmt_len: 0,
                 logical_type: DataType::Datetime(TimeUnit::Microseconds, None),
                 utc: false,
@@ -130,23 +270,31 @@
 #[cfg(feature = "dtype-date")]
 impl TryFrom<Pattern> for DatetimeInfer<i32> {
     type Error = PolarsError;
 
     fn try_from(value: Pattern) -> PolarsResult<Self> {
         match value {
             Pattern::DateDMY => Ok(DatetimeInfer {
+                pattern_with_offset: PatternWithOffset {
+                    pattern: Pattern::DateDMY,
+                    offset: None,
+                },
                 patterns: patterns::DATE_D_M_Y,
                 latest_fmt: patterns::DATE_D_M_Y[0],
                 transform: transform_date,
                 transform_bytes: StrpTimeState::default(),
                 fmt_len: 0,
                 logical_type: DataType::Date,
                 utc: false,
             }),
             Pattern::DateYMD => Ok(DatetimeInfer {
+                pattern_with_offset: PatternWithOffset {
+                    pattern: Pattern::DateYMD,
+                    offset: None,
+                },
                 patterns: patterns::DATE_Y_M_D,
                 latest_fmt: patterns::DATE_Y_M_D[0],
                 transform: transform_date,
                 transform_bytes: StrpTimeState::default(),
                 fmt_len: 0,
                 logical_type: DataType::Date,
                 utc: false,
@@ -158,14 +306,17 @@
 
 impl<T: NativeType> DatetimeInfer<T> {
     pub fn parse(&mut self, val: &str, offset: Option<FixedOffset>) -> Option<T> {
         match (self.transform)(val, self.latest_fmt, offset, self.utc) {
             Some(parsed) => Some(parsed),
             // try other patterns
             None => {
+                if !self.pattern_with_offset.pattern.is_inferable(val) {
+                    return None;
+                }
                 for fmt in self.patterns {
                     self.fmt_len = 0;
                     if let Some(parsed) = (self.transform)(val, fmt, offset, self.utc) {
                         self.latest_fmt = fmt;
                         return Some(parsed);
                     }
                 }
@@ -391,28 +542,28 @@
             }
             match pattern_with_offset.offset {
                 #[cfg(feature = "timezones")]
                 Some(offset) => infer.coerce_utf8(ca, Some(offset)).datetime().map(|ca| {
                     let mut ca = ca.clone();
                     ca.set_time_unit(tu);
                     match utc {
-                        true => Ok(ca.replace_time_zone(Some("UTC"))?),
+                        true => Ok(ca.replace_time_zone(Some("UTC"), None)?),
                         false => Ok(ca
-                            .replace_time_zone(Some("UTC"))?
+                            .replace_time_zone(Some("UTC"), None)?
                             .convert_time_zone(offset.to_string())?),
                     }
                 })?,
                 _ => infer.coerce_utf8(ca, None).datetime().map(|ca| {
                     let mut ca = ca.clone();
                     ca.set_time_unit(tu);
                     match (tz, utc) {
                         #[cfg(feature = "timezones")]
-                        (Some(tz), false) => Ok(ca.replace_time_zone(Some(tz))?),
+                        (Some(tz), false) => Ok(ca.replace_time_zone(Some(tz), None)?),
                         #[cfg(feature = "timezones")]
-                        (None, true) => Ok(ca.replace_time_zone(Some("UTC"))?),
+                        (None, true) => Ok(ca.replace_time_zone(Some("UTC"), None)?),
                         #[cfg(feature = "timezones")]
                         (Some(_), true) => unreachable!(), // has already been validated in strptime
                         _ => Ok(ca),
                     }
                 })?,
             }
         }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -293,15 +293,15 @@
                     None
                 }
             })
             .collect_trusted();
         ca.rename(utf8_ca.name());
         match tz {
             #[cfg(feature = "timezones")]
-            Some(tz) => ca.into_datetime(tu, None).replace_time_zone(Some(tz)),
+            Some(tz) => ca.into_datetime(tu, None).replace_time_zone(Some(tz), None),
             _ => Ok(ca.into_datetime(tu, None)),
         }
     }
 
     #[cfg(feature = "dtype-date")]
     /// Parsing string values and return a [`DateChunked`]
     fn as_date(&self, fmt: Option<&str>, cache: bool) -> PolarsResult<DateChunked> {
@@ -529,17 +529,19 @@
                         })
                     })
                     .collect_trusted()
             };
             ca.rename(utf8_ca.name());
             match (tz, utc) {
                 #[cfg(feature = "timezones")]
-                (Some(tz), false) => ca.into_datetime(tu, None).replace_time_zone(Some(tz)),
+                (Some(tz), false) => ca.into_datetime(tu, None).replace_time_zone(Some(tz), None),
                 #[cfg(feature = "timezones")]
-                (None, true) => ca.into_datetime(tu, None).replace_time_zone(Some("UTC")),
+                (None, true) => ca
+                    .into_datetime(tu, None)
+                    .replace_time_zone(Some("UTC"), None),
                 #[cfg(feature = "timezones")]
                 (Some(_), true) => unreachable!(), // has already been validated in strptime
                 _ => Ok(ca.into_datetime(tu, None)),
             }
         }
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs`

 * *Files 1% similar despite different names*

```diff
@@ -100,14 +100,17 @@
                         (year, offset) = update_and_parse(4, offset, val)?;
                         if negative {
                             year *= -1
                         }
                     }
                     b'm' => {
                         (month, offset) = update_and_parse(2, offset, val)?;
+                        if month > 12 {
+                            return None;
+                        }
                     }
                     b'b' => {
                         (month, offset) = parse_month_abbrev(val, offset)?;
                     }
                     b'd' => {
                         (day, offset) = update_and_parse(2, offset, val)?;
                     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/date_range.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/date_range.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/groupby/dynamic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/groupby/dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/round.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/round.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/_trait.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/_trait.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/floats.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/floats.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/implementations/integers.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/implementations/integers.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/series/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/series/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -300,26 +300,26 @@
             DataType::Date => s.date().map(|ca| ca.month()),
             #[cfg(feature = "dtype-datetime")]
             DataType::Datetime(_, _) => s.datetime().map(|ca| ca.month()),
             dt => polars_bail!(opq = month, dt),
         }
     }
 
-    /// Format Date/Datetimewith a `fmt` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
-    fn strftime(&self, fmt: &str) -> PolarsResult<Series> {
+    /// Format Date/Datetimewith a `format` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
+    fn strftime(&self, format: &str) -> PolarsResult<Series> {
         let s = self.as_series();
         match s.dtype() {
             #[cfg(feature = "dtype-date")]
-            DataType::Date => s.date().map(|ca| ca.strftime(fmt).into_series()),
+            DataType::Date => s.date().map(|ca| ca.strftime(format).into_series()),
             #[cfg(feature = "dtype-datetime")]
-            DataType::Datetime(_, _) => {
-                s.datetime().map(|ca| Ok(ca.strftime(fmt)?.into_series()))?
-            }
+            DataType::Datetime(_, _) => s
+                .datetime()
+                .map(|ca| Ok(ca.strftime(format)?.into_series()))?,
             #[cfg(feature = "dtype-time")]
-            DataType::Time => s.time().map(|ca| ca.strftime(fmt).into_series()),
+            DataType::Time => s.time().map(|ca| ca.strftime(format).into_series()),
             dt => polars_bail!(opq = strftime, dt),
         }
     }
 
     #[cfg(all(feature = "dtype-date", feature = "dtype-datetime"))]
     /// Convert date(time) object to timestamp in [`TimeUnit`].
     fn timestamp(&self, tu: TimeUnit) -> PolarsResult<Int64Chunked> {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/truncate.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/truncate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/upsample.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/upsample.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/bounds.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/bounds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/calendar.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/calendar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/duration.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/groupby.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/test.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/test.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-time/src/windows/window.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-time/src/windows/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/arena.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/arena.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/atomic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/atomic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/cell.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/cell.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/contention_pool.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/contention_pool.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/hash.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/hash.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/iter/enumerate_idx.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/iter/enumerate_idx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/sort.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/sync.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/sync.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/unwrap.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/unwrap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-utils/src/wasm.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-utils/src/wasm.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -177,17 +177,17 @@
 url = { version = "2.3.1", optional = true }
 xxhash-rust= { version = "0.8.6", features = ["xxh3"] }
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/arithmetic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/bitwise.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/bitwise.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/binary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use super::*;
 
+#[derive(Clone)]
 pub struct BooleanChunkedBuilder {
     pub(crate) array_builder: MutableBooleanArray,
-    field: Field,
+    pub(crate) field: Field,
 }
 
 impl ChunkedBuilder<bool, BooleanType> for BooleanChunkedBuilder {
     /// Appends a value of type `T` into the builder
     #[inline]
     fn append_value(&mut self, v: bool) {
         self.array_builder.push(Some(v));
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/list.rs`

 * *Files 2% similar despite different names*

```diff
@@ -653,45 +653,26 @@
         self.fast_explode = false;
         self.builder.push_null()
     }
 
     fn finish(&mut self) -> ListChunked {
         // don't use self from here on one
         let slf = std::mem::take(self);
-        if slf.builder.is_empty() {
-            // not really empty, there were empty null list added probably e.g. []
-            let real_length = slf.builder.offsets().len() - 1;
-            if real_length > 0 {
-                let dtype = slf.inner_dtype.unwrap_or(NULL_DTYPE).to_arrow();
-                let array = new_null_array(dtype.clone(), real_length);
-                let dtype = ListArray::<i64>::default_datatype(dtype);
-                let array = ListArray::new(dtype, slf.builder.take_offsets().into(), array, None);
-                // safety: same type
-                unsafe { ListChunked::from_chunks(&slf.name, vec![Box::new(array)]) }
-            } else {
-                ListChunked::full_null_with_dtype(
-                    &slf.name,
-                    0,
-                    &slf.inner_dtype.unwrap_or(DataType::Null),
-                )
-            }
-        } else {
-            let inner_dtype = slf.inner_dtype.map(|dt| dt.to_physical().to_arrow());
-            let arr = slf.builder.finish(inner_dtype.as_ref()).unwrap();
-            let dtype = DataType::from(arr.data_type());
-            // safety: same type
-            let mut ca = unsafe { ListChunked::from_chunks("", vec![Box::new(arr)]) };
+        let inner_dtype = slf.inner_dtype.map(|dt| dt.to_physical().to_arrow());
+        let arr = slf.builder.finish(inner_dtype.as_ref()).unwrap();
+        let dtype = DataType::from(arr.data_type());
+        // safety: same type
+        let mut ca = unsafe { ListChunked::from_chunks("", vec![Box::new(arr)]) };
 
-            if slf.fast_explode {
-                ca.set_fast_explode();
-            }
-
-            ca.field = Arc::new(Field::new(&slf.name, dtype));
-            ca
+        if slf.fast_explode {
+            ca.set_fast_explode();
         }
+
+        ca.field = Arc::new(Field::new(&slf.name, dtype));
+        ca
     }
 }
 
 impl AnonymousOwnedListBuilder {
     pub fn new(name: &str, capacity: usize, inner_dtype: Option<DataType>) -> Self {
         Self {
             name: name.into(),
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 use super::*;
 
+#[derive(Clone)]
 pub struct PrimitiveChunkedBuilder<T>
 where
     T: PolarsNumericType,
 {
     array_builder: MutablePrimitiveArray<T::Native>,
-    field: Field,
+    pub(crate) field: Field,
 }
 
 impl<T> ChunkedBuilder<T::Native, T> for PrimitiveChunkedBuilder<T>
 where
     T: PolarsNumericType,
 {
     /// Appends a value of type `T` into the builder
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 use super::*;
 
+#[derive(Clone)]
 pub struct Utf8ChunkedBuilder {
     pub(crate) builder: MutableUtf8Array<i64>,
     pub capacity: usize,
-    field: Field,
+    pub(crate) field: Field,
 }
 
 impl Utf8ChunkedBuilder {
     /// Create a new UtfChunkedBuilder
     ///
     /// # Arguments
     ///
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/cast.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/cast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/drop.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/float.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/float.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/kernels/take.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/kernels/take.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/list/iterator.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/list/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/list/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/list/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/date.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs`

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,52 @@
 use super::*;
 use crate::chunked_array::cast::cast_chunks;
 use crate::prelude::*;
 
 pub type DecimalChunked = Logical<DecimalType, Int128Type>;
 
 impl Int128Chunked {
+    fn update_chunks_dtype(&mut self, precision: Option<usize>, scale: usize) {
+        // physical i128 type doesn't exist
+        // so we update the decimal dtype
+        for arr in self.chunks.iter_mut() {
+            let mut default = PrimitiveArray::new_empty(arr.data_type().clone());
+            let arr = arr
+                .as_any_mut()
+                .downcast_mut::<PrimitiveArray<i128>>()
+                .unwrap();
+            std::mem::swap(arr, &mut default);
+            let (_, values, validity) = default.into_inner();
+
+            *arr = PrimitiveArray::new(
+                DataType::Decimal(precision, Some(scale)).to_arrow(),
+                values,
+                validity,
+            );
+        }
+    }
+
     #[inline]
-    pub fn into_decimal_unchecked(self, precision: Option<usize>, scale: usize) -> DecimalChunked {
+    pub fn into_decimal_unchecked(
+        mut self,
+        precision: Option<usize>,
+        scale: usize,
+    ) -> DecimalChunked {
+        self.update_chunks_dtype(precision, scale);
         let mut dt = DecimalChunked::new_logical(self);
         dt.2 = Some(DataType::Decimal(precision, Some(scale)));
         dt
     }
 
     pub fn into_decimal(
-        self,
+        mut self,
         precision: Option<usize>,
         scale: usize,
     ) -> PolarsResult<DecimalChunked> {
+        self.update_chunks_dtype(precision, scale);
         // TODO: if precision is None, do we check that the value fits within precision of 38?...
         if let Some(precision) = precision {
             let precision_max = 10_i128.pow(precision as u32);
             // note: this is not too efficient as it scans through the data twice...
             if let (Some(min), Some(max)) = (self.min(), self.max()) {
                 let max_abs = max.abs().max(min.abs());
                 polars_ensure!(
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/duration.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs`

 * *Files 8% similar despite different names*

```diff
@@ -32,20 +32,33 @@
     field_arrays
         .iter()
         .zip(fields)
         .map(|(arr, s)| ArrowField::new(s.name(), arr.data_type().clone(), true))
         .collect()
 }
 
-fn fields_to_struct_array(fields: &[Series]) -> (ArrayRef, Vec<Series>) {
+fn fields_to_struct_array(fields: &[Series], physical: bool) -> (ArrayRef, Vec<Series>) {
     let fields = fields.iter().map(|s| s.rechunk()).collect::<Vec<_>>();
 
     let field_arrays = fields
         .iter()
-        .map(|s| s.rechunk().to_arrow(0))
+        .map(|s| {
+            let s = s.rechunk();
+            match s.dtype() {
+                #[cfg(feature = "object")]
+                DataType::Object(_) => s.to_arrow(0),
+                _ => {
+                    if physical {
+                        s.chunks()[0].clone()
+                    } else {
+                        s.to_arrow(0)
+                    }
+                }
+            }
+        })
         .collect::<Vec<_>>();
     // we determine fields from arrays as there might be object arrays
     // where the dtype is bound to that single array
     let new_fields = arrays_to_fields(&field_arrays, &fields);
     let arr = StructArray::new(ArrowDataType::Struct(new_fields), field_arrays, None);
     (Box::new(arr), fields)
 }
@@ -114,15 +127,19 @@
     // Should be called after append or extend
     pub(crate) fn update_chunks(&mut self, offset: usize) {
         let n_chunks = self.fields[0].chunks().len();
         for i in offset..n_chunks {
             let field_arrays = self
                 .fields
                 .iter()
-                .map(|s| s.to_arrow(i))
+                .map(|s| match s.dtype() {
+                    #[cfg(feature = "object")]
+                    DataType::Object(_) => s.to_arrow(0),
+                    _ => s.chunks()[i].clone(),
+                })
                 .collect::<Vec<_>>();
 
             // we determine fields from arrays as there might be object arrays
             // where the dtype is bound to that single array
             let new_fields = arrays_to_fields(&field_arrays, &self.fields);
             let arr = Box::new(StructArray::new(
                 ArrowDataType::Struct(new_fields),
@@ -145,15 +162,15 @@
         let dtype = DataType::Struct(
             fields
                 .iter()
                 .map(|s| Field::new(s.name(), s.dtype().clone()))
                 .collect(),
         );
         let field = Field::new(name, dtype);
-        let (arrow_array, fields) = fields_to_struct_array(fields);
+        let (arrow_array, fields) = fields_to_struct_array(fields, true);
 
         let mut out = Self {
             fields,
             field,
             chunks: vec![arrow_array],
             null_count: 0,
         };
@@ -241,14 +258,31 @@
     {
         let fields = self.fields.iter().map(func).collect::<Vec<_>>();
         Self::new_unchecked(self.field.name(), &fields)
     }
     pub fn unnest(self) -> DataFrame {
         self.into()
     }
+
+    pub(crate) fn to_arrow(&self, i: usize) -> ArrayRef {
+        let values = self
+            .fields
+            .iter()
+            .map(|s| s.to_arrow(i))
+            .collect::<Vec<_>>();
+
+        // we determine fields from arrays as there might be object arrays
+        // where the dtype is bound to that single array
+        let new_fields = arrays_to_fields(&values, &self.fields);
+        Box::new(StructArray::new(
+            ArrowDataType::Struct(new_fields),
+            values,
+            None,
+        ))
+    }
 }
 
 impl LogicalType for StructChunked {
     fn dtype(&self) -> &DataType {
         self.field.data_type()
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/logical/time.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/logical/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs`

 * *Files 24% similar despite different names*

```diff
@@ -1,760 +1,765 @@
-//! The typed heart of every Series column.
-use std::iter::Map;
+//! Implementations of upstream traits for ChunkedArray<T>
+use std::borrow::{Borrow, Cow};
+use std::collections::LinkedList;
+use std::iter::FromIterator;
 use std::marker::PhantomData;
 use std::sync::Arc;
 
-use arrow::array::*;
-use arrow::bitmap::Bitmap;
-use polars_arrow::prelude::ValueSize;
-
+use arrow::array::{BooleanArray, PrimitiveArray, Utf8Array};
+use arrow::bitmap::{Bitmap, MutableBitmap};
+use polars_utils::sync::SyncPtr;
+use rayon::iter::{FromParallelIterator, IntoParallelIterator};
+use rayon::prelude::*;
+
+use crate::chunked_array::builder::{
+    get_list_builder, AnonymousListBuilder, AnonymousOwnedListBuilder,
+};
+#[cfg(feature = "object")]
+use crate::chunked_array::object::ObjectArray;
 use crate::prelude::*;
+use crate::utils::{get_iter_capacity, CustomIterTools, NoNull};
 
-pub mod ops;
-#[macro_use]
-pub mod arithmetic;
-pub mod builder;
-pub mod cast;
-pub mod comparison;
-pub mod float;
-pub mod iterator;
-pub mod kernels;
-#[cfg(feature = "ndarray")]
-mod ndarray;
+impl<T: PolarsDataType> Default for ChunkedArray<T> {
+    fn default() -> Self {
+        ChunkedArray {
+            field: Arc::new(Field::new("default", DataType::Null)),
+            chunks: Default::default(),
+            phantom: PhantomData,
+            bit_settings: Default::default(),
+            length: 0,
+        }
+    }
+}
 
-mod bitwise;
-#[cfg(feature = "object")]
-mod drop;
-mod from;
-pub(crate) mod list;
-pub(crate) mod logical;
-#[cfg(feature = "object")]
-pub mod object;
-#[cfg(feature = "random")]
-mod random;
-#[cfg(any(
-    feature = "temporal",
-    feature = "dtype-datetime",
-    feature = "dtype-date"
-))]
-pub mod temporal;
-mod to_vec;
-mod trusted_len;
-pub mod upstream_traits;
-
-use std::mem;
-use std::slice::Iter;
-
-use bitflags::bitflags;
-use polars_arrow::prelude::*;
-
-use crate::series::IsSorted;
-use crate::utils::{first_non_null, last_non_null, CustomIterTools};
-
-#[cfg(not(feature = "dtype-categorical"))]
-pub struct RevMapping {}
-
-pub type ChunkIdIter<'a> = std::iter::Map<std::slice::Iter<'a, ArrayRef>, fn(&ArrayRef) -> usize>;
-
-/// # ChunkedArray
-///
-/// Every Series contains a `ChunkedArray<T>`. Unlike Series, ChunkedArray's are typed. This allows
-/// us to apply closures to the data and collect the results to a `ChunkedArray` of the same type `T`.
-/// Below we use an apply to use the cosine function to the values of a `ChunkedArray`.
-///
-/// ```rust
-/// # use polars_core::prelude::*;
-/// fn apply_cosine(ca: &Float32Chunked) -> Float32Chunked {
-///     ca.apply(|v| v.cos())
-/// }
-/// ```
-///
-/// If we would like to cast the result we could use a Rust Iterator instead of an `apply` method.
-/// Note that Iterators are slightly slower as the null values aren't ignored implicitly.
-///
-/// ```rust
-/// # use polars_core::prelude::*;
-/// fn apply_cosine_and_cast(ca: &Float32Chunked) -> Float64Chunked {
-///     ca.into_iter()
-///         .map(|opt_v| {
-///         opt_v.map(|v| v.cos() as f64)
-///     }).collect()
-/// }
-/// ```
-///
-/// Another option is to first cast and then use an apply.
-///
-/// ```rust
-/// # use polars_core::prelude::*;
-/// fn apply_cosine_and_cast(ca: &Float32Chunked) -> Float64Chunked {
-///     ca.apply_cast_numeric(|v| v.cos() as f64)
-/// }
-/// ```
-///
-/// ## Conversion between Series and ChunkedArray's
-/// Conversion from a `Series` to a `ChunkedArray` is effortless.
-///
-/// ```rust
-/// # use polars_core::prelude::*;
-/// fn to_chunked_array(series: &Series) -> PolarsResult<&Int32Chunked>{
-///     series.i32()
-/// }
-///
-/// fn to_series(ca: Int32Chunked) -> Series {
-///     ca.into_series()
-/// }
-/// ```
-///
-/// # Iterators
-///
-/// `ChunkedArrays` fully support Rust native [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html)
-/// and [DoubleEndedIterator](https://doc.rust-lang.org/std/iter/trait.DoubleEndedIterator.html) traits, thereby
-/// giving access to all the excellent methods available for [Iterators](https://doc.rust-lang.org/std/iter/trait.Iterator.html).
-///
-/// ```rust
-/// # use polars_core::prelude::*;
-///
-/// fn iter_forward(ca: &Float32Chunked) {
-///     ca.into_iter()
-///         .for_each(|opt_v| println!("{:?}", opt_v))
-/// }
-///
-/// fn iter_backward(ca: &Float32Chunked) {
-///     ca.into_iter()
-///         .rev()
-///         .for_each(|opt_v| println!("{:?}", opt_v))
-/// }
-/// ```
-///
-/// # Memory layout
-///
-/// `ChunkedArray`'s use [Apache Arrow](https://github.com/apache/arrow) as backend for the memory layout.
-/// Arrows memory is immutable which makes it possible to make multiple zero copy (sub)-views from a single array.
-///
-/// To be able to append data, Polars uses chunks to append new memory locations, hence the `ChunkedArray<T>` data structure.
-/// Appends are cheap, because it will not lead to a full reallocation of the whole array (as could be the case with a Rust Vec).
-///
-/// However, multiple chunks in a `ChunkArray` will slow down many operations that need random access because we have an extra indirection
-/// and indexes need to be mapped to the proper chunk. Arithmetic may also be slowed down by this.
-/// When multiplying two `ChunkArray'`s with different chunk sizes they cannot utilize [SIMD](https://en.wikipedia.org/wiki/SIMD) for instance.
-///
-/// If you want to have predictable performance
-/// (no unexpected re-allocation of memory), it is advised to call the [ChunkedArray::rechunk] after
-/// multiple append operations.
-///
-/// See also [`ChunkedArray::extend`] for appends within a chunk.
-pub struct ChunkedArray<T: PolarsDataType> {
-    pub(crate) field: Arc<Field>,
-    pub(crate) chunks: Vec<ArrayRef>,
-    phantom: PhantomData<T>,
-    pub(crate) bit_settings: Settings,
-    length: IdxSize,
-}
-
-bitflags! {
-    #[derive(Default)]
-    pub(crate) struct Settings: u8 {
-    const SORTED_ASC = 0x01;
-    const SORTED_DSC = 0x02;
-    const FAST_EXPLODE_LIST = 0x04;
-}}
-
-impl<T: PolarsDataType> ChunkedArray<T> {
-    pub(crate) fn is_sorted_ascending_flag(&self) -> bool {
-        self.bit_settings.contains(Settings::SORTED_ASC)
-    }
-
-    pub(crate) fn is_sorted_descending_flag(&self) -> bool {
-        self.bit_settings.contains(Settings::SORTED_DSC)
-    }
-
-    pub fn unset_fast_explode_list(&mut self) {
-        self.bit_settings.remove(Settings::FAST_EXPLODE_LIST)
-    }
-
-    pub fn is_sorted_flag2(&self) -> IsSorted {
-        if self.is_sorted_ascending_flag() {
-            IsSorted::Ascending
-        } else if self.is_sorted_descending_flag() {
-            IsSorted::Descending
-        } else {
-            IsSorted::Not
-        }
-    }
-
-    /// Set the 'sorted' bit meta info.
-    pub fn set_sorted_flag(&mut self, sorted: IsSorted) {
-        match sorted {
-            IsSorted::Not => {
-                self.bit_settings
-                    .remove(Settings::SORTED_ASC | Settings::SORTED_DSC);
-            }
-            IsSorted::Ascending => {
-                // // unset descending sorted
-                self.bit_settings.remove(Settings::SORTED_DSC);
-                // set ascending sorted
-                self.bit_settings.insert(Settings::SORTED_ASC)
-            }
-            IsSorted::Descending => {
-                // unset ascending sorted
-                self.bit_settings.remove(Settings::SORTED_ASC);
-                // set descending sorted
-                self.bit_settings.insert(Settings::SORTED_DSC)
+/// FromIterator trait
+
+impl<T> FromIterator<Option<T::Native>> for ChunkedArray<T>
+where
+    T: PolarsNumericType,
+{
+    fn from_iter<I: IntoIterator<Item = Option<T::Native>>>(iter: I) -> Self {
+        let iter = iter.into_iter();
+
+        let arr: PrimitiveArray<T::Native> = match iter.size_hint() {
+            (a, Some(b)) if a == b => {
+                // 2021-02-07: ~40% faster than builder.
+                // It is unsafe because we cannot be certain that the iterators length can be trusted.
+                // For most iterators that report the same upper bound as lower bound it is, but still
+                // somebody can create an iterator that incorrectly gives those bounds.
+                // This will not lead to UB, but will panic.
+                #[cfg(feature = "performant")]
+                unsafe {
+                    let arr = PrimitiveArray::from_trusted_len_iter_unchecked(iter)
+                        .to(T::get_dtype().to_arrow());
+                    assert_eq!(arr.len(), a);
+                    arr
+                }
+                #[cfg(not(feature = "performant"))]
+                iter.collect::<PrimitiveArray<T::Native>>()
+                    .to(T::get_dtype().to_arrow())
             }
-        }
+            _ => iter
+                .collect::<PrimitiveArray<T::Native>>()
+                .to(T::get_dtype().to_arrow()),
+        };
+        unsafe { ChunkedArray::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    /// Get the index of the first non null value in this ChunkedArray.
-    pub fn first_non_null(&self) -> Option<usize> {
-        if self.is_empty() {
-            None
-        } else {
-            first_non_null(self.iter_validities())
-        }
+// NoNull is only a wrapper needed for specialization
+impl<T> FromIterator<T::Native> for NoNull<ChunkedArray<T>>
+where
+    T: PolarsNumericType,
+{
+    // We use Vec because it is way faster than Arrows builder. We can do this because we
+    // know we don't have null values.
+    fn from_iter<I: IntoIterator<Item = T::Native>>(iter: I) -> Self {
+        // 2021-02-07: aligned vec was ~2x faster than arrow collect.
+        let av = iter.into_iter().collect::<Vec<T::Native>>();
+        NoNull::new(ChunkedArray::from_vec("", av))
     }
+}
 
-    /// Get the index of the last non null value in this ChunkedArray.
-    pub fn last_non_null(&self) -> Option<usize> {
-        last_non_null(self.iter_validities(), self.length as usize)
+impl FromIterator<Option<bool>> for ChunkedArray<BooleanType> {
+    fn from_iter<I: IntoIterator<Item = Option<bool>>>(iter: I) -> Self {
+        let arr = BooleanArray::from_iter(iter);
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    /// Get the buffer of bits representing null values
-    #[inline]
-    #[allow(clippy::type_complexity)]
-    pub fn iter_validities(&self) -> Map<Iter<'_, ArrayRef>, fn(&ArrayRef) -> Option<&Bitmap>> {
-        fn to_validity(arr: &ArrayRef) -> Option<&Bitmap> {
-            arr.validity()
-        }
-        self.chunks.iter().map(to_validity)
+impl FromIterator<bool> for BooleanChunked {
+    fn from_iter<I: IntoIterator<Item = bool>>(iter: I) -> Self {
+        // 2021-02-07: this was ~70% faster than with the builder, even with the extra Option<T> added.
+        let arr = BooleanArray::from_iter(iter.into_iter().map(Some));
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    #[inline]
-    /// Return if any the chunks in this `[ChunkedArray]` have a validity bitmap.
-    /// no bitmap means no null values.
-    pub fn has_validity(&self) -> bool {
-        self.iter_validities().any(|valid| valid.is_some())
+impl FromIterator<bool> for NoNull<BooleanChunked> {
+    fn from_iter<I: IntoIterator<Item = bool>>(iter: I) -> Self {
+        let ca = iter.into_iter().collect::<BooleanChunked>();
+        NoNull::new(ca)
     }
+}
 
-    /// Shrink the capacity of this array to fit its length.
-    pub fn shrink_to_fit(&mut self) {
-        self.chunks = vec![arrow::compute::concatenate::concatenate(
-            self.chunks
-                .iter()
-                .map(|a| &**a)
-                .collect::<Vec<_>>()
-                .as_slice(),
-        )
-        .unwrap()];
-    }
-
-    /// Unpack a Series to the same physical type.
-    ///
-    /// # Safety
-    ///
-    /// This is unsafe as the dtype may be incorrect and
-    /// is assumed to be correct in other safe code.
-    pub(crate) unsafe fn unpack_series_matching_physical_type(
-        &self,
-        series: &Series,
-    ) -> &ChunkedArray<T> {
-        let series_trait = &**series;
-        if self.dtype() == series.dtype() {
-            &*(series_trait as *const dyn SeriesTrait as *const ChunkedArray<T>)
-        } else {
-            use DataType::*;
-            match (self.dtype(), series.dtype()) {
-                (Int64, Datetime(_, _)) | (Int64, Duration(_)) | (Int32, Date) => {
-                    &*(series_trait as *const dyn SeriesTrait as *const ChunkedArray<T>)
-                }
-                _ => panic!(
-                    "cannot unpack series {:?} into matching type {:?}",
-                    series,
-                    self.dtype()
-                ),
-            }
-        }
+// FromIterator for Utf8Chunked variants.
+
+impl<Ptr> FromIterator<Option<Ptr>> for Utf8Chunked
+where
+    Ptr: AsRef<str>,
+{
+    fn from_iter<I: IntoIterator<Item = Option<Ptr>>>(iter: I) -> Self {
+        let arr = Utf8Array::<i64>::from_iter(iter);
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    /// Series to ChunkedArray<T>
-    pub fn unpack_series_matching_type(&self, series: &Series) -> PolarsResult<&ChunkedArray<T>> {
-        polars_ensure!(
-            self.dtype() == series.dtype(),
-            SchemaMismatch: "cannot unpack series of type `{}` into `{}`",
-            series.dtype(),
-            self.dtype(),
-        );
-        // Safety
-        // dtype will be correct.
-        Ok(unsafe { self.unpack_series_matching_physical_type(series) })
+/// Local AsRef<T> trait to circumvent the orphan rule.
+pub trait PolarsAsRef<T: ?Sized>: AsRef<T> {}
+
+impl PolarsAsRef<str> for String {}
+impl PolarsAsRef<str> for &str {}
+// &["foo", "bar"]
+impl PolarsAsRef<str> for &&str {}
+impl<'a> PolarsAsRef<str> for Cow<'a, str> {}
+
+impl<Ptr> FromIterator<Ptr> for Utf8Chunked
+where
+    Ptr: PolarsAsRef<str>,
+{
+    fn from_iter<I: IntoIterator<Item = Ptr>>(iter: I) -> Self {
+        let arr = Utf8Array::<i64>::from_iter_values(iter.into_iter());
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    /// Unique id representing the number of chunks
-    pub fn chunk_id(&self) -> ChunkIdIter {
-        self.chunks.iter().map(|chunk| chunk.len())
+// FromIterator for BinaryChunked variants.
+impl<Ptr> FromIterator<Option<Ptr>> for BinaryChunked
+where
+    Ptr: AsRef<[u8]>,
+{
+    fn from_iter<I: IntoIterator<Item = Option<Ptr>>>(iter: I) -> Self {
+        let arr = BinaryArray::<i64>::from_iter(iter);
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    /// A reference to the chunks
-    #[inline]
-    pub fn chunks(&self) -> &Vec<ArrayRef> {
-        &self.chunks
+impl PolarsAsRef<[u8]> for Vec<u8> {}
+
+impl PolarsAsRef<[u8]> for &[u8] {}
+
+// TODO: remove!
+impl PolarsAsRef<[u8]> for &&[u8] {}
+
+impl<'a> PolarsAsRef<[u8]> for Cow<'a, [u8]> {}
+
+impl<Ptr> FromIterator<Ptr> for BinaryChunked
+where
+    Ptr: PolarsAsRef<[u8]>,
+{
+    fn from_iter<I: IntoIterator<Item = Ptr>>(iter: I) -> Self {
+        let arr = BinaryArray::<i64>::from_iter_values(iter.into_iter());
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
+}
 
-    /// A mutable reference to the chunks
-    ///
-    /// # Safety
-    /// The caller must ensure to not change the `DataType` or `length` of any of the chunks.
-    #[inline]
-    pub unsafe fn chunks_mut(&mut self) -> &mut Vec<ArrayRef> {
-        &mut self.chunks
+impl<Ptr> FromIterator<Ptr> for ListChunked
+where
+    Ptr: Borrow<Series>,
+{
+    fn from_iter<I: IntoIterator<Item = Ptr>>(iter: I) -> Self {
+        let mut it = iter.into_iter();
+        let capacity = get_iter_capacity(&it);
+
+        // first take one to get the dtype.
+        let v = match it.next() {
+            Some(v) => v,
+            None => return ListChunked::full_null("", 0),
+        };
+        // We don't know the needed capacity. We arbitrarily choose an average of 5 elements per series.
+        let mut builder =
+            get_list_builder(v.borrow().dtype(), capacity * 5, capacity, "collected").unwrap();
+
+        builder.append_series(v.borrow());
+        for s in it {
+            builder.append_series(s.borrow());
+        }
+        builder.finish()
     }
+}
 
-    /// Returns true if contains a single chunk and has no null values
-    pub fn is_optimal_aligned(&self) -> bool {
-        self.chunks.len() == 1 && self.null_count() == 0
+impl FromIterator<Option<Series>> for ListChunked {
+    fn from_iter<I: IntoIterator<Item = Option<Series>>>(iter: I) -> Self {
+        let mut it = iter.into_iter();
+        let capacity = get_iter_capacity(&it);
+
+        // get first non None from iter
+        let first_value;
+        let mut init_null_count = 0;
+        loop {
+            match it.next() {
+                Some(Some(s)) => {
+                    first_value = Some(s);
+                    break;
+                }
+                Some(None) => {
+                    init_null_count += 1;
+                }
+                None => return ListChunked::full_null("", init_null_count),
+            }
+        }
+
+        match first_value {
+            None => {
+                // already returned full_null above
+                unreachable!()
+            }
+            Some(ref first_s) => {
+                // AnyValues with empty lists in python can create
+                // Series of an unknown dtype.
+                // We use the anonymousbuilder without a dtype
+                // the empty arrays is then not added (we add an extra offset instead)
+                // the next non-empty series then must have the correct dtype.
+                if matches!(first_s.dtype(), DataType::Null) && first_s.is_empty() {
+                    let mut builder = AnonymousOwnedListBuilder::new("collected", capacity, None);
+                    for _ in 0..init_null_count {
+                        builder.append_null();
+                    }
+                    builder.append_empty();
+
+                    for opt_s in it {
+                        builder.append_opt_series(opt_s.as_ref());
+                    }
+                    builder.finish()
+                } else {
+                    match first_s.dtype() {
+                        #[cfg(feature = "object")]
+                        DataType::Object(_) => {
+                            let mut builder =
+                                first_s.get_list_builder("collected", capacity * 5, capacity);
+                            for _ in 0..init_null_count {
+                                builder.append_null();
+                            }
+                            builder.append_series(first_s);
+
+                            for opt_s in it {
+                                builder.append_opt_series(opt_s.as_ref());
+                            }
+                            builder.finish()
+                        }
+                        _ => {
+                            // We don't know the needed capacity. We arbitrarily choose an average of 5 elements per series.
+                            let mut builder = get_list_builder(
+                                first_s.dtype(),
+                                capacity * 5,
+                                capacity,
+                                "collected",
+                            )
+                            .unwrap();
+
+                            for _ in 0..init_null_count {
+                                builder.append_null();
+                            }
+                            builder.append_series(first_s);
+
+                            for opt_s in it {
+                                builder.append_opt_series(opt_s.as_ref());
+                            }
+                            builder.finish()
+                        }
+                    }
+                }
+            }
+        }
     }
+}
 
-    /// Count the null values.
-    #[inline]
-    pub fn null_count(&self) -> usize {
-        self.chunks.iter().map(|arr| arr.null_count()).sum()
+impl FromIterator<Option<Box<dyn Array>>> for ListChunked {
+    fn from_iter<I: IntoIterator<Item = Option<Box<dyn Array>>>>(iter: I) -> Self {
+        let mut cap = 0;
+        let mut dtype: Option<DataType> = None;
+        let vals = iter
+            .into_iter()
+            .map(|opt_arr| {
+                opt_arr.map(|arr| {
+                    if dtype.is_none() {
+                        dtype = Some(arr.data_type().into());
+                    }
+                    cap += arr.len();
+                    arr
+                })
+            })
+            .collect::<Vec<_>>();
+
+        let mut builder = AnonymousListBuilder::new("collected", cap, None);
+        for val in &vals {
+            builder.append_opt_array(val.as_deref());
+        }
+        builder.finish()
     }
+}
+
+#[cfg(feature = "object")]
+impl<T: PolarsObject> FromIterator<Option<T>> for ObjectChunked<T> {
+    fn from_iter<I: IntoIterator<Item = Option<T>>>(iter: I) -> Self {
+        let iter = iter.into_iter();
+        let size = iter.size_hint().0;
+        let mut null_mask_builder = MutableBitmap::with_capacity(size);
+
+        let values: Vec<T> = iter
+            .map(|value| match value {
+                Some(value) => {
+                    null_mask_builder.push(true);
+                    value
+                }
+                None => {
+                    null_mask_builder.push(false);
+                    T::default()
+                }
+            })
+            .collect();
+
+        let null_bit_buffer: Option<Bitmap> = null_mask_builder.into();
+        let null_bitmap = null_bit_buffer;
 
-    /// Create a new ChunkedArray from self, where the chunks are replaced.
-    fn copy_with_chunks(
-        &self,
-        chunks: Vec<ArrayRef>,
-        keep_sorted: bool,
-        keep_fast_explode: bool,
-    ) -> Self {
+        let len = values.len();
+
+        let arr = Box::new(ObjectArray {
+            values: Arc::new(values),
+            null_bitmap,
+            offset: 0,
+            len,
+        });
         let mut out = ChunkedArray {
-            field: self.field.clone(),
-            chunks,
+            field: Arc::new(Field::new("", DataType::Object(T::type_name()))),
+            chunks: vec![arr],
             phantom: PhantomData,
-            bit_settings: self.bit_settings,
+            bit_settings: Default::default(),
             length: 0,
         };
         out.compute_len();
-        if !keep_sorted {
-            out.set_sorted_flag(IsSorted::Not);
-        }
-        if !keep_fast_explode {
-            out.unset_fast_explode_list()
-        }
         out
     }
+}
 
-    /// Get data type of ChunkedArray.
-    pub fn dtype(&self) -> &DataType {
-        self.field.data_type()
-    }
-
-    /// Name of the ChunkedArray.
-    pub fn name(&self) -> &str {
-        self.field.name()
-    }
+/// FromParallelIterator trait
+// Code taken from https://docs.rs/rayon/1.3.1/src/rayon/iter/extend.rs.html#356-366
+fn vec_push<T>(mut vec: Vec<T>, elem: T) -> Vec<T> {
+    vec.push(elem);
+    vec
+}
 
-    /// Get a reference to the field.
-    pub fn ref_field(&self) -> &Field {
-        &self.field
-    }
+fn as_list<T>(item: T) -> LinkedList<T> {
+    let mut list = LinkedList::new();
+    list.push_back(item);
+    list
+}
 
-    /// Rename this ChunkedArray.
-    pub fn rename(&mut self, name: &str) {
-        self.field = Arc::new(Field::new(name, self.field.data_type().clone()))
-    }
+fn list_append<T>(mut list1: LinkedList<T>, mut list2: LinkedList<T>) -> LinkedList<T> {
+    list1.append(&mut list2);
+    list1
 }
 
-impl<T> ChunkedArray<T>
+fn collect_into_linked_list<I>(par_iter: I) -> LinkedList<Vec<I::Item>>
 where
-    T: PolarsDataType,
+    I: IntoParallelIterator,
 {
-    /// Should be used to match the chunk_id of another ChunkedArray.
-    /// # Panics
-    /// It is the callers responsibility to ensure that this ChunkedArray has a single chunk.
-    pub(crate) fn match_chunks<I>(&self, chunk_id: I) -> Self
-    where
-        I: Iterator<Item = usize>,
-    {
-        debug_assert!(self.chunks.len() == 1);
-        // Takes a ChunkedArray containing a single chunk
-        let slice = |ca: &Self| {
-            let array = &ca.chunks[0];
-
-            let mut offset = 0;
-            let chunks = chunk_id
-                .map(|len| {
-                    // safety:
-                    // within bounds
-                    debug_assert!((offset + len) <= array.len());
-                    let out = unsafe { array.sliced_unchecked(offset, len) };
-                    offset += len;
-                    out
-                })
-                .collect();
-
-            unsafe { Self::from_chunks(self.name(), chunks) }
-        };
-
-        if self.chunks.len() != 1 {
-            let out = self.rechunk();
-            slice(&out)
-        } else {
-            slice(self)
-        }
-    }
+    let it = par_iter.into_par_iter();
+    // be careful optimizing allocations. Its hard to figure out the size
+    // needed
+    // https://github.com/pola-rs/polars/issues/1562
+    it.fold(Vec::new, vec_push)
+        .map(as_list)
+        .reduce(LinkedList::new, list_append)
 }
 
-impl<T: PolarsDataType> AsRefDataType for ChunkedArray<T> {
-    fn as_ref_dtype(&self) -> &DataType {
-        self.dtype()
-    }
+fn get_capacity_from_par_results<T>(ll: &LinkedList<Vec<T>>) -> usize {
+    ll.iter().map(|list| list.len()).sum()
 }
 
-pub(crate) trait AsSinglePtr: AsRefDataType {
-    /// Rechunk and return a ptr to the start of the array
-    fn as_single_ptr(&mut self) -> PolarsResult<usize> {
-        polars_bail!(opq = as_single_ptr, self.as_ref_dtype());
-    }
+fn get_capacity_from_par_results_slice<T>(bufs: &[Vec<T>]) -> usize {
+    bufs.iter().map(|list| list.len()).sum()
+}
+fn get_offsets<T>(bufs: &[Vec<T>]) -> Vec<usize> {
+    bufs.iter()
+        .scan(0usize, |acc, buf| {
+            let out = *acc;
+            *acc += buf.len();
+            Some(out)
+        })
+        .collect()
 }
 
-impl<T> AsSinglePtr for ChunkedArray<T>
+impl<T> FromParallelIterator<T::Native> for NoNull<ChunkedArray<T>>
 where
     T: PolarsNumericType,
 {
-    fn as_single_ptr(&mut self) -> PolarsResult<usize> {
-        let mut ca = self.rechunk();
-        mem::swap(&mut ca, self);
-        let a = self.data_views().next().unwrap();
-        let ptr = a.as_ptr();
-        Ok(ptr as usize)
+    fn from_par_iter<I: IntoParallelIterator<Item = T::Native>>(iter: I) -> Self {
+        // Get linkedlist filled with different vec result from different threads
+        let vectors = collect_into_linked_list(iter);
+        let capacity: usize = get_capacity_from_par_results(&vectors);
+
+        let mut av = Vec::<T::Native>::with_capacity(capacity);
+        for v in vectors {
+            av.extend_from_slice(&v)
+        }
+        let arr = to_array::<T>(av, None);
+        unsafe { NoNull::new(ChunkedArray::from_chunks("", vec![arr])) }
     }
 }
 
-impl AsSinglePtr for BooleanChunked {}
-impl AsSinglePtr for ListChunked {}
-impl AsSinglePtr for Utf8Chunked {}
-impl AsSinglePtr for BinaryChunked {}
-#[cfg(feature = "object")]
-impl<T: PolarsObject> AsSinglePtr for ObjectChunked<T> {}
+fn finish_validities(validities: Vec<(Option<Bitmap>, usize)>, capacity: usize) -> Option<Bitmap> {
+    if validities.iter().any(|(v, _)| v.is_some()) {
+        let mut bitmap = MutableBitmap::with_capacity(capacity);
+        for (valids, len) in validities {
+            if let Some(valids) = valids {
+                bitmap.extend_from_bitmap(&(valids))
+            } else {
+                bitmap.extend_constant(len, true)
+            }
+        }
+        Some(bitmap.into())
+    } else {
+        None
+    }
+}
 
-impl<T> ChunkedArray<T>
+impl<T> FromParallelIterator<Option<T::Native>> for ChunkedArray<T>
 where
     T: PolarsNumericType,
 {
-    /// Contiguous slice
-    pub fn cont_slice(&self) -> PolarsResult<&[T::Native]> {
-        polars_ensure!(
-            self.chunks.len() == 1 && self.chunks[0].null_count() == 0,
-            ComputeError: "chunked array is not contiguous"
-        );
-        Ok(self.downcast_iter().next().map(|arr| arr.values()).unwrap())
-    }
+    fn from_par_iter<I: IntoParallelIterator<Item = Option<T::Native>>>(iter: I) -> Self {
+        // Get linkedlist filled with different vec result from different threads
+        let vectors = collect_into_linked_list(iter);
+
+        let vectors = vectors.into_iter().collect::<Vec<_>>();
+        let capacity: usize = get_capacity_from_par_results_slice(&vectors);
+        let offsets = get_offsets(&vectors);
+
+        let mut values_buf: Vec<T::Native> = Vec::with_capacity(capacity);
+        let values_buf_ptr = unsafe { SyncPtr::new(values_buf.as_mut_ptr()) };
+
+        let validities = offsets
+            .into_par_iter()
+            .zip(vectors)
+            .map(|(offset, vector)| {
+                let mut local_validity = None;
+                let local_len = vector.len();
+                let mut latest_validy_written = 0;
+                unsafe {
+                    let values_buf_ptr = values_buf_ptr.get().add(offset);
+
+                    for (i, opt_v) in vector.into_iter().enumerate() {
+                        match opt_v {
+                            Some(v) => {
+                                std::ptr::write(values_buf_ptr.add(i), v);
+                            }
+                            None => {
+                                let validity = match &mut local_validity {
+                                    None => {
+                                        let validity = MutableBitmap::with_capacity(local_len);
+                                        local_validity = Some(validity);
+                                        local_validity.as_mut().unwrap_unchecked()
+                                    }
+                                    Some(validity) => validity,
+                                };
+                                validity.extend_constant(i - latest_validy_written, true);
+                                latest_validy_written = i + 1;
+                                validity.push_unchecked(false);
+                                // initialize value
+                                std::ptr::write(values_buf_ptr.add(i), T::Native::default());
+                            }
+                        }
+                    }
+                }
+                if let Some(validity) = &mut local_validity {
+                    validity.extend_constant(local_len - latest_validy_written, true);
+                }
+                (local_validity.map(|b| b.into()), local_len)
+            })
+            .collect::<Vec<_>>();
+        unsafe { values_buf.set_len(capacity) };
 
-    /// Contiguous mutable slice
-    pub(crate) fn cont_slice_mut(&mut self) -> Option<&mut [T::Native]> {
-        if self.chunks.len() == 1 && self.chunks[0].null_count() == 0 {
-            // Safety, we will not swap the PrimitiveArray.
-            let arr = unsafe { self.downcast_iter_mut().next().unwrap() };
-            arr.get_mut_values()
-        } else {
-            None
-        }
-    }
+        let validity = finish_validities(validities, capacity);
 
-    /// Get slices of the underlying arrow data.
-    /// NOTE: null values should be taken into account by the user of these slices as they are handled
-    /// separately
-    pub fn data_views(&self) -> impl Iterator<Item = &[T::Native]> + DoubleEndedIterator {
-        self.downcast_iter().map(|arr| arr.values().as_slice())
-    }
-
-    #[allow(clippy::wrong_self_convention)]
-    pub fn into_no_null_iter(
-        &self,
-    ) -> impl Iterator<Item = T::Native>
-           + '_
-           + Send
-           + Sync
-           + ExactSizeIterator
-           + DoubleEndedIterator
-           + TrustedLen {
-        // .copied was significantly slower in benchmark, next call did not inline?
-        #[allow(clippy::map_clone)]
-        // we know the iterators len
-        unsafe {
-            self.data_views()
-                .flatten()
-                .map(|v| *v)
-                .trust_my_length(self.len())
-        }
+        let arr = PrimitiveArray::from_data_default(values_buf.into(), validity);
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
 }
 
-impl<T: PolarsDataType> Clone for ChunkedArray<T> {
-    fn clone(&self) -> Self {
-        ChunkedArray {
-            field: self.field.clone(),
-            chunks: self.chunks.clone(),
-            phantom: PhantomData,
-            bit_settings: self.bit_settings,
-            length: self.length,
-        }
-    }
-}
+impl FromParallelIterator<bool> for BooleanChunked {
+    fn from_par_iter<I: IntoParallelIterator<Item = bool>>(iter: I) -> Self {
+        let vectors = collect_into_linked_list(iter);
 
-impl<T: PolarsDataType> AsRef<ChunkedArray<T>> for ChunkedArray<T> {
-    fn as_ref(&self) -> &ChunkedArray<T> {
-        self
-    }
-}
+        let capacity: usize = get_capacity_from_par_results(&vectors);
 
-impl ValueSize for ListChunked {
-    fn get_values_size(&self) -> usize {
-        self.chunks
-            .iter()
-            .fold(0usize, |acc, arr| acc + arr.get_values_size())
+        let arr = unsafe {
+            BooleanArray::from_trusted_len_values_iter(
+                vectors.into_iter().flatten().trust_my_length(capacity),
+            )
+        };
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
 }
 
-impl ValueSize for Utf8Chunked {
-    fn get_values_size(&self) -> usize {
-        self.chunks
-            .iter()
-            .fold(0usize, |acc, arr| acc + arr.get_values_size())
-    }
-}
+impl FromParallelIterator<Option<bool>> for BooleanChunked {
+    fn from_par_iter<I: IntoParallelIterator<Item = Option<bool>>>(iter: I) -> Self {
+        // Get linkedlist filled with different vec result from different threads
+        let vectors = collect_into_linked_list(iter);
+        let vectors = vectors.into_iter().collect::<Vec<_>>();
+
+        let chunks = vectors
+            .into_par_iter()
+            .map(|vector| {
+                Box::new(unsafe {
+                    BooleanArray::from_trusted_len_iter_unchecked(vector.into_iter())
+                }) as ArrayRef
+            })
+            .collect::<Vec<_>>();
 
-impl ValueSize for BinaryChunked {
-    fn get_values_size(&self) -> usize {
-        self.chunks
-            .iter()
-            .fold(0usize, |acc, arr| acc + arr.get_values_size())
+        unsafe { BooleanChunked::from_chunks("", chunks).rechunk() }
     }
 }
 
-impl ListChunked {
-    /// Get the inner data type of the list.
-    pub fn inner_dtype(&self) -> DataType {
-        match self.dtype() {
-            DataType::List(dt) => *dt.clone(),
-            _ => unreachable!(),
+impl<Ptr> FromParallelIterator<Ptr> for Utf8Chunked
+where
+    Ptr: PolarsAsRef<str> + Send + Sync,
+{
+    fn from_par_iter<I: IntoParallelIterator<Item = Ptr>>(iter: I) -> Self {
+        let vectors = collect_into_linked_list(iter);
+        let cap = get_capacity_from_par_results(&vectors);
+        let mut builder = MutableUtf8ValuesArray::with_capacities(cap, cap * 10);
+        for vec in vectors {
+            for val in vec {
+                builder.push(val.as_ref())
+            }
         }
-    }
-
-    pub fn set_inner_dtype(&mut self, dtype: DataType) {
-        assert_eq!(dtype.to_physical(), self.inner_dtype().to_physical());
-        let field = Arc::make_mut(&mut self.field);
-        field.coerce(DataType::List(Box::new(dtype)));
+        let arr: LargeStringArray = builder.into();
+        unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
 }
 
-pub(crate) fn to_primitive<T: PolarsNumericType>(
-    values: Vec<T::Native>,
-    validity: Option<Bitmap>,
-) -> PrimitiveArray<T::Native> {
-    PrimitiveArray::new(T::get_dtype().to_arrow(), values.into(), validity)
-}
-
-pub(crate) fn to_array<T: PolarsNumericType>(
-    values: Vec<T::Native>,
-    validity: Option<Bitmap>,
-) -> ArrayRef {
-    Box::new(to_primitive::<T>(values, validity))
-}
-
-impl<T: PolarsNumericType> From<PrimitiveArray<T::Native>> for ChunkedArray<T> {
-    fn from(a: PrimitiveArray<T::Native>) -> Self {
-        unsafe { ChunkedArray::from_chunks("", vec![Box::new(a)]) }
+pub fn flatten_par<T: Send + Sync + Copy>(bufs: &[&[T]]) -> Vec<T> {
+    let len = bufs.iter().map(|b| b.as_ref().len()).sum();
+    let offsets = bufs
+        .iter()
+        .scan(0usize, |acc, buf| {
+            let out = *acc;
+            *acc += buf.len();
+            Some(out)
+        })
+        .collect::<Vec<_>>();
+
+    let mut out = Vec::with_capacity(len);
+    let out_ptr = unsafe { SyncPtr::new(out.as_mut_ptr()) };
+
+    offsets.into_par_iter().enumerate().for_each(|(i, offset)| {
+        let buf = bufs[i];
+        let ptr: *mut T = out_ptr.get();
+        unsafe {
+            let dst = ptr.add(offset);
+            let src = buf.as_ptr();
+            std::ptr::copy_nonoverlapping(src, dst, buf.len())
+        }
+    });
+    unsafe {
+        out.set_len(len);
     }
+    out
 }
 
-#[cfg(test)]
-pub(crate) mod test {
-    use crate::prelude::*;
-
-    pub(crate) fn get_chunked_array() -> Int32Chunked {
-        ChunkedArray::new("a", &[1, 2, 3])
-    }
+impl<Ptr> FromParallelIterator<Option<Ptr>> for Utf8Chunked
+where
+    Ptr: AsRef<str> + Send + Sync,
+{
+    fn from_par_iter<I: IntoParallelIterator<Item = Option<Ptr>>>(iter: I) -> Self {
+        let vectors = collect_into_linked_list(iter);
+        let vectors = vectors.into_iter().collect::<Vec<_>>();
+
+        let arrays = vectors
+            .into_par_iter()
+            .map(|vector| {
+                let cap = vector.len();
+                let mut builder = MutableUtf8Array::with_capacities(cap, cap * 10);
+                for opt_val in vector {
+                    builder.push(opt_val)
+                }
+                let arr: LargeStringArray = builder.into();
+                arr
+            })
+            .collect::<Vec<_>>();
 
-    #[test]
-    fn test_sort() {
-        let a = Int32Chunked::new("a", &[1, 9, 3, 2]);
-        let b = a
-            .sort(false)
-            .into_iter()
-            .map(|opt| opt.unwrap())
+        let mut len = 0;
+        let mut thread_offsets = Vec::with_capacity(arrays.len());
+        let values = arrays
+            .iter()
+            .map(|arr| {
+                thread_offsets.push(len);
+                len += arr.len();
+                arr.values().as_slice()
+            })
             .collect::<Vec<_>>();
-        assert_eq!(b, [1, 2, 3, 9]);
-        let a = Utf8Chunked::new("a", &["b", "a", "c"]);
-        let a = a.sort(false);
-        let b = a.into_iter().collect::<Vec<_>>();
-        assert_eq!(b, [Some("a"), Some("b"), Some("c")]);
-        assert!(a.is_sorted_ascending_flag());
-    }
+        let values = flatten_par(&values);
 
-    #[test]
-    fn arithmetic() {
-        let a = &Int32Chunked::new("a", &[1, 100, 6, 40]);
-        let b = &Int32Chunked::new("b", &[-1, 2, 3, 4]);
-
-        // Not really asserting anything here but shill making sure the code is exercised
-        // This (and more) is properly tested from the integration test suite and Python bindings.
-        println!("{:?}", a + b);
-        println!("{:?}", a - b);
-        println!("{:?}", a * b);
-        println!("{:?}", a / b);
-    }
+        let validity = finish_validities(
+            arrays
+                .iter()
+                .map(|arr| {
+                    let local_len = arr.len();
+                    (arr.validity().cloned(), local_len)
+                })
+                .collect(),
+            len,
+        );
 
-    #[test]
-    fn iter() {
-        let s1 = get_chunked_array();
-        // sum
-        assert_eq!(s1.into_iter().fold(0, |acc, val| { acc + val.unwrap() }), 6)
+        // concat the offsets
+        // this is single threaded as the values depend on previous ones
+        // if this proves to slow we could try parallel reduce
+        let mut offsets = Vec::with_capacity(len + 1);
+        let mut offsets_so_far = 0;
+        let mut first = true;
+        for array in &arrays {
+            let local_offsets = array.offsets().as_slice();
+            if first {
+                offsets.extend_from_slice(local_offsets);
+                first = false;
+            } else {
+                // offset lengths must be updated
+                unsafe {
+                    // safety: there is always a single offset
+                    offsets.extend(
+                        local_offsets
+                            .get_unchecked(1..)
+                            .iter()
+                            .map(|v| *v + offsets_so_far),
+                    )
+                }
+            }
+            offsets_so_far = unsafe { *offsets.last().unwrap_unchecked() };
+        }
+
+        unsafe {
+            offsets.set_len(len + 1);
+            let arr = Utf8Array::<i64>::from_data_unchecked_default(
+                offsets.into(),
+                values.into(),
+                validity,
+            );
+            Self::from_chunks("", vec![Box::new(arr)])
+        }
     }
+}
 
-    #[test]
-    fn limit() {
-        let a = get_chunked_array();
-        let b = a.limit(2);
-        println!("{:?}", b);
-        assert_eq!(b.len(), 2)
+/// From trait
+impl<'a> From<&'a Utf8Chunked> for Vec<Option<&'a str>> {
+    fn from(ca: &'a Utf8Chunked) -> Self {
+        ca.into_iter().collect()
     }
+}
 
-    #[test]
-    fn filter() {
-        let a = get_chunked_array();
-        let b = a
-            .filter(&BooleanChunked::new("filter", &[true, false, false]))
-            .unwrap();
-        assert_eq!(b.len(), 1);
-        assert_eq!(b.into_iter().next(), Some(Some(1)));
+impl From<Utf8Chunked> for Vec<Option<String>> {
+    fn from(ca: Utf8Chunked) -> Self {
+        ca.into_iter()
+            .map(|opt| opt.map(|s| s.to_string()))
+            .collect()
     }
+}
 
-    #[test]
-    fn aggregates() {
-        let a = &Int32Chunked::new("a", &[1, 100, 10, 9]);
-        assert_eq!(a.max(), Some(100));
-        assert_eq!(a.min(), Some(1));
-        assert_eq!(a.sum(), Some(120))
+impl<'a> From<&'a BooleanChunked> for Vec<Option<bool>> {
+    fn from(ca: &'a BooleanChunked) -> Self {
+        ca.into_iter().collect()
     }
+}
 
-    #[test]
-    fn take() {
-        let a = get_chunked_array();
-        let new = a.take([0usize, 1].iter().copied().into()).unwrap();
-        assert_eq!(new.len(), 2)
+impl From<BooleanChunked> for Vec<Option<bool>> {
+    fn from(ca: BooleanChunked) -> Self {
+        ca.into_iter().collect()
     }
+}
 
-    #[test]
-    fn cast() {
-        let a = get_chunked_array();
-        let b = a.cast(&DataType::Int64).unwrap();
-        assert_eq!(b.dtype(), &ArrowDataType::Int64)
+impl<'a, T> From<&'a ChunkedArray<T>> for Vec<Option<T::Native>>
+where
+    T: PolarsNumericType,
+{
+    fn from(ca: &'a ChunkedArray<T>) -> Self {
+        ca.into_iter().collect()
     }
+}
 
-    fn assert_slice_equal<T>(ca: &ChunkedArray<T>, eq: &[T::Native])
+impl FromParallelIterator<Option<Series>> for ListChunked {
+    fn from_par_iter<I>(iter: I) -> Self
     where
-        T: PolarsNumericType,
+        I: IntoParallelIterator<Item = Option<Series>>,
     {
-        assert_eq!(
-            ca.into_iter().map(|opt| opt.unwrap()).collect::<Vec<_>>(),
-            eq
-        )
-    }
+        let mut dtype = None;
+        let vectors = collect_into_linked_list(iter);
 
-    #[test]
-    fn slice() {
-        let mut first = UInt32Chunked::new("first", &[0, 1, 2]);
-        let second = UInt32Chunked::new("second", &[3, 4, 5]);
-        first.append(&second);
-        assert_slice_equal(&first.slice(0, 3), &[0, 1, 2]);
-        assert_slice_equal(&first.slice(0, 4), &[0, 1, 2, 3]);
-        assert_slice_equal(&first.slice(1, 4), &[1, 2, 3, 4]);
-        assert_slice_equal(&first.slice(3, 2), &[3, 4]);
-        assert_slice_equal(&first.slice(3, 3), &[3, 4, 5]);
-        assert_slice_equal(&first.slice(-3, 3), &[3, 4, 5]);
-        assert_slice_equal(&first.slice(-6, 6), &[0, 1, 2, 3, 4, 5]);
-
-        assert_eq!(first.slice(-7, 2).len(), 2);
-        assert_eq!(first.slice(-3, 4).len(), 3);
-        assert_eq!(first.slice(3, 4).len(), 3);
-        assert_eq!(first.slice(10, 4).len(), 0);
-    }
-
-    #[test]
-    fn sorting() {
-        let s = UInt32Chunked::new("", &[9, 2, 4]);
-        let sorted = s.sort(false);
-        assert_slice_equal(&sorted, &[2, 4, 9]);
-        let sorted = s.sort(true);
-        assert_slice_equal(&sorted, &[9, 4, 2]);
-
-        let s: Utf8Chunked = ["b", "a", "z"].iter().collect();
-        let sorted = s.sort(false);
-        assert_eq!(
-            sorted.into_iter().collect::<Vec<_>>(),
-            &[Some("a"), Some("b"), Some("z")]
-        );
-        let sorted = s.sort(true);
-        assert_eq!(
-            sorted.into_iter().collect::<Vec<_>>(),
-            &[Some("z"), Some("b"), Some("a")]
-        );
-        let s: Utf8Chunked = [Some("b"), None, Some("z")].iter().copied().collect();
-        let sorted = s.sort(false);
-        assert_eq!(
-            sorted.into_iter().collect::<Vec<_>>(),
-            &[None, Some("b"), Some("z")]
-        );
-    }
-
-    #[test]
-    fn reverse() {
-        let s = UInt32Chunked::new("", &[1, 2, 3]);
-        // path with continuous slice
-        assert_slice_equal(&s.reverse(), &[3, 2, 1]);
-        // path with options
-        let s = UInt32Chunked::new("", &[Some(1), None, Some(3)]);
-        assert_eq!(Vec::from(&s.reverse()), &[Some(3), None, Some(1)]);
-        let s = BooleanChunked::new("", &[true, false]);
-        assert_eq!(Vec::from(&s.reverse()), &[Some(false), Some(true)]);
-
-        let s = Utf8Chunked::new("", &["a", "b", "c"]);
-        assert_eq!(Vec::from(&s.reverse()), &[Some("c"), Some("b"), Some("a")]);
+        let list_capacity: usize = get_capacity_from_par_results(&vectors);
+        let value_capacity = vectors
+            .iter()
+            .map(|list| {
+                list.iter()
+                    .map(|opt_s| {
+                        opt_s
+                            .as_ref()
+                            .map(|s| {
+                                if dtype.is_none() && !matches!(s.dtype(), DataType::Null) {
+                                    dtype = Some(s.dtype().clone())
+                                }
+                                s.len()
+                            })
+                            .unwrap_or(0)
+                    })
+                    .sum::<usize>()
+            })
+            .sum::<usize>();
 
-        let s = Utf8Chunked::new("", &[Some("a"), None, Some("c")]);
-        assert_eq!(Vec::from(&s.reverse()), &[Some("c"), None, Some("a")]);
+        match &dtype {
+            #[cfg(feature = "object")]
+            Some(DataType::Object(_)) => {
+                let s = vectors
+                    .iter()
+                    .flatten()
+                    .find_map(|opt_s| opt_s.as_ref())
+                    .unwrap();
+                let mut builder = s.get_list_builder("collected", value_capacity, list_capacity);
+
+                for v in vectors {
+                    for val in v {
+                        builder.append_opt_series(val.as_ref());
+                    }
+                }
+                builder.finish()
+            }
+            Some(dtype) => {
+                let mut builder =
+                    get_list_builder(dtype, value_capacity, list_capacity, "collected").unwrap();
+                for v in &vectors {
+                    for val in v {
+                        builder.append_opt_series(val.as_ref());
+                    }
+                }
+                builder.finish()
+            }
+            None => ListChunked::full_null_with_dtype("collected", list_capacity, &DataType::Null),
+        }
     }
+}
 
-    #[test]
-    #[cfg(feature = "dtype-categorical")]
-    fn test_iter_categorical() {
-        use crate::{reset_string_cache, SINGLE_LOCK};
-        let _lock = SINGLE_LOCK.lock();
-        reset_string_cache();
-        let ca = Utf8Chunked::new("", &[Some("foo"), None, Some("bar"), Some("ham")]);
-        let ca = ca.cast(&DataType::Categorical(None)).unwrap();
-        let ca = ca.categorical().unwrap();
-        let v: Vec<_> = ca.logical().into_iter().collect();
-        assert_eq!(v, &[Some(0), None, Some(1), Some(2)]);
-    }
+#[cfg(test)]
+mod test {
+    use crate::prelude::*;
 
     #[test]
-    #[ignore]
-    fn test_shrink_to_fit() {
-        let mut builder = Utf8ChunkedBuilder::new("foo", 2048, 100 * 2048);
-        builder.append_value("foo");
-        let mut arr = builder.finish();
-        let before = arr
-            .chunks()
-            .iter()
-            .map(|arr| arrow::compute::aggregate::estimated_bytes_size(arr.as_ref()))
-            .sum::<usize>();
-        arr.shrink_to_fit();
-        let after = arr
-            .chunks()
-            .iter()
-            .map(|arr| arrow::compute::aggregate::estimated_bytes_size(arr.as_ref()))
-            .sum::<usize>();
-        assert!(before > after);
+    fn test_collect_into_list() {
+        let s1 = Series::new("", &[true, false, true]);
+        let s2 = Series::new("", &[true, false, true]);
+
+        let ll: ListChunked = [&s1, &s2].iter().copied().collect();
+        assert_eq!(ll.len(), 2);
+        assert_eq!(ll.null_count(), 0);
+        let ll: ListChunked = [None, Some(s2)].into_iter().collect();
+        assert_eq!(ll.len(), 2);
+        assert_eq!(ll.null_count(), 1);
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ndarray.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ndarray.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/builder.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/iterator.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/object/registry.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/object/registry.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/append.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/append.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/apply.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/explode.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/explode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/extend.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/extend.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/filter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/full.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/full.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/set.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/shift.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/shift.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/ops/zip.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/ops/zip.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/random.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/date.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/date.rs`

 * *Files 4% similar despite different names*

```diff
@@ -26,30 +26,30 @@
 
     /// Construct a new [`DateChunked`] from an iterator over [`NaiveDate`].
     pub fn from_naive_date<I: IntoIterator<Item = NaiveDate>>(name: &str, v: I) -> Self {
         let unit = v.into_iter().map(naive_date_to_date).collect::<Vec<_>>();
         Int32Chunked::from_vec(name, unit).into()
     }
 
-    /// Format Date with a `fmt` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
-    pub fn strftime(&self, fmt: &str) -> Utf8Chunked {
+    /// Format Date with a `format` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
+    pub fn strftime(&self, format: &str) -> Utf8Chunked {
         let date = NaiveDate::from_ymd_opt(2001, 1, 1).unwrap();
-        let fmted = format!("{}", date.format(fmt));
+        let fmted = format!("{}", date.format(format));
 
         let mut ca: Utf8Chunked = self.apply_kernel_cast(&|arr| {
             let mut buf = String::new();
             let mut mutarr =
                 MutableUtf8Array::with_capacities(arr.len(), arr.len() * fmted.len() + 1);
 
             for opt in arr.into_iter() {
                 match opt {
                     None => mutarr.push_null(),
                     Some(v) => {
                         buf.clear();
-                        let datefmt = date32_to_date(*v).format(fmt);
+                        let datefmt = date32_to_date(*v).format(format);
                         write!(buf, "{datefmt}").unwrap();
                         mutarr.push(Some(&buf))
                     }
                 }
             }
 
             let arr: Utf8Array<i64> = mutarr.into();
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs`

 * *Files 6% similar despite different names*

```diff
@@ -115,46 +115,62 @@
         match self.2.as_ref().unwrap() {
             DataType::Datetime(_, tz) => tz,
             _ => unreachable!(),
         }
     }
 
     #[cfg(feature = "timezones")]
-    pub fn replace_time_zone(&self, time_zone: Option<&str>) -> PolarsResult<DatetimeChunked> {
+    pub fn replace_time_zone(
+        &self,
+        time_zone: Option<&str>,
+        use_earliest: Option<bool>,
+    ) -> PolarsResult<DatetimeChunked> {
         match (self.time_zone(), time_zone) {
             (Some(from), Some(to)) => {
                 let chunks = self
                     .downcast_iter()
-                    .map(|arr| replace_timezone(arr, self.time_unit().to_arrow(), to, from))
+                    .map(|arr| {
+                        replace_timezone(arr, self.time_unit().to_arrow(), to, from, use_earliest)
+                    })
                     .collect::<PolarsResult<_>>()?;
                 let out = unsafe { ChunkedArray::from_chunks(self.name(), chunks) };
                 Ok(out.into_datetime(self.time_unit(), Some(to.to_string())))
             }
             (Some(from), None) => {
                 let chunks = self
                     .downcast_iter()
-                    .map(|arr| replace_timezone(arr, self.time_unit().to_arrow(), "UTC", from))
+                    .map(|arr| {
+                        replace_timezone(
+                            arr,
+                            self.time_unit().to_arrow(),
+                            "UTC",
+                            from,
+                            use_earliest,
+                        )
+                    })
                     .collect::<PolarsResult<_>>()?;
                 let out = unsafe { ChunkedArray::from_chunks(self.name(), chunks) };
                 Ok(out.into_datetime(self.time_unit(), None))
             }
             (None, Some(to)) => {
                 let chunks = self
                     .downcast_iter()
-                    .map(|arr| replace_timezone(arr, self.time_unit().to_arrow(), to, "UTC"))
+                    .map(|arr| {
+                        replace_timezone(arr, self.time_unit().to_arrow(), to, "UTC", use_earliest)
+                    })
                     .collect::<PolarsResult<_>>()?;
                 let out = unsafe { ChunkedArray::from_chunks(self.name(), chunks) };
                 Ok(out.into_datetime(self.time_unit(), Some(to.to_string())))
             }
             (None, None) => Ok(self.clone()),
         }
     }
 
-    /// Format Datetime with a `fmt` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
-    pub fn strftime(&self, fmt: &str) -> PolarsResult<Utf8Chunked> {
+    /// Format Datetime with a `format` rule. See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
+    pub fn strftime(&self, format: &str) -> PolarsResult<Utf8Chunked> {
         #[cfg(feature = "timezones")]
         use chrono::Utc;
         let conversion_f = match self.time_unit() {
             TimeUnit::Nanoseconds => timestamp_ns_to_datetime,
             TimeUnit::Microseconds => timestamp_us_to_datetime,
             TimeUnit::Milliseconds => timestamp_ms_to_datetime,
         };
@@ -165,39 +181,39 @@
             .unwrap();
         let mut fmted = String::new();
         match self.time_zone() {
             #[cfg(feature = "timezones")]
             Some(_) => write!(
                 fmted,
                 "{}",
-                Utc.from_local_datetime(&dt).earliest().unwrap().format(fmt)
+                Utc.from_local_datetime(&dt).earliest().unwrap().format(format)
             )
             .map_err(
-                |_| polars_err!(ComputeError: "cannot format DateTime with format '{}'", fmt),
+                |_| polars_err!(ComputeError: "cannot format DateTime with format '{}'", format),
             )?,
-            _ => write!(fmted, "{}", dt.format(fmt)).map_err(
-                |_| polars_err!(ComputeError: "cannot format NaiveDateTime with format '{}'", fmt),
+            _ => write!(fmted, "{}", dt.format(format)).map_err(
+                |_| polars_err!(ComputeError: "cannot format NaiveDateTime with format '{}'", format),
             )?,
         };
         let fmted = fmted; // discard mut
 
         let mut ca: Utf8Chunked = match self.time_zone() {
             #[cfg(feature = "timezones")]
             Some(time_zone) => match parse_offset(time_zone) {
                 Ok(time_zone) => self.apply_kernel_cast(&|arr| {
-                    format_fixed_offset(time_zone, arr, fmt, &fmted, conversion_f)
+                    format_fixed_offset(time_zone, arr, format, &fmted, conversion_f)
                 }),
                 Err(_) => match time_zone.parse::<Tz>() {
                     Ok(time_zone) => self.apply_kernel_cast(&|arr| {
-                        format_tz(time_zone, arr, fmt, &fmted, conversion_f)
+                        format_tz(time_zone, arr, format, &fmted, conversion_f)
                     }),
                     Err(_) => unreachable!(),
                 },
             },
-            _ => self.apply_kernel_cast(&|arr| format_naive(arr, fmt, &fmted, conversion_f)),
+            _ => self.apply_kernel_cast(&|arr| format_naive(arr, format, &fmted, conversion_f)),
         };
         ca.rename(self.name());
         Ok(ca)
     }
 
     /// Construct a new [`DatetimeChunked`] from an iterator over [`NaiveDateTime`].
     pub fn from_naive_datetime<I: IntoIterator<Item = NaiveDateTime>>(
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/temporal/time.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/temporal/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/to_vec.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/to_vec.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/chunked_array/trusted_len.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/chunked_array/trusted_len.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/cloud.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/cloud.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/config.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/config.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/_serde.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/_serde.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/aliases.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/aliases.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/any_value.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/any_value.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/dtype.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/dtype.rs`

 * *Files 2% similar despite different names*

```diff
@@ -118,14 +118,22 @@
             Date => Int32,
             Datetime(_, _) => Int64,
             Duration(_) => Int64,
             Time => Int64,
             #[cfg(feature = "dtype-categorical")]
             Categorical(_) => UInt32,
             List(dt) => List(Box::new(dt.to_physical())),
+            #[cfg(feature = "dtype-struct")]
+            Struct(fields) => {
+                let new_fields = fields
+                    .iter()
+                    .map(|s| Field::new(s.name(), s.data_type().to_physical()))
+                    .collect();
+                Struct(new_fields)
+            }
             _ => self.clone(),
         }
     }
 
     /// Check if this [`DataType`] is a logical type
     pub fn is_logical(&self) -> bool {
         self != &self.to_physical()
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/field.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/field.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -58,14 +58,15 @@
     fn get_dtype() -> DataType
     where
         Self: Sized;
 }
 
 macro_rules! impl_polars_datatype {
     ($ca:ident, $variant:ident, $physical:ty) => {
+        #[derive(Clone, Copy)]
         pub struct $ca {}
 
         impl PolarsDataType for $ca {
             #[inline]
             fn get_dtype() -> DataType {
                 DataType::$variant
             }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/datatypes/time_unit.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/datatypes/time_unit.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_7.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_7.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_8.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/doc/changelog/v0_9.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/doc/changelog/v0_9.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/fmt.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/fmt.rs`

 * *Files 14% similar despite different names*

```diff
@@ -90,30 +90,30 @@
                     write!(f, "\t{}\n", v_trunc)?;
                 }
             } else {
                 write!(f, "\t{}\n", v)?;
             };
             Ok(())
         };
-        if limit < $a.len() {
+        if (limit == 0 && $a.len() > 0) || ($a.len() > limit + 1) {
             if limit > 0 {
                 for i in 0..std::cmp::max((limit / 2), 1) {
                     let v = $a.get_any_value(i).unwrap();
                     write_fn(v, $f)?;
                 }
             }
             write!($f, "\t\n")?;
             if limit > 1 {
                 for i in ($a.len() - (limit + 1) / 2)..$a.len() {
                     let v = $a.get_any_value(i).unwrap();
                     write_fn(v, $f)?;
                 }
             }
         } else {
-            for i in 0..limit {
+            for i in 0..$a.len() {
                 let v = $a.get_any_value(i).unwrap();
                 write_fn(v, $f)?;
             }
         }
 
         write!($f, "]")
     }};
@@ -494,15 +494,17 @@
                 .load_preset(preset)
                 .set_content_arrangement(ContentArrangement::Dynamic);
 
             if is_utf8 && env_is_true(FMT_TABLE_ROUNDED_CORNERS) {
                 table.apply_modifier(UTF8_ROUND_CORNERS);
             }
             if max_n_rows > 0 {
-                if height > max_n_rows {
+                if height > max_n_rows + 1 {
+                    // Truncate the table if we have more rows than the configured maximum number
+                    // of rows plus the single row which would contain "".
                     let mut rows = Vec::with_capacity(std::cmp::max(max_n_rows, 2));
                     for i in 0..std::cmp::max(max_n_rows / 2, 1) {
                         let row = self
                             .columns
                             .iter()
                             .map(|s| s.str_value(i).unwrap())
                             .collect();
@@ -854,124 +856,33 @@
         }
         // last value has no trailing comma
         write!(f, "{}", vals[vals.len() - 1])?;
     }
     write!(f, "}}")
 }
 
-macro_rules! impl_fmt_list {
-    ($self:ident) => {{
-        match $self.len() {
-            0 => format!("[]"),
-            1 => format!("[{}]", $self.get_any_value(0).unwrap()),
-            2 => format!(
-                "[{}, {}]",
-                $self.get_any_value(0).unwrap(),
-                $self.get_any_value(1).unwrap()
-            ),
+impl Series {
+    pub fn fmt_list(&self) -> String {
+        match self.len() {
+            0 => "[]".to_string(),
+            1 => format!("[{}]", self.get(0).unwrap()),
+            2 => format!("[{}, {}]", self.get(0).unwrap(), self.get(1).unwrap()),
             3 => format!(
                 "[{}, {}, {}]",
-                $self.get_any_value(0).unwrap(),
-                $self.get_any_value(1).unwrap(),
-                $self.get_any_value(2).unwrap()
+                self.get(0).unwrap(),
+                self.get(1).unwrap(),
+                self.get(2).unwrap()
             ),
             _ => format!(
                 "[{}, {},  {}]",
-                $self.get_any_value(0).unwrap(),
-                $self.get_any_value(1).unwrap(),
-                $self.get_any_value($self.len() - 1).unwrap()
+                self.get(0).unwrap(),
+                self.get(1).unwrap(),
+                self.get(self.len() - 1).unwrap()
             ),
         }
-    }};
-}
-
-pub(crate) trait FmtList {
-    fn fmt_list(&self) -> String;
-}
-
-impl<T> FmtList for ChunkedArray<T>
-where
-    T: PolarsNumericType,
-    T::Native: fmt::Display,
-{
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-impl FmtList for BooleanChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-impl FmtList for Utf8Chunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-impl FmtList for BinaryChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-impl FmtList for ListChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "dtype-categorical")]
-impl FmtList for CategoricalChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "dtype-date")]
-impl FmtList for DateChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "dtype-datetime")]
-impl FmtList for DatetimeChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "dtype-duration")]
-impl FmtList for DurationChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "dtype-time")]
-impl FmtList for TimeChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "dtype-struct")]
-impl FmtList for StructChunked {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
-    }
-}
-
-#[cfg(feature = "object")]
-impl<T: PolarsObject> FmtList for ObjectChunked<T> {
-    fn fmt_list(&self) -> String {
-        impl_fmt_list!(self)
     }
 }
 
 #[cfg(feature = "dtype-decimal")]
 mod decimal {
     use std::fmt::Formatter;
     use std::{fmt, ptr, str};
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/arithmetic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/asof_join/asof.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/asof_join/asof.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/asof_join/groups.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/asof_join/groups.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/asof_join/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/asof_join/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/chunks.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/chunks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/cross_join.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/cross_join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/explode.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/explode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -317,15 +317,15 @@
                 let ca_self = self.rechunk();
                 let arr = ca_self.downcast_iter().next().unwrap();
                 _agg_helper_idx_utf8(groups, |(first, idx)| {
                     debug_assert!(idx.len() <= ca_self.len());
                     if idx.is_empty() {
                         None
                     } else if idx.len() == 1 {
-                        ca_self.get(first as usize)
+                        arr.get_unchecked(first as usize)
                     } else if self.null_count() == 0 {
                         take_agg_utf8_iter_unchecked_no_null(
                             arr,
                             indexes_to_usizes(idx),
                             |acc, v| if acc < v { acc } else { v },
                         )
                     } else {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/hashing.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/hashing.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/into_groups.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/into_groups.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/perfect.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/perfect.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/groupby/proxy.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/groupby/proxy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/av_buffer.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/av_buffer.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 #[cfg(feature = "dtype-struct")]
 use polars_utils::slice::GetSaferUnchecked;
+use polars_utils::unreachable_unchecked_release;
 #[cfg(feature = "dtype-struct")]
 use smartstring::alias::String as SmartString;
 
 use super::*;
 #[cfg(feature = "dtype-struct")]
 use crate::prelude::any_value::arr_to_any_value;
 
+#[derive(Clone)]
 pub enum AnyValueBuffer<'a> {
     Boolean(BooleanChunkedBuilder),
     #[cfg(feature = "dtype-i8")]
     Int8(PrimitiveChunkedBuilder<Int8Type>),
     #[cfg(feature = "dtype-i16")]
     Int16(PrimitiveChunkedBuilder<Int16Type>),
     Int32(PrimitiveChunkedBuilder<Int32Type>),
@@ -126,47 +128,130 @@
             polars_err!(
                 ComputeError: "could not append {:?} to the builder; make sure that all rows \
                 have the same schema or consider increasing `schema_inference_length`"
             )
         })
     }
 
-    pub fn into_series(self) -> Series {
+    pub fn reset(&mut self, capacity: usize) -> Series {
         use AnyValueBuffer::*;
         match self {
-            Boolean(b) => b.finish().into_series(),
-            Int32(b) => b.finish().into_series(),
-            Int64(b) => b.finish().into_series(),
-            UInt32(b) => b.finish().into_series(),
-            UInt64(b) => b.finish().into_series(),
+            Boolean(b) => {
+                let mut new = BooleanChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Int32(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Int64(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            UInt32(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            UInt64(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-date")]
-            Date(b) => b.finish().into_date().into_series(),
+            Date(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_date().into_series()
+            }
             #[cfg(feature = "dtype-datetime")]
-            Datetime(b, tu, tz) => b.finish().into_datetime(tu, tz).into_series(),
+            Datetime(b, tu, tz) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                let tz = if capacity > 0 {
+                    tz.clone()
+                } else {
+                    std::mem::take(tz)
+                };
+                new.finish().into_datetime(*tu, tz).into_series()
+            }
             #[cfg(feature = "dtype-duration")]
-            Duration(b, tu) => b.finish().into_duration(tu).into_series(),
+            Duration(b, tu) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_duration(*tu).into_series()
+            }
             #[cfg(feature = "dtype-time")]
-            Time(b) => b.finish().into_time().into_series(),
-            Float32(b) => b.finish().into_series(),
-            Float64(b) => b.finish().into_series(),
-            Utf8(b) => b.finish().into_series(),
+            Time(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_time().into_series()
+            }
+            Float32(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Float64(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Utf8(b) => {
+                let avg_values_len = b
+                    .builder
+                    .values()
+                    .len()
+                    .saturating_div(b.builder.capacity() + 1)
+                    + 1;
+                let mut new =
+                    Utf8ChunkedBuilder::new(b.field.name(), capacity, avg_values_len * capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-i8")]
-            Int8(b) => b.finish().into_series(),
+            Int8(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-i16")]
-            Int16(b) => b.finish().into_series(),
+            Int16(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-u8")]
-            UInt8(b) => b.finish().into_series(),
+            UInt8(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-u16")]
-            UInt16(b) => b.finish().into_series(),
+            UInt16(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             All(dtype, vals) => {
-                Series::from_any_values_and_dtype("", &vals, &dtype, false).unwrap()
+                let out = Series::from_any_values_and_dtype("", vals, dtype, false).unwrap();
+                let mut new = Vec::with_capacity(capacity);
+                std::mem::swap(&mut new, vals);
+                out
             }
         }
     }
 
+    pub fn into_series(mut self) -> Series {
+        self.reset(0)
+    }
+
     pub fn new(dtype: &DataType, capacity: usize) -> AnyValueBuffer<'a> {
         (dtype, capacity).into()
     }
 }
 
 // datatype and length
 impl From<(&DataType, usize)> for AnyValueBuffer<'_> {
@@ -203,14 +288,15 @@
             // Struct and List can be recursive so use anyvalues for that
             dt => AnyValueBuffer::All(dt.clone(), Vec::with_capacity(len)),
         }
     }
 }
 
 //// An `AnyValyeBuffer` that should be used when we trust the builder
+#[derive(Clone)]
 pub enum AnyValueBufferTrusted<'a> {
     Boolean(BooleanChunkedBuilder),
     #[cfg(feature = "dtype-i8")]
     Int8(PrimitiveChunkedBuilder<Int8Type>),
     #[cfg(feature = "dtype-i16")]
     Int16(PrimitiveChunkedBuilder<Int16Type>),
     Int32(PrimitiveChunkedBuilder<Int32Type>),
@@ -231,106 +317,159 @@
 }
 
 impl<'a> AnyValueBufferTrusted<'a> {
     pub fn new(dtype: &DataType, len: usize) -> Self {
         (dtype, len).into()
     }
 
+    #[inline]
+    unsafe fn add_null(&mut self) {
+        use AnyValueBufferTrusted::*;
+        match self {
+            Boolean(builder) => builder.append_null(),
+            #[cfg(feature = "dtype-i8")]
+            Int8(builder) => builder.append_null(),
+            #[cfg(feature = "dtype-i16")]
+            Int16(builder) => builder.append_null(),
+            Int32(builder) => builder.append_null(),
+            Int64(builder) => builder.append_null(),
+            #[cfg(feature = "dtype-u8")]
+            UInt8(builder) => builder.append_null(),
+            #[cfg(feature = "dtype-u16")]
+            UInt16(builder) => builder.append_null(),
+            UInt32(builder) => builder.append_null(),
+            UInt64(builder) => builder.append_null(),
+            Float32(builder) => builder.append_null(),
+            Float64(builder) => builder.append_null(),
+            Utf8(builder) => builder.append_null(),
+            #[cfg(feature = "dtype-struct")]
+            Struct(builders) => {
+                for (b, _) in builders.iter_mut() {
+                    b.add(AnyValue::Null);
+                }
+            }
+            All(_, vals) => vals.push(AnyValue::Null),
+        }
+    }
+
+    #[inline]
+    unsafe fn add_physical(&mut self, val: &AnyValue<'_>) {
+        use AnyValueBufferTrusted::*;
+        match self {
+            Boolean(builder) => {
+                let AnyValue::Boolean(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            #[cfg(feature = "dtype-i8")]
+            Int8(builder) => {
+                let AnyValue::Int8(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            #[cfg(feature = "dtype-i16")]
+            Int16(builder) => {
+                let AnyValue::Int16(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            Int32(builder) => {
+                let AnyValue::Int32(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            Int64(builder) => {
+                let AnyValue::Int64(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            #[cfg(feature = "dtype-u8")]
+            UInt8(builder) => {
+                let AnyValue::UInt8(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            #[cfg(feature = "dtype-u16")]
+            UInt16(builder) => {
+                let AnyValue::UInt16(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            UInt32(builder) => {
+                let AnyValue::UInt32(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            UInt64(builder) => {
+                let AnyValue::UInt64(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            Float32(builder) => {
+                let AnyValue::Float32(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            Float64(builder) => {
+                let AnyValue::Float64(v) = val else { unreachable_unchecked_release!() };
+                builder.append_value(*v)
+            }
+            _ => {
+                unreachable_unchecked_release!()
+            }
+        }
+    }
+
     /// Will add the AnyValue into `Self` and unpack as the physical type
     /// belonging to `Self`. This should only be used with physical buffers
     ///
     /// If a type is not primitive or utf8, the anyvalue will be converted to static
     ///
     /// # Safety
-    /// The caller must ensure that the `AnyValue` type exactly matches the `Buffer` type.
+    /// The caller must ensure that the `AnyValue` type exactly matches the `Buffer` type and is owned.
+    #[inline]
     pub unsafe fn add_unchecked_owned_physical(&mut self, val: &AnyValue<'_>) {
         use AnyValueBufferTrusted::*;
         match val {
-            AnyValue::Null => match self {
-                Boolean(builder) => builder.append_null(),
-                #[cfg(feature = "dtype-i8")]
-                Int8(builder) => builder.append_null(),
-                #[cfg(feature = "dtype-i16")]
-                Int16(builder) => builder.append_null(),
-                Int32(builder) => builder.append_null(),
-                Int64(builder) => builder.append_null(),
-                #[cfg(feature = "dtype-u8")]
-                UInt8(builder) => builder.append_null(),
-                #[cfg(feature = "dtype-u16")]
-                UInt16(builder) => builder.append_null(),
-                UInt32(builder) => builder.append_null(),
-                UInt64(builder) => builder.append_null(),
-                Float32(builder) => builder.append_null(),
-                Float64(builder) => builder.append_null(),
-                Utf8(builder) => builder.append_null(),
-                #[cfg(feature = "dtype-struct")]
-                Struct(builders) => {
-                    for (b, _) in builders.iter_mut() {
-                        b.add(AnyValue::Null);
-                    }
-                }
-                All(_, vals) => vals.push(val.clone().into_static().unwrap()),
-            },
+            AnyValue::Null => self.add_null(),
             _ => {
                 match self {
-                    Boolean(builder) => {
-                        let AnyValue::Boolean(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    #[cfg(feature = "dtype-i8")]
-                    Int8(builder) => {
-                        let AnyValue::Int8(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    #[cfg(feature = "dtype-i16")]
-                    Int16(builder) => {
-                        let AnyValue::Int16(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    Int32(builder) => {
-                        let AnyValue::Int32(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    Int64(builder) => {
-                        let AnyValue::Int64(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    #[cfg(feature = "dtype-u8")]
-                    UInt8(builder) => {
-                        let AnyValue::UInt8(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    #[cfg(feature = "dtype-u16")]
-                    UInt16(builder) => {
-                        let AnyValue::UInt16(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    UInt32(builder) => {
-                        let AnyValue::UInt32(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    UInt64(builder) => {
-                        let AnyValue::UInt64(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
-                    }
-                    Float32(builder) => {
-                        let AnyValue::Float32(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
+                    Utf8(builder) => {
+                        let AnyValue::Utf8Owned(v) = val else { unreachable_unchecked_release!() };
+                        builder.append_value(v)
                     }
-                    Float64(builder) => {
-                        let AnyValue::Float64(v) = val else { unreachable_unchecked() };
-                        builder.append_value(*v)
+                    #[cfg(feature = "dtype-struct")]
+                    Struct(builders) => {
+                        let AnyValue::StructOwned(payload) = val else { unreachable_unchecked_release!() };
+                        let avs = &*payload.0;
+                        // amortize loop counter
+                        for i in 0..avs.len() {
+                            unsafe {
+                                let (builder, _) = builders.get_unchecked_release_mut(i);
+                                let av = avs.get_unchecked_release(i).clone();
+                                // lifetime is bound to 'a
+                                let av = std::mem::transmute::<AnyValue<'_>, AnyValue<'a>>(av);
+                                builder.add(av.clone());
+                            }
+                        }
                     }
+                    All(_, vals) => vals.push(val.clone().into_static().unwrap()),
+                    _ => self.add_physical(val),
+                }
+            }
+        }
+    }
+
+    /// # Safety
+    /// The caller must ensure that the `AnyValue` type exactly matches the `Buffer` type and is borrowed.
+    #[inline]
+    pub unsafe fn add_unchecked_borrowed_physical(&mut self, val: &AnyValue<'_>) {
+        use AnyValueBufferTrusted::*;
+        match val {
+            AnyValue::Null => self.add_null(),
+            _ => {
+                match self {
                     Utf8(builder) => {
-                        let AnyValue::Utf8(v) = val else { unreachable_unchecked() };
+                        let AnyValue::Utf8(v) = val else { unreachable_unchecked_release!() };
                         builder.append_value(v)
                     }
                     #[cfg(feature = "dtype-struct")]
                     Struct(builders) => {
-                        let AnyValue::Struct(idx, arr, fields) = val else { unreachable_unchecked() };
+                        dbg!(&val);
+                        let AnyValue::Struct(idx, arr, fields) = val else { unreachable_unchecked_release!() };
                         let arrays = arr.values();
                         // amortize loop counter
                         for i in 0..fields.len() {
                             unsafe {
                                 let array = arrays.get_unchecked_release(i);
                                 let field = fields.get_unchecked_release(i);
                                 let (builder, _) = builders.get_unchecked_release_mut(i);
@@ -338,56 +477,112 @@
                                 // lifetime is bound to 'a
                                 let av = std::mem::transmute::<AnyValue<'_>, AnyValue<'a>>(av);
                                 builder.add(av);
                             }
                         }
                     }
                     All(_, vals) => vals.push(val.clone().into_static().unwrap()),
+                    _ => self.add_physical(val),
                 }
             }
         }
     }
 
-    pub fn into_series(self) -> Series {
+    pub fn reset(&mut self, capacity: usize) -> Series {
         use AnyValueBufferTrusted::*;
         match self {
-            Boolean(b) => b.finish().into_series(),
-            Int32(b) => b.finish().into_series(),
-            Int64(b) => b.finish().into_series(),
-            UInt32(b) => b.finish().into_series(),
-            UInt64(b) => b.finish().into_series(),
-            Float32(b) => b.finish().into_series(),
-            Float64(b) => b.finish().into_series(),
-            Utf8(b) => b.finish().into_series(),
+            Boolean(b) => {
+                let mut new = BooleanChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Int32(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Int64(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            UInt32(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            UInt64(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Float32(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Float64(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
+            Utf8(b) => {
+                let avg_values_len =
+                    (b.builder.values().len() as f64) / ((b.builder.capacity() + 1) as f64) + 1.0;
+                // alloc some extra to reduce realloc prob.
+                let new_values_len = (avg_values_len * capacity as f64 * 1.3) as usize;
+                let mut new = Utf8ChunkedBuilder::new(b.field.name(), capacity, new_values_len);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-i8")]
-            Int8(b) => b.finish().into_series(),
+            Int8(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-i16")]
-            Int16(b) => b.finish().into_series(),
+            Int16(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-u8")]
-            UInt8(b) => b.finish().into_series(),
+            UInt8(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-u16")]
-            UInt16(b) => b.finish().into_series(),
+            UInt16(b) => {
+                let mut new = PrimitiveChunkedBuilder::new(b.field.name(), capacity);
+                std::mem::swap(&mut new, b);
+                new.finish().into_series()
+            }
             #[cfg(feature = "dtype-struct")]
             Struct(b) => {
                 let v = b
-                    .into_iter()
+                    .iter_mut()
                     .map(|(b, name)| {
-                        let mut s = b.into_series();
+                        let mut s = b.reset(capacity);
                         s.rename(name.as_str());
                         s
                     })
                     .collect::<Vec<_>>();
                 StructChunked::new("", &v).unwrap().into_series()
             }
-            All(dtype, vals) => {
-                Series::from_any_values_and_dtype("", &vals, &dtype, false).unwrap()
-            }
+            All(dtype, vals) => Series::from_any_values_and_dtype("", vals, dtype, false).unwrap(),
         }
     }
+
+    pub fn into_series(mut self) -> Series {
+        self.reset(0)
+    }
 }
+
 impl From<(&DataType, usize)> for AnyValueBufferTrusted<'_> {
     fn from(a: (&DataType, usize)) -> Self {
         let (dt, len) = a;
         use DataType::*;
         match dt {
             Boolean => AnyValueBufferTrusted::Boolean(BooleanChunkedBuilder::new("", len)),
             Int32 => AnyValueBufferTrusted::Int32(PrimitiveChunkedBuilder::new("", len)),
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/dataframe.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/dataframe.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/row/transpose.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/row/transpose.rs`

 * *Files 1% similar despite different names*

```diff
@@ -37,17 +37,17 @@
                     .collect::<Vec<_>>();
 
                 // this is very expensive. A lot of cache misses here.
                 // This is the part that is performance critical.
                 for s in columns {
                     polars_ensure!(s.dtype() == &phys_dtype, ComputeError: "cannot transpose with supertype: {}", dtype);
                     s.iter().zip(buffers.iter_mut()).for_each(|(av, buf)| {
-                        // safety: we checked the type
+                        // safety: we checked the type and we borrow
                         unsafe {
-                            buf.add_unchecked_owned_physical(&av);
+                            buf.add_unchecked_borrowed_physical(&av);
                         }
                     });
                 }
                 let cols = buffers
                     .into_iter()
                     .enumerate()
                     .map(|(i, buf)| {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/top_k.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/top_k.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/frame/upstream_traits.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/frame/upstream_traits.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/fx.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/fx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/identity.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/identity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/partition.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/partition.rs`

 * *Files 5% similar despite different names*

```diff
@@ -127,12 +127,12 @@
     fn as_u64(self) -> u64 {
         self.hash
     }
 }
 
 #[inline]
 /// For partitions that are a power of 2 we can use a bitshift instead of a modulo.
-pub(crate) fn this_partition(h: u64, thread_no: u64, n_partitions: u64) -> bool {
+pub fn this_partition(h: u64, thread_no: u64, n_partitions: u64) -> bool {
     debug_assert!(n_partitions.is_power_of_two());
     // n % 2^i = n & (2^i - 1)
-    (h.wrapping_add(thread_no)) & n_partitions.wrapping_sub(1) == 0
+    (h & n_partitions.wrapping_sub(1)) == thread_no
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/hashing/vector_hasher.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/hashing/vector_hasher.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/lib.rs`

 * *Files 8% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 #[cfg(feature = "docs")]
 pub mod doc;
 pub mod error;
 pub mod export;
 pub mod fmt;
 pub mod frame;
 pub mod functions;
-pub(crate) mod hashing;
+pub mod hashing;
 mod named_from;
 pub mod prelude;
 pub mod schema;
 #[cfg(feature = "serde")]
 pub mod serde;
 pub mod series;
 pub mod testing;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/named_from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/named_from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/prelude.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/schema.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/serde/chunked_array.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/serde/chunked_array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/serde/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/serde/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/serde/series.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/serde/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/any_value.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/any_value.rs`

 * *Files 2% similar despite different names*

```diff
@@ -129,15 +129,16 @@
 fn any_values_to_list(
     avs: &[AnyValue],
     inner_type: &DataType,
     strict: bool,
 ) -> PolarsResult<ListChunked> {
     // this is handled downstream. The builder will choose the first non null type
     let mut valid = true;
-    let out = if inner_type == &DataType::Null {
+    #[allow(unused_mut)]
+    let mut out: ListChunked = if inner_type == &DataType::Null {
         avs.iter()
             .map(|av| match av {
                 AnyValue::List(b) => Some(b.clone()),
                 AnyValue::Null => None,
                 _ => {
                     valid = false;
                     None
@@ -163,14 +164,23 @@
                 _ => {
                     valid = false;
                     None
                 }
             })
             .collect_trusted()
     };
+    #[cfg(feature = "dtype-struct")]
+    if !matches!(inner_type, DataType::Null)
+        && matches!(out.inner_dtype(), DataType::Struct(_) | DataType::List(_))
+    {
+        // ensure the logical type is correct
+        unsafe {
+            out.set_dtype(DataType::List(Box::new(inner_type.clone())));
+        };
+    }
     if valid || !strict {
         Ok(out)
     } else {
         polars_bail!(ComputeError: "got mixed dtypes while constructing List Series")
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/arithmetic/owned.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/arithmetic/owned.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/comparison.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/from.rs`

 * *Files 2% similar despite different names*

```diff
@@ -285,15 +285,15 @@
                     let s = pe.get_series(name);
                     pe.take_and_forget();
                     s
                 };
                 Ok(s)
             }
             #[cfg(feature = "dtype-struct")]
-            ArrowDataType::Struct(_) => {
+            ArrowDataType::Struct(logical_fields) => {
                 let arr = if chunks.len() > 1 {
                     // don't spuriously call this. This triggers a read on memmapped data
                     concatenate_owned_unchecked(&chunks).unwrap() as ArrayRef
                 } else {
                     chunks[0].clone()
                 };
                 let arr = convert_inner_types(&arr);
@@ -317,18 +317,26 @@
 
                     struct_arr = std::borrow::Cow::Owned(StructArray::new(
                         struct_arr.data_type().clone(),
                         new_values,
                         None,
                     ));
                 }
+
+                // ensure we maintain logical types if proved by the caller
+                let dtype_fields = if logical_fields.is_empty() {
+                    struct_arr.fields()
+                } else {
+                    logical_fields
+                };
+
                 let fields = struct_arr
                     .values()
                     .iter()
-                    .zip(struct_arr.fields())
+                    .zip(dtype_fields)
                     .map(|(arr, field)| {
                         Series::try_from_arrow_unchecked(
                             &field.name,
                             vec![arr.clone()],
                             &field.data_type,
                         )
                     })
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/binary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/binary.rs`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 use super::{private, IntoSeries, SeriesTrait, *};
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::compare_inner::{
     IntoPartialEqInner, IntoPartialOrdInner, PartialEqInner, PartialOrdInner,
 };
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::ZipOuterJoinColumn;
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 
 impl private::PrivateSeries for SeriesWrap<BinaryChunked> {
     fn compute_len(&mut self) {
@@ -280,17 +279,14 @@
     }
     fn max_as_series(&self) -> Series {
         ChunkAggSeries::max_as_series(&self.0)
     }
     fn min_as_series(&self) -> Series {
         ChunkAggSeries::min_as_series(&self.0)
     }
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     #[cfg(feature = "is_in")]
     fn is_in(&self, other: &Series) -> PolarsResult<BooleanChunked> {
         IsIn::is_in(&self.0, other)
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/boolean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/boolean.rs`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,14 @@
 use super::{private, IntoSeries, SeriesTrait, *};
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::compare_inner::{
     IntoPartialEqInner, IntoPartialOrdInner, PartialEqInner, PartialOrdInner,
 };
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::{AsSinglePtr, ChunkIdIter};
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::ZipOuterJoinColumn;
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 
 impl private::PrivateSeries for SeriesWrap<BooleanChunked> {
     fn compute_len(&mut self) {
@@ -332,17 +331,14 @@
         self.0
             .cast(&DataType::Float32)
             .unwrap()
             .std_as_series(_ddof)
             .cast(&DataType::Float64)
             .unwrap()
     }
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     #[cfg(feature = "is_in")]
     fn is_in(&self, other: &Series) -> PolarsResult<BooleanChunked> {
         IsIn::is_in(&self.0, other)
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/categorical.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/categorical.rs`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 use polars_arrow::prelude::QuantileInterpolOptions;
 
 use super::{private, IntoSeries, SeriesTrait, *};
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::compare_inner::{IntoPartialOrdInner, PartialOrdInner};
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::ZipOuterJoinColumn;
 #[cfg(feature = "is_in")]
 use crate::frame::hash_join::_check_categorical_src;
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 
@@ -366,17 +365,14 @@
         &self,
         _quantile: f64,
         _interpol: QuantileInterpolOptions,
     ) -> PolarsResult<Series> {
         Ok(CategoricalChunked::full_null(self.0.logical().name(), 1).into_series())
     }
 
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     #[cfg(feature = "is_in")]
     fn is_in(&self, other: &Series) -> PolarsResult<BooleanChunked> {
         _check_categorical_src(self.dtype(), other.dtype())?;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/dates_time.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/dates_time.rs`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,14 @@
 use ahash::RandomState;
 use polars_arrow::prelude::QuantileInterpolOptions;
 
 use super::{private, IntoSeries, SeriesTrait, SeriesWrap, *};
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::ops::ToBitRepr;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::*;
 use crate::prelude::*;
 
 macro_rules! impl_dyn_series {
     ($ca: ident, $into_logical: ident) => {
         unsafe impl IntoSeries for $ca {
@@ -416,18 +415,14 @@
             ) -> PolarsResult<Series> {
                 Ok(Int32Chunked::full_null(self.name(), 1)
                     .cast(self.dtype())
                     .unwrap()
                     .into())
             }
 
-            fn fmt_list(&self) -> String {
-                FmtList::fmt_list(&self.0)
-            }
-
             fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
                 Arc::new(SeriesWrap(Clone::clone(&self.0)))
             }
 
             fn peak_max(&self) -> BooleanChunked {
                 self.0.peak_max()
             }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/datetime.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/datetime.rs`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 use std::ops::{Deref, DerefMut};
 
 use ahash::RandomState;
 
 use super::{private, IntoSeries, SeriesTrait, SeriesWrap, *};
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::*;
 use crate::prelude::*;
 
 unsafe impl IntoSeries for DatetimeChunked {
     fn into_series(self) -> Series {
         Series(Arc::new(SeriesWrap(self)))
@@ -442,18 +441,14 @@
         _interpol: QuantileInterpolOptions,
     ) -> PolarsResult<Series> {
         Ok(Int32Chunked::full_null(self.name(), 1)
             .cast(self.dtype())
             .unwrap())
     }
 
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
-
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     fn peak_max(&self) -> BooleanChunked {
         self.0.peak_max()
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/decimal.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/duration.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/duration.rs`

 * *Files 6% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 
 use ahash::RandomState;
 
 use super::{private, IntoSeries, SeriesTrait, SeriesWrap, *};
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::*;
 use crate::prelude::*;
 
 unsafe impl IntoSeries for DurationChunked {
     fn into_series(self) -> Series {
         Series(Arc::new(SeriesWrap(self)))
@@ -146,50 +145,58 @@
             .zip_outer_join_column(&right_column, opt_join_tuples)
             .into_duration(self.0.time_unit())
             .into_series()
     }
     fn subtract(&self, rhs: &Series) -> PolarsResult<Series> {
         match (self.dtype(), rhs.dtype()) {
             (DataType::Duration(tu), DataType::Duration(tur)) => {
-                assert_eq!(tu, tur);
+                polars_ensure!(tu == tur, InvalidOperation: "units are different");
                 let lhs = self.cast(&DataType::Int64).unwrap();
                 let rhs = rhs.cast(&DataType::Int64).unwrap();
                 Ok(lhs.subtract(&rhs)?.into_duration(*tu).into_series())
             }
             (dtl, dtr) => polars_bail!(opq = sub, dtl, dtr),
         }
     }
     fn add_to(&self, rhs: &Series) -> PolarsResult<Series> {
         match (self.dtype(), rhs.dtype()) {
             (DataType::Duration(tu), DataType::Duration(tur)) => {
-                assert_eq!(tu, tur);
+                polars_ensure!(tu == tur, InvalidOperation: "units are different");
                 let lhs = self.cast(&DataType::Int64).unwrap();
                 let rhs = rhs.cast(&DataType::Int64).unwrap();
                 Ok(lhs.add_to(&rhs)?.into_duration(*tu).into_series())
             }
             (DataType::Duration(tu), DataType::Datetime(tur, tz)) => {
-                assert_eq!(tu, tur);
+                polars_ensure!(tu == tur, InvalidOperation: "units are different");
                 let lhs = self.cast(&DataType::Int64).unwrap();
                 let rhs = rhs.cast(&DataType::Int64).unwrap();
                 Ok(lhs
                     .add_to(&rhs)?
                     .into_datetime(*tu, tz.clone())
                     .into_series())
             }
             (dtl, dtr) => polars_bail!(opq = add, dtl, dtr),
         }
     }
     fn multiply(&self, rhs: &Series) -> PolarsResult<Series> {
+        // dependent on units, doesn't make sense
         polars_bail!(opq = mul, self.dtype(), rhs.dtype());
     }
     fn divide(&self, rhs: &Series) -> PolarsResult<Series> {
+        // dependent on units, doesn't make sense
         polars_bail!(opq = div, self.dtype(), rhs.dtype());
     }
     fn remainder(&self, rhs: &Series) -> PolarsResult<Series> {
-        polars_bail!(opq = rem, self.dtype(), rhs.dtype());
+        polars_ensure!(self.dtype() == rhs.dtype(), InvalidOperation: "dtypes and units must be equal in duration arithmetic");
+        let lhs = self.cast(&DataType::Int64).unwrap();
+        let rhs = rhs.cast(&DataType::Int64).unwrap();
+        Ok(lhs
+            .remainder(&rhs)?
+            .into_duration(self.0.time_unit())
+            .into_series())
     }
     fn group_tuples(&self, multithreaded: bool, sorted: bool) -> PolarsResult<GroupsProxy> {
         self.0.group_tuples(multithreaded, sorted)
     }
 
     fn arg_sort_multiple(&self, by: &[Series], descending: &[bool]) -> PolarsResult<IdxCa> {
         self.0.deref().arg_sort_multiple(by, descending)
@@ -442,18 +449,14 @@
         _interpol: QuantileInterpolOptions,
     ) -> PolarsResult<Series> {
         Ok(Int32Chunked::full_null(self.name(), 1)
             .cast(self.dtype())
             .unwrap())
     }
 
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
-
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     fn peak_max(&self) -> BooleanChunked {
         self.0.peak_max()
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/floats.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/floats.rs`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,14 @@
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::aggregate::{ChunkAggSeries, QuantileAggSeries, VarAggSeries};
 use crate::chunked_array::ops::compare_inner::{
     IntoPartialEqInner, IntoPartialOrdInner, PartialEqInner, PartialOrdInner,
 };
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::ZipOuterJoinColumn;
 use crate::prelude::*;
 #[cfg(feature = "checked_arithmetic")]
 use crate::series::arithmetic::checked::NumOpsDispatchChecked;
 
 macro_rules! impl_dyn_series {
@@ -363,17 +362,14 @@
                 &self,
                 quantile: f64,
                 interpol: QuantileInterpolOptions,
             ) -> PolarsResult<Series> {
                 QuantileAggSeries::quantile_as_series(&self.0, quantile, interpol)
             }
 
-            fn fmt_list(&self) -> String {
-                FmtList::fmt_list(&self.0)
-            }
             fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
                 Arc::new(SeriesWrap(Clone::clone(&self.0)))
             }
 
             fn peak_max(&self) -> BooleanChunked {
                 self.0.peak_max()
             }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/list.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 use std::any::Any;
 use std::borrow::Cow;
 
 use super::{private, IntoSeries, SeriesTrait};
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 use crate::series::IsSorted;
 
 impl private::PrivateSeries for SeriesWrap<ListChunked> {
     fn compute_len(&mut self) {
@@ -192,17 +191,14 @@
     }
     fn max_as_series(&self) -> Series {
         ChunkAggSeries::max_as_series(&self.0)
     }
     fn min_as_series(&self) -> Series {
         ChunkAggSeries::min_as_series(&self.0)
     }
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
     fn as_any(&self) -> &dyn Any {
         &self.0
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -35,15 +35,14 @@
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::aggregate::{ChunkAggSeries, QuantileAggSeries, VarAggSeries};
 use crate::chunked_array::ops::compare_inner::{
     IntoPartialEqInner, IntoPartialOrdInner, PartialEqInner, PartialOrdInner,
 };
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::ZipOuterJoinColumn;
 use crate::prelude::*;
 #[cfg(feature = "checked_arithmetic")]
 use crate::series::arithmetic::checked::NumOpsDispatchChecked;
 
 // Utility wrapper struct
@@ -453,17 +452,14 @@
                 &self,
                 quantile: f64,
                 interpol: QuantileInterpolOptions,
             ) -> PolarsResult<Series> {
                 QuantileAggSeries::quantile_as_series(&self.0, quantile, interpol)
             }
 
-            fn fmt_list(&self) -> String {
-                FmtList::fmt_list(&self.0)
-            }
             fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
                 Arc::new(SeriesWrap(Clone::clone(&self.0)))
             }
 
             fn peak_max(&self) -> BooleanChunked {
                 self.0.peak_max()
             }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/null.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/null.rs`

 * *Files 7% similar despite different names*

```diff
@@ -38,14 +38,17 @@
             ))],
         }
     }
 }
 impl PrivateSeriesNumeric for NullChunked {}
 
 impl PrivateSeries for NullChunked {
+    fn compute_len(&mut self) {
+        // no-op
+    }
     fn _field(&self) -> Cow<Field> {
         Cow::Owned(Field::new(self.name(), DataType::Null))
     }
 
     fn _dtype(&self) -> &DataType {
         &DataType::Null
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/object.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/object.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 use std::any::Any;
 use std::borrow::Cow;
 
 use ahash::RandomState;
 
 use crate::chunked_array::object::compare_inner::{IntoPartialEqInner, PartialEqInner};
 use crate::chunked_array::object::PolarsObjectSafe;
-use crate::fmt::FmtList;
 use crate::frame::groupby::{GroupsProxy, IntoGroupsProxy};
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 use crate::series::private::{PrivateSeries, PrivateSeriesNumeric};
 use crate::series::IsSorted;
 
 impl<T: PolarsObject> PrivateSeriesNumeric for SeriesWrap<ObjectChunked<T>> {}
@@ -23,14 +22,18 @@
         _name: &str,
         _values_capacity: usize,
         _list_capacity: usize,
     ) -> Box<dyn ListBuilderTrait> {
         ObjectChunked::<T>::get_list_builder(_name, _values_capacity, _list_capacity)
     }
 
+    fn compute_len(&mut self) {
+        self.0.compute_len()
+    }
+
     fn _field(&self) -> Cow<Field> {
         Cow::Borrowed(self.0.ref_field())
     }
 
     fn _dtype(&self) -> &DataType {
         self.0.dtype()
     }
@@ -203,18 +206,14 @@
         ChunkReverse::reverse(&self.0).into_series()
     }
 
     fn shift(&self, periods: i64) -> Series {
         ChunkShift::shift(&self.0, periods).into_series()
     }
 
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
-
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     fn get_object(&self, index: usize) -> Option<&dyn PolarsObjectSafe> {
         ObjectChunked::<T>::get_object(&self.0, index)
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/struct_.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/struct_.rs`

 * *Files 1% similar despite different names*

```diff
@@ -326,18 +326,14 @@
     }
 
     #[cfg(feature = "is_in")]
     fn is_in(&self, other: &Series) -> PolarsResult<BooleanChunked> {
         self.0.is_in(other)
     }
 
-    fn fmt_list(&self) -> String {
-        self.0.fmt_list()
-    }
-
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     fn as_any(&self) -> &dyn Any {
         &self.0
     }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/implementations/utf8.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/implementations/utf8.rs`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 use super::{private, IntoSeries, SeriesTrait, *};
 use crate::chunked_array::comparison::*;
 use crate::chunked_array::ops::compare_inner::{
     IntoPartialEqInner, IntoPartialOrdInner, PartialEqInner, PartialOrdInner,
 };
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
-use crate::fmt::FmtList;
 use crate::frame::groupby::*;
 use crate::frame::hash_join::ZipOuterJoinColumn;
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 
 impl private::PrivateSeries for SeriesWrap<Utf8Chunked> {
     fn compute_len(&mut self) {
@@ -294,17 +293,14 @@
     }
     fn max_as_series(&self) -> Series {
         ChunkAggSeries::max_as_series(&self.0)
     }
     fn min_as_series(&self) -> Series {
         ChunkAggSeries::min_as_series(&self.0)
     }
-    fn fmt_list(&self) -> String {
-        FmtList::fmt_list(&self.0)
-    }
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     #[cfg(feature = "is_in")]
     fn is_in(&self, other: &Series) -> PolarsResult<BooleanChunked> {
         IsIn::is_in(&self.0, other)
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/into.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/into.rs`

 * *Files 6% similar despite different names*

```diff
@@ -16,14 +16,17 @@
     }
 
     /// Convert a chunk in the Series to the correct Arrow type.
     /// This conversion is needed because polars doesn't use a
     /// 1 on 1 mapping for logical/ categoricals, etc.
     pub fn to_arrow(&self, chunk_idx: usize) -> ArrayRef {
         match self.dtype() {
+            // make sure that we recursively apply all logical types.
+            #[cfg(feature = "dtype-struct")]
+            DataType::Struct(_) => self.struct_().unwrap().to_arrow(chunk_idx),
             // special list branch to
             // make sure that we recursively apply all logical types.
             DataType::List(inner) => {
                 let ca = self.list().unwrap();
                 let arr = ca.chunks[chunk_idx].clone();
                 let arr = arr.as_any().downcast_ref::<ListArray<i64>>().unwrap();
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/iterator.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 use std::borrow::Cow;
 use std::hash::{Hash, Hasher};
 use std::ops::Deref;
 use std::sync::Arc;
 
 use ahash::RandomState;
 use arrow::compute::aggregate::estimated_bytes_size;
+use arrow::offset::Offsets;
 pub use from::*;
 pub use iterator::{SeriesIter, SeriesPhysIter};
 use num_traits::NumCast;
 use rayon::prelude::*;
 pub use series_trait::{IsSorted, *};
 
 #[cfg(feature = "rank")]
@@ -613,14 +614,20 @@
                     let ca = self.f32().unwrap();
                     ca.cumsum(reverse).into_series()
                 }
                 Float64 => {
                     let ca = self.f64().unwrap();
                     ca.cumsum(reverse).into_series()
                 }
+                #[cfg(feature = "dtype-duration")]
+                Duration(tu) => {
+                    let ca = self.to_physical_repr();
+                    let ca = ca.i64().unwrap();
+                    ca.cumsum(reverse).cast(&Duration(*tu)).unwrap()
+                }
                 dt => panic!("cumsum not supported for dtype: {dt:?}"),
             }
         }
         #[cfg(not(feature = "cum_agg"))]
         {
             panic!("activate 'cum_agg' feature")
         }
@@ -942,14 +949,30 @@
                 }
             },
             _ => {}
         }
 
         size
     }
+
+    /// Packs every element into a list
+    pub fn as_list(&self) -> ListChunked {
+        let s = self.rechunk();
+        let values = s.to_arrow(0);
+        let offsets = (0i64..(s.len() as i64 + 1)).collect::<Vec<_>>();
+        let offsets = unsafe { Offsets::new_unchecked(offsets) };
+
+        let new_arr = LargeListArray::new(
+            DataType::List(Box::new(s.dtype().clone())).to_arrow(),
+            offsets.into(),
+            values,
+            None,
+        );
+        unsafe { ListChunked::from_chunks(s.name(), vec![Box::new(new_arr)]) }
+    }
 }
 
 impl Deref for Series {
     type Target = dyn SeriesTrait;
 
     fn deref(&self) -> &Self::Target {
         self.0.as_ref()
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/diff.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/diff.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/downcast.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/downcast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/ewm.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/ewm.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/moment.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/moment.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/null.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/pct_change.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/pct_change.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/round.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/round.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/to_list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/to_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/ops/unique.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/ops/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/series_trait.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/series_trait.rs`

 * *Files 2% similar despite different names*

```diff
@@ -59,17 +59,15 @@
         }
 
         /// Get field (used in schema)
         fn _field(&self) -> Cow<Field>;
 
         fn _dtype(&self) -> &DataType;
 
-        fn compute_len(&mut self) {
-            unimplemented!()
-        }
+        fn compute_len(&mut self);
 
         fn explode_by_offsets(&self, _offsets: &[i64]) -> Series {
             invalid_operation_panic!(explode_by_offsets, self)
         }
 
         /// Get an array with the cumulative max computed at every element
         #[cfg(feature = "cum_agg")]
@@ -462,18 +460,14 @@
         &self,
         _quantile: f64,
         _interpol: QuantileInterpolOptions,
     ) -> PolarsResult<Series> {
         Ok(Series::full_null(self.name(), 1, self.dtype()))
     }
 
-    fn fmt_list(&self) -> String {
-        "fmt implemented".into()
-    }
-
     /// Clone inner ChunkedArray and wrap in a new Arc
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         invalid_operation_panic!(clone_inner, self)
     }
 
     #[cfg(feature = "object")]
     /// Get the value at this index as a downcastable Any trait ref.
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/series/unstable.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/series/unstable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/testing.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/testing.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/utils/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/utils/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/utils/series.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/utils/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-core/src/utils/supertype.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/src/utils/supertype.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 readme = "../README.md"
 repository = "https://github.com/pola-rs/polars"
 description = "DataFrame Library based on Apache Arrow"
 
 [features]
 sql = ["polars-sql"]
 rows = ["polars-core/rows"]
-simd = ["polars-core/simd", "polars-io/simd"]
+simd = ["polars-core/simd", "polars-io/simd", "polars-ops/simd"]
 avx512 = ["polars-core/avx512"]
 nightly = ["polars-core/nightly", "polars-ops/nightly", "simd"]
 docs = ["polars-core/docs"]
 temporal = ["polars-core/temporal", "polars-lazy/temporal", "polars-io/temporal", "polars-time"]
 random = ["polars-core/random", "polars-lazy/random"]
 default = [
   "docs",
@@ -76,14 +76,15 @@
 fmt = ["polars-core/fmt"]
 fmt_no_tty = ["polars-core/fmt_no_tty"]
 
 # sort by multiple columns
 sort_multiple = ["polars-core/sort_multiple"]
 
 # extra operations
+approx_unique = ["polars-lazy/approx_unique", "polars-ops/approx_unique"]
 is_in = ["polars-core/is_in", "polars-lazy/is_in"]
 zip_with = ["polars-core/zip_with"]
 round_series = ["polars-core/round_series", "polars-lazy/round_series", "polars-ops/round_series"]
 checked_arithmetic = ["polars-core/checked_arithmetic"]
 repeat_by = ["polars-core/repeat_by", "polars-lazy/repeat_by"]
 is_first = ["polars-lazy/is_first", "polars-ops/is_first"]
 is_unique = ["polars-lazy/is_unique", "polars-ops/is_unique"]
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/eager.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/eager.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/lazy.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/lazy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/src/docs/performance.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/src/docs/performance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/src/lib.rs`

 * *Files 0% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 //!         col("foo")
 //!             .sort_by([col("ham").rank(Default::default())], [false])
 //!             .last()
 //!             .alias("last_foo_ranked_by_ham"),
 //!         // every expression runs in parallel
 //!         col("foo").cummin(false).alias("cumulative_min_per_group"),
 //!         // every expression runs in parallel
-//!         col("foo").reverse().list().alias("reverse_group"),
+//!         col("foo").reverse().implode().alias("reverse_group"),
 //!     ]);
 //!
 //! let lf2 = LazyFrame::scan_parquet("myfile_2.parquet", Default::default())?
 //!     .select([col("ham"), col("spam")]);
 //!
 //! let df = lf1
 //!     .join(lf2, [col("reverse")], [col("foo")], JoinType::Left)
@@ -320,29 +320,29 @@
 //! ```ignore
 //! [dependencies]
 //! mimalloc = { version = "*", default-features = false }
 //! ```
 //! ## Config with ENV vars
 //!
 //! * `POLARS_FMT_TABLE_FORMATTING` -> define styling of tables using any of the following options (default = UTF8_FULL_CONDENSED):
-//!     
+//!
 //!                                    ASCII_FULL
 //!                                    ASCII_FULL_CONDENSED
 //!                                    ASCII_NO_BORDERS
 //!                                    ASCII_BORDERS_ONLY
 //!                                    ASCII_BORDERS_ONLY_CONDENSED
 //!                                    ASCII_HORIZONTAL_ONLY
 //!                                    ASCII_MARKDOWN
 //!                                    UTF8_FULL
 //!                                    UTF8_FULL_CONDENSED
 //!                                    UTF8_NO_BORDERS
 //!                                    UTF8_BORDERS_ONLY
 //!                                    UTF8_HORIZONTAL_ONLY
 //!                                    NOTHING
-//!                                     
+//!
 //!                                    These options are defined by comfy-table which provides examples for each at:
 //!                                    https://github.com/Nukesor/comfy-table/blob/main/src/style/presets.rs
 //! * `POLARS_FMT_TABLE_CELL_ALIGNMENT` -> define cell alignment using any of the following options (default = LEFT):
 //!                                    LEFT
 //!                                    CENTER
 //!                                    RIGHT
 //! * `POLARS_FMT_TABLE_DATAFRAME_SHAPE_BELOW` -> print shape information below the table.
@@ -356,16 +356,14 @@
 //! * `POLARS_FMT_MAX_ROWS` -> maximum number of rows shown when formatting DataFrames, `-1` to show all.
 //! * `POLARS_FMT_STR_LEN` -> maximum number of characters printed per string value.
 //! * `POLARS_TABLE_WIDTH` -> width of the tables used during DataFrame formatting.
 //! * `POLARS_MAX_THREADS` -> maximum number of threads used to initialize thread pool (on startup).
 //! * `POLARS_VERBOSE` -> print logging info to stderr.
 //! * `POLARS_NO_PARTITION` -> polars may choose to partition the groupby operation, based on data
 //!                            cardinality. Setting this env var will turn partitioned groupby's off.
-//! * `POLARS_PARTITION_SAMPLE_FRAC` -> how large chunk of the dataset to sample to determine cardinality,
-//!                                     defaults to `0.001`.
 //! * `POLARS_PARTITION_UNIQUE_COUNT` -> at which (estimated) key count a partitioned groupby should run.
 //!                                          defaults to `1000`, any higher cardinality will run default groupby.
 //! * `POLARS_FORCE_PARTITION` -> force partitioned groupby if the keys and aggregations allow it.
 //! * `POLARS_ALLOW_EXTENSION` -> allows for `[ObjectChunked<T>]` to be used in arrow, opening up possibilities like using
 //!                               `T` in complex lazy expressions. However this does require `unsafe` code allow this.
 //! * `POLARS_NO_PARQUET_STATISTICS` -> if set, statistics in parquet files are ignored.
 //! * `POLARS_PANIC_ON_ERR` -> panic instead of returning an Error.
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/date_like.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/date_like.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/groupby.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/joins.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/joins.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/pivot.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/pivot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/random.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/rolling_window.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/rolling_window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/core/series.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/core/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/csv.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/csv.rs`

 * *Files 0% similar despite different names*

```diff
@@ -602,18 +602,18 @@
     Ok(())
 }
 
 #[test]
 #[cfg(feature = "temporal")]
 fn test_automatic_datetime_parsing_default_formats() -> PolarsResult<()> {
     let csv = r"ts_dmy,ts_dmy_f,ts_dmy_p
-01/01/21 00:00:00,31-01-2021T00:00:00.123,31-01-2021 11:00 AM
-01/01/21 00:15:00,31-01-2021T00:15:00.123,31-01-2021 01:00 PM
-01/01/21 00:30:00,31-01-2021T00:30:00.123,31-01-2021 01:15 PM
-01/01/21 00:45:00,31-01-2021T00:45:00.123,31-01-2021 01:30 PM
+01/01/2021 00:00:00,31-01-2021T00:00:00.123,31-01-2021 11:00
+01/01/2021 00:15:00,31-01-2021T00:15:00.123,31-01-2021 01:00
+01/01/2021 00:30:00,31-01-2021T00:30:00.123,31-01-2021 01:15
+01/01/2021 00:45:00,31-01-2021T00:45:00.123,31-01-2021 01:30
 ";
 
     let file = Cursor::new(csv);
     let df = CsvReader::new(file).with_try_parse_dates(true).finish()?;
 
     for col in df.get_column_names() {
         let ts = df.column(col)?;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/ipc_stream.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/ipc_stream.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/json.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/json.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/io/parquet.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/io/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/joins.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/joins.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/aggregation.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/cse.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/apply.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/arity.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/expand.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/expand.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/filter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/expressions/window.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/expressions/window.rs`

 * *Files 2% similar despite different names*

```diff
@@ -45,27 +45,27 @@
     let out1 = df
         .clone()
         .lazy()
         .select([
             col("fruits"),
             col("B")
                 .shift_and_fill(-1, lit(-1))
-                .list()
+                .implode()
                 .over([col("fruits")]),
         ])
         .collect()?;
 
     // same expression, no final list aggregation
     let out2 = df
         .lazy()
         .select([
             col("fruits"),
             col("B")
                 .shift_and_fill(-1, lit(-1))
-                .list()
+                .implode()
                 .over([col("fruits")]),
         ])
         .collect()?;
 
     assert!(out1.frame_equal(&out2));
 
     Ok(())
@@ -79,15 +79,15 @@
         .clone()
         .lazy()
         .sort("fruits", Default::default())
         .select([
             col("fruits"),
             col("B")
                 .shift(1)
-                .list()
+                .implode()
                 .over([col("fruits")])
                 .explode()
                 .alias("shifted"),
         ])
         .collect()?;
 
     assert_eq!(
@@ -100,15 +100,15 @@
     let out = df
         .lazy()
         .sort("fruits", Default::default())
         .select([
             col("fruits"),
             col("B")
                 .shift_and_fill(1, lit(-1.0f32))
-                .list()
+                .implode()
                 .over([col("fruits")])
                 .explode()
                 .alias("shifted"),
         ])
         .collect()?;
 
     // even though we fill with f32, cast i32 -> f32 can overflow so the result is f64
@@ -148,15 +148,15 @@
         .lazy()
         .sort("cars", Default::default())
         .select([
             col("fruits"),
             col("cars"),
             col("A")
                 .sort_by([col("B")], [false])
-                .list()
+                .implode()
                 .over([col("cars")])
                 .explode()
                 .alias("sorted_A_by_B"),
         ])
         .collect()?;
 
     assert_eq!(
@@ -171,15 +171,15 @@
         "chars" => ["a", "a", "b"]
     ]?;
 
     let out = df
         .lazy()
         .select([repeat(1, count())
             .cumsum(false)
-            .list()
+            .implode()
             .over([col("chars")])
             .alias("foo")])
         .collect()?;
 
     let out = out.column("foo")?;
     assert!(matches!(out.dtype(), DataType::List(_)));
     let flat = out.explode()?;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/folds.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/folds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/groupby.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/predicate_queries.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/predicate_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/projection_queries.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/projection_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/lazy/queries.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/lazy/queries.rs`

 * *Files 1% similar despite different names*

```diff
@@ -253,15 +253,15 @@
         &DataType::List(Box::new(DataType::Int32))
     );
 
     let out = df
         .clone()
         .lazy()
         .groupby([col("groups")])
-        .agg([col("arrays").list()])
+        .agg([col("arrays").implode()])
         .collect()?;
 
     // a list of lists
     assert_eq!(
         out.column("arrays")?.dtype(),
         &DataType::List(Box::new(DataType::List(Box::new(DataType::List(
             Box::new(DataType::Int32)
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars/tests/it/schema.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars/tests/it/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -6,27 +6,29 @@
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "More operations on polars data structures"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
+argminmax = { version = "0.6.1", default-features = false, features = ["float"] }
 base64 = { version = "0.21", optional = true }
 either= "1.8"
 hex = { version = "0.4", optional = true }
 jsonpath_lib = { version = "0.3.0", optional = true, git = "https://github.com/ritchie46/jsonpath", branch = "improve_compiled" }
 memchr= "2"
 polars-arrow = { version = "0.28.0", path = "../polars-arrow", default-features = false }
 polars-core = { version = "0.28.0", path = "../polars-core", features = ["private"], default-features = false }
 polars-utils = { version = "0.28.0", path = "../polars-utils", default-features = false }
 serde = { version = "1", features = ["derive"], optional = true }
 serde_json = { version = "1", optional = true }
 smartstring= { version = "1" }
 
 [features]
+simd = ["argminmax/nightly_simd"]
 nightly = ["polars-utils/nightly"]
 dtype-categorical = ["polars-core/dtype-categorical"]
 dtype-date = ["polars-core/dtype-date", "polars-core/temporal"]
 dtype-datetime = ["polars-core/dtype-datetime", "polars-core/temporal"]
 dtype-time = ["polars-core/dtype-time", "polars-core/temporal"]
 dtype-duration = ["polars-core/dtype-duration", "polars-core/temporal"]
 dtype-struct = ["polars-core/dtype-struct", "polars-core/temporal"]
@@ -38,14 +40,15 @@
 object = ["polars-core/object"]
 propagate_nans = []
 performant = ["polars-core/performant"]
 big_idx = ["polars-core/bigidx"]
 round_series = []
 is_first = []
 is_unique = []
+approx_unique = []
 
 # extra utilities for BinaryChunked
 binary_encoding = ["base64", "hex"]
 string_encoding = ["base64", "hex"]
 
 # ops
 to_dummies = []
@@ -71,17 +74,17 @@
 semi_anti_join = ["polars-core/semi_anti_join"]
 list_take = []
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/interpolate.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/interpolate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/count.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/hash.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/hash.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/set.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/case.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/case.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/chunked_array/top_k.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/chunked_array/top_k.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/join/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/join/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/pivot/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/pivot/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/frame/pivot/positioning.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/frame/pivot/positioning.rs`

 * *Files 1% similar despite different names*

```diff
@@ -75,15 +75,15 @@
                     #[cfg(feature = "dtype-struct")]
                     DataType::Struct(_) => {
                         // we know we can trust this data, so we use the explicit builder
                         use polars_core::frame::row::AnyValueBufferTrusted;
                         let mut buf = AnyValueBufferTrusted::new(&phys_type, avs.len());
                         for av in avs {
                             unsafe {
-                                buf.add_unchecked_owned_physical(av);
+                                buf.add_unchecked_borrowed_physical(av);
                             }
                         }
                         let mut out = buf.into_series();
                         out.rename(name);
                         out
                     }
                     _ => Series::from_any_values_and_dtype(name, avs, &phys_type, false).unwrap(),
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/floor_divide.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/floor_divide.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/is_first.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/is_first.rs`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 use arrow::array::BooleanArray;
 use arrow::bitmap::MutableBitmap;
 use polars_arrow::utils::CustomIterTools;
 use polars_core::prelude::*;
 use polars_core::with_match_physical_integer_polars_type;
 
-use crate::series::ops::arg_min_max::arg_max;
+use crate::series::ops::arg_min_max::arg_max_bool;
 
 fn is_first_numeric<T>(ca: &ChunkedArray<T>) -> BooleanChunked
 where
     T: PolarsNumericType,
     T::Native: Hash + Eq,
 {
     let mut unique = PlHashSet::new();
@@ -43,15 +43,15 @@
 
     unsafe { BooleanChunked::from_chunks(ca.name(), chunks) }
 }
 
 fn is_first_boolean(ca: &BooleanChunked) -> BooleanChunked {
     let mut out = MutableBitmap::with_capacity(ca.len());
     out.extend_constant(ca.len(), false);
-    if let Some(index) = arg_max(ca) {
+    if let Some(index) = arg_max_bool(ca) {
         out.set(index, true)
     }
     if let Some(index) = ca.first_non_null() {
         out.set(index, true)
     }
 
     let chunks =
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/is_unique.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/is_unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/log.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/log.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/mod.rs`

 * *Files 16% similar despite different names*

```diff
@@ -1,7 +1,10 @@
+mod approx_algo;
+#[cfg(feature = "approx_unique")]
+mod approx_unique;
 mod arg_min_max;
 #[cfg(feature = "round_series")]
 mod floor_divide;
 #[cfg(feature = "is_first")]
 mod is_first;
 #[cfg(feature = "is_unique")]
 mod is_unique;
@@ -11,14 +14,17 @@
 mod rolling;
 #[cfg(feature = "search_sorted")]
 mod search_sorted;
 #[cfg(feature = "to_dummies")]
 mod to_dummies;
 mod various;
 
+pub use approx_algo::*;
+#[cfg(feature = "approx_unique")]
+pub use approx_unique::*;
 pub use arg_min_max::ArgAgg;
 #[cfg(feature = "round_series")]
 pub use floor_divide::*;
 #[cfg(feature = "is_first")]
 pub use is_first::*;
 #[cfg(feature = "is_unique")]
 pub use is_unique::*;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/rolling.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/rolling.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/search_sorted.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/search_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/to_dummies.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/to_dummies.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-ops/src/series/ops/various.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-ops/src/series/ops/various.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-error/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-error/Cargo.toml`

 * *Files 16% similar despite different names*

```diff
@@ -12,17 +12,17 @@
 regex = { version = "1.6", optional = true }
 thiserror= "^1"
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-error/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-error/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-error/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -81,17 +81,17 @@
 tokio = { version = "1.26.0", features = ["net"], optional = true }
 url = { version = "2.3.1", optional = true }
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-lazy/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/avro/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/avro/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/avro/read.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/avro/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/avro/write.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/avro/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/cloud/adaptors.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/cloud/adaptors.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/cloud/glob.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/cloud/glob.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/cloud/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/cloud/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/buffer.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/buffer.rs`

 * *Files 1% similar despite different names*

```diff
@@ -419,33 +419,49 @@
     } else if !ignore_errors && std::str::from_utf8(bytes).is_err() {
         polars_bail!(ComputeError: "invalid utf-8 sequence");
     } else {
         buf.builder.append_null();
         return Ok(());
     };
 
-    match infer_pattern_single(val) {
-        None => {
-            buf.builder.append_null();
-            Ok(())
-        }
-        Some(pattern_with_offset) => {
-            match DatetimeInfer::<T::Native>::try_from(pattern_with_offset.pattern) {
+    match &buf.compiled {
+        Some(compiled) => {
+            match DatetimeInfer::<T::Native>::try_from(compiled.pattern_with_offset.pattern) {
                 Ok(mut infer) => {
-                    let parsed = infer.parse(val, pattern_with_offset.offset);
+                    let parsed = infer.parse(val, compiled.pattern_with_offset.offset);
                     buf.compiled = Some(infer);
                     buf.builder.append_option(parsed);
                     Ok(())
                 }
                 Err(_) => {
                     buf.builder.append_null();
                     Ok(())
                 }
             }
         }
+        None => match infer_pattern_single(val) {
+            None => {
+                buf.builder.append_null();
+                Ok(())
+            }
+            Some(pattern_with_offset) => {
+                match DatetimeInfer::<T::Native>::try_from(pattern_with_offset.pattern) {
+                    Ok(mut infer) => {
+                        let parsed = infer.parse(val, pattern_with_offset.offset);
+                        buf.compiled = Some(infer);
+                        buf.builder.append_option(parsed);
+                        Ok(())
+                    }
+                    Err(_) => {
+                        buf.builder.append_null();
+                        Ok(())
+                    }
+                }
+            }
+        },
     }
 }
 
 #[cfg(any(feature = "dtype-datetime", feature = "dtype-date"))]
 impl<T> ParsedBuffer for DatetimeField<T>
 where
     T: PolarsNumericType,
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/parser.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/parser.rs`

 * *Files 4% similar despite different names*

```diff
@@ -44,15 +44,25 @@
         let mut count = 0usize;
         for (field, _) in SplitFields::new(line, delimiter, quote_char, eol_char) {
             if memchr2_iter(delimiter, eol_char, field).count() >= expected_fields {
                 return false;
             }
             count += 1;
         }
-        count == expected_fields
+
+        // if the latest field is missing
+        // e.g.:
+        // a,b,c
+        // vala,valb,
+        // SplitFields returns a count that is 1 less
+        // There fore we accept:
+        // expected == count
+        // and
+        // expected == count - 1
+        expected_fields.wrapping_sub(count) <= 1
     }
 
     // we check 3 subsequent lines for `accept_line` before we accept
     // if 3 groups are rejected we reject completely
     let mut rejected_line_groups = 0u8;
 
     let mut total_pos = 0;
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/read_impl/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/read_impl/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/splitfields.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/splitfields.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/utils.rs`

 * *Files 1% similar despite different names*

```diff
@@ -118,19 +118,17 @@
                         } => DataType::Datetime(TimeUnit::Microseconds, None),
                         PatternWithOffset {
                             pattern: Pattern::DateYMD | Pattern::DateDMY,
                             offset: _,
                         } => DataType::Date,
                         PatternWithOffset {
                             pattern: Pattern::DatetimeYMDZ,
-                            offset,
-                        } => DataType::Datetime(
-                            TimeUnit::Microseconds,
-                            offset.map(|x| x.to_string()),
-                        ),
+                            offset: _,
+                        } => DataType::Utf8, // TODO: support tz-aware,
+                                             // need to keep track of offset
                     },
                     None => DataType::Utf8,
                 }
             }
             #[cfg(not(feature = "polars-time"))]
             {
                 panic!("activate one of {{'dtype-date', 'dtype-datetime', dtype-time'}} features")
@@ -157,16 +155,17 @@
                     } => DataType::Datetime(TimeUnit::Microseconds, None),
                     PatternWithOffset {
                         pattern: Pattern::DateYMD | Pattern::DateDMY,
                         offset: _,
                     } => DataType::Date,
                     PatternWithOffset {
                         pattern: Pattern::DatetimeYMDZ,
-                        offset,
-                    } => DataType::Datetime(TimeUnit::Microseconds, offset.map(|x| x.to_string())),
+                        offset: _,
+                    } => DataType::Utf8, // TODO: support tz-aware,
+                                         // need to keep track of offset
                 },
                 None => DataType::Utf8,
             }
         }
         #[cfg(not(feature = "polars-time"))]
         {
             panic!("activate one of {{'dtype-date', 'dtype-datetime', dtype-time'}} features")
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/write.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/csv/write_impl.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/csv/write_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/ipc_file.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/ipc_file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/ipc_stream.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/ipc_stream.rs`

 * *Files 1% similar despite different names*

```diff
@@ -29,15 +29,15 @@
 //! // reset the buffers index after writing to the beginning of the buffer
 //! buf.set_position(0);
 //!
 //! // read the buffer into a DataFrame
 //! let df_read = IpcStreamReader::new(buf).finish().unwrap();
 //! assert!(df.frame_equal(&df_read));
 //! ```
-use std::io::{Read, Seek, Write};
+use std::io::{Read, Write};
 use std::path::PathBuf;
 
 use arrow::io::ipc::read::{StreamMetadata, StreamState};
 use arrow::io::ipc::write::WriteOptions;
 use arrow::io::ipc::{read, write};
 use polars_core::prelude::*;
 
@@ -69,15 +69,15 @@
     n_rows: Option<usize>,
     projection: Option<Vec<usize>>,
     columns: Option<Vec<String>>,
     row_count: Option<RowCount>,
     metadata: Option<StreamMetadata>,
 }
 
-impl<R: Read + Seek> IpcStreamReader<R> {
+impl<R: Read> IpcStreamReader<R> {
     /// Get schema of the Ipc Stream File
     pub fn schema(&mut self) -> PolarsResult<Schema> {
         Ok((self.metadata()?.schema.fields.iter()).into())
     }
 
     /// Get arrow schema of the Ipc Stream File, this is faster than creating a polars schema.
     pub fn arrow_schema(&mut self) -> PolarsResult<ArrowSchema> {
@@ -118,30 +118,30 @@
             Some(md) => Ok(md.clone()),
         }
     }
 }
 
 impl<R> ArrowReader for read::StreamReader<R>
 where
-    R: Read + Seek,
+    R: Read,
 {
     fn next_record_batch(&mut self) -> ArrowResult<Option<ArrowChunk>> {
         self.next().map_or(Ok(None), |v| match v {
             Ok(stream_state) => match stream_state {
                 StreamState::Waiting => Ok(None),
                 StreamState::Some(chunk) => Ok(Some(chunk)),
             },
             Err(err) => Err(err),
         })
     }
 }
 
 impl<R> SerReader<R> for IpcStreamReader<R>
 where
-    R: Read + Seek,
+    R: Read,
 {
     fn new(reader: R) -> Self {
         IpcStreamReader {
             reader,
             rechunk: true,
             n_rows: None,
             columns: None,
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/mmap.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/write.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ipc/write_async.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ipc/write_async.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/json.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/json.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -37,15 +37,15 @@
 #[cfg(all(test, feature = "csv-file"))]
 mod tests;
 pub(crate) mod utils;
 
 #[cfg(feature = "partition")]
 pub mod partition;
 
-use std::io::{Read, Seek, Write};
+use std::io::{Read, Write};
 use std::path::{Path, PathBuf};
 
 #[allow(unused)] // remove when updating to rust nightly >= 1.61
 use arrow::array::new_empty_array;
 use arrow::error::Result as ArrowResult;
 pub use options::*;
 use polars_core::frame::ArrowChunk;
@@ -57,15 +57,15 @@
     feature = "avro",
     feature = "ipc_streaming",
 ))]
 use crate::predicates::PhysicalIoExpr;
 
 pub trait SerReader<R>
 where
-    R: Read + Seek,
+    R: Read,
 {
     /// Create a new instance of the `[SerReader]`
     fn new(reader: R) -> Self;
 
     /// Make sure that all columns are contiguous in memory by
     /// aggregating the chunks into a single array.
     #[must_use]
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/mmap.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ndjson_core/buffer.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ndjson_core/buffer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/ndjson_core/ndjson.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/ndjson_core/ndjson.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/async_impl.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/async_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/mmap.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/predicates.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/predicates.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/read.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/read_impl.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/read_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/parquet/write.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/parquet/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/partition.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/predicates.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/predicates.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/prelude.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-io/src/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-io/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/Cargo.toml`

 * *Files 6% similar despite different names*

```diff
@@ -63,14 +63,15 @@
 trigonometry = []
 sign = []
 timezones = ["chrono-tz", "polars-time/timezones", "polars-core/timezones", "regex"]
 binary_encoding = ["polars-ops/binary_encoding"]
 true_div = []
 
 # operations
+approx_unique = ["polars-ops/approx_unique"]
 is_in = ["polars-core/is_in"]
 repeat_by = ["polars-core/repeat_by"]
 round_series = ["polars-core/round_series"]
 is_first = ["polars-core/is_first", "polars-ops/is_first"]
 is_unique = ["polars-ops/is_unique"]
 cross_join = ["polars-core/cross_join"]
 asof_join = ["polars-core/asof_join", "polars-time", "polars-ops/asof_join"]
@@ -126,17 +127,17 @@
 # defines the configuration attribute `docsrs`
 rustdoc-args = ["--cfg", "docsrs"]
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-algo/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dot.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/arithmetic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/binary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/cat.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,31 +1,45 @@
 use super::*;
+use crate::map;
 
-/// Specialized expressions for Categorical dtypes.
-pub struct CategoricalNameSpace(pub(crate) Expr);
+#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
+#[derive(Clone, PartialEq, Debug, Eq, Hash)]
+pub enum CategoricalFunction {
+    SetOrdering { lexical: bool },
+}
+
+impl CategoricalFunction {
+    pub(super) fn get_field(&self, mapper: FieldsMapper) -> PolarsResult<Field> {
+        mapper.with_dtype(DataType::Boolean)
+    }
+}
+
+impl Display for CategoricalFunction {
+    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
+        use CategoricalFunction::*;
+        let s = match self {
+            SetOrdering { .. } => "set_ordering",
+        };
+        write!(f, "{s}")
+    }
+}
+
+impl From<CategoricalFunction> for SpecialEq<Arc<dyn SeriesUdf>> {
+    fn from(func: CategoricalFunction) -> Self {
+        use CategoricalFunction::*;
+        match func {
+            SetOrdering { lexical } => map!(set_ordering, lexical),
+        }
+    }
+}
 
-#[derive(Copy, Clone, Debug)]
-pub enum CategoricalOrdering {
-    /// Use the physical categories for sorting
-    Physical,
-    /// Use the string value for sorting
-    Lexical,
-}
-
-impl CategoricalNameSpace {
-    pub fn set_ordering(self, ordering: CategoricalOrdering) -> Expr {
-        self.0
-            .map(
-                move |s| {
-                    let mut ca = s.categorical()?.clone();
-                    let set_lexical = match ordering {
-                        CategoricalOrdering::Lexical => true,
-                        CategoricalOrdering::Physical => false,
-                    };
-                    ca.set_lexical_sorted(set_lexical);
-                    Ok(Some(ca.into_series()))
-                },
-                GetOutput::from_type(DataType::Categorical(None)),
-            )
-            .with_fmt("set_ordering")
+impl From<CategoricalFunction> for FunctionExpr {
+    fn from(func: CategoricalFunction) -> Self {
+        FunctionExpr::Categorical(func)
     }
 }
+
+fn set_ordering(s: &Series, lexical: bool) -> PolarsResult<Series> {
+    let mut ca = s.categorical()?.clone();
+    ca.set_lexical_sorted(lexical);
+    Ok(ca.into_series())
+}
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/dt.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/dt.rs`

 * *Files 6% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 
 /// Specialized expressions for [`Series`] with dates/datetimes.
 pub struct DateLikeNameSpace(pub(crate) Expr);
 
 impl DateLikeNameSpace {
     /// Format Date/datetime with a formatting rule
     /// See [chrono strftime/strptime](https://docs.rs/chrono/0.4.19/chrono/format/strftime/index.html).
-    pub fn strftime(self, fmt: &str) -> Expr {
-        let fmt = fmt.to_string();
-        let function = move |s: Series| s.strftime(&fmt).map(Some);
+    pub fn strftime(self, format: &str) -> Expr {
+        let format = format.to_string();
+        let function = move |s: Series| s.strftime(&format).map(Some);
         self.0
             .map(function, GetOutput::from_type(DataType::Utf8))
             .with_fmt("strftime")
     }
 
     /// Change the underlying [`TimeUnit`]. And update the data accordingly.
     pub fn cast_time_unit(self, tu: TimeUnit) -> Expr {
@@ -240,18 +240,23 @@
     /// This will take leap years/ months into account.
     #[cfg(feature = "date_offset")]
     pub fn offset_by(self, by: Duration) -> Expr {
         self.0.map_private(FunctionExpr::DateOffset(by))
     }
 
     #[cfg(feature = "timezones")]
-    pub fn replace_time_zone(self, time_zone: Option<TimeZone>) -> Expr {
+    pub fn replace_time_zone(
+        self,
+        time_zone: Option<TimeZone>,
+        use_earliest: Option<bool>,
+    ) -> Expr {
         self.0
             .map_private(FunctionExpr::TemporalExpr(TemporalFunction::CastTimezone(
                 time_zone,
+                use_earliest,
             )))
     }
 
     pub fn combine(self, time: Expr, tu: TimeUnit) -> Expr {
         self.0.map_many_private(
             FunctionExpr::TemporalExpr(TemporalFunction::Combine(tu)),
             &[time],
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/expr.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/expr.rs`

 * *Files 1% similar despite different names*

```diff
@@ -262,15 +262,15 @@
         propagate_nans: bool,
     },
     Median(Box<Expr>),
     NUnique(Box<Expr>),
     First(Box<Expr>),
     Last(Box<Expr>),
     Mean(Box<Expr>),
-    List(Box<Expr>),
+    Implode(Box<Expr>),
     Count(Box<Expr>),
     Quantile {
         expr: Box<Expr>,
         quantile: Box<Expr>,
         interpol: QuantileInterpolOptions,
     },
     Sum(Box<Expr>),
@@ -286,15 +286,15 @@
             Min { input, .. } => input,
             Max { input, .. } => input,
             Median(e) => e,
             NUnique(e) => e,
             First(e) => e,
             Last(e) => e,
             Mean(e) => e,
-            List(e) => e,
+            Implode(e) => e,
             Count(e) => e,
             Quantile { expr, .. } => expr,
             Sum(e) => e,
             AggGroups(e) => e,
             Std(e, _) => e,
             Var(e, _) => e,
         }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/from.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs`

 * *Files 15% similar despite different names*

```diff
@@ -24,16 +24,16 @@
     #[cfg(feature = "is_unique")]
     IsDuplicated,
     #[cfg(feature = "is_in")]
     IsIn,
 }
 
 impl BooleanFunction {
-    pub(super) fn dtype_out(&self) -> DataType {
-        DataType::Boolean
+    pub(super) fn get_field(&self, mapper: FieldsMapper) -> PolarsResult<Field> {
+        mapper.with_dtype(DataType::Boolean)
     }
 }
 
 impl Display for BooleanFunction {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use BooleanFunction::*;
         let s = match self {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs`

 * *Files 2% similar despite different names*

```diff
@@ -29,15 +29,15 @@
     Millisecond,
     Microsecond,
     Nanosecond,
     TimeStamp(TimeUnit),
     Truncate(String, String),
     Round(String, String),
     #[cfg(feature = "timezones")]
-    CastTimezone(Option<TimeZone>),
+    CastTimezone(Option<TimeZone>, Option<bool>),
     #[cfg(feature = "timezones")]
     TzLocalize(TimeZone),
     DateRange {
         name: String,
         every: Duration,
         closed: ClosedWindow,
         tz: Option<TimeZone>,
@@ -67,15 +67,15 @@
             Millisecond => "millisecond",
             Microsecond => "microsecond",
             Nanosecond => "nanosecond",
             TimeStamp(tu) => return write!(f, "dt.timestamp({tu})"),
             Truncate(..) => "truncate",
             Round(..) => "round",
             #[cfg(feature = "timezones")]
-            CastTimezone(_) => "replace_timezone",
+            CastTimezone(_, _) => "replace_timezone",
             #[cfg(feature = "timezones")]
             TzLocalize(_) => "tz_localize",
             DateRange { .. } => return write!(f, "date_range"),
             Combine(_) => "combine",
         };
         write!(f, "dt.{s}")
     }
@@ -110,42 +110,42 @@
 }
 pub(super) fn time(s: &Series) -> PolarsResult<Series> {
     match s.dtype() {
         #[cfg(feature = "timezones")]
         DataType::Datetime(_, Some(_)) => s
             .datetime()
             .unwrap()
-            .replace_time_zone(None)?
+            .replace_time_zone(None, None)?
             .cast(&DataType::Time),
         DataType::Datetime(_, _) => s.datetime().unwrap().cast(&DataType::Time),
         DataType::Date => s.datetime().unwrap().cast(&DataType::Time),
         DataType::Time => Ok(s.clone()),
         dtype => polars_bail!(ComputeError: "expected Datetime, Date, or Time, got {}", dtype),
     }
 }
 pub(super) fn date(s: &Series) -> PolarsResult<Series> {
     match s.dtype() {
         #[cfg(feature = "timezones")]
         DataType::Datetime(_, Some(_)) => s
             .datetime()
             .unwrap()
-            .replace_time_zone(None)?
+            .replace_time_zone(None, None)?
             .cast(&DataType::Date),
         DataType::Datetime(_, _) => s.datetime().unwrap().cast(&DataType::Date),
         DataType::Date => Ok(s.clone()),
         dtype => polars_bail!(ComputeError: "expected Datetime or Date, got {}", dtype),
     }
 }
 pub(super) fn datetime(s: &Series) -> PolarsResult<Series> {
     match s.dtype() {
         #[cfg(feature = "timezones")]
         DataType::Datetime(tu, Some(_)) => s
             .datetime()
             .unwrap()
-            .replace_time_zone(None)?
+            .replace_time_zone(None, None)?
             .cast(&DataType::Datetime(*tu, None)),
         DataType::Datetime(tu, _) => s.datetime().unwrap().cast(&DataType::Datetime(*tu, None)),
         dtype => polars_bail!(ComputeError: "expected Datetime, got {}", dtype),
     }
 }
 pub(super) fn hour(s: &Series) -> PolarsResult<Series> {
     s.hour().map(|ca| ca.into_series())
@@ -238,30 +238,35 @@
             .round(every, offset, NO_TIMEZONE)?
             .into_series(),
         dt => polars_bail!(opq = round, got = dt, expected = "date/datetime"),
     })
 }
 
 #[cfg(feature = "timezones")]
-pub(super) fn replace_timezone(s: &Series, time_zone: Option<&str>) -> PolarsResult<Series> {
+pub(super) fn replace_timezone(
+    s: &Series,
+    time_zone: Option<&str>,
+    use_earliest: Option<bool>,
+) -> PolarsResult<Series> {
     let ca = s.datetime()?;
-    ca.replace_time_zone(time_zone).map(|ca| ca.into_series())
+    ca.replace_time_zone(time_zone, use_earliest)
+        .map(|ca| ca.into_series())
 }
 
 #[cfg(feature = "timezones")]
 #[deprecated(note = "use replace_time_zone")]
 pub(super) fn tz_localize(s: &Series, tz: &str) -> PolarsResult<Series> {
     let ca = s.datetime()?.clone();
     polars_ensure!(
         ca.time_zone().as_ref().map_or(true, |tz| tz.is_empty()),
         ComputeError:
         "cannot localize a tz-aware datetime \
         (consider using 'dt.convert_time_zone' or 'dt.replace_time_zone')"
     );
-    Ok(ca.replace_time_zone(Some(tz))?.into_series())
+    Ok(ca.replace_time_zone(Some(tz), None)?.into_series())
 }
 
 pub(super) fn date_range_dispatch(
     s: &[Series],
     name: &str,
     every: Duration,
     closed: ClosedWindow,
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs`

 * *Files 18% similar despite different names*

```diff
@@ -4,14 +4,19 @@
     Ok(s.shift(periods))
 }
 
 pub(super) fn reverse(s: &Series) -> PolarsResult<Series> {
     Ok(s.reverse())
 }
 
+#[cfg(feature = "approx_unique")]
+pub(super) fn approx_unique(s: &Series) -> PolarsResult<Series> {
+    polars_ops::prelude::approx_unique(s)
+}
+
 #[cfg(feature = "diff")]
 pub(super) fn diff(s: &Series, n: i64, null_behavior: NullBehavior) -> PolarsResult<Series> {
     s.diff(n, null_behavior)
 }
 
 #[cfg(feature = "interpolate")]
 pub(super) fn interpolate(s: &Series, method: InterpolationMethod) -> PolarsResult<Series> {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/log.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/log.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,32 @@
 #[cfg(feature = "abs")]
 mod abs;
 #[cfg(feature = "arg_where")]
 mod arg_where;
 mod binary;
 mod boolean;
+mod bounds;
+#[cfg(feature = "dtype-categorical")]
+mod cat;
 #[cfg(feature = "round_series")]
 mod clip;
 mod cum;
 #[cfg(feature = "temporal")]
 mod datetime;
 mod dispatch;
 mod fill_null;
 mod list;
 #[cfg(feature = "log")]
 mod log;
 mod nan;
 mod pow;
 #[cfg(all(feature = "rolling_window", feature = "moment"))]
 mod rolling;
+#[cfg(feature = "round_series")]
+mod round;
 #[cfg(feature = "row_hash")]
 mod row_hash;
 mod schema;
 #[cfg(feature = "search_sorted")]
 mod search_sorted;
 mod shift_and_fill;
 mod shrink_type;
@@ -37,19 +42,22 @@
 mod trigonometry;
 mod unique;
 
 use std::fmt::{Display, Formatter};
 
 pub(super) use list::ListFunction;
 use polars_core::prelude::*;
+use schema::FieldsMapper;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 
 pub(crate) use self::binary::BinaryFunction;
 pub use self::boolean::BooleanFunction;
+#[cfg(feature = "dtype-categorical")]
+pub(crate) use self::cat::CategoricalFunction;
 #[cfg(feature = "temporal")]
 pub(super) use self::datetime::TemporalFunction;
 #[cfg(feature = "strings")]
 pub(crate) use self::strings::StringFunction;
 #[cfg(feature = "dtype-struct")]
 pub(super) use self::struct_::StructFunction;
 #[cfg(feature = "trigonometry")]
@@ -120,14 +128,18 @@
         reverse: bool,
     },
     Cummax {
         reverse: bool,
     },
     Reverse,
     Boolean(BooleanFunction),
+    #[cfg(feature = "approx_unique")]
+    ApproxUnique,
+    #[cfg(feature = "dtype-categorical")]
+    Categorical(CategoricalFunction),
     Coalesce,
     ShrinkType,
     #[cfg(feature = "diff")]
     Diff(i64, NullBehavior),
     #[cfg(feature = "interpolate")]
     Interpolate(InterpolationMethod),
     #[cfg(feature = "dot_product")]
@@ -142,14 +154,24 @@
         base: f64,
     },
     #[cfg(feature = "log")]
     Log1p,
     #[cfg(feature = "log")]
     Exp,
     Unique(bool),
+    #[cfg(feature = "round_series")]
+    Round {
+        decimals: u32,
+    },
+    #[cfg(feature = "round_series")]
+    Floor,
+    #[cfg(feature = "round_series")]
+    Ceil,
+    UpperBound,
+    LowerBound,
 }
 
 impl Display for FunctionExpr {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use FunctionExpr::*;
 
         let s = match self {
@@ -195,14 +217,18 @@
             Cumcount { .. } => "cumcount",
             Cumsum { .. } => "cumsum",
             Cumprod { .. } => "cumprod",
             Cummin { .. } => "cummin",
             Cummax { .. } => "cummax",
             Reverse => "reverse",
             Boolean(func) => return write!(f, "{func}"),
+            #[cfg(feature = "approx_unique")]
+            ApproxUnique => "approx_unique",
+            #[cfg(feature = "dtype-categorical")]
+            Categorical(func) => return write!(f, "{func}"),
             Coalesce => "coalesce",
             ShrinkType => "shrink_dtype",
             #[cfg(feature = "diff")]
             Diff(_, _) => "diff",
             #[cfg(feature = "interpolate")]
             Interpolate(_) => "interpolate",
             #[cfg(feature = "dot_product")]
@@ -218,14 +244,22 @@
             Unique(stable) => {
                 if *stable {
                     "unique_stable"
                 } else {
                     "unique"
                 }
             }
+            #[cfg(feature = "round_series")]
+            Round { .. } => "round",
+            #[cfg(feature = "round_series")]
+            Floor => "floor",
+            #[cfg(feature = "round_series")]
+            Ceil => "ceil",
+            UpperBound => "upper_bound",
+            LowerBound => "lower_bound",
         };
         write!(f, "{s}")
     }
 }
 
 #[macro_export]
 macro_rules! wrap {
@@ -393,14 +427,18 @@
             Cumcount { reverse } => map!(cum::cumcount, reverse),
             Cumsum { reverse } => map!(cum::cumsum, reverse),
             Cumprod { reverse } => map!(cum::cumprod, reverse),
             Cummin { reverse } => map!(cum::cummin, reverse),
             Cummax { reverse } => map!(cum::cummax, reverse),
             Reverse => map!(dispatch::reverse),
             Boolean(func) => func.into(),
+            #[cfg(feature = "approx_unique")]
+            ApproxUnique => map!(dispatch::approx_unique),
+            #[cfg(feature = "dtype-categorical")]
+            Categorical(func) => func.into(),
             Coalesce => map_as_slice!(fill_null::coalesce),
             ShrinkType => map_owned!(shrink_type::shrink),
             #[cfg(feature = "diff")]
             Diff(n, null_behavior) => map!(dispatch::diff, n, null_behavior),
             #[cfg(feature = "interpolate")]
             Interpolate(method) => {
                 map!(dispatch::interpolate, method)
@@ -414,14 +452,22 @@
             #[cfg(feature = "log")]
             Log { base } => map!(log::log, base),
             #[cfg(feature = "log")]
             Log1p => map!(log::log1p),
             #[cfg(feature = "log")]
             Exp => map!(log::exp),
             Unique(stable) => map!(unique::unique, stable),
+            #[cfg(feature = "round_series")]
+            Round { decimals } => map!(round::round, decimals),
+            #[cfg(feature = "round_series")]
+            Floor => map!(round::floor),
+            #[cfg(feature = "round_series")]
+            Ceil => map!(round::ceil),
+            UpperBound => map!(bounds::upper_bound),
+            LowerBound => map!(bounds::lower_bound),
         }
     }
 }
 
 #[cfg(feature = "strings")]
 impl From<StringFunction> for SpecialEq<Arc<dyn SeriesUdf>> {
     fn from(func: StringFunction) -> Self {
@@ -514,15 +560,17 @@
             Millisecond => map!(datetime::millisecond),
             Microsecond => map!(datetime::microsecond),
             Nanosecond => map!(datetime::nanosecond),
             TimeStamp(tu) => map!(datetime::timestamp, tu),
             Truncate(every, offset) => map!(datetime::truncate, &every, &offset),
             Round(every, offset) => map!(datetime::round, &every, &offset),
             #[cfg(feature = "timezones")]
-            CastTimezone(tz) => map!(datetime::replace_timezone, tz.as_deref()),
+            CastTimezone(tz, use_earliest) => {
+                map!(datetime::replace_timezone, tz.as_deref(), use_earliest)
+            }
             #[cfg(feature = "timezones")]
             TzLocalize(tz) => map!(datetime::tz_localize, &tz),
             Combine(tu) => map_as_slice!(temporal::combine, tu),
             DateRange {
                 name,
                 every,
                 closed,
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs`

 * *Files 20% similar despite different names*

```diff
@@ -3,205 +3,93 @@
 impl FunctionExpr {
     pub(crate) fn get_field(
         &self,
         _input_schema: &Schema,
         _cntxt: Context,
         fields: &[Field],
     ) -> PolarsResult<Field> {
-        // set a dtype
-        let with_dtype = |dtype: DataType| Ok(Field::new(fields[0].name(), dtype));
-
-        // map a single dtype
-        let map_dtype = |func: &dyn Fn(&DataType) -> DataType| {
-            let dtype = func(fields[0].data_type());
-            Ok(Field::new(fields[0].name(), dtype))
-        };
-
-        // map a single dtype
-        #[cfg(feature = "timezones")]
-        let try_map_dtype = |func: &dyn Fn(&DataType) -> PolarsResult<DataType>| {
-            let dtype = func(fields[0].data_type())?;
-            let out: PolarsResult<_> = Ok(Field::new(fields[0].name(), dtype));
-            out
-        };
-
-        // map all dtypes
-        let try_map_dtypes = |func: &dyn Fn(&[&DataType]) -> PolarsResult<DataType>| {
-            let mut fld = fields[0].clone();
-            let dtypes = fields.iter().map(|fld| fld.data_type()).collect::<Vec<_>>();
-            let new_type = func(&dtypes)?;
-            fld.coerce(new_type);
-            Ok(fld)
-        };
-
-        // set float supertype
-        let float_dtype = || {
-            map_dtype(&|dtype| match dtype {
-                DataType::Float32 => DataType::Float32,
-                _ => DataType::Float64,
-            })
-        };
-
-        // map to same type
-        let same_type = || map_dtype(&|dtype| dtype.clone());
-
-        // get supertype of all types
-        let super_type = || {
-            let mut first = fields[0].clone();
-            let mut st = first.data_type().clone();
-            for field in &fields[1..] {
-                st = try_get_supertype(&st, field.data_type())?
-            }
-            first.coerce(st);
-            Ok(first)
-        };
-
-        let inner_type_list = || {
-            let mut first = fields[0].clone();
-            let dt = first
-                .data_type()
-                .inner_dtype()
-                .cloned()
-                .unwrap_or(DataType::Unknown);
-            first.coerce(dt);
-            Ok(first)
-        };
-
-        // inner super type of lists
-        let inner_super_type_list = || {
-            try_map_dtypes(&|dts| {
-                let mut super_type_inner = None;
-
-                for dt in dts {
-                    match dt {
-                        DataType::List(inner) => match super_type_inner {
-                            None => super_type_inner = Some(*inner.clone()),
-                            Some(st_inner) => {
-                                super_type_inner = Some(try_get_supertype(&st_inner, inner)?)
-                            }
-                        },
-                        dt => match super_type_inner {
-                            None => super_type_inner = Some((*dt).clone()),
-                            Some(st_inner) => {
-                                super_type_inner = Some(try_get_supertype(&st_inner, dt)?)
-                            }
-                        },
-                    }
-                }
-                Ok(DataType::List(Box::new(super_type_inner.unwrap())))
-            })
-        };
-
-        #[cfg(feature = "timezones")]
-        let cast_tz = |tz: Option<&TimeZone>| {
-            try_map_dtype(&|dt| {
-                if let DataType::Datetime(tu, _) = dt {
-                    Ok(DataType::Datetime(*tu, tz.cloned()))
-                } else {
-                    polars_bail!(op = "cast-timezone", got = dt, expected = "Datetime");
-                }
-            })
-        };
-
         use FunctionExpr::*;
+
+        let mapper = FieldsMapper { fields };
         match self {
             #[cfg(feature = "abs")]
-            Abs => same_type(),
-            NullCount => with_dtype(IDX_DTYPE),
-            Pow => float_dtype(),
-            Coalesce => super_type(),
+            Abs => mapper.with_same_dtype(),
+            NullCount => mapper.with_dtype(IDX_DTYPE),
+            Pow => mapper.map_to_float_dtype(),
+            Coalesce => mapper.map_to_list_supertype(),
             #[cfg(feature = "row_hash")]
-            Hash(..) => with_dtype(DataType::UInt64),
+            Hash(..) => mapper.with_dtype(DataType::UInt64),
             #[cfg(feature = "arg_where")]
-            ArgWhere => with_dtype(IDX_DTYPE),
+            ArgWhere => mapper.with_dtype(IDX_DTYPE),
             #[cfg(feature = "search_sorted")]
-            SearchSorted(_) => with_dtype(IDX_DTYPE),
+            SearchSorted(_) => mapper.with_dtype(IDX_DTYPE),
             #[cfg(feature = "strings")]
-            StringExpr(s) => {
-                use StringFunction::*;
-                match s {
-                    #[cfg(feature = "regex")]
-                    Contains { .. } => with_dtype(DataType::Boolean),
-                    EndsWith | StartsWith => with_dtype(DataType::Boolean),
-                    Extract { .. } => same_type(),
-                    ExtractAll => with_dtype(DataType::List(Box::new(DataType::Utf8))),
-                    CountMatch(_) => with_dtype(DataType::UInt32),
-                    #[cfg(feature = "string_justify")]
-                    Zfill { .. } | LJust { .. } | RJust { .. } => same_type(),
-                    #[cfg(feature = "temporal")]
-                    Strptime(options) => with_dtype(options.date_dtype.clone()),
-                    #[cfg(feature = "concat_str")]
-                    ConcatVertical(_) | ConcatHorizontal(_) => with_dtype(DataType::Utf8),
-                    #[cfg(feature = "regex")]
-                    Replace { .. } => with_dtype(DataType::Utf8),
-                    Uppercase | Lowercase | Strip(_) | LStrip(_) | RStrip(_) => {
-                        with_dtype(DataType::Utf8)
-                    }
-                    #[cfg(feature = "string_from_radix")]
-                    FromRadix { .. } => with_dtype(DataType::Int32),
-                }
-            }
+            StringExpr(s) => s.get_field(mapper),
             BinaryExpr(s) => {
                 use BinaryFunction::*;
                 match s {
-                    Contains { .. } | EndsWith(_) | StartsWith(_) => with_dtype(DataType::Boolean),
+                    Contains { .. } | EndsWith(_) | StartsWith(_) => {
+                        mapper.with_dtype(DataType::Boolean)
+                    }
                 }
             }
             #[cfg(feature = "temporal")]
             TemporalExpr(fun) => {
                 use TemporalFunction::*;
                 let dtype = match fun {
                     Year | IsoYear => DataType::Int32,
                     Month | Quarter | Week | WeekDay | Day | OrdinalDay | Hour | Minute
                     | Millisecond | Microsecond | Nanosecond | Second => DataType::UInt32,
                     TimeStamp(_) => DataType::Int64,
                     IsLeapYear => DataType::Boolean,
                     Time => DataType::Time,
                     Date => DataType::Date,
-                    Datetime => match same_type().unwrap().dtype {
+                    Datetime => match mapper.with_same_dtype().unwrap().dtype {
                         DataType::Datetime(tu, _) => DataType::Datetime(tu, None),
                         dtype => polars_bail!(ComputeError: "expected Datetime, got {}", dtype),
                     },
-                    Truncate(..) => same_type().unwrap().dtype,
-                    Round(..) => same_type().unwrap().dtype,
+                    Truncate(..) => mapper.with_same_dtype().unwrap().dtype,
+                    Round(..) => mapper.with_same_dtype().unwrap().dtype,
                     #[cfg(feature = "timezones")]
-                    CastTimezone(tz) => return cast_tz(tz.as_ref()),
+                    CastTimezone(tz, _use_earliest) => {
+                        return mapper.map_datetime_dtype_timezone(tz.as_ref())
+                    }
                     #[cfg(feature = "timezones")]
-                    TzLocalize(tz) => return cast_tz(Some(tz)),
-                    DateRange { .. } => return super_type(),
+                    TzLocalize(tz) => return mapper.map_datetime_dtype_timezone(Some(tz)),
+                    DateRange { .. } => return mapper.map_to_supertype(),
                     Combine(tu) => DataType::Datetime(*tu, None),
                 };
-                with_dtype(dtype)
+                mapper.with_dtype(dtype)
             }
 
             #[cfg(feature = "date_offset")]
-            DateOffset(_) => same_type(),
+            DateOffset(_) => mapper.with_same_dtype(),
             #[cfg(feature = "trigonometry")]
-            Trigonometry(_) => float_dtype(),
+            Trigonometry(_) => mapper.map_to_float_dtype(),
             #[cfg(feature = "sign")]
-            Sign => with_dtype(DataType::Int64),
-            FillNull { super_type, .. } => with_dtype(super_type.clone()),
+            Sign => mapper.with_dtype(DataType::Int64),
+            FillNull { super_type, .. } => mapper.with_dtype(super_type.clone()),
             #[cfg(all(feature = "rolling_window", feature = "moment"))]
-            RollingSkew { .. } => float_dtype(),
-            ShiftAndFill { .. } => same_type(),
-            DropNans => same_type(),
+            RollingSkew { .. } => mapper.map_to_float_dtype(),
+            ShiftAndFill { .. } => mapper.with_same_dtype(),
+            DropNans => mapper.with_same_dtype(),
             #[cfg(feature = "round_series")]
-            Clip { .. } => same_type(),
+            Clip { .. } => mapper.with_same_dtype(),
             ListExpr(l) => {
                 use ListFunction::*;
                 match l {
-                    Concat => inner_super_type_list(),
+                    Concat => mapper.map_to_list_supertype(),
                     #[cfg(feature = "is_in")]
-                    Contains => with_dtype(DataType::Boolean),
-                    Slice => same_type(),
-                    Get => inner_type_list(),
+                    Contains => mapper.with_dtype(DataType::Boolean),
+                    Slice => mapper.with_same_dtype(),
+                    Get => mapper.map_to_list_inner_dtype(),
                     #[cfg(feature = "list_take")]
-                    Take(_) => same_type(),
+                    Take(_) => mapper.with_same_dtype(),
                     #[cfg(feature = "list_count")]
-                    CountMatch => with_dtype(IDX_DTYPE),
+                    CountMatch => mapper.with_dtype(IDX_DTYPE),
                     Sum => {
                         let mut first = fields[0].clone();
                         use DataType::*;
                         let dt = first.data_type().inner_dtype().cloned().unwrap_or(Unknown);
 
                         if matches!(dt, UInt8 | Int8 | Int16 | UInt16) {
                             first.coerce(Int64);
@@ -235,67 +123,190 @@
                         } else {
                             polars_bail!(StructFieldNotFound: "{}", name.as_ref());
                         }
                     }
                 }
             }
             #[cfg(feature = "top_k")]
-            TopK { .. } => same_type(),
-            Shift(..) | Reverse => same_type(),
-            Boolean(f) => with_dtype(f.dtype_out()),
-            Cumcount { .. } => with_dtype(IDX_DTYPE),
-            Cumsum { .. } => map_dtype(&cum::dtypes::cumsum),
-            Cumprod { .. } => map_dtype(&cum::dtypes::cumprod),
-            Cummin { .. } => same_type(),
-            Cummax { .. } => same_type(),
+            TopK { .. } => mapper.with_same_dtype(),
+            Shift(..) | Reverse => mapper.with_same_dtype(),
+            Boolean(func) => func.get_field(mapper),
+            #[cfg(feature = "dtype-categorical")]
+            Categorical(func) => func.get_field(mapper),
+            Cumcount { .. } => mapper.with_dtype(IDX_DTYPE),
+            Cumsum { .. } => mapper.map_dtype(cum::dtypes::cumsum),
+            Cumprod { .. } => mapper.map_dtype(cum::dtypes::cumprod),
+            Cummin { .. } => mapper.with_same_dtype(),
+            Cummax { .. } => mapper.with_same_dtype(),
+            #[cfg(feature = "approx_unique")]
+            ApproxUnique => mapper.with_dtype(IDX_DTYPE),
             #[cfg(feature = "diff")]
-            Diff(_, _) => map_dtype(&|dt| match dt {
+            Diff(_, _) => mapper.map_dtype(|dt| match dt {
                 #[cfg(feature = "dtype-datetime")]
                 DataType::Datetime(tu, _) => DataType::Duration(*tu),
                 #[cfg(feature = "dtype-date")]
                 DataType::Date => DataType::Duration(TimeUnit::Milliseconds),
                 #[cfg(feature = "dtype-time")]
                 DataType::Time => DataType::Duration(TimeUnit::Nanoseconds),
                 DataType::UInt64 | DataType::UInt32 => DataType::Int64,
                 DataType::UInt16 => DataType::Int32,
                 DataType::UInt8 => DataType::Int16,
                 dt => dt.clone(),
             }),
             #[cfg(feature = "interpolate")]
-            Interpolate(_) => same_type(),
+            Interpolate(_) => mapper.with_same_dtype(),
             ShrinkType => {
                 // we return the smallest type this can return
                 // this might not be correct once the actual data
                 // comes in, but if we set the smallest datatype
                 // we have the least chance that the smaller dtypes
                 // get cast to larger types in type-coercion
                 // this will lead to an incorrect schema in polars
                 // but we because only the numeric types deviate in
                 // bit size this will likely not lead to issues
-                map_dtype(&|dt| {
+                mapper.map_dtype(|dt| {
                     if dt.is_numeric() {
                         if dt.is_float() {
                             DataType::Float32
                         } else if dt.is_unsigned() {
                             DataType::Int8
                         } else {
                             DataType::UInt8
                         }
                     } else {
                         dt.clone()
                     }
                 })
             }
             #[cfg(feature = "dot_product")]
-            Dot => map_dtype(&|dt| {
+            Dot => mapper.map_dtype(|dt| {
                 use DataType::*;
                 match dt {
                     Int8 | Int16 | UInt16 | UInt8 => Int64,
                     _ => dt.clone(),
                 }
             }),
             #[cfg(feature = "log")]
-            Entropy { .. } | Log { .. } | Log1p | Exp => float_dtype(),
-            Unique(_) => same_type(),
+            Entropy { .. } | Log { .. } | Log1p | Exp => mapper.map_to_float_dtype(),
+            Unique(_) => mapper.with_same_dtype(),
+            #[cfg(feature = "round_series")]
+            Round { .. } | Floor | Ceil => mapper.with_same_dtype(),
+            UpperBound | LowerBound => mapper.with_same_dtype(),
         }
     }
 }
+
+pub(super) struct FieldsMapper<'a> {
+    fields: &'a [Field],
+}
+
+impl<'a> FieldsMapper<'a> {
+    /// Field with the same dtype.
+    pub(super) fn with_same_dtype(&self) -> PolarsResult<Field> {
+        self.map_dtype(|dtype| dtype.clone())
+    }
+
+    /// Set a dtype.
+    pub(super) fn with_dtype(&self, dtype: DataType) -> PolarsResult<Field> {
+        Ok(Field::new(self.fields[0].name(), dtype))
+    }
+
+    /// Map a single dtype.
+    pub(super) fn map_dtype(&self, func: impl Fn(&DataType) -> DataType) -> PolarsResult<Field> {
+        let dtype = func(self.fields[0].data_type());
+        Ok(Field::new(self.fields[0].name(), dtype))
+    }
+
+    /// Map to a float supertype.
+    pub(super) fn map_to_float_dtype(&self) -> PolarsResult<Field> {
+        self.map_dtype(|dtype| match dtype {
+            DataType::Float32 => DataType::Float32,
+            _ => DataType::Float64,
+        })
+    }
+
+    /// Map a single dtype with a potentially failing mapper function.
+    #[cfg(feature = "timezones")]
+    pub(super) fn try_map_dtype(
+        &self,
+        func: impl Fn(&DataType) -> PolarsResult<DataType>,
+    ) -> PolarsResult<Field> {
+        let dtype = func(self.fields[0].data_type())?;
+        Ok(Field::new(self.fields[0].name(), dtype))
+    }
+
+    /// Map all dtypes with a potentially failing mapper function.
+    pub(super) fn try_map_dtypes(
+        &self,
+        func: impl Fn(&[&DataType]) -> PolarsResult<DataType>,
+    ) -> PolarsResult<Field> {
+        let mut fld = self.fields[0].clone();
+        let dtypes = self
+            .fields
+            .iter()
+            .map(|fld| fld.data_type())
+            .collect::<Vec<_>>();
+        let new_type = func(&dtypes)?;
+        fld.coerce(new_type);
+        Ok(fld)
+    }
+
+    /// Map the dtype to the "supertype" of all fields.
+    pub(super) fn map_to_supertype(&self) -> PolarsResult<Field> {
+        let mut first = self.fields[0].clone();
+        let mut st = first.data_type().clone();
+        for field in &self.fields[1..] {
+            st = try_get_supertype(&st, field.data_type())?
+        }
+        first.coerce(st);
+        Ok(first)
+    }
+
+    /// Map the dtype to the dtype of the list elements.
+    pub(super) fn map_to_list_inner_dtype(&self) -> PolarsResult<Field> {
+        let mut first = self.fields[0].clone();
+        let dt = first
+            .data_type()
+            .inner_dtype()
+            .cloned()
+            .unwrap_or(DataType::Unknown);
+        first.coerce(dt);
+        Ok(first)
+    }
+
+    /// Map the dtypes to the "supertype" of a list of lists.
+    pub(super) fn map_to_list_supertype(&self) -> PolarsResult<Field> {
+        self.try_map_dtypes(|dts| {
+            let mut super_type_inner = None;
+
+            for dt in dts {
+                match dt {
+                    DataType::List(inner) => match super_type_inner {
+                        None => super_type_inner = Some(*inner.clone()),
+                        Some(st_inner) => {
+                            super_type_inner = Some(try_get_supertype(&st_inner, inner)?)
+                        }
+                    },
+                    dt => match super_type_inner {
+                        None => super_type_inner = Some((*dt).clone()),
+                        Some(st_inner) => {
+                            super_type_inner = Some(try_get_supertype(&st_inner, dt)?)
+                        }
+                    },
+                }
+            }
+            Ok(DataType::List(Box::new(super_type_inner.unwrap())))
+        })
+    }
+
+    /// Set the timezone of a datetime dtype.
+    #[cfg(feature = "timezones")]
+    pub(super) fn map_datetime_dtype_timezone(&self, tz: Option<&TimeZone>) -> PolarsResult<Field> {
+        self.try_map_dtype(|dt| {
+            if let DataType::Datetime(tu, _) = dt {
+                Ok(DataType::Datetime(*tu, tz.cloned()))
+            } else {
+                polars_bail!(op = "cast-timezone", got = dt, expected = "Datetime");
+            }
+        })
+    }
+}
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs`

 * *Files 5% similar despite different names*

```diff
@@ -60,14 +60,41 @@
     Strip(Option<String>),
     RStrip(Option<String>),
     LStrip(Option<String>),
     #[cfg(feature = "string_from_radix")]
     FromRadix(u32, bool),
 }
 
+impl StringFunction {
+    pub(super) fn get_field(&self, mapper: FieldsMapper) -> PolarsResult<Field> {
+        use StringFunction::*;
+        match self {
+            #[cfg(feature = "regex")]
+            Contains { .. } => mapper.with_dtype(DataType::Boolean),
+            EndsWith | StartsWith => mapper.with_dtype(DataType::Boolean),
+            Extract { .. } => mapper.with_same_dtype(),
+            ExtractAll => mapper.with_dtype(DataType::List(Box::new(DataType::Utf8))),
+            CountMatch(_) => mapper.with_dtype(DataType::UInt32),
+            #[cfg(feature = "string_justify")]
+            Zfill { .. } | LJust { .. } | RJust { .. } => mapper.with_same_dtype(),
+            #[cfg(feature = "temporal")]
+            Strptime(options) => mapper.with_dtype(options.date_dtype.clone()),
+            #[cfg(feature = "concat_str")]
+            ConcatVertical(_) | ConcatHorizontal(_) => mapper.with_dtype(DataType::Utf8),
+            #[cfg(feature = "regex")]
+            Replace { .. } => mapper.with_dtype(DataType::Utf8),
+            Uppercase | Lowercase | Strip(_) | LStrip(_) | RStrip(_) => {
+                mapper.with_dtype(DataType::Utf8)
+            }
+            #[cfg(feature = "string_from_radix")]
+            FromRadix { .. } => mapper.with_dtype(DataType::Int32),
+        }
+    }
+}
+
 impl Display for StringFunction {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use self::*;
         let s = match self {
             #[cfg(feature = "regex")]
             StringFunction::Contains { .. } => "contains",
             StringFunction::StartsWith { .. } => "starts_with",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs`

 * *Files 14% similar despite different names*

```diff
@@ -15,50 +15,38 @@
         DataType::Date => {
             let s = s
                 .cast(&DataType::Datetime(TimeUnit::Milliseconds, None))
                 .unwrap();
             date_offset(s, offset).and_then(|s| s.cast(&DataType::Date))
         }
         DataType::Datetime(tu, tz) => {
-            // drop series, so that we might modify in place
-            let mut ca = {
-                let me = std::mem::ManuallyDrop::new(s);
-                me.datetime().unwrap().clone()
-            };
+            let ca = s.datetime().unwrap();
 
             fn adder<T: PolarsTimeZone>(
                 tu: TimeUnit,
             ) -> fn(&Duration, i64, Option<&T>) -> PolarsResult<i64> {
                 match tu {
                     TimeUnit::Nanoseconds => Duration::add_ns,
                     TimeUnit::Microseconds => Duration::add_us,
                     TimeUnit::Milliseconds => Duration::add_ms,
                 }
             }
 
-            match tz {
+            let out = match tz {
                 #[cfg(feature = "timezones")]
-                Some(tz) => match tz.parse::<Tz>() {
-                    // TODO write `try_apply_mut` and use that instead of `apply_mut`,
-                    // then remove `unwrap`.
-                    Ok(tz) => {
-                        ca.0.apply_mut(|v| adder(tu)(&offset, v, Some(&tz)).unwrap())
-                    }
-                    Err(_) => match parse_offset(&tz) {
-                        Ok(tz) => {
-                            ca.0.apply_mut(|v| adder(tu)(&offset, v, Some(&tz)).unwrap())
-                        }
+                Some(ref tz) => match tz.parse::<Tz>() {
+                    Ok(tz) => ca.0.try_apply(|v| adder(tu)(&offset, v, Some(&tz))),
+                    Err(_) => match parse_offset(tz) {
+                        Ok(tz) => ca.0.try_apply(|v| adder(tu)(&offset, v, Some(&tz))),
                         Err(_) => unreachable!(),
                     },
                 },
-                _ => {
-                    ca.0.apply_mut(|v| adder(tu)(&offset, v, NO_TIMEZONE).unwrap())
-                }
-            };
-            Ok(ca.into_series())
+                _ => ca.0.try_apply(|v| adder(tu)(&offset, v, NO_TIMEZONE)),
+            }?;
+            out.cast(&DataType::Datetime(tu, tz))
         }
         dt => polars_bail!(
             ComputeError: "cannot use 'date_offset' on Series of datatype {}", dt,
         ),
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/functions.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/functions.rs`

 * *Files 11% similar despite different names*

```diff
@@ -445,26 +445,94 @@
             high,
             f,
             GetOutput::map_field(|_| Field::new("arange", DataType::List(DataType::Int64.into()))),
         )
     }
 }
 
-#[derive(Default)]
+macro_rules! impl_unit_setter {
+    ($fn_name:ident($field:ident)) => {
+        #[doc = concat!("Set the ", stringify!($field))]
+        pub fn $fn_name(mut self, n: Expr) -> Self {
+            self.$field = n.into();
+            self
+        }
+    };
+}
+
+/// Arguments used by [`datetime`] in order to produce an `Expr` of `Datetime`
+///
+/// Construct a `DatetimeArgs` with `DatetimeArgs::new(y, m, d)`. This will set the other time units to `lit(0)`. You
+/// can then set the other fields with the `with_*` methods, or use `with_hms` to set `hour`, `minute`, and `second` all
+/// at once.
+///
+/// # Examples
+/// ```
+/// // construct a DatetimeArgs set to July 20, 1969 at 20:17
+/// let args = DatetimeArgs::new(lit(1969), lit(7), lit(20)).with_hms(lit(20), lit(17), lit(0));
+/// // or
+/// let args = DatetimeArgs::new(lit(1969), lit(7), lit(20)).with_hour(lit(20)).with_minute(lit(17));
+///
+/// // construct a DatetimeArgs using existing columns
+/// let args = DatetimeArgs::new(lit(2023), col("month"), col("day"));
+/// ```
+#[derive(Debug, Clone)]
 pub struct DatetimeArgs {
     pub year: Expr,
     pub month: Expr,
     pub day: Expr,
-    pub hour: Option<Expr>,
-    pub minute: Option<Expr>,
-    pub second: Option<Expr>,
-    pub microsecond: Option<Expr>,
+    pub hour: Expr,
+    pub minute: Expr,
+    pub second: Expr,
+    pub microsecond: Expr,
 }
 
-/// Construct a column of `Datetime` from the provided args.
+impl DatetimeArgs {
+    /// Construct a new `DatetimeArgs` set to `year`, `month`, `day`
+    ///
+    /// Other fields default to `lit(0)`. Use the `with_*` methods to set them.
+    pub fn new(year: Expr, month: Expr, day: Expr) -> Self {
+        Self {
+            year,
+            month,
+            day,
+            hour: lit(0),
+            minute: lit(0),
+            second: lit(0),
+            microsecond: lit(0),
+        }
+    }
+
+    /// Set `hour`, `minute`, and `second`
+    ///
+    /// Equivalent to
+    /// ```ignore
+    /// self.with_hour(hour)
+    ///     .with_minute(minute)
+    ///     .with_second(second)
+    /// ```
+    pub fn with_hms(self, hour: Expr, minute: Expr, second: Expr) -> Self {
+        Self {
+            hour,
+            minute,
+            second,
+            ..self
+        }
+    }
+
+    impl_unit_setter!(with_year(year));
+    impl_unit_setter!(with_month(month));
+    impl_unit_setter!(with_day(day));
+    impl_unit_setter!(with_hour(hour));
+    impl_unit_setter!(with_minute(minute));
+    impl_unit_setter!(with_second(second));
+    impl_unit_setter!(with_microsecond(microsecond));
+}
+
+/// Construct a column of `Datetime` from the provided [`DatetimeArgs`].
 #[cfg(feature = "temporal")]
 pub fn datetime(args: DatetimeArgs) -> Expr {
     use polars_core::export::chrono::NaiveDate;
     use polars_core::utils::CustomIterTools;
 
     let year = args.year;
     let month = args.month;
@@ -539,48 +607,127 @@
 
         Ok(Some(
             ca.into_datetime(TimeUnit::Microseconds, None).into_series(),
         ))
     }) as Arc<dyn SeriesUdf>);
 
     Expr::AnonymousFunction {
-        input: vec![
-            year,
-            month,
-            day,
-            hour.unwrap_or_else(|| lit(0)),
-            minute.unwrap_or_else(|| lit(0)),
-            second.unwrap_or_else(|| lit(0)),
-            microsecond.unwrap_or_else(|| lit(0)),
-        ],
+        input: vec![year, month, day, hour, minute, second, microsecond],
         function,
         output_type: GetOutput::from_type(DataType::Datetime(TimeUnit::Microseconds, None)),
         options: FunctionOptions {
             collect_groups: ApplyOptions::ApplyFlat,
             input_wildcard_expansion: true,
             fmt_str: "datetime",
             ..Default::default()
         },
     }
     .alias("datetime")
 }
 
-#[derive(Default)]
+/// Arguments used by [`duration`] in order to produce an `Expr` of `Duration`
+///
+/// To construct a `DurationArgs`, use struct literal syntax with `..Default::default()` to leave unspecified fields at
+/// their default value of `lit(0)`, as demonstrated below.
+///
+/// ```
+/// let args = DurationArgs {
+///     days: lit(5),
+///     hours: col("num_hours"),
+///     minutes: col("num_minutes"),
+///     ..Default::default()  // other fields are lit(0)
+/// };
+/// ```
+/// If you prefer builder syntax, `with_*` methods are also available.
+/// ```
+/// let args = DurationArgs::new().with_weeks(lit(42)).with_hours(lit(84));
+/// ```
+#[derive(Debug, Clone)]
 pub struct DurationArgs {
-    pub days: Option<Expr>,
-    pub seconds: Option<Expr>,
-    pub nanoseconds: Option<Expr>,
-    pub microseconds: Option<Expr>,
-    pub milliseconds: Option<Expr>,
-    pub minutes: Option<Expr>,
-    pub hours: Option<Expr>,
-    pub weeks: Option<Expr>,
+    pub weeks: Expr,
+    pub days: Expr,
+    pub hours: Expr,
+    pub minutes: Expr,
+    pub seconds: Expr,
+    pub milliseconds: Expr,
+    pub microseconds: Expr,
+    pub nanoseconds: Expr,
+}
+
+impl Default for DurationArgs {
+    fn default() -> Self {
+        Self {
+            weeks: lit(0),
+            days: lit(0),
+            hours: lit(0),
+            minutes: lit(0),
+            seconds: lit(0),
+            milliseconds: lit(0),
+            microseconds: lit(0),
+            nanoseconds: lit(0),
+        }
+    }
+}
+
+impl DurationArgs {
+    /// Create a new `DurationArgs` with all fields set to `lit(0)`. Use the `with_*` methods to set the fields.
+    pub fn new() -> Self {
+        Self::default()
+    }
+
+    /// Set `hours`, `minutes`, and `seconds`
+    ///
+    /// Equivalent to
+    /// ```ignore
+    /// self.with_hours(hours)
+    ///     .with_minutes(minutes)
+    ///     .with_seconds(seconds)
+    /// ```.
+    pub fn with_hms(self, hours: Expr, minutes: Expr, seconds: Expr) -> Self {
+        Self {
+            hours,
+            minutes,
+            seconds,
+            ..self
+        }
+    }
+
+    /// Set `milliseconds`, `microseconds`, and `nanoseconds`
+    ///
+    /// Equivalent to
+    /// ```ignore
+    /// self.with_milliseconds(milliseconds)
+    ///     .with_microseconds(microseconds)
+    ///     .with_nanoseconds(nanoseconds)
+    /// ```
+    pub fn with_fractional_seconds(
+        self,
+        milliseconds: Expr,
+        microseconds: Expr,
+        nanoseconds: Expr,
+    ) -> Self {
+        Self {
+            milliseconds,
+            microseconds,
+            nanoseconds,
+            ..self
+        }
+    }
+
+    impl_unit_setter!(with_weeks(weeks));
+    impl_unit_setter!(with_days(days));
+    impl_unit_setter!(with_hours(hours));
+    impl_unit_setter!(with_minutes(minutes));
+    impl_unit_setter!(with_seconds(seconds));
+    impl_unit_setter!(with_milliseconds(milliseconds));
+    impl_unit_setter!(with_microseconds(microseconds));
+    impl_unit_setter!(with_nanoseconds(nanoseconds));
 }
 
-/// Construct a column of `Duration` from the provided args.
+/// Construct a column of `Duration` from the provided [`DurationArgs`]
 #[cfg(feature = "temporal")]
 pub fn duration(args: DurationArgs) -> Expr {
     let function = SpecialEq::new(Arc::new(move |s: &mut [Series]| {
         assert_eq!(s.len(), 8);
         let days = s[0].cast(&DataType::Int64).unwrap();
         let seconds = s[1].cast(&DataType::Int64).unwrap();
         let mut nanoseconds = s[2].cast(&DataType::Int64).unwrap();
@@ -625,22 +772,22 @@
         nanoseconds
             .cast(&DataType::Duration(TimeUnit::Nanoseconds))
             .map(Some)
     }) as Arc<dyn SeriesUdf>);
 
     Expr::AnonymousFunction {
         input: vec![
-            args.days.unwrap_or_else(|| lit(0i64)),
-            args.seconds.unwrap_or_else(|| lit(0i64)),
-            args.nanoseconds.unwrap_or_else(|| lit(0i64)),
-            args.microseconds.unwrap_or_else(|| lit(0i64)),
-            args.milliseconds.unwrap_or_else(|| lit(0i64)),
-            args.minutes.unwrap_or_else(|| lit(0i64)),
-            args.hours.unwrap_or_else(|| lit(0i64)),
-            args.weeks.unwrap_or_else(|| lit(0i64)),
+            args.days,
+            args.seconds,
+            args.nanoseconds,
+            args.microseconds,
+            args.milliseconds,
+            args.minutes,
+            args.hours,
+            args.weeks,
         ],
         function,
         output_type: GetOutput::from_type(DataType::Duration(TimeUnit::Nanoseconds)),
         options: FunctionOptions {
             collect_groups: ApplyOptions::ApplyFlat,
             input_wildcard_expansion: true,
             fmt_str: "duration",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/meta.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/meta.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/mod.rs`

 * *Files 6% similar despite different names*

```diff
@@ -36,14 +36,15 @@
 #[cfg(feature = "diff")]
 use polars_core::series::ops::NullBehavior;
 use polars_core::series::IsSorted;
 use polars_core::utils::{try_get_supertype, NoNull};
 #[cfg(feature = "rolling_window")]
 use polars_time::series::SeriesOpsTime;
 
+use crate::constants::MAP_LIST_NAME;
 pub use crate::logical_plan::lit;
 use crate::prelude::*;
 use crate::utils::has_expr;
 #[cfg(feature = "is_in")]
 use crate::utils::has_root_literal_expr;
 
 /// Compute `op(l, r)` (or equivalently `l op r`). `l` and `r` must have types compatible with the Operator.
@@ -361,16 +362,16 @@
 
     /// Get the last value in the group.
     pub fn last(self) -> Self {
         AggExpr::Last(Box::new(self)).into()
     }
 
     /// Aggregate the group to a Series
-    pub fn list(self) -> Self {
-        AggExpr::List(Box::new(self)).into()
+    pub fn implode(self) -> Self {
+        AggExpr::Implode(Box::new(self)).into()
     }
 
     /// Compute the quantile per group.
     pub fn quantile(self, quantile: Expr, interpol: QuantileInterpolOptions) -> Self {
         AggExpr::Quantile {
             expr: Box::new(self),
             quantile: Box::new(quantile),
@@ -716,15 +717,15 @@
 
         Expr::AnonymousFunction {
             input: vec![self],
             function: SpecialEq::new(Arc::new(f)),
             output_type,
             options: FunctionOptions {
                 collect_groups: ApplyOptions::ApplyList,
-                fmt_str: "map_list",
+                fmt_str: MAP_LIST_NAME,
                 ..Default::default()
             },
         }
     }
 
     /// A function that cannot be expressed with `map` or `apply` and requires extra settings.
     pub fn function_with_options<F>(
@@ -955,33 +956,27 @@
         )
         .with_fmt("forward_fill")
     }
 
     /// Round underlying floating point array to given decimal numbers.
     #[cfg(feature = "round_series")]
     pub fn round(self, decimals: u32) -> Self {
-        self.map(
-            move |s: Series| s.round(decimals).map(Some),
-            GetOutput::same_type(),
-        )
-        .with_fmt("round")
+        self.map_private(FunctionExpr::Round { decimals })
     }
 
     /// Floor underlying floating point array to the lowest integers smaller or equal to the float value.
     #[cfg(feature = "round_series")]
     pub fn floor(self) -> Self {
-        self.map(move |s: Series| s.floor().map(Some), GetOutput::same_type())
-            .with_fmt("floor")
+        self.map_private(FunctionExpr::Floor)
     }
 
     /// Ceil underlying floating point array to the highest integers smaller or equal to the float value.
     #[cfg(feature = "round_series")]
     pub fn ceil(self) -> Self {
-        self.map(move |s: Series| s.ceil().map(Some), GetOutput::same_type())
-            .with_fmt("ceil")
+        self.map_private(FunctionExpr::Ceil)
     }
 
     /// Clip underlying values to a set boundary.
     #[cfg(feature = "round_series")]
     pub fn clip(self, min: AnyValue<'_>, max: AnyValue<'_>) -> Self {
         self.map_private(FunctionExpr::Clip {
             min: Some(min.into_static().unwrap()),
@@ -1136,14 +1131,24 @@
     /// Get a mask of unique values
     #[allow(clippy::wrong_self_convention)]
     #[cfg(feature = "is_unique")]
     pub fn is_unique(self) -> Self {
         self.apply_private(BooleanFunction::IsUnique.into())
     }
 
+    /// Get the approximate count of unique values.
+    #[cfg(feature = "approx_unique")]
+    pub fn approx_unique(self) -> Self {
+        self.apply_private(FunctionExpr::ApproxUnique)
+            .with_function_options(|mut options| {
+                options.auto_explode = true;
+                options
+            })
+    }
+
     /// and operation
     pub fn and<E: Into<Expr>>(self, expr: E) -> Self {
         binary_expr(self, Operator::And, expr.into())
     }
 
     // xor operation
     pub fn xor<E: Into<Expr>>(self, expr: E) -> Self {
@@ -1651,74 +1656,20 @@
             options.auto_explode = true;
             options
         })
     }
 
     /// Get maximal value that could be hold by this dtype.
     pub fn upper_bound(self) -> Expr {
-        self.map(
-            |s| {
-                let name = s.name();
-                use DataType::*;
-                let s = match s.dtype().to_physical() {
-                    #[cfg(feature = "dtype-i8")]
-                    Int8 => Series::new(name, &[i8::MAX]),
-                    #[cfg(feature = "dtype-i16")]
-                    Int16 => Series::new(name, &[i16::MAX]),
-                    Int32 => Series::new(name, &[i32::MAX]),
-                    Int64 => Series::new(name, &[i64::MAX]),
-                    #[cfg(feature = "dtype-u8")]
-                    UInt8 => Series::new(name, &[u8::MAX]),
-                    #[cfg(feature = "dtype-u16")]
-                    UInt16 => Series::new(name, &[u16::MAX]),
-                    UInt32 => Series::new(name, &[u32::MAX]),
-                    UInt64 => Series::new(name, &[u64::MAX]),
-                    Float32 => Series::new(name, &[f32::INFINITY]),
-                    Float64 => Series::new(name, &[f64::INFINITY]),
-                    dt => polars_bail!(
-                        ComputeError: "cannot determine upper bound for dtype `{}`", dt,
-                    ),
-                };
-                Ok(Some(s))
-            },
-            GetOutput::same_type(),
-        )
-        .with_fmt("upper_bound")
+        self.map_private(FunctionExpr::UpperBound)
     }
 
     /// Get minimal value that could be hold by this dtype.
     pub fn lower_bound(self) -> Expr {
-        self.map(
-            |s| {
-                let name = s.name();
-                use DataType::*;
-                let s = match s.dtype().to_physical() {
-                    #[cfg(feature = "dtype-i8")]
-                    Int8 => Series::new(name, &[i8::MIN]),
-                    #[cfg(feature = "dtype-i16")]
-                    Int16 => Series::new(name, &[i16::MIN]),
-                    Int32 => Series::new(name, &[i32::MIN]),
-                    Int64 => Series::new(name, &[i64::MIN]),
-                    #[cfg(feature = "dtype-u8")]
-                    UInt8 => Series::new(name, &[u8::MIN]),
-                    #[cfg(feature = "dtype-u16")]
-                    UInt16 => Series::new(name, &[u16::MIN]),
-                    UInt32 => Series::new(name, &[u32::MIN]),
-                    UInt64 => Series::new(name, &[u64::MIN]),
-                    Float32 => Series::new(name, &[f32::NEG_INFINITY]),
-                    Float64 => Series::new(name, &[f64::NEG_INFINITY]),
-                    dt => polars_bail!(
-                        ComputeError: "cannot determine lower bound for dtype `{}`", dt,
-                    ),
-                };
-                Ok(Some(s))
-            },
-            GetOutput::same_type(),
-        )
-        .with_fmt("lower_bound")
+        self.map_private(FunctionExpr::LowerBound)
     }
 
     pub fn reshape(self, dims: &[i64]) -> Self {
         let dims = dims.to_vec();
         let output_type = if dims.len() == 1 {
             GetOutput::map_field(|fld| {
                 Field::new(
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/options.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/options.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/string.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/dsl/struct_.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/dsl/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/frame/opt_state.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/frame/opt_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -24,15 +24,15 @@
         propagate_nans: bool,
     },
     Median(Node),
     NUnique(Node),
     First(Node),
     Last(Node),
     Mean(Node),
-    List(Node),
+    Implode(Node),
     Quantile {
         expr: Node,
         quantile: Node,
         interpol: QuantileInterpolOptions,
     },
     Sum(Node),
     Count(Node),
@@ -231,15 +231,15 @@
             Min { input, .. } => Single(*input),
             Max { input, .. } => Single(*input),
             Median(input) => Single(*input),
             NUnique(input) => Single(*input),
             First(input) => Single(*input),
             Last(input) => Single(*input),
             Mean(input) => Single(*input),
-            List(input) => Single(*input),
+            Implode(input) => Single(*input),
             Quantile { expr, .. } => Single(*expr),
             Sum(input) => Single(*input),
             Count(input) => Single(*input),
             Std(input, _) => Single(*input),
             Var(input, _) => Single(*input),
             AggGroups(input) => Single(*input),
         }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs`

 * *Files 0% similar despite different names*

```diff
@@ -113,15 +113,15 @@
                     }
                     Mean(expr) => {
                         let mut field =
                             arena.get(*expr).to_field(schema, Context::Default, arena)?;
                         float_type(&mut field);
                         Ok(field)
                     }
-                    List(expr) => {
+                    Implode(expr) => {
                         // default context because `col()` would return a list in aggregation context
                         let mut field =
                             arena.get(*expr).to_field(schema, Context::Default, arena)?;
                         field.coerce(DataType::List(field.data_type().clone().into()));
                         Ok(field)
                     }
                     Std(expr, _) => {
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/alp.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/alp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/apply.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/builder.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/conversion.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/conversion.rs`

 * *Files 0% similar despite different names*

```diff
@@ -69,15 +69,15 @@
                     propagate_nans,
                 },
                 AggExpr::Median(expr) => AAggExpr::Median(to_aexpr(*expr, arena)),
                 AggExpr::NUnique(expr) => AAggExpr::NUnique(to_aexpr(*expr, arena)),
                 AggExpr::First(expr) => AAggExpr::First(to_aexpr(*expr, arena)),
                 AggExpr::Last(expr) => AAggExpr::Last(to_aexpr(*expr, arena)),
                 AggExpr::Mean(expr) => AAggExpr::Mean(to_aexpr(*expr, arena)),
-                AggExpr::List(expr) => AAggExpr::List(to_aexpr(*expr, arena)),
+                AggExpr::Implode(expr) => AAggExpr::Implode(to_aexpr(*expr, arena)),
                 AggExpr::Count(expr) => AAggExpr::Count(to_aexpr(*expr, arena)),
                 AggExpr::Quantile {
                     expr,
                     quantile,
                     interpol,
                 } => AAggExpr::Quantile {
                     expr: to_aexpr(*expr, arena),
@@ -519,17 +519,17 @@
                 let exp = node_to_expr(expr, expr_arena);
                 AggExpr::Last(Box::new(exp)).into()
             }
             AAggExpr::Mean(expr) => {
                 let exp = node_to_expr(expr, expr_arena);
                 AggExpr::Mean(Box::new(exp)).into()
             }
-            AAggExpr::List(expr) => {
+            AAggExpr::Implode(expr) => {
                 let exp = node_to_expr(expr, expr_arena);
-                AggExpr::List(Box::new(exp)).into()
+                AggExpr::Implode(Box::new(exp)).into()
             }
             AAggExpr::Quantile {
                 expr,
                 quantile,
                 interpol,
             } => {
                 let expr = node_to_expr(expr, expr_arena);
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/format.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/format.rs`

 * *Files 1% similar despite different names*

```diff
@@ -339,15 +339,15 @@
                             write!(f, "{input:?}.max()")
                         }
                     }
                     Median(expr) => write!(f, "{expr:?}.median()"),
                     Mean(expr) => write!(f, "{expr:?}.mean()"),
                     First(expr) => write!(f, "{expr:?}.first()"),
                     Last(expr) => write!(f, "{expr:?}.last()"),
-                    List(expr) => write!(f, "{expr:?}.list()"),
+                    Implode(expr) => write!(f, "{expr:?}.list()"),
                     NUnique(expr) => write!(f, "{expr:?}.n_unique()"),
                     Sum(expr) => write!(f, "{expr:?}.sum()"),
                     AggGroups(expr) => write!(f, "{expr:?}.groups()"),
                     Count(expr) => write!(f, "{expr:?}.count()"),
                     Var(expr, _) => write!(f, "{expr:?}.var()"),
                     Std(expr, _) => write!(f, "{expr:?}.var()"),
                     Quantile { expr, .. } => write!(f, "{expr:?}.quantile()"),
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/iterator.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/iterator.rs`

 * *Files 1% similar despite different names*

```diff
@@ -34,15 +34,15 @@
                     Max { input, .. } => $push(input),
                     Min { input, .. } => $push(input),
                     Mean(e) => $push(e),
                     Median(e) => $push(e),
                     NUnique(e) => $push(e),
                     First(e) => $push(e),
                     Last(e) => $push(e),
-                    List(e) => $push(e),
+                    Implode(e) => $push(e),
                     Count(e) => $push(e),
                     Quantile { expr, .. } => $push(expr),
                     Sum(e) => $push(e),
                     AggGroups(e) => $push(e),
                     Std(e, _) => $push(e),
                     Var(e, _) => $push(e),
                 }
@@ -196,15 +196,15 @@
                     Max { input, .. } => push(input),
                     Min { input, .. } => push(input),
                     Mean(e) => push(e),
                     Median(e) => push(e),
                     NUnique(e) => push(e),
                     First(e) => push(e),
                     Last(e) => push(e),
-                    List(e) => push(e),
+                    Implode(e) => push(e),
                     Count(e) => push(e),
                     Quantile { expr, .. } => push(expr),
                     Sum(e) => push(e),
                     AggGroups(e) => push(e),
                     Std(e, _) => push(e),
                     Var(e, _) => push(e),
                 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/lit.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/lit.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/options.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/options.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/projection.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/logical_plan/schema.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/logical_plan/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/prelude.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-plan/src/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/Cargo.toml`

 * *Files 16% similar despite different names*

```diff
@@ -12,17 +12,17 @@
 polars-error = { version = "0.28.0", path = "../polars-error" }
 polars-utils = { version = "0.28.0", path = "../polars-utils" }
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-core/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encode.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encodings/fixed.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encodings/fixed.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/encodings/variable.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/encodings/variable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/lib.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/row.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/row.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-row/src/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-row/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/Cargo.toml` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/Cargo.toml`

 * *Files 7% similar despite different names*

```diff
@@ -29,17 +29,17 @@
 timezones = ["chrono-tz", "chrono"]
 simd = []
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
-# rev = "f258a3e06ac408aebe7a7a497694729dc65a5e46"
+rev = "11933119612e072a6eefaa65abec8c16241073c6"
 # path = "../arrow2"
-branch = "polars_2023-04-05"
+# branch = "polars_2023-04-05"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/LICENSE` & `polars_lts_cpu-0.17.3/local_dependencies/polars-plan/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/default_arrays.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/default_arrays.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/get.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/get.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/list.rs`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-use arrow::array::{Array, ListArray};
+use arrow::array::{Array, ListArray, NullArray};
 use arrow::bitmap::MutableBitmap;
 use arrow::compute::concatenate;
 use arrow::datatypes::DataType;
 use arrow::error::Result;
 use arrow::offset::Offsets;
 
 use crate::prelude::*;
@@ -87,22 +87,28 @@
     fn update_validity(&mut self) {
         if let Some(validity) = &mut self.validity {
             validity.push(true)
         }
     }
 
     pub fn finish(self, inner_dtype: Option<&DataType>) -> Result<ListArray<i64>> {
-        let inner_dtype = inner_dtype.unwrap_or_else(|| self.arrays[0].data_type());
-        let values = concatenate::concatenate(&self.arrays)?;
-        let dtype = ListArray::<i64>::default_datatype(inner_dtype.clone());
         // Safety:
         // offsets are monotonically increasing
-        unsafe {
-            Ok(ListArray::<i64>::new(
-                dtype,
-                Offsets::new_unchecked(self.offsets).into(),
-                values,
-                self.validity.map(|validity| validity.into()),
-            ))
-        }
+        let offsets = unsafe { Offsets::new_unchecked(self.offsets) };
+        let (inner_dtype, values) = if self.arrays.is_empty() {
+            let len = *offsets.last() as usize;
+            let values = NullArray::new(DataType::Null, len).boxed();
+            (DataType::Null, values)
+        } else {
+            let inner_dtype = inner_dtype.unwrap_or_else(|| self.arrays[0].data_type());
+            let values = concatenate::concatenate(&self.arrays)?;
+            (inner_dtype.clone(), values)
+        };
+        let dtype = ListArray::<i64>::default_datatype(inner_dtype);
+        Ok(ListArray::<i64>::new(
+            dtype,
+            offsets.into(),
+            values,
+            self.validity.map(|validity| validity.into()),
+        ))
     }
 }
```

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/null.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/array/utf8.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/array/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/bit_util.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/bit_util.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/bitmap/mutable.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/bitmap/mutable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/compute/take/boolean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/compute/take/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/compute/take/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/compute/take/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/conversion.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/conversion.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/data_types.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/data_types.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/floats/ord.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/floats/ord.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/index.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/index.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/is_valid.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/is_valid.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/agg_mean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/agg_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/concatenate.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/concatenate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/ewm/average.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/ewm/average.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/float.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/float.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/list.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/rolling/window.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/rolling/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/set.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sort_partition.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sort_partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/string.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/kernels/take_agg.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/kernels/take_agg.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/slice.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/time_zone.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/time_zone.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/boolean.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/mod.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/local_dependencies/polars-arrow/src/utils.rs` & `polars_lts_cpu-0.17.3/local_dependencies/polars-arrow/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/Cargo.toml` & `polars_lts_cpu-0.17.3/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 [package]
 name = "py-polars"
-version = "0.17.2"
+version = "0.17.3"
 edition = "2021"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [workspace]
 # prevents package from thinking it's in the workspace
 [target.'cfg(any(not(target_os = "linux"), use_mimalloc))'.dependencies]
 mimalloc = { version = "*", default-features = false }
 
 [target.'cfg(all(target_os = "linux", not(use_mimalloc)))'.dependencies]
 jemallocator = { version = "0.5", features = ["disable_initial_exec_tls"] }
 
 [dependencies]
 ahash = "0.8"
-bincode = "1.3"
+ciborium = "0.2.0"
 lexical-core = "0.8"
 # todo: unfix when compilation problem is solved
 libc = "0.2"
 ndarray = "0.15"
 numpy = "0.18"
 once_cell = "1"
 polars-algo = { path = "local_dependencies/polars-algo", default-features = false }
@@ -160,14 +160,15 @@
   "cumulative_eval",
   "list_to_struct",
   "to_dummies",
   "string_justify",
   "string_from_radix",
   "arg_where",
   "date_offset",
+  "approx_unique",
 ]
 
 [lib]
 name = "polars"
 crate-type = ["cdylib"]
 
 [profile.release]
```

### Comparing `polars_lts_cpu-0.17.2/LICENSE` & `polars_lts_cpu-0.17.3/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/Makefile` & `polars_lts_cpu-0.17.3/Makefile`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/README.md` & `polars_lts_cpu-0.17.3/README.md`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/build.rs` & `polars_lts_cpu-0.17.3/build.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/Makefile` & `polars_lts_cpu-0.17.3/docs/Makefile`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/_templates/autosummary/class.rst` & `polars_lts_cpu-0.17.3/docs/_templates/autosummary/class.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/_static/css/custom.css` & `polars_lts_cpu-0.17.3/docs/source/_static/css/custom.css`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/conf.py` & `polars_lts_cpu-0.17.3/docs/source/conf.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/api.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/api.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/config.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/config.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/dataframe/modify_select.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/dataframe/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/datatypes.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/datatypes.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/computation.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/computation.rst`

 * *Files 10% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 ===========
 
 .. currentmodule:: polars
 .. autosummary::
    :toctree: api/
 
     Expr.abs
+    Expr.approx_unique
     Expr.arccos
     Expr.arccosh
     Expr.arcsin
     Expr.arcsinh
     Expr.arctan
     Expr.arctanh
     Expr.arg_unique
```

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/functions.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/functions.rst`

 * *Files 9% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 .. currentmodule:: polars
 .. autosummary::
    :toctree: api/
 
    all
    any
    apply
+   approx_unique
    arange
    arg_sort_by
    avg
    coalesce
    concat_list
    concat_str
    corr
@@ -64,20 +65,21 @@
 
 .. autosummary::
    :toctree: api/
 
    Expr.all
    Expr.any
    Expr.apply
+   Expr.approx_unique
    Expr.count
    Expr.cumsum
    Expr.exclude
    Expr.first
    Expr.head
-   Expr.list
+   Expr.implode
    Expr.map
    Expr.max
    Expr.mean
    Expr.median
    Expr.min
    Expr.n_unique
    Expr.quantile
```

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/list.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/list.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/modify_select.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/operators.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/operators.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/string.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/string.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/expressions/temporal.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/expressions/temporal.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/functions.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/functions.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/io.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/io.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/lazyframe/modify_select.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/lazyframe/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/series/computation.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/series/computation.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/series/descriptive.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/series/descriptive.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/series/list.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/series/list.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/series/modify_select.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/series/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/series/string.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/series/string.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/series/temporal.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/series/temporal.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/docs/source/reference/testing.rst` & `polars_lts_cpu-0.17.3/docs/source/reference/testing.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/__init__.py` & `polars_lts_cpu-0.17.3/polars/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,17 @@
+import contextlib
 import os
 
+with contextlib.suppress(ImportError):  # Module not available when building docs
+    # ensure the object constructor is known by polars
+    # we set this once on import
+    from polars.polars import register_object_builder
+
+    register_object_builder()
+
 from polars import api
 from polars.config import Config
 from polars.convert import (
     from_arrow,
     from_dataframe,
     from_dict,
     from_dicts,
@@ -70,14 +78,15 @@
     ones,
     zeros,
 )
 from polars.functions.lazy import (
     all,
     any,
     apply,
+    approx_unique,
     arange,
     arg_sort_by,
     arg_where,
     avg,
     coalesce,
     col,
     collect_all,
@@ -94,14 +103,15 @@
     exclude,
     first,
     fold,
     format,
     from_epoch,
     groups,
     head,
+    implode,
     last,
     lit,
     map,
     max,
     mean,
     median,
     min,
@@ -290,23 +300,25 @@
     "exclude",
     "first",
     "fold",
     "format",
     "from_epoch",
     "groups",
     "head",
+    "implode",
     "last",
     "list",  # named list_, see import above
     "lit",
     "map",
     "max",
     "mean",
     "median",
     "min",
     "n_unique",
+    "approx_unique",
     "pearson_corr",
     "quantile",
     "reduce",
     "select",
     "spearman_rank_corr",
     "std",
     "struct",
```

### Comparing `polars_lts_cpu-0.17.2/polars/api.py` & `polars_lts_cpu-0.17.3/polars/api.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/config.py` & `polars_lts_cpu-0.17.3/polars/config.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/convert.py` & `polars_lts_cpu-0.17.3/polars/convert.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/dataframe/_html.py` & `polars_lts_cpu-0.17.3/polars/dataframe/_html.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/dataframe/frame.py` & `polars_lts_cpu-0.17.3/polars/dataframe/frame.py`

 * *Files 0% similar despite different names*

```diff
@@ -3583,18 +3583,26 @@
 
         if not return_as_string:
             print(s, end=None)
             return None
         else:
             return s
 
-    def describe(self) -> Self:
+    def describe(
+        self, percentiles: Sequence[float] | float | None = (0.25, 0.75)
+    ) -> Self:
         """
         Summary statistics for a DataFrame.
 
+        Parameters
+        ----------
+        percentiles
+            One or more percentiles to include in the summary statistics.
+            All values must be in the range `[0, 1]`.
+
         See Also
         --------
         glimpse
 
         Examples
         --------
         >>> from datetime import date
@@ -3605,64 +3613,68 @@
         ...         "c": [True, False, True],
         ...         "d": [None, "b", "c"],
         ...         "e": ["usd", "eur", None],
         ...         "f": [date(2020, 1, 1), date(2021, 1, 1), date(2022, 1, 1)],
         ...     }
         ... )
         >>> df.describe()
-        shape: (7, 7)
+        shape: (9, 7)
         
          describe    a         b         c         d     e     f          
          ---         ---       ---       ---       ---   ---   ---        
          str         f64       f64       f64       str   str   str        
         
          count       3.0       3.0       3.0       3     3     3          
          null_count  0.0       1.0       0.0       1     1     0          
          mean        2.266667  4.5       0.666667  null  null  null       
          std         1.101514  0.707107  0.57735   null  null  null       
          min         1.0       4.0       0.0       b     eur   2020-01-01 
          max         3.0       5.0       1.0       c     usd   2022-01-01 
          median      2.8       4.5       1.0       null  null  null       
+         25%         1.0       4.0       null      null  null  null       
+         75%         3.0       5.0       null      null  null  null       
         
 
         """
+        if isinstance(percentiles, float):
+            percentiles = [percentiles]
+        if percentiles and not all((0 <= p <= 1) for p in percentiles):
+            raise ValueError("Percentiles must all be in the range [0, 1].")
 
         def describe_cast(stat: Self) -> Self:
             columns = []
             for i, s in enumerate(self.columns):
                 if self[s].is_numeric() or self[s].is_boolean():
                     columns.append(stat[:, i].cast(float))
                 else:
                     # for dates, strings, etc, we cast to string so that all
                     # statistics can be shown
                     columns.append(stat[:, i].cast(str))
             return self.__class__(columns)
 
-        summary = self._from_pydf(
-            F.concat(
-                [
-                    describe_cast(
-                        self.__class__({c: [len(self)] for c in self.columns})
-                    ),
-                    describe_cast(self.null_count()),
-                    describe_cast(self.mean()),
-                    describe_cast(self.std()),
-                    describe_cast(self.min()),
-                    describe_cast(self.max()),
-                    describe_cast(self.median()),
-                ]
-            )._df
-        )
-        summary.insert_at_idx(
-            0,
-            pli.Series(
-                "describe",
-                ["count", "null_count", "mean", "std", "min", "max", "median"],
-            ),
-        )
+        # Build output rows
+        output_rows = [
+            describe_cast(self.__class__({c: [len(self)] for c in self.columns})),
+            describe_cast(self.null_count()),
+            describe_cast(self.mean()),
+            describe_cast(self.std()),
+            describe_cast(self.min()),
+            describe_cast(self.max()),
+            describe_cast(self.median()),
+        ]
+        row_identifiers = ["count", "null_count", "mean", "std", "min", "max", "median"]
+
+        # Dynamically add rows for quantiles
+        for p in percentiles or ():
+            output_rows.append(describe_cast(self.quantile(p)))
+            row_identifiers.append(f"{p:.0%}")
+
+        # Build summary dataframe
+        summary = self._from_pydf(F.concat(output_rows)._df)
+        summary.insert_at_idx(0, pli.Series("describe", row_identifiers))
         return summary
 
     def find_idx_by_name(self, name: str) -> int:
         """
         Find the index of a column by name.
 
         Parameters
@@ -6075,14 +6087,38 @@
          ---  ---  ---  --- 
          str  i64  i64  i64 
         
          one  1    2    3   
          two  4    5    6   
         
 
+        Run an expression as aggregation function
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "col1": ["a", "a", "a", "b", "b", "b"],
+        ...         "col2": ["x", "x", "x", "x", "y", "y"],
+        ...         "col3": [6, 7, 3, 2, 5, 7],
+        ...     }
+        ... )
+        >>> df.pivot(
+        ...     index="col1",
+        ...     columns="col2",
+        ...     values="col3",
+        ...     aggregate_function=pl.element().tanh().mean(),
+        ... )
+        shape: (2, 3)
+        
+         col1  x         y        
+         ---   ---       ---      
+         str   f64       f64      
+        
+         a     0.998347  null     
+         b     0.964028  0.999954 
+        
+
         """  # noqa: W505
         if isinstance(values, str):
             values = [values]
         if isinstance(index, str):
             index = [index]
         if isinstance(columns, str):
             columns = [columns]
@@ -6246,15 +6282,15 @@
          ---   ---  
          str   i64  
         
          A     0    
          B     1    
          C     2    
          D     3    
-                  
+         E     4    
          F     5    
          G     6    
          H     7    
          I     8    
         
         >>> df.unstack(step=3, how="vertical")
         shape: (3, 6)
```

### Comparing `polars_lts_cpu-0.17.2/polars/dataframe/groupby.py` & `polars_lts_cpu-0.17.3/polars/dataframe/groupby.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/datatypes/__init__.py` & `polars_lts_cpu-0.17.3/polars/datatypes/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -35,24 +35,25 @@
     DATETIME_DTYPES,
     DTYPE_TEMPORAL_UNITS,
     DURATION_DTYPES,
     FLOAT_DTYPES,
     INTEGER_DTYPES,
     N_INFER_DEFAULT,
     NUMERIC_DTYPES,
+    SIGNED_INTEGER_DTYPES,
     TEMPORAL_DTYPES,
+    UNSIGNED_INTEGER_DTYPES,
 )
 from polars.datatypes.constructor import (
     numpy_type_to_constructor,
     numpy_values_and_dtype,
     polars_type_to_constructor,
     py_type_to_constructor,
 )
 from polars.datatypes.convert import (
-    dtype_to_arrow_type,
     dtype_to_ctype,
     dtype_to_ffiname,
     dtype_to_py_type,
     is_polars_dtype,
     maybe_cast,
     numpy_char_code_to_dtype,
     py_type_to_arrow_type,
@@ -103,34 +104,35 @@
     "Utf8",
     # constants
     "DATETIME_DTYPES",
     "DTYPE_TEMPORAL_UNITS",
     "DURATION_DTYPES",
     "FLOAT_DTYPES",
     "INTEGER_DTYPES",
-    "N_INFER_DEFAULT",
     "NUMERIC_DTYPES",
+    "N_INFER_DEFAULT",
+    "SIGNED_INTEGER_DTYPES",
     "TEMPORAL_DTYPES",
+    "UNSIGNED_INTEGER_DTYPES",
     # constructor
     "numpy_type_to_constructor",
     "numpy_values_and_dtype",
     "polars_type_to_constructor",
     "py_type_to_constructor",
     # convert
-    "dtype_to_arrow_type",
     "dtype_to_ctype",
     "dtype_to_ffiname",
     "dtype_to_py_type",
     "is_polars_dtype",
     "maybe_cast",
     "numpy_char_code_to_dtype",
     "py_type_to_arrow_type",
     "py_type_to_dtype",
     "supported_numpy_char_code",
     # type_aliases
     "OneOrMoreDataTypes",
     "PolarsDataType",
     "PolarsTemporalType",
     "PythonDataType",
-    "SchemaDict",
     "SchemaDefinition",
+    "SchemaDict",
 ]
```

### Comparing `polars_lts_cpu-0.17.2/polars/datatypes/classes.py` & `polars_lts_cpu-0.17.3/polars/datatypes/classes.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/datatypes/constants.py` & `polars_lts_cpu-0.17.3/polars/datatypes/constants.py`

 * *Files 10% similar despite different names*

```diff
@@ -38,26 +38,33 @@
         Duration("us"),
         Duration("ns"),
     ]
 )
 TEMPORAL_DTYPES: frozenset[PolarsDataType] = (
     frozenset([Date, Time]) | DATETIME_DTYPES | DURATION_DTYPES
 )
-INTEGER_DTYPES: frozenset[PolarsDataType] = frozenset(
+SIGNED_INTEGER_DTYPES: frozenset[PolarsDataType] = frozenset(
     [
-        UInt8,
-        UInt16,
-        UInt32,
-        UInt64,
         Int8,
         Int16,
         Int32,
         Int64,
     ]
 )
+UNSIGNED_INTEGER_DTYPES: frozenset[PolarsDataType] = frozenset(
+    [
+        UInt8,
+        UInt16,
+        UInt32,
+        UInt64,
+    ]
+)
+INTEGER_DTYPES: frozenset[PolarsDataType] = (
+    SIGNED_INTEGER_DTYPES | UNSIGNED_INTEGER_DTYPES
+)
 FLOAT_DTYPES: frozenset[PolarsDataType] = frozenset([Float32, Float64])
 NUMERIC_DTYPES: frozenset[PolarsDataType] = (
     FLOAT_DTYPES | INTEGER_DTYPES | frozenset([Decimal])
 )
 
 # number of rows to scan by default when inferring datatypes
 N_INFER_DEFAULT = 100
```

### Comparing `polars_lts_cpu-0.17.2/polars/datatypes/constructor.py` & `polars_lts_cpu-0.17.3/polars/datatypes/constructor.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/datatypes/convert.py` & `polars_lts_cpu-0.17.3/polars/datatypes/convert.py`

 * *Files 4% similar despite different names*

```diff
@@ -256,43 +256,14 @@
             datetime: pa.timestamp("us"),
             timedelta: pa.duration("us"),
             None.__class__: pa.null(),
         }
 
     @property
     @cache
-    def DTYPE_TO_ARROW_TYPE(self) -> dict[PolarsDataType, pa.lib.DataType]:
-        return {
-            Int8: pa.int8(),
-            Int16: pa.int16(),
-            Int32: pa.int32(),
-            Int64: pa.int64(),
-            UInt8: pa.uint8(),
-            UInt16: pa.uint16(),
-            UInt32: pa.uint32(),
-            UInt64: pa.uint64(),
-            Float32: pa.float32(),
-            Float64: pa.float64(),
-            Boolean: pa.bool_(),
-            Utf8: pa.large_utf8(),
-            Date: pa.date32(),
-            Datetime: pa.timestamp("us"),
-            Datetime("ms"): pa.timestamp("ms"),
-            Datetime("us"): pa.timestamp("us"),
-            Datetime("ns"): pa.timestamp("ns"),
-            Duration: pa.duration("us"),
-            Duration("ms"): pa.duration("ms"),
-            Duration("us"): pa.duration("us"),
-            Duration("ns"): pa.duration("ns"),
-            Time: pa.time64("us"),
-            Null: pa.null(),
-        }
-
-    @property
-    @cache
     def REPR_TO_DTYPE(self) -> dict[str, PolarsDataType]:
         def _dtype_str_repr_safe(o: Any) -> PolarsDataType | None:
             try:
                 return _dtype_str_repr(o.base_type()).split("[")[0]
             except ValueError:
                 return None
 
@@ -398,33 +369,14 @@
         return DataTypeMappings.PY_TYPE_TO_ARROW_TYPE[dtype]
     except KeyError:  # pragma: no cover
         raise ValueError(
             f"Cannot parse Python data type {dtype} into Arrow data type."
         ) from None
 
 
-def dtype_to_arrow_type(dtype: PolarsDataType) -> pa.lib.DataType:
-    """Convert a Polars dtype to an Arrow dtype."""
-    try:
-        # special handling for mapping to tz-aware timestamp type.
-        # (don't want to include every possible tz string in the lookup)
-        time_zone = None
-        if dtype == Datetime:
-            dtype, time_zone = Datetime(dtype.time_unit), dtype.time_zone  # type: ignore[union-attr]
-
-        arrow_type = DataTypeMappings.DTYPE_TO_ARROW_TYPE[dtype]
-        if time_zone:
-            arrow_type = pa.timestamp(dtype.time_unit or "us", time_zone)  # type: ignore[union-attr]
-        return arrow_type
-    except KeyError:  # pragma: no cover
-        raise ValueError(
-            f"Cannot parse data type {dtype} into Arrow data type."
-        ) from None
-
-
 def dtype_short_repr_to_dtype(dtype_string: str | None) -> PolarsDataType | None:
     """Map a PolarsDataType short repr (eg: 'i64', 'list[str]') back into a dtype."""
     if dtype_string is None:
         return None
     m = re.match(r"^(\w+)(?:\[(.+)\])?$", dtype_string)
     if m is None:
         return None
```

### Comparing `polars_lts_cpu-0.17.2/polars/dependencies.py` & `polars_lts_cpu-0.17.3/polars/dependencies.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,21 +4,22 @@
 import sys
 from functools import lru_cache
 from importlib import import_module
 from importlib.util import find_spec
 from types import ModuleType
 from typing import TYPE_CHECKING, Any, Hashable, cast
 
+_DELTALAKE_AVAILABLE = True
 _FSSPEC_AVAILABLE = True
+_HYPOTHESIS_AVAILABLE = True
 _NUMPY_AVAILABLE = True
 _PANDAS_AVAILABLE = True
 _PYARROW_AVAILABLE = True
+_PYDANTIC_AVAILABLE = True
 _ZONEINFO_AVAILABLE = True
-_HYPOTHESIS_AVAILABLE = True
-_DELTALAKE_AVAILABLE = True
 
 
 class _LazyModule(ModuleType):
     """
     Module that can act both as a lazy-loader and as a proxy.
 
     Notes
@@ -150,34 +151,36 @@
 
     import deltalake
     import fsspec
     import hypothesis
     import numpy
     import pandas
     import pyarrow
+    import pydantic
 
     if sys.version_info >= (3, 9):
         import zoneinfo
     else:
         from backports import zoneinfo
 else:
     # infrequently-used builtins
     dataclasses, _ = _lazy_import("dataclasses")
     html, _ = _lazy_import("html")
     json, _ = _lazy_import("json")
     pickle, _ = _lazy_import("pickle")
     subprocess, _ = _lazy_import("subprocess")
 
-    # heavy third party libs
+    # heavy/optional third party libs
     deltalake, _DELTALAKE_AVAILABLE = _lazy_import("deltalake")
     fsspec, _FSSPEC_AVAILABLE = _lazy_import("fsspec")
     hypothesis, _HYPOTHESIS_AVAILABLE = _lazy_import("hypothesis")
     numpy, _NUMPY_AVAILABLE = _lazy_import("numpy")
     pandas, _PANDAS_AVAILABLE = _lazy_import("pandas")
     pyarrow, _PYARROW_AVAILABLE = _lazy_import("pyarrow")
+    pydantic, _PYDANTIC_AVAILABLE = _lazy_import("pydantic")
     zoneinfo, _ZONEINFO_AVAILABLE = (
         _lazy_import("zoneinfo")
         if sys.version_info >= (3, 9)
         else _lazy_import("backports.zoneinfo")
     )
 
 
@@ -199,32 +202,38 @@
     return _PANDAS_AVAILABLE and _might_be(cast(Hashable, type(obj)), "pandas")
 
 
 def _check_for_pyarrow(obj: Any) -> bool:
     return _PYARROW_AVAILABLE and _might_be(cast(Hashable, type(obj)), "pyarrow")
 
 
+def _check_for_pydantic(obj: Any) -> bool:
+    return _PYDANTIC_AVAILABLE and _might_be(cast(Hashable, type(obj)), "pydantic")
+
+
 __all__ = [
     # lazy-load rarely-used/heavy builtins (for fast startup)
     "dataclasses",
     "html",
     "json",
     "pickle",
     "subprocess",
     # lazy-load third party libs
     "deltalake",
     "fsspec",
     "numpy",
     "pandas",
+    "pydantic",
     "pyarrow",
     "zoneinfo",
     # lazy utilities
     "_check_for_numpy",
     "_check_for_pandas",
     "_check_for_pyarrow",
+    "_check_for_pydantic",
     "_LazyModule",
     # exported flags/guards
     "_DELTALAKE_AVAILABLE",
     "_FSSPEC_AVAILABLE",
     "_HYPOTHESIS_AVAILABLE",
     "_NUMPY_AVAILABLE",
     "_PANDAS_AVAILABLE",
```

### Comparing `polars_lts_cpu-0.17.2/polars/exceptions.py` & `polars_lts_cpu-0.17.3/polars/exceptions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/expr/binary.py` & `polars_lts_cpu-0.17.3/polars/expr/binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/expr/categorical.py` & `polars_lts_cpu-0.17.3/polars/expr/categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/expr/datetime.py` & `polars_lts_cpu-0.17.3/polars/expr/datetime.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 
 from polars import functions as F
 from polars import internals as pli
 from polars.datatypes import DTYPE_TEMPORAL_UNITS, Date, Int32
 from polars.utils._parse_expr_input import expr_to_lit_or_expr
 from polars.utils._wrap import wrap_expr
 from polars.utils.convert import _timedelta_to_pl_duration
+from polars.utils.decorators import deprecated_alias
 
 if TYPE_CHECKING:
     from datetime import timedelta
 
     from polars.expr import Expr
     from polars.type_aliases import EpochTimeUnit, TimeUnit
 
@@ -316,20 +317,25 @@
         if not isinstance(time, (dt.time, pli.Expr)):
             raise TypeError(
                 f"expected 'time' to be a python time or polars expression, found {time!r}"
             )
         time = expr_to_lit_or_expr(time)
         return wrap_expr(self._pyexpr.dt_combine(time._pyexpr, time_unit))
 
-    def strftime(self, fmt: str) -> Expr:
+    @deprecated_alias(fmt="format")
+    def strftime(self, format: str) -> Expr:
         """
         Format Date/Datetime with a formatting rule.
 
-        See `chrono strftime/strptime
-        <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_.
+        Parameters
+        ----------
+        format
+            Format to use, refer to the `chrono strftime documentation
+            <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_
+            for specification. Example: ``"%y-%m-%d"``.
 
         Examples
         --------
         >>> from datetime import timedelta, datetime
         >>> df = pl.DataFrame(
         ...     {
         ...         "date": pl.date_range(
@@ -353,15 +359,15 @@
         
          2020-03-01 00:00:00  2020/03/01 00:00:00 
          2020-04-01 00:00:00  2020/04/01 00:00:00 
          2020-05-01 00:00:00  2020/05/01 00:00:00 
         
 
         """
-        return wrap_expr(self._pyexpr.strftime(fmt))
+        return wrap_expr(self._pyexpr.strftime(format))
 
     def year(self) -> Expr:
         """
         Extract year from underlying Date representation.
 
         Applies to Date and Datetime columns.
 
@@ -1254,25 +1260,31 @@
          2020-03-01 00:00:00 UTC  2020-03-01 00:00:00 GMT     
          2020-04-01 00:00:00 UTC  2020-04-01 01:00:00 BST     
          2020-05-01 00:00:00 UTC  2020-05-01 01:00:00 BST     
         
         """
         return wrap_expr(self._pyexpr.dt_convert_time_zone(time_zone))
 
-    def replace_time_zone(self, time_zone: str | None) -> Expr:
+    def replace_time_zone(
+        self, time_zone: str | None, *, use_earliest: bool | None = None
+    ) -> Expr:
         """
         Replace time zone for a Series of type Datetime.
 
         Different from ``convert_time_zone``, this will also modify
         the underlying timestamp and will ignore the original time zone.
 
         Parameters
         ----------
         time_zone
             Time zone for the `Datetime` Series. Pass `None` to unset time zone.
+        use_earliest
+            If localizing an ambiguous datetime (say, due to daylight saving time),
+            determine whether to localize to the earliest datetime or not.
+            If None (the default), then ambiguous datetimes will raise.
 
         Examples
         --------
         >>> from datetime import datetime
         >>> df = pl.DataFrame(
         ...     {
         ...         "london_timezone": pl.date_range(
@@ -1300,16 +1312,57 @@
          2020-03-01 00:00:00 GMT      2020-03-01 00:00:00 CET        
          2020-04-01 01:00:00 BST      2020-04-01 01:00:00 CEST       
          2020-05-01 01:00:00 BST      2020-05-01 01:00:00 CEST       
          2020-06-01 01:00:00 BST      2020-06-01 01:00:00 CEST       
          2020-07-01 01:00:00 BST      2020-07-01 01:00:00 CEST       
         
 
+        You can use `use_earliest` to deal with ambiguous datetimes:
+
+        >>> dates = [
+        ...     "2018-10-28 01:30",
+        ...     "2018-10-28 02:00",
+        ...     "2018-10-28 02:30",
+        ...     "2018-10-28 02:00",
+        ...     "2018-10-28 02:30",
+        ... ]
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "ts": pl.Series(dates).str.strptime(pl.Datetime),
+        ...         "DST": [True, True, True, False, False],
+        ...     }
+        ... )
+        >>> df.with_columns(
+        ...     ts_localized=pl.when(pl.col("DST"))
+        ...     .then(
+        ...         pl.col("ts").dt.replace_time_zone(
+        ...             "Europe/Brussels", use_earliest=True
+        ...         )
+        ...     )
+        ...     .otherwise(
+        ...         pl.col("ts").dt.replace_time_zone(
+        ...             "Europe/Brussels", use_earliest=False
+        ...         )
+        ...     )
+        ... )
+        shape: (5, 3)
+        
+         ts                   DST    ts_localized                  
+         ---                  ---    ---                           
+         datetime[s]         bool   datetime[s, Europe/Brussels] 
+        
+         2018-10-28 01:30:00  true   2018-10-28 01:30:00 CEST      
+         2018-10-28 02:00:00  true   2018-10-28 02:00:00 CEST      
+         2018-10-28 02:30:00  true   2018-10-28 02:30:00 CEST      
+         2018-10-28 02:00:00  false  2018-10-28 02:00:00 CET       
+         2018-10-28 02:30:00  false  2018-10-28 02:30:00 CET       
+        
+
         """
-        return wrap_expr(self._pyexpr.dt_replace_time_zone(time_zone))
+        return wrap_expr(self._pyexpr.dt_replace_time_zone(time_zone, use_earliest))
 
     def days(self) -> Expr:
         """
         Extract the days from a Duration type.
 
         Returns
         -------
@@ -1650,9 +1703,30 @@
          2002-01-01 00:00:00  1999-11-01 00:00:00 
          2003-01-01 00:00:00  2000-11-01 00:00:00 
          2004-01-01 00:00:00  2001-11-01 00:00:00 
          2005-01-01 00:00:00  2002-11-01 00:00:00 
          2006-01-01 00:00:00  2003-11-01 00:00:00 
         
 
+        To get to the end of each month, combine with `truncate`:
+
+        >>> df.select(
+        ...     pl.col("dates")
+        ...     .dt.truncate("1mo")
+        ...     .dt.offset_by("1mo")
+        ...     .dt.offset_by("-1d")
+        ... )
+        shape: (6, 1)
+        
+         dates               
+         ---                 
+         datetime[s]        
+        
+         2000-01-31 00:00:00 
+         2001-01-31 00:00:00 
+         2002-01-31 00:00:00 
+         2003-01-31 00:00:00 
+         2004-01-31 00:00:00 
+         2005-01-31 00:00:00 
+        
         """
         return wrap_expr(self._pyexpr.dt_offset_by(by))
```

### Comparing `polars_lts_cpu-0.17.2/polars/expr/expr.py` & `polars_lts_cpu-0.17.3/polars/expr/expr.py`

 * *Files 0% similar despite different names*

```diff
@@ -41,15 +41,15 @@
 from polars.expr.datetime import ExprDateTimeNameSpace
 from polars.expr.list import ExprListNameSpace
 from polars.expr.meta import ExprMetaNameSpace
 from polars.expr.string import ExprStringNameSpace
 from polars.expr.struct import ExprStructNameSpace
 from polars.utils._parse_expr_input import expr_to_lit_or_expr, selection_to_pyexpr_list
 from polars.utils.convert import _timedelta_to_pl_duration
-from polars.utils.decorators import deprecated_alias
+from polars.utils.decorators import deprecated_alias, redirect
 from polars.utils.meta import threadpool_size
 from polars.utils.various import find_stacklevel, sphinx_accessor
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import arg_where as py_arg_where
     from polars.polars import reduce as pyreduce
 if TYPE_CHECKING:
@@ -81,14 +81,15 @@
     T = TypeVar("T")
     P = ParamSpec("P")
 
 elif os.getenv("BUILDING_SPHINX_DOCS"):
     property = sphinx_accessor
 
 
+@redirect({"list": "implode"})
 class Expr:
     """Expressions that can be used in various contexts."""
 
     _pyexpr: PyExpr = None
     _accessors: set[str] = {"arr", "cat", "dt", "meta", "str", "bin", "struct"}
 
     @classmethod
@@ -2705,14 +2706,36 @@
         
          2   
         
 
         """
         return self._from_pyexpr(self._pyexpr.n_unique())
 
+    def approx_unique(self) -> Self:
+        """
+        Approx count unique values.
+
+        This is done using the HyperLogLog++ algorithm for cardinality estimation.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame({"a": [1, 1, 2]})
+        >>> df.select(pl.col("a").approx_unique())
+        shape: (1, 1)
+        
+         a   
+         --- 
+         u32 
+        
+         2   
+        
+
+        """
+        return self._from_pyexpr(self._pyexpr.approx_unique())
+
     def null_count(self) -> Self:
         """
         Count null values.
 
         Examples
         --------
         >>> df = pl.DataFrame(
@@ -3439,14 +3462,39 @@
             " under the list and string namespaces. Use `.arr.explode()` or"
             " `.str.explode()` instead.",
             DeprecationWarning,
             stacklevel=find_stacklevel(),
         )
         return self._from_pyexpr(self._pyexpr.explode())
 
+    def implode(self) -> Self:
+        """
+        Aggregate all column values into a list.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "a": [1, 2, 3],
+        ...         "b": [4, 5, 6],
+        ...     }
+        ... )
+        >>> df.select(pl.all().implode())
+        shape: (1, 2)
+        
+         a          b         
+         ---        ---       
+         list[i64]  list[i64] 
+        
+         [1, 2, 3]  [4, 5, 6] 
+        
+
+        """
+        return self._from_pyexpr(self._pyexpr.implode())
+
     def take_every(self, n: int) -> Self:
         """
         Take every nth value in the Series and return as a new Series.
 
         Examples
         --------
         >>> df = pl.DataFrame({"foo": [1, 2, 3, 4, 5, 6, 7, 8, 9]})
@@ -6800,42 +6848,14 @@
         
          3      
         
 
         """
         return self._from_pyexpr(self._pyexpr.set_sorted_flag(descending))
 
-    # Keep the `list` and `str` methods below at the end of the definition of Expr,
-    # as to not confuse mypy with the type annotation `str` and `list`
-
-    def list(self) -> Self:
-        """
-        Aggregate to list.
-
-        Examples
-        --------
-        >>> df = pl.DataFrame(
-        ...     {
-        ...         "a": [1, 2, 3],
-        ...         "b": [4, 5, 6],
-        ...     }
-        ... )
-        >>> df.select(pl.all().list())
-        shape: (1, 2)
-        
-         a          b         
-         ---        ---       
-         list[i64]  list[i64] 
-        
-         [1, 2, 3]  [4, 5, 6] 
-        
-
-        """
-        return self._from_pyexpr(self._pyexpr.list())
-
     def shrink_dtype(self) -> Self:
         """
         Shrink numeric columns to the minimal required datatype.
 
         Shrink to the dtype needed to fit the extrema of this [`Series`].
         This can be used to reduce memory pressure.
 
@@ -7352,14 +7372,17 @@
         Create an object namespace of all meta related expression methods.
 
         This can be used to modify and traverse existing expressions
 
         """
         return ExprMetaNameSpace(self)
 
+    # Keep the `str` property below at the end of the definition of Expr,
+    # as to not confuse mypy with the type annotation `str`
+
     @property
     def str(self) -> ExprStringNameSpace:
         """
         Create an object namespace of all string related methods.
 
         See the individual method pages for full details
```

### Comparing `polars_lts_cpu-0.17.2/polars/expr/list.py` & `polars_lts_cpu-0.17.3/polars/expr/list.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/expr/meta.py` & `polars_lts_cpu-0.17.3/polars/expr/meta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/expr/string.py` & `polars_lts_cpu-0.17.3/polars/expr/string.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,14 +10,15 @@
     Time,
     is_polars_dtype,
     py_type_to_dtype,
 )
 from polars.utils import no_default
 from polars.utils._parse_expr_input import expr_to_lit_or_expr
 from polars.utils._wrap import wrap_expr
+from polars.utils.decorators import deprecated_alias
 from polars.utils.various import find_stacklevel
 
 if TYPE_CHECKING:
     from polars.expr.expr import Expr
     from polars.type_aliases import PolarsDataType, PolarsTemporalType, TransferEncoding
     from polars.utils import NoDefault
 
@@ -26,33 +27,34 @@
     """Namespace for string related expressions."""
 
     _accessor = "str"
 
     def __init__(self, expr: Expr):
         self._pyexpr = expr._pyexpr
 
+    @deprecated_alias(datatype="dtype", fmt="format")
     def strptime(
         self,
-        datatype: PolarsTemporalType,
-        fmt: str | None = None,
+        dtype: PolarsTemporalType,
+        format: str | None = None,
         *,
         strict: bool = True,
         exact: bool = True,
         cache: bool = True,
         tz_aware: bool | NoDefault = no_default,
         utc: bool = False,
     ) -> Expr:
         """
         Parse a Utf8 expression to a Date/Datetime/Time type.
 
         Parameters
         ----------
-        datatype
+        dtype
             Date | Datetime | Time
-        fmt
+        format
             Format to use, refer to the `chrono strftime documentation
             <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_
             for specification. Example: ``"%y-%m-%d"``.
         strict
             Raise an error if any conversion fails.
         exact
             - If True, require an exact format match.
@@ -116,47 +118,58 @@
          2021-04-22 
          2022-01-04 
          2022-01-31 
          2001-07-08 
         
 
         """
-        if not is_polars_dtype(datatype):  # pragma: no cover
-            raise ValueError(f"expected: {DataType} got: {datatype}")
+        if not is_polars_dtype(dtype):  # pragma: no cover
+            raise ValueError(f"expected: {DataType} got: {dtype}")
+
+        if format is not None and "%f" in format:
+            raise ValueError(
+                "Directive '%f' is not supported in Python Polars, "
+                "as it differs from the Python standard library.\n"
+                "Instead, please use one of:\n"
+                " - '%.f'\n"
+                " - '%3f'\n"
+                " - '%6f'\n"
+                " - '%9f'"
+            )
 
         if tz_aware is no_default:
             tz_aware = False
         else:
             warnings.warn(
-                "`tz_aware` is now auto-inferred from `fmt` and will be removed "
+                "`tz_aware` is now auto-inferred from `format` and will be removed "
                 "in a future version. You can safely drop this argument.",
                 category=DeprecationWarning,
                 stacklevel=find_stacklevel(),
             )
 
-        if datatype == Date:
-            return wrap_expr(self._pyexpr.str_parse_date(fmt, strict, exact, cache))
-        elif datatype == Datetime:
-            time_unit = datatype.time_unit  # type: ignore[union-attr]
-            time_zone = datatype.time_zone  # type: ignore[union-attr]
+        if dtype == Date:
+            return wrap_expr(self._pyexpr.str_parse_date(format, strict, exact, cache))
+        elif dtype == Datetime:
+            time_unit = dtype.time_unit  # type: ignore[union-attr]
+            time_zone = dtype.time_zone  # type: ignore[union-attr]
             dtcol = wrap_expr(
                 self._pyexpr.str_parse_datetime(
-                    fmt,
+                    format,
                     strict,
                     exact,
                     cache,
                     tz_aware,
                     utc,
                     time_unit,
                     time_zone,
                 )
             )
             return dtcol if (time_unit is None) else dtcol.dt.cast_time_unit(time_unit)
-        elif datatype == Time:
-            return wrap_expr(self._pyexpr.str_parse_time(fmt, strict, exact, cache))
+        elif dtype == Time:
+            return wrap_expr(self._pyexpr.str_parse_time(format, strict, exact, cache))
         else:  # pragma: no cover
             raise ValueError("dtype should be of type {Date, Datetime, Time}")
 
     def lengths(self) -> Expr:
         """
         Get length of the strings as UInt32 (as number of bytes).
```

### Comparing `polars_lts_cpu-0.17.2/polars/expr/struct.py` & `polars_lts_cpu-0.17.3/polars/expr/struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/functions/__init__.py` & `polars_lts_cpu-0.17.3/polars/functions/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
     ones,
     zeros,
 )
 from polars.functions.lazy import (
     all,
     any,
     apply,
+    approx_unique,
     arange,
     arg_sort_by,
     arg_where,
     avg,
     coalesce,
     col,
     collect_all,
@@ -59,14 +60,15 @@
 from polars.functions.lazy import datetime_ as datetime
 from polars.functions.lazy import list_ as list
 from polars.functions.whenthen import when
 
 __all__ = [
     # polars.functions.eager
     "align_frames",
+    "approx_unique",
     "arg_where",
     "concat",
     "cut",
     "date_range",
     "element",
     "get_dummies",
     "ones",
```

### Comparing `polars_lts_cpu-0.17.2/polars/functions/eager.py` & `polars_lts_cpu-0.17.3/polars/functions/eager.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/functions/lazy.py` & `polars_lts_cpu-0.17.3/polars/functions/lazy.py`

 * *Files 1% similar despite different names*

```diff
@@ -358,25 +358,46 @@
         return wrap_expr(_count())
 
     if isinstance(column, pli.Series):
         return column.len()
     return col(column).count()
 
 
+def implode(name: str) -> Expr:
+    """
+    Aggregate all column values into a list.
+
+    Parameters
+    ----------
+    name
+        Name of the column that should be imploded.
+
+    """
+    return col(name).implode()
+
+
 def list_(name: str) -> Expr:
     """
     Aggregate to list.
 
+    .. deprecated:: 0.17.3
+        ``list`` will be removed in favor of ``implode``.
+
     Parameters
     ----------
     name
         Name of the column that should be aggregated into a list.
 
     """
-    return col(name).list()
+    warnings.warn(
+        "`pl.list` is deprecated, please use `pl.implode` instead.",
+        DeprecationWarning,
+        stacklevel=find_stacklevel(),
+    )
+    return col(name).implode()
 
 
 @overload
 def std(column: str, ddof: int = 1) -> Expr:
     ...
 
 
@@ -908,14 +929,44 @@
 
     """
     if isinstance(column, pli.Series):
         return column.n_unique()
     return col(column).n_unique()
 
 
+def approx_unique(column: str | Expr) -> Expr:
+    """
+    Approx count unique values.
+
+    This is done using the HyperLogLog++ algorithm for cardinality estimation.
+
+    Parameters
+    ----------
+    column
+        Column name or Series.
+
+    Examples
+    --------
+    >>> df = pl.DataFrame({"a": [1, 8, 1], "b": [4, 5, 2], "c": ["foo", "bar", "foo"]})
+    >>> df.select(pl.approx_unique("a"))
+    shape: (1, 1)
+    
+     a   
+     --- 
+     u32 
+    
+     2   
+    
+
+    """
+    if isinstance(column, pli.Expr):
+        return column.approx_unique()
+    return col(column).approx_unique()
+
+
 @overload
 def first(column: str) -> Expr:
     ...
 
 
 @overload
 def first(column: Series) -> Any:
```

### Comparing `polars_lts_cpu-0.17.2/polars/functions/whenthen.py` & `polars_lts_cpu-0.17.3/polars/functions/whenthen.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/__init__.py` & `polars_lts_cpu-0.17.3/polars/io/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/_utils.py` & `polars_lts_cpu-0.17.3/polars/io/_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/avro.py` & `polars_lts_cpu-0.17.3/polars/io/avro.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/csv/_utils.py` & `polars_lts_cpu-0.17.3/polars/io/csv/_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/csv/batched_reader.py` & `polars_lts_cpu-0.17.3/polars/io/csv/batched_reader.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/csv/functions.py` & `polars_lts_cpu-0.17.3/polars/io/csv/functions.py`

 * *Files 0% similar despite different names*

```diff
@@ -137,15 +137,15 @@
     n_rows
         Stop reading from CSV file after reading ``n_rows``.
         During multi-threaded parsing, an upper bound of ``n_rows``
         rows cannot be guaranteed.
     encoding : {'utf8', 'utf8-lossy', ...}
         Lossy means that invalid utf8 values are replaced with ````
         characters. When using other encodings than ``utf8`` or
-        ``utf8-lossy``, the input is first decoded im memory with
+        ``utf8-lossy``, the input is first decoded in memory with
         python. Defaults to ``utf8``.
     low_memory
         Reduce memory usage at expense of performance.
     rechunk
         Make sure that all columns are contiguous in memory by
         aggregating the chunks into a single array.
     use_pyarrow
@@ -484,15 +484,15 @@
     n_rows
         Stop reading from CSV file after reading ``n_rows``.
         During multi-threaded parsing, an upper bound of ``n_rows``
         rows cannot be guaranteed.
     encoding : {'utf8', 'utf8-lossy', ...}
         Lossy means that invalid utf8 values are replaced with ````
         characters. When using other encodings than ``utf8`` or
-        ``utf8-lossy``, the input is first decoded im memory with
+        ``utf8-lossy``, the input is first decoded in memory with
         python. Defaults to ``utf8``.
     low_memory
         Reduce memory usage at expense of performance.
     rechunk
         Make sure that all columns are contiguous in memory by
         aggregating the chunks into a single array.
     skip_rows_after_header
```

### Comparing `polars_lts_cpu-0.17.2/polars/io/database.py` & `polars_lts_cpu-0.17.3/polars/io/database.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/delta.py` & `polars_lts_cpu-0.17.3/polars/io/delta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/excel/_write_utils.py` & `polars_lts_cpu-0.17.3/polars/io/excel/_write_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/excel/functions.py` & `polars_lts_cpu-0.17.3/polars/io/excel/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/ipc/anonymous_scan.py` & `polars_lts_cpu-0.17.3/polars/io/ipc/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/ipc/functions.py` & `polars_lts_cpu-0.17.3/polars/io/ipc/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/json.py` & `polars_lts_cpu-0.17.3/polars/io/json.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/ndjson.py` & `polars_lts_cpu-0.17.3/polars/io/ndjson.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/parquet/anonymous_scan.py` & `polars_lts_cpu-0.17.3/polars/io/parquet/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/parquet/functions.py` & `polars_lts_cpu-0.17.3/polars/io/parquet/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/pyarrow_dataset/anonymous_scan.py` & `polars_lts_cpu-0.17.3/polars/io/pyarrow_dataset/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/io/pyarrow_dataset/functions.py` & `polars_lts_cpu-0.17.3/polars/io/pyarrow_dataset/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/lazyframe/frame.py` & `polars_lts_cpu-0.17.3/polars/lazyframe/frame.py`

 * *Files 0% similar despite different names*

```diff
@@ -290,14 +290,21 @@
 
     @classmethod
     def _from_pyldf(cls, ldf: PyLazyFrame) -> Self:
         self = cls.__new__(cls)
         self._ldf = ldf
         return self
 
+    def __getstate__(self) -> Any:
+        return self._ldf.__getstate__()
+
+    def __setstate__(self, state) -> None:  # type: ignore[no-untyped-def]
+        self._ldf = LazyFrame("", [])._ldf
+        self._ldf.__setstate__(state)
+
     @classmethod
     def _scan_csv(
         cls,
         source: str,
         *,
         has_header: bool = True,
         separator: str = ",",
@@ -3683,14 +3690,41 @@
         
          1    2   
         
 
         """
         return self.slice(0, 1)
 
+    def approx_unique(self) -> Self:
+        """
+        Approx count unique values.
+
+        This is done using the HyperLogLog++ algorithm for cardinality estimation.
+
+        Examples
+        --------
+        >>> lf = pl.LazyFrame(
+        ...     {
+        ...         "a": [1, 2, 3, 4],
+        ...         "b": [1, 2, 1, 1],
+        ...     }
+        ... )
+        >>> lf.approx_unique().collect()
+        shape: (1, 2)
+        
+         a    b   
+         ---  --- 
+         u32  u32 
+        
+         4    2   
+        
+
+        """
+        return self.select(F.all().approx_unique())
+
     def with_row_count(self, name: str = "row_nr", offset: int = 0) -> Self:
         """
         Add a column at index 0 that counts the rows.
 
         Parameters
         ----------
         name
```

### Comparing `polars_lts_cpu-0.17.2/polars/lazyframe/groupby.py` & `polars_lts_cpu-0.17.3/polars/lazyframe/groupby.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/series/_numpy.py` & `polars_lts_cpu-0.17.3/polars/series/_numpy.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/series/binary.py` & `polars_lts_cpu-0.17.3/polars/series/binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/series/categorical.py` & `polars_lts_cpu-0.17.3/polars/series/categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/series/list.py` & `polars_lts_cpu-0.17.3/polars/series/list.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/series/series.py` & `polars_lts_cpu-0.17.3/polars/series/series.py`

 * *Files 1% similar despite different names*

```diff
@@ -558,68 +558,112 @@
         return self._from_pyseries(f(other))
 
     @overload
     def __add__(self, other: DataFrame) -> DataFrame:  # type: ignore[misc]
         ...
 
     @overload
+    def __add__(self, other: Expr) -> Expr:  # type: ignore[misc]
+        ...
+
+    @overload
     def __add__(self, other: Any) -> Self:
         ...
 
-    def __add__(self, other: Any) -> Self | DataFrame:
+    def __add__(self, other: Any) -> Self | DataFrame | Expr:
         if isinstance(other, str):
             other = Series("", [other])
         elif isinstance(other, pli.DataFrame):
             return other + self
+        elif isinstance(other, pli.Expr):
+            return F.lit(self) + other
         return self._arithmetic(other, "add", "add_<>")
 
+    @overload
+    def __sub__(self, other: Expr) -> Expr:  # type: ignore[misc]
+        ...
+
+    @overload
     def __sub__(self, other: Any) -> Self:
+        ...
+
+    def __sub__(self, other: Any) -> Self | Expr:
+        if isinstance(other, pli.Expr):
+            return F.lit(self) - other
         return self._arithmetic(other, "sub", "sub_<>")
 
-    def __truediv__(self, other: Any) -> Self:
+    @overload
+    def __truediv__(self, other: Expr) -> Expr:  # type: ignore[misc]
+        ...
+
+    @overload
+    def __truediv__(self, other: Any) -> Series:
+        ...
+
+    def __truediv__(self, other: Any) -> Series | Expr:
+        if isinstance(other, pli.Expr):
+            return F.lit(self) / other
         if self.is_temporal():
             raise ValueError("first cast to integer before dividing datelike dtypes")
 
         # this branch is exactly the floordiv function without rounding the floats
         if self.is_float():
             return self._arithmetic(other, "div", "div_<>")
 
         return self.cast(Float64) / other
 
     # python 3.7 is not happy. Remove this when we finally ditch that
     @typing.no_type_check
     def __floordiv__(self, other: Any) -> Series:
+        if isinstance(other, pli.Expr):
+            return F.lit(self).__floordiv__(other)
         if self.is_temporal():
             raise ValueError("first cast to integer before dividing datelike dtypes")
         if not isinstance(other, pli.Expr):
             other = F.lit(other)
         return self.to_frame().select(F.col(self.name) // other).to_series()
 
     def __invert__(self) -> Self:
         if self.dtype == Boolean:
             return self._from_pyseries(self._s._not())
         return NotImplemented
 
     @overload
+    def __mul__(self, other: Expr) -> Expr:  # type: ignore[misc]
+        ...
+
+    @overload
     def __mul__(self, other: DataFrame) -> DataFrame:  # type: ignore[misc]
         ...
 
     @overload
     def __mul__(self, other: Any) -> Series:
         ...
 
-    def __mul__(self, other: Any) -> Series | DataFrame:
+    def __mul__(self, other: Any) -> Series | DataFrame | Expr:
+        if isinstance(other, pli.Expr):
+            return F.lit(self) * other
         if self.is_temporal():
             raise ValueError("first cast to integer before multiplying datelike dtypes")
         elif isinstance(other, pli.DataFrame):
             return other * self
         else:
             return self._arithmetic(other, "mul", "mul_<>")
 
+    @overload
+    def __mod__(self, other: Expr) -> Expr:  # type: ignore[misc]
+        ...
+
+    @overload
     def __mod__(self, other: Any) -> Series:
+        ...
+
+    def __mod__(self, other: Any) -> Series | Expr:
+        if isinstance(other, pli.Expr):
+            return F.lit(self).__mod__(other)
         if self.is_temporal():
             raise ValueError(
                 "first cast to integer before applying modulo on datelike dtypes"
             )
         return self._arithmetic(other, "rem", "rem_<>")
 
     def __rmod__(self, other: Any) -> Series:
@@ -1141,42 +1185,52 @@
         
 
         """
         if isinstance(name, str):
             return wrap_df(PyDataFrame([self.rename(name)._s]))
         return wrap_df(PyDataFrame([self._s]))
 
-    def describe(self) -> DataFrame:
+    def describe(
+        self, percentiles: Sequence[float] | float | None = (0.25, 0.75)
+    ) -> DataFrame:
         """
         Quick summary statistics of a series.
 
         Series with mixed datatypes will return summary statistics for the datatype of
         the first value.
 
+        Parameters
+        ----------
+        percentiles
+            One or more percentiles to include in the summary statistics (if the
+            series has a numeric dtype). All values must be in the range `[0, 1]`.
+
         Returns
         -------
         Dictionary with summary statistics of a Series.
 
         Examples
         --------
         >>> series_num = pl.Series([1, 2, 3, 4, 5])
         >>> series_num.describe()
-        shape: (7, 2)
+        shape: (9, 2)
         
          statistic   value    
          ---         ---      
          str         f64      
         
          count       5.0      
          null_count  0.0      
          mean        3.0      
          std         1.581139 
          min         1.0      
          max         5.0      
          median      3.0      
+         25%         2.0      
+         75%         4.0      
         
 
         >>> series_str = pl.Series(["a", "a", None, "b", "c"])
         >>> series_str.describe()
         shape: (3, 2)
         
          statistic   value 
@@ -1185,29 +1239,38 @@
         
          count       5     
          null_count  1     
          unique      4     
         
 
         """
+        if isinstance(percentiles, float):
+            percentiles = [percentiles]
+        if percentiles and not all((0 <= p <= 1) for p in percentiles):
+            raise ValueError("Percentiles must all be in the range [0, 1].")
+
         stats: dict[str, PythonLiteral | None]
 
         if self.len() == 0:
             raise ValueError("Series must contain at least one value")
+
         elif self.is_numeric():
             s = self.cast(Float64)
             stats = {
                 "count": s.len(),
                 "null_count": s.null_count(),
                 "mean": s.mean(),
                 "std": s.std(),
                 "min": s.min(),
                 "max": s.max(),
                 "median": s.median(),
             }
+            if percentiles:
+                stats.update({f"{p:.0%}": s.quantile(p) for p in percentiles})
+
         elif self.is_boolean():
             stats = {
                 "count": self.len(),
                 "null_count": self.null_count(),
                 "sum": self.sum(),
             }
         elif self.is_utf8():
```

### Comparing `polars_lts_cpu-0.17.2/polars/series/string.py` & `polars_lts_cpu-0.17.3/polars/series/string.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,64 +1,72 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from polars import functions as F
 from polars.series.utils import expr_dispatch
+from polars.utils import no_default
 from polars.utils._wrap import wrap_s
+from polars.utils.decorators import deprecated_alias
 
 if TYPE_CHECKING:
     from polars.expr import Expr
     from polars.polars import PySeries
     from polars.series import Series
     from polars.type_aliases import PolarsDataType, PolarsTemporalType, TransferEncoding
+    from polars.utils import NoDefault
 
 
 @expr_dispatch
 class StringNameSpace:
     """Series.str namespace."""
 
     _accessor = "str"
 
     def __init__(self, series: Series):
         self._s: PySeries = series._s
 
+    @deprecated_alias(datatype="dtype", fmt="format")
     def strptime(
         self,
-        datatype: PolarsTemporalType,
-        fmt: str | None = None,
+        dtype: PolarsTemporalType,
+        format: str | None = None,
         *,
         strict: bool = True,
         exact: bool = True,
         cache: bool = True,
-        tz_aware: bool = False,
+        tz_aware: bool | NoDefault = no_default,
         utc: bool = False,
     ) -> Series:
         """
         Parse a Series of dtype Utf8 to a Date/Datetime Series.
 
         Parameters
         ----------
-        datatype
+        dtype
             Date, Datetime or Time.
-        fmt
+        format
             Format to use, refer to the
             `chrono strftime documentation
             <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_
             for specification. Example: ``"%y-%m-%d"``.
         strict
             Raise an error if any conversion fails.
         exact
             - If True, require an exact format match.
             - If False, allow the format to match anywhere in the target string.
         cache
             Use a cache of unique, converted dates to apply the datetime conversion.
         tz_aware
             Parse timezone aware datetimes. This may be automatically toggled by the
-            'fmt' given.
+            `fmt` given.
+
+            .. deprecated:: 0.16.17
+                This is now auto-inferred from the given `fmt`. You can safely drop
+                this argument, it will be removed in a future version.
         utc
             Parse timezone aware datetimes as UTC. This may be useful if you have data
             with mixed offsets.
 
         Returns
         -------
         A Date / Datetime / Time Series
@@ -107,14 +115,30 @@
          2021-04-22 
          2022-01-04 
          2022-01-31 
          2001-07-08 
         
 
         """
+        s = wrap_s(self._s)
+        return (
+            s.to_frame()
+            .select(
+                F.col(s.name).str.strptime(
+                    dtype,
+                    format,
+                    strict=strict,
+                    exact=exact,
+                    cache=cache,
+                    tz_aware=tz_aware,
+                    utc=utc,
+                )
+            )
+            .to_series()
+        )
 
     def lengths(self) -> Series:
         """
         Get length of the string values in the Series (as number of bytes).
 
         Notes
         -----
```

### Comparing `polars_lts_cpu-0.17.2/polars/series/struct.py` & `polars_lts_cpu-0.17.3/polars/series/struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/series/utils.py` & `polars_lts_cpu-0.17.3/polars/series/utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/slice.py` & `polars_lts_cpu-0.17.3/polars/slice.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/sql/context.py` & `polars_lts_cpu-0.17.3/polars/sql/context.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/string_cache.py` & `polars_lts_cpu-0.17.3/polars/string_cache.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/testing/_parametric.py` & `polars_lts_cpu-0.17.3/polars/testing/parametric/primitives.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,156 +1,74 @@
 from __future__ import annotations
 
-import os
 import random
 import warnings
 from dataclasses import dataclass
-from datetime import datetime, timedelta
 from math import isfinite
 from textwrap import dedent
-from typing import TYPE_CHECKING, Any, Sequence, cast
+from typing import TYPE_CHECKING, Any, Sequence
 
-from hypothesis import settings
 from hypothesis.errors import InvalidArgument, NonInteractiveExampleWarning
 from hypothesis.strategies import (
     booleans,
     composite,
-    dates,
-    datetimes,
-    floats,
-    from_type,
-    integers,
     lists,
     sampled_from,
-    text,
-    timedeltas,
-    times,
 )
 from hypothesis.strategies._internal.utils import defines_strategy
 
 from polars.dataframe import DataFrame
 from polars.datatypes import (
-    Boolean,
+    FLOAT_DTYPES,
     Categorical,
-    Date,
-    Datetime,
-    Duration,
-    Float32,
-    Float64,
-    Int8,
-    Int16,
-    Int32,
-    Int64,
-    Time,
-    UInt8,
-    UInt16,
-    UInt32,
-    UInt64,
-    Utf8,
     is_polars_dtype,
     py_type_to_dtype,
 )
 from polars.series import Series
 from polars.string_cache import StringCache
 from polars.testing.asserts import is_categorical_dtype
-from polars.type_aliases import Orientation
+from polars.testing.parametric.strategies import (
+    between,
+    scalar_strategies,
+)
 
 if TYPE_CHECKING:
     from hypothesis.strategies import DrawFn, SearchStrategy
 
     from polars.lazyframe import LazyFrame
     from polars.type_aliases import OneOrMoreDataTypes, PolarsDataType
 
-# Default profile (eg: running locally)
-common_settings = {"print_blob": True, "deadline": None}
-settings.register_profile(
-    name="polars.default",
-    max_examples=100,
-    **common_settings,  # type: ignore[arg-type]
-)
-# CI 'max' profile (10x the number of iterations).
-# this is expensive, and not actually enabled in
-# our usual CI pipeline; requires explicit opt-in.
-settings.register_profile(
-    name="polars.ci",
-    max_examples=1000,
-    **common_settings,  # type: ignore[arg-type]
-)
-if os.getenv("CI_MAX"):
-    settings.load_profile("polars.ci")
-else:
-    settings.load_profile("polars.default")
 
+def empty_list(value: Any, nested: bool) -> bool:
+    """Check if value is an empty list, or a list that contains only empty lists."""
+    if isinstance(value, list):
+        return True if value and not nested else all(empty_list(v, True) for v in value)
+    return False
 
-MAX_DATA_SIZE = 10
-MAX_COLS = 8
 
-# =====================================================================
-# Polars-specific 'hypothesis' strategies and helper functions
+# ====================================================================
+# Polars 'hypothesis' primitives for Series, DataFrame, and LazyFrame
 # See: https://hypothesis.readthedocs.io/
-# =====================================================================
+# ====================================================================
+MAX_DATA_SIZE = 10  # max generated frame length
+MAX_COLS = 8  # max number of generated cols
 
-dtype_strategy_mapping: dict[PolarsDataType, Any] = {
-    Boolean: booleans(),
-    Float32: floats(width=32),
-    Float64: floats(width=64),
-    Int8: integers(min_value=-(2**7), max_value=(2**7) - 1),
-    Int16: integers(min_value=-(2**15), max_value=(2**15) - 1),
-    Int32: integers(min_value=-(2**31), max_value=(2**31) - 1),
-    Int64: integers(min_value=-(2**63), max_value=(2**63) - 1),
-    UInt8: integers(min_value=0, max_value=(2**8) - 1),
-    UInt16: integers(min_value=0, max_value=(2**16) - 1),
-    UInt32: integers(min_value=0, max_value=(2**32) - 1),
-    UInt64: integers(min_value=0, max_value=(2**64) - 1),
-    # TODO: when generating text for categorical, ensure there are repeats -
-    #  don't want all to be unique.
-    Categorical: text(max_size=10),
-    Utf8: text(max_size=10),
-    # TODO: generate arrow temporal types with different resolution (32/64) to
-    #  validate compatibility.
-    Time: times(),
-    Date: dates(),
-    Duration: timedeltas(
-        min_value=timedelta(microseconds=-(2**63)),
-        max_value=timedelta(microseconds=(2**63) - 1),
-    ),
-    # TODO: confirm datetime min/max limits with different timeunit granularity.
-    # TODO: specific strategies for temporal dtypes with timeunits.
-    Datetime: datetimes(min_value=datetime(1970, 1, 1)),
-    # Datetime("ms")
-    # Datetime("us")
-    # Datetime("ns")
-    # Duration("ms")
-    # Duration("us")
-    # Duration("ns")
-    # TODO: strategies for non-scalar/structured dtypes.
-    # List
-    # Struct
-    # Object
-}
-
-strategy_dtypes = list(dtype_strategy_mapping)
-
-
-def between(draw: DrawFn, type_: type, min_: Any, max_: Any) -> Any:
-    """Draw a value in a given range from a type-inferred strategy."""
-    strategy_init = from_type(type_).function  # type: ignore[attr-defined]
-    return draw(strategy_init(min_, max_))
+strategy_dtypes = list(scalar_strategies)
 
 
 @dataclass
 class column:
     """
     Define a column for use with the @dataframes strategy.
 
     Parameters
     ----------
     name : str
         string column name.
-    dtype : dtype
+    dtype : PolarsDataType
         a recognised polars dtype.
     strategy : strategy, optional
         supports overriding the default strategy for the given dtype.
     null_probability : float, optional
         percentage chance (expressed between 0.0 => 1.0) that a generated value
         is None. this is applied in addition to any None values output by the
         given/inferred strategy for the column.
@@ -178,17 +96,24 @@
         if (self.null_probability is not None) and (
             self.null_probability < 0 or self.null_probability > 1
         ):
             raise InvalidArgument(
                 "null_probability should be between 0.0 and 1.0, or None; found"
                 f" {self.null_probability}"
             )
+
+        if self.dtype is None:
+            tp = getattr(self.strategy, "_dtype", None)
+            if is_polars_dtype(tp):
+                self.dtype = tp
+
         if self.dtype is None and self.strategy is None:
             self.dtype = random.choice(strategy_dtypes)
-        elif self.dtype not in dtype_strategy_mapping:
+
+        elif self.dtype not in scalar_strategies:
             if self.dtype is not None:
                 raise InvalidArgument(
                     f"No strategy (currently) available for {self.dtype} type"
                 )
             else:
                 # given a custom strategy, but no explicit dtype. infer one
                 # from the first non-None value that the strategy produces.
@@ -199,15 +124,19 @@
                     warnings.simplefilter("ignore", NonInteractiveExampleWarning)
                     sample_value_iter = (
                         self.strategy.example()  # type: ignore[union-attr]
                         for _ in range(100)
                     )
                     try:
                         sample_value_type = type(
-                            next(e for e in sample_value_iter if e is not None)
+                            next(
+                                e
+                                for e in sample_value_iter
+                                if e is not None and not empty_list(e, nested=True)
+                            )
                         )
                     except StopIteration:
                         raise InvalidArgument(
                             "Unable to determine dtype for strategy"
                         ) from None
                 if sample_value_type is not None:
                     self.dtype = py_type_to_dtype(sample_value_type)
@@ -236,15 +165,15 @@
 
     Parameters
     ----------
     cols : {int, [str]}, optional
         integer number of cols to create, or explicit list of column names. if
         omitted a random number of columns (between mincol and max_cols) are
         created.
-    dtype : dtype, optional
+    dtype : PolarsDataType, optional
         a single dtype for all cols, or list of dtypes (the same length as `cols`).
         if omitted, each generated column is assigned a random dtype.
     min_cols : int, optional
         if not passing an exact size, can set a minimum here (defaults to 0).
     max_cols : int, optional
         if not passing an exact size, can set a maximum value here (defaults to
         MAX_COLS).
@@ -317,15 +246,15 @@
     Strategy for producing a polars Series.
 
     Parameters
     ----------
     name : {str, strategy}, optional
         literal string or a strategy for strings (or None), passed to the Series
         constructor name-param.
-    dtype : dtype, optional
+    dtype : PolarsDataType, optional
         a valid polars DataType for the resulting series.
     size : int, optional
         if set, creates a Series of exactly this size (ignoring min/max params).
     min_size : int, optional
         if not passing an exact size, can set a minimum here (defaults to 0).
         no-op if `size` is set.
     max_size : int, optional
@@ -394,19 +323,19 @@
     def draw_series(draw: DrawFn) -> Series:
         with StringCache():
             # create/assign series dtype and retrieve matching strategy
             series_dtype = (
                 draw(sampled_from(selectable_dtypes)) if dtype is None else dtype
             )
             if strategy is None:
-                dtype_strategy = dtype_strategy_mapping[series_dtype]
+                dtype_strategy = scalar_strategies[series_dtype]
             else:
                 dtype_strategy = strategy
 
-            if series_dtype in (Float32, Float64) and not allow_infinities:
+            if series_dtype in FLOAT_DTYPES and not allow_infinities:
                 dtype_strategy = dtype_strategy.filter(
                     lambda x: not isinstance(x, float) or isfinite(x)
                 )
 
             # create/assign series size
             series_size = (
                 between(
@@ -631,20 +560,23 @@
                         unique=c.unique,
                         chunked=(chunked is None and draw(booleans())),
                     )
                 )
                 for c in coldefs
             }
 
-            # note: randomly change between row-wise and column-wise frame init
-            orient = cast(Orientation, "row" if draw(booleans()) else "col")
-            data = list(zip(*data.values())) if orient == "row" else data  # type: ignore[assignment]
+            # note: randomly change between column-wise and row-wise frame init
+            orient = "col"
+            if draw(booleans()):
+                data = list(zip(*data.values()))  # type: ignore[assignment]
+                orient = "row"
+
             schema = [(c.name, c.dtype) for c in coldefs]
             try:
-                df = DataFrame(data=data, schema=schema, orient=orient)
+                df = DataFrame(data=data, schema=schema, orient=orient)  # type: ignore[arg-type]
 
                 # optionally generate chunked frames
                 if series_size > 1 and chunked is True:
                     split_at = series_size // 2
                     df = df[:split_at].vstack(df[split_at:])
 
                 _failed_frame_init_msgs_.clear()
```

### Comparing `polars_lts_cpu-0.17.2/polars/testing/_private.py` & `polars_lts_cpu-0.17.3/polars/testing/_private.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/testing/asserts.py` & `polars_lts_cpu-0.17.3/polars/testing/asserts.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 import textwrap
 from typing import Any
 
 from polars import functions as F
 from polars.dataframe import DataFrame
 from polars.datatypes import (
+    UNSIGNED_INTEGER_DTYPES,
     Categorical,
     DataTypeClass,
     Float32,
     Float64,
     dtype_to_py_type,
 )
 from polars.exceptions import ComputeError, InvalidAssert
@@ -339,16 +340,23 @@
         if check_exact:
             raise_assert_detail(
                 "Series", "Exact value mismatch", left=list(left), right=list(right)
             )
         else:
             # apply check with tolerance (to the known-unequal matches).
             left, right = left.filter(unequal), right.filter(unequal)
+
+            if all(tp in UNSIGNED_INTEGER_DTYPES for tp in (left.dtype, right.dtype)):
+                # avoid potential "subtract-with-overflow" panic on uint math
+                s_diff = Series("diff", [abs(v1 - v2) for v1, v2 in zip(left, right)])
+            else:
+                s_diff = (left - right).abs()
+
             mismatch, nan_info = False, ""
-            if (((left - right).abs() > (atol + rtol * right.abs())).sum() != 0) or (
+            if ((s_diff > (atol + rtol * right.abs())).sum() != 0) or (
                 left.is_null() != right.is_null()
             ).any():
                 mismatch = True
             elif comparing_float_dtypes:
                 # note: take special care with NaN values.
                 if not nans_compare_equal and (left.is_nan() == right.is_nan()).any():
                     nan_info = " (nans_compare_equal=False)"
```

### Comparing `polars_lts_cpu-0.17.2/polars/type_aliases.py` & `polars_lts_cpu-0.17.3/polars/type_aliases.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/__init__.py` & `polars_lts_cpu-0.17.3/polars/utils/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -3,14 +3,16 @@
 
 Functions that are part of the public API are re-exported here.
 """
 from polars.utils._scan import _deserialize_and_execute
 from polars.utils.build_info import build_info
 from polars.utils.convert import (
     _date_to_pl_date,
+    _datetime_for_anyvalue,
+    _datetime_for_anyvalue_windows,
     _time_to_pl_time,
     _timedelta_to_pl_timedelta,
     _to_python_datetime,
     _to_python_decimal,
     _to_python_time,
     _to_python_timedelta,
     _tzinfo_to_str,
@@ -32,9 +34,11 @@
     "_deserialize_and_execute",
     "_time_to_pl_time",
     "_timedelta_to_pl_timedelta",
     "_to_python_datetime",
     "_to_python_decimal",
     "_to_python_time",
     "_to_python_timedelta",
+    "_datetime_for_anyvalue",
+    "_datetime_for_anyvalue_windows",
     "_tzinfo_to_str",
 ]
```

### Comparing `polars_lts_cpu-0.17.2/polars/utils/_construction.py` & `polars_lts_cpu-0.17.3/polars/utils/_construction.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import contextlib
 from datetime import date, datetime, time, timedelta
 from decimal import Decimal as PyDecimal
-from functools import singledispatch
+from functools import lru_cache, partial, singledispatch
 from itertools import islice, zip_longest
 from sys import version_info
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
     Generator,
@@ -44,15 +44,17 @@
     polars_type_to_constructor,
     py_type_to_constructor,
 )
 from polars.dependencies import (
     _NUMPY_AVAILABLE,
     _check_for_numpy,
     _check_for_pandas,
+    _check_for_pydantic,
     dataclasses,
+    pydantic,
 )
 from polars.dependencies import numpy as np
 from polars.dependencies import pandas as pd
 from polars.dependencies import pyarrow as pa
 from polars.exceptions import ComputeError, ShapeError
 from polars.utils._wrap import wrap_df, wrap_s
 from polars.utils.convert import _tzinfo_to_str
@@ -70,40 +72,72 @@
         PolarsDataType,
         SchemaDefinition,
         SchemaDict,
     )
 
 if version_info >= (3, 10):
 
-    def dataclass_type_hints(obj: type) -> dict[str, Any]:
+    def type_hints(obj: type) -> dict[str, Any]:
         return get_type_hints(obj)
 
 else:
 
-    def dataclass_type_hints(obj: type) -> dict[str, Any]:
+    def type_hints(obj: type) -> dict[str, Any]:
         return getattr(obj, "__annotations__", {})
 
 
-def is_namedtuple(value: Any, annotated: bool = False) -> bool:
-    """Infer whether value is a NamedTuple."""
-    if all(hasattr(value, attr) for attr in ("_fields", "_field_defaults", "_replace")):
-        return len(value.__annotations__) == len(value._fields) if annotated else True
+@lru_cache(64)
+def is_namedtuple(cls: Any, annotated: bool = False) -> bool:
+    """Check whether given class derives from NamedTuple."""
+    if all(hasattr(cls, attr) for attr in ("_fields", "_field_defaults", "_replace")):
+        if len(cls.__annotations__) == len(cls._fields) if annotated else True:
+            return all(isinstance(fld, str) for fld in cls._fields)
+    return False
+
+
+def is_pydantic_model(value: Any) -> bool:
+    """Check whether value derives from a pydantic.BaseModel."""
+    return _check_for_pydantic(value) and isinstance(value, pydantic.BaseModel)
+
+
+def contains_nested(value: Any, is_nested: Callable[[Any], bool]) -> bool:
+    """Determine if value contains (or is) nested structured data."""
+    if is_nested(value):
+        return True
+    elif isinstance(value, dict):
+        return any(contains_nested(v, is_nested) for v in value.values())
+    elif isinstance(value, (list, tuple)):
+        return any(contains_nested(v, is_nested) for v in value)
     return False
 
 
 def include_unknowns(
     schema: SchemaDict, cols: Sequence[str]
 ) -> MutableMapping[str, PolarsDataType]:
     """Complete partial schema dict by including Unknown type."""
     return {
         col: (schema.get(col, Unknown) or Unknown)  # type: ignore[truthy-bool]
         for col in cols
     }
 
 
+def nt_unpack(obj: Any) -> Any:
+    """Recursively unpack a nested NamedTuple."""
+    if isinstance(obj, dict):
+        return {key: nt_unpack(value) for key, value in obj.items()}
+    elif isinstance(obj, list):
+        return [nt_unpack(value) for value in obj]
+    elif is_namedtuple(obj):
+        return {key: nt_unpack(value) for key, value in obj._asdict().items()}
+    elif isinstance(obj, tuple):
+        return tuple(nt_unpack(value) for value in obj)
+    else:
+        return obj
+
+
 ################################
 # Series constructor interface #
 ################################
 
 
 def series_to_pyseries(name: str, values: Series) -> PySeries:
     """Construct a PySeries from a Polars Series."""
@@ -312,15 +346,19 @@
 
     # infer temporal type handling
     py_temporal_types = {date, datetime, timedelta, time}
     pl_temporal_types = {Date, Datetime, Duration, Time}
 
     value = _get_first_non_none(values)
     if value is not None:
-        if dataclasses.is_dataclass(value) or is_namedtuple(value, annotated=True):
+        if (
+            dataclasses.is_dataclass(value)
+            or is_pydantic_model(value)
+            or is_namedtuple(value.__class__, annotated=True)
+        ):
             return pli.DataFrame(values).to_struct(name)._s
         elif isinstance(value, range):
             values = [range_to_series("", v) for v in values]
         else:
             # for temporal dtypes:
             # * if the values are integer, we take the physical branch.
             # * if the values are python types, take the temporal branch.
@@ -804,15 +842,18 @@
 
     elif _check_for_pandas(first_element) and isinstance(
         first_element, (pd.Series, pd.DatetimeIndex)
     ):
         to_pydf = _sequence_of_pandas_to_pydf
 
     elif dataclasses.is_dataclass(first_element):
-        to_pydf = _sequence_of_dataclasses_to_pydf
+        to_pydf = _dataclasses_or_models_to_pydf
+
+    elif is_pydantic_model(first_element):
+        to_pydf = partial(_dataclasses_or_models_to_pydf, pydantic_model=True)
     else:
         to_pydf = _sequence_of_elements_to_pydf
 
     if register_with_singledispatch:
         _sequence_to_pydf_dispatcher.register(type(first_element), to_pydf)
 
     common_params["first_element"] = first_element
@@ -842,29 +883,38 @@
         else:
             orient = "row"
 
     if orient == "row":
         column_names, schema_overrides = _unpack_schema(
             schema, schema_overrides=schema_overrides, n_expected=len(first_element)
         )
-        schema_override = (
+        local_schema_override = (
             include_unknowns(schema_overrides, column_names) if schema_overrides else {}
         )
         if column_names and len(first_element) != len(column_names):
             raise ShapeError("The row data does not match the number of columns")
 
-        for col, tp in schema_override.items():
+        unpack_nested = False
+        for col, tp in local_schema_override.items():
             if tp == Categorical:
-                schema_override[col] = Utf8
+                local_schema_override[col] = Utf8
+            elif not unpack_nested and (tp.base_type() in (Unknown, Struct)):
+                unpack_nested = contains_nested(
+                    getattr(first_element, col, None), is_namedtuple
+                )
 
-        pydf = PyDataFrame.read_rows(
-            data,
-            infer_schema_length,
-            schema_override or None,
-        )
+        if unpack_nested:
+            dicts = [nt_unpack(d) for d in data]
+            pydf = PyDataFrame.read_dicts(dicts, infer_schema_length)
+        else:
+            pydf = PyDataFrame.read_rows(
+                data,
+                infer_schema_length,
+                local_schema_override or None,
+            )
         if column_names or schema_overrides:
             pydf = _post_apply_columns(
                 pydf, column_names, schema_overrides=schema_overrides
             )
         return pydf
 
     if orient == "col" or orient is None:
@@ -889,16 +939,16 @@
     first_element: tuple[Any, ...],
     data: Sequence[Any],
     schema: SchemaDefinition | None,
     schema_overrides: SchemaDict | None,
     orient: Orientation | None,
     infer_schema_length: int | None,
 ) -> PyDataFrame:
-    # infer additional meta information if NAMED tuple...
-    if is_namedtuple(first_element):
+    # infer additional meta information if named tuple
+    if is_namedtuple(first_element.__class__):
         if schema is None:
             schema = first_element._fields  # type: ignore[attr-defined]
             if len(first_element.__annotations__) == len(schema):
                 schema = [
                     (name, py_type_to_dtype(tp, raise_unmatched=False))
                     for name, tp in first_element.__annotations__.items()
                 ]
@@ -999,49 +1049,72 @@
         if dtype is not None and dtype != pyseries.dtype():
             pyseries = pyseries.cast(dtype, strict=True)
         data_series.append(pyseries)
 
     return PyDataFrame(data_series)
 
 
-def _sequence_of_dataclasses_to_pydf(
+def _dataclasses_or_models_to_pydf(
     first_element: Any,
     data: Sequence[Any],
     schema: SchemaDefinition | None,
     schema_overrides: SchemaDict | None,
     infer_schema_length: int | None,
     **kwargs: Any,
 ) -> PyDataFrame:
-    from dataclasses import astuple
+    """Initialise DataFrame from python dataclass and/or pydantic model objects."""
+    from dataclasses import asdict, astuple
 
+    from_model = kwargs.get("pydantic_model")
+    unpack_nested = False
     if schema:
         column_names, schema_overrides = _unpack_schema(schema, schema_overrides)
         schema_override = {
             col: schema_overrides.get(col, Unknown) for col in column_names
         }
     else:
         column_names = []
         schema_override = {
             col: (py_type_to_dtype(tp, raise_unmatched=False) or Unknown)
-            for col, tp in dataclass_type_hints(first_element.__class__).items()
+            for col, tp in type_hints(first_element.__class__).items()
+            if col != "__slots__"
         }
         schema_override.update(schema_overrides or {})
 
     for col, tp in schema_override.items():
         if tp == Categorical:
             schema_override[col] = Utf8
+        elif not unpack_nested and (tp.base_type() in (Unknown, Struct)):
+            unpack_nested = contains_nested(
+                getattr(first_element, col, None),
+                is_pydantic_model if from_model else dataclasses.is_dataclass,  # type: ignore[arg-type]
+            )
+
+    if unpack_nested:
+        if from_model:
+            dicts = (
+                [md.model_dump(mode="python") for md in data]
+                if hasattr(first_element, "model_dump")
+                else [md.dict() for md in data]
+            )
+        else:
+            dicts = [asdict(md) for md in data]
+        pydf = PyDataFrame.read_dicts(dicts, infer_schema_length)
+    else:
+        rows = (
+            [tuple(md.__dict__.values()) for md in data]
+            if from_model
+            else [astuple(dc) for dc in data]
+        )
+        pydf = PyDataFrame.read_rows(rows, infer_schema_length, schema_override or None)
 
-    pydf = PyDataFrame.read_rows(
-        [astuple(dc) for dc in data],
-        infer_schema_length,
-        schema_override or None,
-    )
     if schema_override:
         structs = {c: tp for c, tp in schema_override.items() if isinstance(tp, Struct)}
         pydf = _post_apply_columns(pydf, column_names, structs, schema_overrides)
+
     return pydf
 
 
 def numpy_to_pydf(
     data: np.ndarray[Any, Any],
     schema: SchemaDefinition | None = None,
     schema_overrides: SchemaDict | None = None,
```

### Comparing `polars_lts_cpu-0.17.2/polars/utils/_parse_expr_input.py` & `polars_lts_cpu-0.17.3/polars/utils/_parse_expr_input.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/_scan.py` & `polars_lts_cpu-0.17.3/polars/utils/_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/_wrap.py` & `polars_lts_cpu-0.17.3/polars/utils/_wrap.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/build_info.py` & `polars_lts_cpu-0.17.3/polars/utils/build_info.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/convert.py` & `polars_lts_cpu-0.17.3/polars/utils/convert.py`

 * *Files 5% similar despite different names*

```diff
@@ -222,14 +222,30 @@
     except zoneinfo.ZoneInfoNotFoundError:
         # try fixed offset, which is not supported by ZoneInfo
         _tzinfo = _parse_fixed_tz_offset(time_zone)
 
     return dt.astimezone(_tzinfo)
 
 
+def _datetime_for_anyvalue(dt: datetime) -> tuple[float, int]:
+    """Used in pyo3 anyvalue conversion."""
+    if dt.tzinfo is None:
+        dt = dt.replace(tzinfo=timezone.utc)
+    # returns (s, ms)
+    return (dt.replace(microsecond=0).timestamp(), dt.microsecond)
+
+
+def _datetime_for_anyvalue_windows(dt: datetime) -> tuple[float, int]:
+    """Used in pyo3 anyvalue conversion."""
+    if dt.tzinfo is None:
+        dt = _localize(dt, "UTC")
+    # returns (s, ms)
+    return (dt.replace(microsecond=0).timestamp(), dt.microsecond)
+
+
 # cache here as we have a single tz per column
 # and this function will be called on every conversion
 @functools.lru_cache(16)
 def _parse_fixed_tz_offset(offset: str) -> tzinfo:
     try:
         # use fromisoformat to parse the offset
         dt_offset = datetime.fromisoformat("2000-01-01T00:00:00" + offset)
```

### Comparing `polars_lts_cpu-0.17.2/polars/utils/decorators.py` & `polars_lts_cpu-0.17.3/polars/utils/decorators.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/meta.py` & `polars_lts_cpu-0.17.3/polars/utils/meta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/polars_version.py` & `polars_lts_cpu-0.17.3/polars/utils/polars_version.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/show_versions.py` & `polars_lts_cpu-0.17.3/polars/utils/show_versions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/polars/utils/various.py` & `polars_lts_cpu-0.17.3/polars/utils/various.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/pyproject.toml` & `polars_lts_cpu-0.17.3/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -66,33 +66,35 @@
 ]
 disable_error_code = [
   "empty-body",
 ]
 
 [[tool.mypy.overrides]]
 module = [
+  "IPython.*",
   "backports",
-  "pyarrow.*",
-  "polars.polars",
-  "matplotlib.*",
-  "fsspec.*",
   "connectorx",
   "deltalake",
-  "IPython.*",
+  "fsspec.*",
+  "matplotlib.*",
+  "polars.polars",
+  "pyarrow.*",
+  "pydantic",
+  "sqlalchemy",
   "xlsx2csv",
-  "xlsxwriter",
-  "xlsxwriter.format",
-  "xlsxwriter.utility",
-  "xlsxwriter.worksheet",
+  "xlsxwriter.*",
   "zoneinfo",
-  "sqlalchemy",
 ]
 ignore_missing_imports = true
 
 [[tool.mypy.overrides]]
+module = ["polars.testing._tempdir"]
+ignore_errors = true
+
+[[tool.mypy.overrides]]
 module = ["IPython.*"]
 follow_imports = "skip"
 
 [[tool.mypy.overrides]]
 module = ["polars.*"]
 # We exclude the polars module from warn_return_any, because the PyO3 api does not have Python
 # type annotations. See https://github.com/PyO3/pyo3/issues/1112 for a discussion on adding
```

### Comparing `polars_lts_cpu-0.17.2/requirements-dev.txt` & `polars_lts_cpu-0.17.3/requirements-dev.txt`

 * *Files 16% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 --prefer-binary
 
 # Dependencies
 deltalake >= 0.8.0
 numpy
 pandas
 pyarrow
+pydantic
 backports.zoneinfo; python_version < '3.9'
 tzdata; platform_system == 'Windows'
 xlsx2csv
 XlsxWriter
 adbc_driver_sqlite; python_version >= '3.9' and platform_system != 'Windows'
 connectorx==0.3.2a2; python_version >= '3.8'  # Latest full release is broken - unpin when 0.3.2 released
```

### Comparing `polars_lts_cpu-0.17.2/scripts/check_stacklevels.py` & `polars_lts_cpu-0.17.3/scripts/check_stacklevels.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 import subprocess
 import sys
 from ast import NodeVisitor
 
 # Files in which it's OK to set the stacklevel manually.
 # `git ls-files` lists files with forwards-slashes
 # even on Windows, so it's OK to list them like that.
-EXCLUDE = frozenset(["polars/utils/polars_version.py"])
+EXCLUDE = frozenset(["polars/utils/polars_version.py", "polars/testing/_tempdir.py"])
 
 
 class StackLevelChecker(NodeVisitor):
     def __init__(self, file) -> None:
         self.file = file
         self.violations = set()
```

### Comparing `polars_lts_cpu-0.17.2/src/apply/dataframe.rs` & `polars_lts_cpu-0.17.3/src/apply/dataframe.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/apply/mod.rs` & `polars_lts_cpu-0.17.3/src/apply/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/apply/series.rs` & `polars_lts_cpu-0.17.3/src/apply/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/arrow_interop/to_py.rs` & `polars_lts_cpu-0.17.3/src/arrow_interop/to_py.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/arrow_interop/to_rust.rs` & `polars_lts_cpu-0.17.3/src/arrow_interop/to_rust.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/batched_csv.rs` & `polars_lts_cpu-0.17.3/src/batched_csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/conversion.rs` & `polars_lts_cpu-0.17.3/src/conversion.rs`

 * *Files 2% similar despite different names*

```diff
@@ -633,56 +633,30 @@
     })
 }
 fn convert_datetime(ob: &PyAny) -> PyResult<Wrap<AnyValue>> {
     Python::with_gil(|py| {
         // windows
         #[cfg(target_arch = "windows")]
         let (seconds, microseconds) = {
-            let tzinfo = ob.getattr("tzinfo")?;
-            let dt = if tzinfo.is_none() {
-                let kwargs = PyDict::new(py);
-                kwargs.set_item("tzinfo", py.None())?;
-                let dt = ob.call_method("replace", (), Some(kwargs))?;
-                let localize = UTILS.getattr("_localize").unwrap();
-                localize.call1((dt, "UTC"))
-            } else {
-                ob
-            };
-            let kwargs = PyDict::new(py);
-            kwargs.set_item("microsecond", 0)?;
-            let seconds = dt
-                .call_method("replace", (), Some(kwargs))?
-                .call_method0("timestamp")?;
-            let microseconds = dt.getattr("microsecond")?.extract::<i64>()?;
-            (seconds, microseconds)
+            let convert = UTILS.getattr(py, "_datetime_for_anyvalue_windows").unwrap();
+            let out = convert.call1(py, (ob,)).unwrap();
+            let out: (f64, i64) = out.extract(py).unwrap();
+            out
         };
         // unix
         #[cfg(not(target_arch = "windows"))]
         let (seconds, microseconds) = {
-            let datetime = PyModule::import(py, "datetime")?;
-            let timezone = datetime.getattr("timezone")?;
-            let tzinfo = ob.getattr("tzinfo")?;
-            let dt = if tzinfo.is_none() {
-                let kwargs = PyDict::new(py);
-                kwargs.set_item("tzinfo", timezone.getattr("utc")?)?;
-                ob.call_method("replace", (), Some(kwargs))?
-            } else {
-                ob
-            };
-            let kwargs = PyDict::new(py);
-            kwargs.set_item("microsecond", 0)?;
-            let seconds = dt
-                .call_method("replace", (), Some(kwargs))?
-                .call_method0("timestamp")?;
-            let microseconds = dt.getattr("microsecond")?.extract::<i64>()?;
-            (seconds, microseconds)
+            let convert = UTILS.getattr(py, "_datetime_for_anyvalue").unwrap();
+            let out = convert.call1(py, (ob,)).unwrap();
+            let out: (f64, i64) = out.extract(py).unwrap();
+            out
         };
 
         // s to us
-        let mut v = (seconds.extract::<f64>()? as i64) * 1_000_000;
+        let mut v = (seconds as i64) * 1_000_000;
         v += microseconds;
 
         // choose "us" as that is python's default unit
         Ok(AnyValue::Datetime(v, TimeUnit::Microseconds, &None).into())
     })
 }
 
@@ -760,14 +734,19 @@
                     if sign > 0 {
                         v = -v; // won't overflow since -i128::MAX > i128::MIN
                     }
                     Ok(Wrap(AnyValue::Decimal(v, scale)))
                 }
                 "range" => materialize_list(ob),
                 _ => {
+                    // special branch for np.float as this fails isinstance float
+                    if let Ok(value) = ob.extract::<f64>() {
+                        return Ok(AnyValue::Float64(value).into());
+                    }
+
                     // Can't use pyo3::types::PyDateTime with abi3-py37 feature,
                     // so need this workaround instead of `isinstance(ob, datetime)`.
                     let bases = ob.get_type().getattr("__bases__")?.iter()?;
                     for base in bases {
                         let parent_type = base.unwrap().str().unwrap().to_str().unwrap();
                         match parent_type {
                             "<class 'datetime.datetime'>" => {
```

### Comparing `polars_lts_cpu-0.17.2/src/dataframe.rs` & `polars_lts_cpu-0.17.3/src/dataframe.rs`

 * *Files 0% similar despite different names*

```diff
@@ -48,18 +48,15 @@
     }
 
     fn finish_from_rows(
         rows: Vec<Row>,
         infer_schema_length: Option<usize>,
         schema_overwrite: Option<Schema>,
     ) -> PyResult<Self> {
-        // object builder must be registered.
-        #[cfg(feature = "object")]
-        crate::object::register_object_builder();
-
+        // object builder must be registered. this is done on import
         let schema =
             rows_to_schema_supertypes(&rows, infer_schema_length.map(|n| std::cmp::max(1, n)))
                 .map_err(PyPolarsErr::from)?;
         // replace inferred nulls with boolean and erase scale from inferred decimals
         let fields = schema.iter_fields().map(|mut fld| match fld.data_type() {
             DataType::Null => {
                 fld.coerce(DataType::Boolean);
```

### Comparing `polars_lts_cpu-0.17.2/src/datatypes.rs` & `polars_lts_cpu-0.17.3/src/datatypes.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/error.rs` & `polars_lts_cpu-0.17.3/src/error.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/file.rs` & `polars_lts_cpu-0.17.3/src/file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/lazy/apply.rs` & `polars_lts_cpu-0.17.3/src/lazy/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/lazy/dataframe.rs` & `polars_lts_cpu-0.17.3/src/lazy/dataframe.rs`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 use polars::time::*;
 use polars_core::cloud;
 use polars_core::frame::explode::MeltArgs;
 use polars_core::frame::UniqueKeepStrategy;
 use polars_core::prelude::*;
 use pyo3::exceptions::PyValueError;
 use pyo3::prelude::*;
-use pyo3::types::{PyDict, PyList};
+use pyo3::types::{PyBytes, PyDict, PyList};
 
 use crate::arrow_interop::to_rust::pyarrow_schema_to_rust;
 use crate::conversion::Wrap;
 use crate::dataframe::PyDataFrame;
 use crate::error::PyPolarsErr;
 use crate::file::get_file_like;
 use crate::lazy::dsl::PyExpr;
@@ -129,14 +129,36 @@
         PyLazyFrame { ldf }
     }
 }
 
 #[pymethods]
 #[allow(clippy::should_implement_trait)]
 impl PyLazyFrame {
+    pub fn __getstate__(&self, py: Python) -> PyResult<PyObject> {
+        // Used in pickle/pickling
+        let mut writer: Vec<u8> = vec![];
+        ciborium::ser::into_writer(&self.ldf.logical_plan, &mut writer)
+            .map_err(|e| PyPolarsErr::Other(format!("{}", e)))?;
+
+        Ok(PyBytes::new(py, &writer).to_object(py))
+    }
+
+    pub fn __setstate__(&mut self, py: Python, state: PyObject) -> PyResult<()> {
+        // Used in pickle/pickling
+        match state.extract::<&PyBytes>(py) {
+            Ok(s) => {
+                let lp: LogicalPlan = ciborium::de::from_reader(s.as_bytes())
+                    .map_err(|e| PyPolarsErr::Other(format!("{}", e)))?;
+                self.ldf = LazyFrame::from(lp);
+                Ok(())
+            }
+            Err(e) => Err(e),
+        }
+    }
+
     #[cfg(all(feature = "json", feature = "serde_json"))]
     pub fn write_json(&self, py_f: PyObject) -> PyResult<()> {
         let file = BufWriter::new(get_file_like(py_f, true)?);
         serde_json::to_writer(file, &self.ldf.logical_plan)
             .map_err(|err| PyValueError::new_err(format!("{err:?}")))?;
         Ok(())
     }
```

### Comparing `polars_lts_cpu-0.17.2/src/lazy/dsl.rs` & `polars_lts_cpu-0.17.3/src/lazy/dsl.rs`

 * *Files 1% similar despite different names*

```diff
@@ -183,16 +183,16 @@
     }
     pub fn first(&self) -> PyExpr {
         self.clone().inner.first().into()
     }
     pub fn last(&self) -> PyExpr {
         self.clone().inner.last().into()
     }
-    pub fn list(&self) -> PyExpr {
-        self.clone().inner.list().into()
+    pub fn implode(&self) -> PyExpr {
+        self.clone().inner.implode().into()
     }
     pub fn quantile(
         &self,
         quantile: PyExpr,
         interpolation: Wrap<QuantileInterpolOptions>,
     ) -> PyExpr {
         self.clone()
@@ -345,14 +345,18 @@
     pub fn var(&self, ddof: u8) -> PyExpr {
         self.clone().inner.var(ddof).into()
     }
     pub fn is_unique(&self) -> PyExpr {
         self.clone().inner.is_unique().into()
     }
 
+    pub fn approx_unique(&self) -> PyExpr {
+        self.clone().inner.approx_unique().into()
+    }
+
     pub fn is_first(&self) -> PyExpr {
         self.clone().inner.is_first().into()
     }
 
     pub fn explode(&self) -> PyExpr {
         self.clone().inner.explode().into()
     }
@@ -912,16 +916,16 @@
         self.inner.clone().str().extract_all(pat.inner).into()
     }
 
     pub fn count_match(&self, pat: &str) -> PyExpr {
         self.inner.clone().str().count_match(pat).into()
     }
 
-    pub fn strftime(&self, fmt: &str) -> PyExpr {
-        self.inner.clone().dt().strftime(fmt).into()
+    pub fn strftime(&self, format: &str) -> PyExpr {
+        self.inner.clone().dt().strftime(format).into()
     }
     pub fn str_split(&self, by: &str) -> PyExpr {
         self.inner.clone().str().split(by).into()
     }
     pub fn str_split_inclusive(&self, by: &str) -> PyExpr {
         self.inner.clone().str().split_inclusive(by).into()
     }
@@ -1095,16 +1099,24 @@
     }
 
     pub fn dt_cast_time_unit(&self, time_unit: Wrap<TimeUnit>) -> PyExpr {
         self.inner.clone().dt().cast_time_unit(time_unit.0).into()
     }
 
     #[cfg(feature = "timezones")]
-    pub fn dt_replace_time_zone(&self, time_zone: Option<String>) -> PyExpr {
-        self.inner.clone().dt().replace_time_zone(time_zone).into()
+    pub fn dt_replace_time_zone(
+        &self,
+        time_zone: Option<String>,
+        use_earliest: Option<bool>,
+    ) -> PyExpr {
+        self.inner
+            .clone()
+            .dt()
+            .replace_time_zone(time_zone, use_earliest)
+            .into()
     }
 
     #[cfg(feature = "timezones")]
     #[allow(deprecated)]
     pub fn dt_tz_localize(&self, time_zone: String) -> PyExpr {
         self.inner.clone().dt().tz_localize(time_zone).into()
     }
```

### Comparing `polars_lts_cpu-0.17.2/src/lazy/meta.rs` & `polars_lts_cpu-0.17.3/src/lazy/meta.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/lazy/mod.rs` & `polars_lts_cpu-0.17.3/src/lazy/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/lib.rs` & `polars_lts_cpu-0.17.3/src/lib.rs`

 * *Files 3% similar despite different names*

```diff
@@ -19,15 +19,14 @@
 mod batched_csv;
 pub mod conversion;
 pub mod dataframe;
 pub mod datatypes;
 pub mod error;
 pub mod file;
 pub mod lazy;
-mod list_construction;
 pub mod npy;
 #[cfg(feature = "object")]
 mod object;
 pub mod prelude;
 pub(crate) mod py_modules;
 pub mod series;
 mod set;
@@ -36,14 +35,16 @@
 pub mod utils;
 
 #[cfg(all(target_os = "linux", not(use_mimalloc)))]
 use jemallocator::Jemalloc;
 use lazy::ToExprs;
 #[cfg(any(not(target_os = "linux"), use_mimalloc))]
 use mimalloc::MiMalloc;
+#[cfg(feature = "object")]
+pub use object::register_object_builder;
 use polars_core::datatypes::{TimeUnit, TimeZone};
 use polars_core::prelude::{DataFrame, IntoSeries, IDX_DTYPE};
 use polars_core::POOL;
 use polars_rs::functions::{diag_concat_df, hor_concat_df};
 use polars_rs::prelude::Null;
 use pyo3::exceptions::PyValueError;
 use pyo3::panic::PanicException;
@@ -243,33 +244,40 @@
 #[pyfunction]
 fn concat_lst(s: Vec<dsl::PyExpr>) -> PyResult<dsl::PyExpr> {
     let s = s.into_iter().map(|e| e.inner).collect::<Vec<_>>();
     let expr = polars_rs::lazy::dsl::concat_lst(s).map_err(PyPolarsErr::from)?;
     Ok(expr.into())
 }
 
+macro_rules! set_unwrapped_or_0 {
+    ($($var:ident),+ $(,)?) => {
+        $(let $var = $var.map(|e| e.inner).unwrap_or(polars_rs::lazy::dsl::lit(0));)+
+    };
+}
+
 #[pyfunction]
 fn py_datetime(
     year: dsl::PyExpr,
     month: dsl::PyExpr,
     day: dsl::PyExpr,
     hour: Option<dsl::PyExpr>,
     minute: Option<dsl::PyExpr>,
     second: Option<dsl::PyExpr>,
     microsecond: Option<dsl::PyExpr>,
 ) -> dsl::PyExpr {
-    let hour = hour.map(|e| e.inner);
-    let minute = minute.map(|e| e.inner);
-    let second = second.map(|e| e.inner);
-    let microsecond = microsecond.map(|e| e.inner);
+    let year = year.inner;
+    let month = month.inner;
+    let day = day.inner;
+
+    set_unwrapped_or_0!(hour, minute, second, microsecond);
 
     let args = DatetimeArgs {
-        year: year.inner,
-        month: month.inner,
-        day: day.inner,
+        year,
+        month,
+        day,
         hour,
         minute,
         second,
         microsecond,
     };
 
     polars_rs::lazy::dsl::datetime(args).into()
@@ -283,23 +291,34 @@
     nanoseconds: Option<PyExpr>,
     microseconds: Option<PyExpr>,
     milliseconds: Option<PyExpr>,
     minutes: Option<PyExpr>,
     hours: Option<PyExpr>,
     weeks: Option<PyExpr>,
 ) -> dsl::PyExpr {
+    set_unwrapped_or_0!(
+        days,
+        seconds,
+        nanoseconds,
+        microseconds,
+        milliseconds,
+        minutes,
+        hours,
+        weeks,
+    );
+
     let args = DurationArgs {
-        days: days.map(|e| e.inner),
-        seconds: seconds.map(|e| e.inner),
-        nanoseconds: nanoseconds.map(|e| e.inner),
-        microseconds: microseconds.map(|e| e.inner),
-        milliseconds: milliseconds.map(|e| e.inner),
-        minutes: minutes.map(|e| e.inner),
-        hours: hours.map(|e| e.inner),
-        weeks: weeks.map(|e| e.inner),
+        days,
+        seconds,
+        nanoseconds,
+        microseconds,
+        milliseconds,
+        minutes,
+        hours,
+        weeks,
     };
 
     polars_rs::lazy::dsl::duration(args).into()
 }
 
 #[pyfunction]
 fn concat_df(dfs: &PyAny, py: Python) -> PyResult<PyDataFrame> {
@@ -699,9 +718,12 @@
     m.add_wrapped(wrap_pyfunction!(repeat)).unwrap();
     m.add_wrapped(wrap_pyfunction!(threadpool_size)).unwrap();
     m.add_wrapped(wrap_pyfunction!(arg_where)).unwrap();
     m.add_wrapped(wrap_pyfunction!(get_index_type)).unwrap();
     m.add_wrapped(wrap_pyfunction!(coalesce_exprs)).unwrap();
     m.add_wrapped(wrap_pyfunction!(set_float_fmt)).unwrap();
     m.add_wrapped(wrap_pyfunction!(get_float_fmt)).unwrap();
+    #[cfg(feature = "object")]
+    m.add_wrapped(wrap_pyfunction!(register_object_builder))
+        .unwrap();
     Ok(())
 }
```

### Comparing `polars_lts_cpu-0.17.2/src/npy.rs` & `polars_lts_cpu-0.17.3/src/npy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/object.rs` & `polars_lts_cpu-0.17.3/src/object.rs`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,16 @@
 use pyo3::prelude::*;
 
 use crate::prelude::ObjectValue;
 use crate::Wrap;
 
 pub(crate) const OBJECT_NAME: &str = "object";
 
-pub(crate) fn register_object_builder() {
+#[pyfunction]
+pub fn register_object_builder() {
     if !registry::is_object_builder_registered() {
         let object_builder = Box::new(|name: &str, capacity: usize| {
             Box::new(ObjectChunkedBuilder::<ObjectValue>::new(name, capacity))
                 as Box<dyn AnonymousObjectBuilder>
         });
 
         let object_converter = Arc::new(|av: AnyValue| {
```

### Comparing `polars_lts_cpu-0.17.2/src/series.rs` & `polars_lts_cpu-0.17.3/src/series.rs`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 use pyo3::types::{PyBytes, PyList};
 use pyo3::Python;
 
 use crate::apply::series::{call_lambda_and_extract, ApplyLambda};
 use crate::arrow_interop::to_rust::array_to_rust;
 use crate::dataframe::PyDataFrame;
 use crate::error::PyPolarsErr;
-use crate::list_construction::py_seq_to_list;
 use crate::prelude::*;
 use crate::py_modules::POLARS;
 use crate::set::set_at_idx;
 use crate::{apply_method_all_arrow_series2, arrow_interop, raise_err};
 
 #[pyclass]
 #[repr(transparent)]
@@ -257,16 +256,15 @@
         Ok(PySeries::new(s))
     }
 
     #[staticmethod]
     pub fn new_object(name: &str, val: Vec<ObjectValue>, _strict: bool) -> Self {
         #[cfg(feature = "object")]
         {
-            // object builder must be registered.
-            crate::object::register_object_builder();
+            // object builder must be registered. this is done on import
             let s = ObjectChunked::<ObjectValue>::new_from_vec(name, val).into_series();
             s.into()
         }
         #[cfg(not(feature = "object"))]
         {
             todo!()
         }
@@ -363,19 +361,14 @@
                 let series: Series =
                     std::convert::TryFrom::try_from((name, arr)).map_err(PyPolarsErr::from)?;
                 Ok(series.into())
             }
         }
     }
 
-    #[staticmethod]
-    pub fn new_list(name: &str, seq: &PyAny, dtype: Wrap<DataType>) -> PyResult<Self> {
-        py_seq_to_list(name, seq, &dtype.0).map(|s| s.into())
-    }
-
     pub fn estimated_size(&self) -> usize {
         self.series.estimated_size()
     }
 
     #[cfg(feature = "object")]
     pub fn get_object(&self, index: usize) -> PyObject {
         Python::with_gil(|py| {
@@ -1134,22 +1127,27 @@
 
     pub fn dot(&self, other: &PySeries) -> Option<f64> {
         self.series.dot(&other.series)
     }
 
     pub fn __getstate__(&self, py: Python) -> PyResult<PyObject> {
         // Used in pickle/pickling
-        Ok(PyBytes::new(py, &bincode::serialize(&self.series).unwrap()).to_object(py))
+        let mut writer: Vec<u8> = vec![];
+        ciborium::ser::into_writer(&self.series, &mut writer)
+            .map_err(|e| PyPolarsErr::Other(format!("{}", e)))?;
+
+        Ok(PyBytes::new(py, &writer).to_object(py))
     }
 
     pub fn __setstate__(&mut self, py: Python, state: PyObject) -> PyResult<()> {
         // Used in pickle/pickling
         match state.extract::<&PyBytes>(py) {
             Ok(s) => {
-                self.series = bincode::deserialize(s.as_bytes()).unwrap();
+                self.series = ciborium::de::from_reader(s.as_bytes())
+                    .map_err(|e| PyPolarsErr::Other(format!("{}", e)))?;
                 Ok(())
             }
             Err(e) => Err(e),
         }
     }
 
     pub fn skew(&self, bias: bool) -> PyResult<Option<f64>> {
```

### Comparing `polars_lts_cpu-0.17.2/src/set.rs` & `polars_lts_cpu-0.17.3/src/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/sql.rs` & `polars_lts_cpu-0.17.3/src/sql.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/src/utils.rs` & `polars_lts_cpu-0.17.3/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/README.md` & `polars_lts_cpu-0.17.3/tests/README.md`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/benchmark/groupby-datagen.R` & `polars_lts_cpu-0.17.3/tests/benchmark/groupby-datagen.R`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/benchmark/run_h2oai_benchmark.py` & `polars_lts_cpu-0.17.3/tests/benchmark/run_h2oai_benchmark.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/benchmark/test_release.py` & `polars_lts_cpu-0.17.3/tests/benchmark/test_release.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/docs/run_doctest.py` & `polars_lts_cpu-0.17.3/tests/docs/run_doctest.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/parametric/test_dataframe.py` & `polars_lts_cpu-0.17.3/tests/parametric/test_dataframe.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/parametric/test_lazyframe.py` & `polars_lts_cpu-0.17.3/tests/parametric/test_lazyframe.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/parametric/test_series.py` & `polars_lts_cpu-0.17.3/tests/parametric/test_series.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/parametric/test_testing.py` & `polars_lts_cpu-0.17.3/tests/parametric/test_testing.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,15 +13,14 @@
 
 import polars as pl
 from polars.testing.parametric import (
     column,
     columns,
     dataframes,
     series,
-    strategy_dtypes,
 )
 
 # TODO: make dtype categories flexible and available from datatypes module
 TEMPORAL_DTYPES = [pl.Datetime, pl.Date, pl.Time, pl.Duration]
 
 
 @given(df=dataframes(), lf=dataframes(lazy=True), srs=series())
@@ -51,15 +50,15 @@
     assert 3 <= len(df2) <= 8
 
     assert s1.len() == 5
     assert 3 <= s2.len() <= 8
     assert s1.name == ""
     assert s2.name == "col"
 
-    from polars.testing._parametric import MAX_COLS
+    from polars.testing.parametric.primitives import MAX_COLS
 
     assert 0 <= len(columns(None)) <= MAX_COLS
 
 
 @given(
     lf=dataframes(
         # generate lazyframes with at least one row
@@ -96,37 +95,34 @@
     xyz = {"x", "y", "z"}
     assert all(v in xyz for v in df["d"].to_list())
 
 
 @given(
     df=dataframes(allowed_dtypes=TEMPORAL_DTYPES, max_size=1, max_cols=5),
     lf=dataframes(excluded_dtypes=TEMPORAL_DTYPES, max_size=1, max_cols=5, lazy=True),
-    s1=series(max_size=1),
-    s2=series(dtype=pl.Boolean, max_size=1),
-    s3=series(allowed_dtypes=TEMPORAL_DTYPES, max_size=1),
-    s4=series(excluded_dtypes=TEMPORAL_DTYPES, max_size=1),
+    s1=series(dtype=pl.Boolean, max_size=1),
+    s2=series(allowed_dtypes=TEMPORAL_DTYPES, max_size=1),
+    s3=series(excluded_dtypes=TEMPORAL_DTYPES, max_size=1),
 )
 @settings(max_examples=50)
 def test_strategy_dtypes(
     df: pl.DataFrame,
     lf: pl.LazyFrame,
     s1: pl.Series,
     s2: pl.Series,
     s3: pl.Series,
-    s4: pl.Series,
 ) -> None:
     # dataframe, lazyframe
     assert all(tp in TEMPORAL_DTYPES for tp in df.dtypes)
     assert all(tp not in TEMPORAL_DTYPES for tp in lf.dtypes)
 
     # series
-    assert s1.dtype in strategy_dtypes
-    assert s2.dtype == pl.Boolean
-    assert s3.dtype in TEMPORAL_DTYPES
-    assert s4.dtype not in TEMPORAL_DTYPES
+    assert s1.dtype == pl.Boolean
+    assert s2.dtype in TEMPORAL_DTYPES
+    assert s3.dtype not in TEMPORAL_DTYPES
 
 
 @given(
     # set global, per-column, and overridden null-probabilities
     s=series(size=50, null_probability=0.10),
     df1=dataframes(cols=1, size=50, null_probability=0.30),
     df2=dataframes(cols=2, size=50, null_probability={"col0": 0.70}),
@@ -216,18 +212,17 @@
                 series(name="colx", null_probability=invalid_probability).example()
             with pytest.raises(InvalidArgument, match="between 0.0 and 1.0"):
                 dataframes(
                     cols=column(None),  # type: ignore[arg-type]
                     null_probability=invalid_probability,
                 ).example()
 
-    for unsupported_type in (pl.List, pl.Struct):
-        # TODO: add support for compound types
-        with pytest.raises(InvalidArgument, match=f"for {unsupported_type} type"):
-            column("colx", dtype=unsupported_type)
+    with pytest.raises(InvalidArgument):
+        # TODO: add support for remaining compound types
+        column("colx", dtype=pl.Struct)
 
     with pytest.raises(InvalidArgument, match="not a valid polars datatype"):
         columns(["colx", "coly"], dtype=pl.DataFrame)  # type: ignore[arg-type]
 
     with pytest.raises(InvalidArgument, match=r"\d dtypes for \d names"):
         columns(["colx", "coly"], dtype=[pl.Date, pl.Date, pl.Datetime])
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/conftest.py` & `polars_lts_cpu-0.17.3/tests/unit/conftest.py`

 * *Files 3% similar despite different names*

```diff
@@ -68,15 +68,15 @@
             f"{T}%H:%M",
             f"{T}%H%M",
         ]
         + [f"{T}%H:%M:%S.{fraction}" for fraction in ["%9f", "%6f", "%3f"]]
         + [f"{T}%H%M%S.{fraction}" for fraction in ["%9f", "%6f", "%3f"]]
         + [""]
     ):
-        for date_sep in ("/", "-", ""):
+        for date_sep in ("/", "-"):
             fmt = f"%Y{date_sep}%m{date_sep}%d{hms}"
             ISO8601_FORMATS_DATETIME.append(fmt)
 
 
 @pytest.fixture(params=ISO8601_FORMATS_DATETIME)
 def iso8601_format_datetime(request: pytest.FixtureRequest) -> list[str]:
     return cast(List[str], request.param)
@@ -91,27 +91,27 @@
             f"{T}%H%M%S",
             f"{T}%H:%M",
             f"{T}%H%M",
         ]
         + [f"{T}%H:%M:%S.{fraction}" for fraction in ["%9f", "%6f", "%3f"]]
         + [f"{T}%H%M%S.{fraction}" for fraction in ["%9f", "%6f", "%3f"]]
     ):
-        for date_sep in ("/", "-", ""):
+        for date_sep in ("/", "-"):
             fmt = f"%Y{date_sep}%m{date_sep}%d{hms}%#z"
             ISO8601_TZ_AWARE_FORMATS_DATETIME.append(fmt)
 
 
 @pytest.fixture(params=ISO8601_TZ_AWARE_FORMATS_DATETIME)
 def iso8601_tz_aware_format_datetime(request: pytest.FixtureRequest) -> list[str]:
     return cast(List[str], request.param)
 
 
 ISO8601_FORMATS_DATE = []
 
-for date_sep in ("/", "-", ""):
+for date_sep in ("/", "-"):
     fmt = f"%Y{date_sep}%m{date_sep}%d"
     ISO8601_FORMATS_DATE.append(fmt)
 
 
 @pytest.fixture(params=ISO8601_FORMATS_DATE)
 def iso8601_format_date(request: pytest.FixtureRequest) -> list[str]:
     return cast(List[str], request.param)
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_bool.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_bool.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_categorical.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_decimal.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_decimal.py`

 * *Files 11% similar despite different names*

```diff
@@ -88,7 +88,12 @@
                 D("2"),
             ],
         }
     )
     assert df.with_columns(pl.col("decimals").cast(pl.Float32).alias("b2")).to_dict(
         False
     ) == {"decimals": [D("2"), D("2")], "b2": [2.0, 2.0]}
+
+
+def test_decimal_scale_precision_roundtrip(monkeypatch: Any) -> None:
+    monkeypatch.setenv("POLARS_ACTIVATE_DECIMAL", "1")
+    assert pl.from_arrow(pl.Series("dec", [D("10.0")]).to_arrow()).item() == D("10.0")
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_list.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_list.py`

 * *Files 1% similar despite different names*

```diff
@@ -262,15 +262,15 @@
     assert df.with_columns(
         [pl.lit(None).cast(pl.Int64).is_in(empty_list).alias("in_empty_list")]
     ).to_dict(False) == {"in_empty_list": [False]}
 
 
 def test_inner_type_categorical_on_rechunk() -> None:
     df = pl.DataFrame({"cats": ["foo", "bar"]}).select(
-        pl.col(pl.Utf8).cast(pl.Categorical).list()
+        pl.col(pl.Utf8).cast(pl.Categorical).implode()
     )
 
     assert pl.concat([df, df], rechunk=True).dtypes == [pl.List(pl.Categorical)]
 
 
 def test_groupby_list_column() -> None:
     df = (
@@ -349,15 +349,15 @@
         "group": [1, 2, 3],
         "value": [[["a"]], [["b"], ["c"]], [["d"]]],
     }
 
     # nested list
     assert df.groupby("group").agg(
         [
-            pl.concat_list(pl.col("value").list()).alias("result"),
+            pl.concat_list(pl.col("value").implode()).alias("result"),
         ]
     ).sort("group").to_dict(False) == {
         "group": [1, 2, 3],
         "result": [[["a"]], [["b", "c"]], [["d"]]],
     }
 
 
@@ -366,15 +366,15 @@
         pl.DataFrame({"a": [1, 2, 3]}).with_columns(pl.concat_list([]))
 
 
 def test_flat_aggregation_to_list_conversion_6918() -> None:
     df = pl.DataFrame({"a": [1, 2, 2], "b": [[0, 1], [2, 3], [4, 5]]})
 
     assert df.groupby("a", maintain_order=True).agg(
-        pl.concat_list([pl.col("b").arr.get(i).mean().list() for i in range(2)])
+        pl.concat_list([pl.col("b").arr.get(i).mean().implode() for i in range(2)])
     ).to_dict(False) == {"a": [1, 2], "b": [[[0.0, 1.0]], [[3.0, 4.0]]]}
 
 
 def test_concat_list_with_lit() -> None:
     df = pl.DataFrame({"a": [1, 2, 3]})
 
     assert df.select(pl.concat_list([pl.col("a"), pl.lit(1)]).alias("a")).to_dict(
@@ -459,9 +459,15 @@
 
 def test_fill_null_empty_list() -> None:
     assert pl.Series([["a"], None]).fill_null([]).to_list() == [["a"], []]
 
 
 def test_nested_logical() -> None:
     assert pl.select(
-        pl.lit(pl.Series(["a", "b"], dtype=pl.Categorical)).list().list()
+        pl.lit(pl.Series(["a", "b"], dtype=pl.Categorical)).implode().implode()
     ).to_dict(False) == {"": [[["a", "b"]]]}
+
+
+def test_null_list_construction_and_materialization() -> None:
+    s = pl.Series([None, []])
+    assert s.dtype == pl.List(pl.Null)
+    assert s.to_list() == [None, []]
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_object.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_object.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_struct.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_struct.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 import typing
 from dataclasses import dataclass
-from datetime import datetime
+from datetime import datetime, time
 
 import pandas as pd
 import pyarrow as pa
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
@@ -898,7 +898,26 @@
     )
     s2 = (
         pl.DataFrame({"x": [4, 3, 5, 9], "y": [0, 7, 6, 2]})
         .select(pl.struct(["x", "y"]))
         .to_series()
     )
     assert s1.is_in(s2).to_list() == [True, False, False, True]
+
+
+@typing.no_type_check
+def test_nested_struct_logicals() -> None:
+    # single nested
+    payload = [[{"a": time(10)}], [{"a": time(10)}]]
+    assert pl.Series(payload).to_list() == payload
+    # double nested
+    payload = [[[{"a": time(10)}]], [[{"a": time(10)}]]]
+    assert pl.Series(payload).to_list() == payload
+
+
+def test_struct_list_cat_8235() -> None:
+    df = pl.DataFrame(
+        {"values": [["a", "b", "c"]]}, schema={"values": pl.List(pl.Categorical)}
+    )
+    assert df.select(pl.struct("values")).to_dict(False) == {
+        "values": [{"values": ["a", "b", "c"]}]
+    }
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/datatypes/test_temporal.py` & `polars_lts_cpu-0.17.3/tests/unit/datatypes/test_temporal.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pytest
 
 import polars as pl
 from polars.datatypes import DATETIME_DTYPES, DTYPE_TEMPORAL_UNITS, TEMPORAL_DTYPES
-from polars.exceptions import ComputeError, PolarsPanicError
+from polars.exceptions import ArrowError, ComputeError, PolarsPanicError
 from polars.testing import (
     assert_frame_equal,
     assert_series_equal,
     assert_series_not_equal,
 )
 
 if TYPE_CHECKING:
@@ -170,18 +170,16 @@
             "timestamp": ["2021-02-01", "2021-03-1", "2850-04-1"],
             "guild": [1, 2, 3],
             "char": ["a", "a", "b"],
         }
     )
     out = (
         df.with_columns(
-            [
-                pl.col("timestamp").str.strptime(pl.Date, fmt="%Y-%m-%d"),
-            ]
-        ).with_columns([pl.col("timestamp").diff().list().over("char")])
+            pl.col("timestamp").str.strptime(pl.Date, format="%Y-%m-%d"),
+        ).with_columns(pl.col("timestamp").diff().implode().over("char"))
     )["timestamp"]
     assert (out[0] == out[1]).all()
 
 
 def test_from_pydatetime() -> None:
     datetimes = [
         datetime(2021, 1, 1),
@@ -543,15 +541,15 @@
     df = pl.DataFrame({"misc": ["x"]}).with_columns(
         pl.date_range(
             date(2000, 1, 1),
             date(2023, 8, 31),
             interval="987d",
             lazy=True,
         )
-        .list()
+        .implode()
         .alias("dts")
     )
     assert df.rows() == [
         (
             "x",
             [
                 date(2000, 1, 1),
@@ -578,15 +576,15 @@
 @pytest.mark.parametrize("high", ["stop", pl.col("stop")])
 def test_date_range_lazy_with_expressions(
     low: str | pl.Expr, high: str | pl.Expr
 ) -> None:
     ldf = (
         pl.DataFrame({"start": [date(2015, 6, 30)], "stop": [date(2022, 12, 31)]})
         .with_columns(
-            pl.date_range(low, high, interval="678d", lazy=True).list().alias("dts")
+            pl.date_range(low, high, interval="678d", lazy=True).implode().alias("dts")
         )
         .lazy()
     )
 
     assert ldf.collect().rows() == [
         (
             date(2015, 6, 30),
@@ -795,15 +793,15 @@
         pl.DataFrame(
             data={
                 "timestamp": ["1970-01-01 00:00:00+01:00", "1970-01-01 01:00:00+01:00"],
                 "value": [1, 1],
             }
         )
         .with_columns(
-            pl.col("timestamp").str.strptime(pl.Datetime, fmt="%Y-%m-%d %H:%M:%S%:z")
+            pl.col("timestamp").str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S%:z")
         )
         .with_columns(
             pl.col("timestamp").dt.convert_time_zone("UTC").alias("timestamp_utc")
         )
     )
     result = df.groupby_dynamic(
         index_column="timestamp", every="1d", closed="left"
@@ -1299,15 +1297,15 @@
                 "val_mean": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0],
             }
         )
         assert_frame_equal(result, expected)
 
 
 def test_asof_join() -> None:
-    fmt = "%F %T%.3f"
+    format = "%F %T%.3f"
     dates = [
         "2016-05-25 13:30:00.023",
         "2016-05-25 13:30:00.023",
         "2016-05-25 13:30:00.030",
         "2016-05-25 13:30:00.041",
         "2016-05-25 13:30:00.048",
         "2016-05-25 13:30:00.049",
@@ -1322,15 +1320,15 @@
         "GOOG",
         "AAPL",
         "GOOG",
         "MSFT",
     ]
     quotes = pl.DataFrame(
         {
-            "dates": pl.Series(dates).str.strptime(pl.Datetime, fmt=fmt),
+            "dates": pl.Series(dates).str.strptime(pl.Datetime, format=format),
             "ticker": ticker,
             "bid": [720.5, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
         }
     )
     dates = [
         "2016-05-25 13:30:00.023",
         "2016-05-25 13:30:00.038",
@@ -1343,15 +1341,15 @@
         "MSFT",
         "GOOG",
         "GOOG",
         "AAPL",
     ]
     trades = pl.DataFrame(
         {
-            "dates": pl.Series(dates).str.strptime(pl.Datetime, fmt=fmt),
+            "dates": pl.Series(dates).str.strptime(pl.Datetime, format=format),
             "ticker": ticker,
             "bid": [51.95, 51.95, 720.77, 720.92, 98.0],
         }
     )
     assert trades.schema == {
         "dates": pl.Datetime("ms"),
         "ticker": pl.Utf8,
@@ -1922,14 +1920,36 @@
 ) -> None:
     ts = pl.Series(["2020-01-01"]).str.strptime(pl.Datetime(time_unit))
     result = ts.dt.replace_time_zone(from_tz).dt.replace_time_zone(to_tz).item()
     expected = datetime(2020, 1, 1, 0, 0, tzinfo=tzinfo)
     assert result == expected
 
 
+def test_strptime_subseconds_datetime() -> None:
+    with pytest.raises(ValueError, match="not supported"):
+        pl.Series(["2023-02-05T05:10:10.074000"]).str.strptime(
+            pl.Datetime, "%Y-%m-%dT%H:%M:%S.%f"
+        )
+    result = (
+        pl.Series(["2023-02-05T05:10:10.074000"])
+        .str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%.f")
+        .item()
+    )
+    expected = datetime(2023, 2, 5, 5, 10, 10, 74000)
+    assert result == expected
+
+
+def test_strptime_subseconds_time() -> None:
+    with pytest.raises(ValueError, match="not supported"):
+        pl.Series(["05:10:10.074000"]).str.strptime(pl.Time, "%H:%M:%S.%f")
+    result = pl.Series(["05:10:10.074000"]).str.strptime(pl.Time, "%H:%M:%S%.f").item()
+    expected = time(5, 10, 10, 74000)
+    assert result == expected
+
+
 def test_strptime_with_tz() -> None:
     result = (
         pl.Series(["2020-01-01 03:00:00"])
         .str.strptime(pl.Datetime("us", "Africa/Monrovia"))
         .item()
     )
     assert result == datetime(2020, 1, 1, 3, tzinfo=ZoneInfo(key="Africa/Monrovia"))
@@ -2215,14 +2235,45 @@
         "date": [
             datetime(2022, 1, 1, 0, 0, tzinfo=ZoneInfo(key="America/New_York")),
             datetime(2022, 1, 2, 0, 0, tzinfo=ZoneInfo(key="America/New_York")),
         ]
     }
 
 
+@pytest.mark.parametrize(
+    ("use_earliest", "expected"),
+    [
+        (
+            False,
+            datetime(2018, 10, 28, 2, 30, fold=0, tzinfo=ZoneInfo("Europe/Brussels")),
+        ),
+        (
+            True,
+            datetime(2018, 10, 28, 2, 30, fold=1, tzinfo=ZoneInfo("Europe/Brussels")),
+        ),
+    ],
+)
+def test_replace_time_zone_ambiguous_with_use_earliest(
+    use_earliest: bool, expected: datetime
+) -> None:
+    ts = pl.Series(["2018-10-28 02:30:00"]).str.strptime(pl.Datetime)
+    result = ts.dt.replace_time_zone(
+        "Europe/Brussels", use_earliest=use_earliest
+    ).item()
+    assert result == expected
+
+
+def test_replace_time_zone_ambiguous_raises() -> None:
+    ts = pl.Series(["2018-10-28 02:30:00"]).str.strptime(pl.Datetime)
+    with pytest.raises(
+        ArrowError, match="Please use `use_earliest` to tell how it should be localized"
+    ):
+        ts.dt.replace_time_zone("Europe/Brussels")
+
+
 def test_unlocalize() -> None:
     tz_naive = pl.Series(["2020-01-01 03:00:00"]).str.strptime(pl.Datetime)
     tz_aware = tz_naive.dt.replace_time_zone("UTC").dt.convert_time_zone(
         "Europe/Brussels"
     )
     result = tz_aware.dt.replace_time_zone(None).item()
     assert result == datetime(2020, 1, 1, 4)
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json` & `polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json` & `polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet` & `polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet` & `polars_lts_cpu-0.17.3/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/example.xlsx` & `polars_lts_cpu-0.17.3/tests/unit/io/files/example.xlsx`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.ipc` & `polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.ipc`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.ndjson` & `polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.ndjson`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/foods1.parquet` & `polars_lts_cpu-0.17.3/tests/unit/io/files/foods1.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.ipc` & `polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.ipc`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.ndjson` & `polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.ndjson`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/foods2.parquet` & `polars_lts_cpu-0.17.3/tests/unit/io/files/foods2.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/files/small.parquet` & `polars_lts_cpu-0.17.3/tests/unit/io/files/small.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_avro.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_avro.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 import io
-import tempfile
 from pathlib import Path
 from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
+from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
     from polars.type_aliases import AvroCompression
 
 COMPRESSIONS = ["uncompressed", "snappy", "deflate"]
 
 
@@ -30,15 +30,15 @@
     read_df = pl.read_avro(buf)
     assert_frame_equal(example_df, read_df)
 
 
 @pytest.mark.write_disk()
 @pytest.mark.parametrize("compression", COMPRESSIONS)
 def test_from_to_file(example_df: pl.DataFrame, compression: AvroCompression) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.avro"
         example_df.write_avro(file_path, compression=compression)
         df_read = pl.read_avro(file_path)
 
     assert_frame_equal(example_df, df_read)
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_csv.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_csv.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from __future__ import annotations
 
 import gzip
 import io
-import tempfile
 import textwrap
 import typing
 import zlib
 from datetime import date, datetime, time, timedelta, timezone
 from pathlib import Path
 from typing import TYPE_CHECKING
 
@@ -16,14 +15,15 @@
 import polars as pl
 from polars.exceptions import ComputeError, NoDataError
 from polars.testing import (
     assert_frame_equal,
     assert_frame_equal_local_categoricals,
     assert_series_equal,
 )
+from polars.testing._tempdir import TemporaryDirectory
 from polars.utils.various import normalise_filepath
 
 if TYPE_CHECKING:
     from polars.type_aliases import TimeUnit
 
 
 @pytest.fixture()
@@ -59,15 +59,15 @@
         assert_frame_equal_local_categoricals(df.select(["time", "cat"]), read_df)
 
 
 @pytest.mark.write_disk()
 def test_to_from_file(df_no_lists: pl.DataFrame) -> None:
     df = df_no_lists.drop("strings_nulls")
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.csv"
         df.write_csv(file_path)
         read_df = pl.read_csv(file_path, try_parse_dates=True)
 
     read_df = read_df.with_columns(
         [pl.col("cat").cast(pl.Categorical), pl.col("time").cast(pl.Time)]
     )
@@ -257,18 +257,18 @@
     assert df.dtypes == [pl.Datetime, pl.Float64, pl.Float64]
 
 
 def test_datetime_parsing_default_formats() -> None:
     csv = textwrap.dedent(
         """\
         ts_dmy,ts_dmy_f,ts_dmy_p
-        01/01/21 00:00:00,31-01-2021T00:00:00.123,31-01-2021 11:00 AM
-        01/01/21 00:15:00,31-01-2021T00:15:00.123,31-01-2021 01:00 PM
-        01/01/21 00:30:00,31-01-2021T00:30:00.123,31-01-2021 01:15 PM
-        01/01/21 00:45:00,31-01-2021T00:45:00.123,31-01-2021 01:30 PM
+        01/01/21 00:00:00,31-01-2021T00:00:00.123,31-01-2021 11:00
+        01/01/21 00:15:00,31-01-2021T00:15:00.123,31-01-2021 01:00
+        01/01/21 00:30:00,31-01-2021T00:30:00.123,31-01-2021 01:15
+        01/01/21 00:45:00,31-01-2021T00:45:00.123,31-01-2021 01:30
         """
     )
 
     f = io.StringIO(csv)
     df = pl.read_csv(f, try_parse_dates=True)
     assert df.dtypes == [pl.Datetime, pl.Datetime, pl.Datetime]
 
@@ -371,15 +371,15 @@
     bts = (
         b"Value1,Value2,Value3,Value4,Region\n"
         b"-30,7.5,2578,1,\xa5x\xa5_\n-32,7.97,3006,1,\xa5x\xa4\xa4\n"
         b"-31,8,3242,2,\xb7s\xa6\xcb\n-33,7.97,3300,3,\xb0\xaa\xb6\xaf\n"
         b"-20,7.91,3384,4,\xac\xfc\xb0\xea\n"
     )
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "encoding.csv"
         with open(file_path, "wb") as f:
             f.write(bts)
 
         file_str = str(file_path)
         bytesio = io.BytesIO(bts)
 
@@ -743,14 +743,15 @@
     2021-10-10,2021-10-10
     """
     )
     df = pl.read_csv(data.encode(), try_parse_dates=True)
     assert df.null_count().row(0) == (0, 0)
 
 
+@pytest.mark.xfail(reason="Not yet supported, GH8213", strict=True)
 def test_tz_aware_try_parse_dates() -> None:
     data = (
         "a,b,c,d\n"
         "2020-01-01T01:00:00+01:00,2021-04-28T00:00:00+02:00,2021-03-28T00:00:00+01:00,2\n"
         "2020-01-01T02:00:00+01:00,2021-04-29T00:00:00+02:00,2021-03-29T00:00:00+02:00,3\n"
     )
     result = pl.read_csv(io.StringIO(data), try_parse_dates=True)
@@ -780,15 +781,15 @@
     df_read = pl.read_csv(f)
     assert_frame_equal(df_read, df)
 
 
 @pytest.mark.write_disk()
 def test_glob_csv(df_no_lists: pl.DataFrame) -> None:
     df = df_no_lists.drop("strings_nulls")
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.csv"
         df.write_csv(file_path)
 
         path_glob = Path(temp_dir) / "small*.csv"
         assert pl.scan_csv(path_glob).collect().shape == (3, 11)
         assert pl.read_csv(path_glob).shape == (3, 11)
 
@@ -1222,15 +1223,15 @@
     assert pl.read_csv(io.StringIO(csv), n_rows=N).height == 4999
 
 
 @pytest.mark.write_disk()
 def test_csv_scan_categorical() -> None:
     N = 5_000
     df = pl.DataFrame({"x": ["A"] * N})
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "test_csv_scan_categorical.csv"
         df.write_csv(file_path)
         result = pl.scan_csv(file_path, dtypes={"x": pl.Categorical}).collect()
 
     assert result["x"].dtype == pl.Categorical
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_database.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_database.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 import os
 import sys
-import tempfile
 from datetime import date
 from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
+from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
     from polars.type_aliases import (
         DbReadEngine,
         DbWriteEngine,
         DbWriteMode,
     )
@@ -93,39 +93,26 @@
     ],
 )
 def test_read_database(
     engine: DbReadEngine,
     expected_dtypes: dict[str, pl.DataType],
     expected_dates: list[date | str],
 ) -> None:
-    try:
-        with tempfile.TemporaryDirectory(prefix=f"pl_{engine}_") as tmpdir_name:
-            test_db = os.path.join(tmpdir_name, "test.db")
-            create_temp_sqlite_db(test_db)
-
-            df = pl.read_database(
-                connection_uri=f"sqlite:///{test_db}",
-                query="SELECT * FROM test_data",
-                engine=engine,
-            )
-            assert df.schema == expected_dtypes
-            assert df.shape == (2, 4)
-            assert df["date"].to_list() == expected_dates
-
-    except (PermissionError, NotADirectoryError):
-        # Note: Windows can sometimes lock files without a great reason; the situation
-        # is bad enough that python 3.10 added a dedicated 'ignore_cleanup_errors'
-        # parameter to TemporaryDirectory just to handle it, and go out of their
-        # way to mention Windows in the associated docs... ;p
-        # ----------------------------------------------------------------------------
-        # https://docs.python.org/3/library/tempfile.html#tempfile.TemporaryDirectory
-        # ----------------------------------------------------------------------------
-        print(f"tempdir cleanup failed: {tmpdir_name}")
-        if os.name != "nt":
-            raise
+    with TemporaryDirectory(prefix=f"pl_{engine}_") as tmpdir_name:
+        test_db = os.path.join(tmpdir_name, "test.db")
+        create_temp_sqlite_db(test_db)
+
+        df = pl.read_database(
+            connection_uri=f"sqlite:///{test_db}",
+            query="SELECT * FROM test_data",
+            engine=engine,
+        )
+        assert df.schema == expected_dtypes
+        assert df.shape == (2, 4)
+        assert df["date"].to_list() == expected_dates
 
 
 @pytest.mark.parametrize(
     ("engine", "query", "database", "err"),
     [
         pytest.param(
             "not_engine",
@@ -149,15 +136,15 @@
             id="Unavailable database for adbc.",
         ),
     ],
 )
 def test_read_database_exceptions(
     engine: DbReadEngine, query: str, database: str, err: str
 ) -> None:
-    with tempfile.TemporaryDirectory() as tmpdir_name:
+    with TemporaryDirectory() as tmpdir_name:
         test_db = os.path.join(tmpdir_name, "test.db")
         create_temp_sqlite_db(test_db)
 
         with pytest.raises(ValueError, match=err):
             pl.read_database(
                 connection_uri=f"{database}:///{test_db}",
                 query=query,
@@ -188,15 +175,15 @@
             ),
         ),
     ],
 )
 def test_write_database(
     engine: DbWriteEngine, mode: DbWriteMode, sample_df: pl.DataFrame
 ) -> None:
-    with tempfile.TemporaryDirectory() as tmpdir_name:
+    with TemporaryDirectory() as tmpdir_name:
         test_db = os.path.join(tmpdir_name, "test.db")
 
         sample_df.write_database(
             table_name="test_data",
             connection_uri=f"sqlite:///{test_db}",
             if_exists="replace",
             engine=engine,
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_delta.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_delta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_excel.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_excel.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_ipc.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_ipc.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 import io
 import sys
-import tempfile
 from pathlib import Path
 from typing import TYPE_CHECKING
 
 import pandas as pd
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_frame_equal_local_categoricals
+from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
     from polars.type_aliases import IpcCompression
 
 COMPRESSIONS = ["uncompressed", "lz4", "zstd"]
 
 
@@ -46,27 +46,27 @@
     ],
 )
 @pytest.mark.parametrize("path_type", [str, Path])
 @pytest.mark.write_disk()
 def test_from_to_file(
     df: pl.DataFrame, compression: IpcCompression, path_type: type[str] | type[Path]
 ) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.ipc"
         file_path_cast = path_type(file_path)
         df.write_ipc(file_path_cast, compression=compression)
         df_read = pl.read_ipc(file_path_cast, use_pyarrow=False)
 
     assert_frame_equal_local_categoricals(df, df_read)
 
 
 @pytest.mark.write_disk()
 @pytest.mark.xfail(sys.platform == "win32", reason="Does not work on Windows")
 def test_select_columns_from_file(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.ipc"
         df.write_ipc(file_path)
         df_read = pl.read_ipc(file_path, columns=["bools"])
 
     assert df_read.columns == ["bools"]
 
 
@@ -122,15 +122,15 @@
 @pytest.mark.parametrize("compression", COMPRESSIONS)
 @pytest.mark.parametrize("path_type", [str, Path])
 def test_ipc_schema_from_file(
     df_no_lists: pl.DataFrame,
     compression: IpcCompression,
     path_type: type[str] | type[Path],
 ) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.ipc"
         file_path_cast = path_type(file_path)
         df_no_lists.write_ipc(file_path_cast, compression=compression)
         schema = pl.read_ipc_schema(file_path_cast)
 
     expected = {
         "bools": pl.Boolean,
@@ -165,15 +165,15 @@
     # read file into polars; the specified column order is no longer respected
     assert pl.read_ipc(f, columns=columns).columns == columns
 
 
 @pytest.mark.write_disk()
 @pytest.mark.xfail(sys.platform == "win32", reason="Does not work on Windows")
 def test_glob_ipc(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.ipc"
         df.write_ipc(file_path)
 
         file_path_glob = Path(temp_dir) / "small*.ipc"
 
         result_scan = pl.scan_ipc(file_path_glob).collect()
         result_read = pl.read_ipc(file_path_glob, use_pyarrow=False)
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_json.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_json.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 from __future__ import annotations
 
 import io
-import tempfile
 from pathlib import Path
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_frame_equal_local_categoricals
+from polars.testing._tempdir import TemporaryDirectory
 
 
 @pytest.mark.parametrize("buf", [io.BytesIO(), io.StringIO()])
 def test_to_from_buffer(df: pl.DataFrame, buf: io.IOBase) -> None:
     df.write_json(buf)
     buf.seek(0)
     read_df = pl.read_json(buf)
     assert_frame_equal_local_categoricals(df, read_df)
 
 
 @pytest.mark.write_disk()
 def test_to_from_file(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.json"
         df.write_json(file_path)
         out = pl.read_json(file_path)
 
     assert_frame_equal_local_categoricals(df, out)
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_csv.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_csv.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
-import tempfile
 from pathlib import Path
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.exceptions import PolarsPanicError
 from polars.testing import assert_frame_equal
+from polars.testing._tempdir import TemporaryDirectory
 
 
 @pytest.fixture()
 def foods_file_path(io_files_path: Path) -> Path:
     return io_files_path / "foods1.csv"
 
 
@@ -28,15 +28,15 @@
 
 
 @pytest.mark.write_disk()
 def test_invalid_utf8() -> None:
     np.random.seed(1)
     bts = bytes(np.random.randint(0, 255, 200))
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "nonutf8.csv"
         with open(file_path, "wb") as f:
             f.write(bts)
 
         a = pl.read_csv(file_path, has_header=False, encoding="utf8-lossy")
         b = pl.scan_csv(file_path, has_header=False, encoding="utf8-lossy").collect()
 
@@ -176,15 +176,15 @@
 def test_scan_slice_streaming(foods_file_path: Path) -> None:
     df = pl.scan_csv(foods_file_path).head(5).collect(streaming=True)
     assert df.shape == (5, 4)
 
 
 @pytest.mark.write_disk()
 def test_glob_skip_rows() -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         for i in range(2):
             file_path = Path(temp_dir) / f"test_{i}.csv"
             with open(file_path, "w") as f:
                 f.write(
                     f"""
 metadata goes here
 file number {i}
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_ipc.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_ipc.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_json.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_json.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from __future__ import annotations
 
-import tempfile
 from pathlib import Path
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
+from polars.testing._tempdir import TemporaryDirectory
 
 
 @pytest.fixture()
 def foods_ndjson_path(io_files_path: Path) -> Path:
     return io_files_path / "foods1.ndjson"
 
 
@@ -48,15 +48,15 @@
 {"id": 4, "text":"\"'/\n...","date":"2009-05-19 21:07:53"}
 {"id": 5, "text":".h\"h1hh\\21hi1e2emm...","date":"2009-05-19 21:07:53"}
 {"id": 6, "text":"xxxx....","date":"2009-05-19 21:07:53"}
 {"id": 7, "text":".\"quoted text\".","date":"2009-05-19 21:07:53"}
 """
     json_bytes = bytes(json, "utf-8")
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "escape_chars.json"
         with open(file_path, "wb") as f:
             f.write(json_bytes)
         actual = pl.scan_ndjson(file_path).select(["id", "text"]).collect()
     expected = pl.DataFrame(
         {
             "id": [1, 10, 0, 1, 2, 3, 4, 5, 6, 7],
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_lazy_parquet.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_lazy_parquet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
-import tempfile
 from pathlib import Path
 from typing import TYPE_CHECKING, Any
 
 import pandas as pd
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
+from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
     from polars.type_aliases import ParallelStrategy
 
 
 @pytest.fixture()
 def parquet_file_path(io_files_path: Path) -> Path:
@@ -66,15 +66,15 @@
                 "bookC",
             ],
             "transaction_id": [1, 2, 3, 4, 5, 6, 7, 8],
             "user": ["bob", "bob", "bob", "tim", "lucy", "lucy", "lucy", "lucy"],
         }
     ).with_columns(pl.col("book").cast(pl.Categorical))
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "books.parquet"
         df.write_parquet(file_path, statistics=True)
 
         parallel_options: list[ParallelStrategy] = [
             "auto",
             "columns",
             "row_groups",
@@ -88,24 +88,24 @@
             )
         assert df.shape == (4, 3)
 
 
 @pytest.mark.write_disk()
 def test_null_parquet() -> None:
     df = pl.DataFrame([pl.Series("foo", [], dtype=pl.Int8)])
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "null.parquet"
         df.write_parquet(file_path)
         out = pl.read_parquet(file_path)
     assert_frame_equal(out, df)
 
 
 @pytest.mark.write_disk()
 def test_parquet_eq_stats() -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
 
         df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
         df1.to_parquet(file_path, engine="pyarrow")
         df = pl.scan_parquet(file_path).filter(pl.col("a") == 4).collect()
         assert df["a"].to_list() == [4.0, 4.0]
 
@@ -119,15 +119,15 @@
             2,
             1,
         )
 
 
 @pytest.mark.write_disk()
 def test_parquet_is_in_stats() -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
 
         df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
         df1.to_parquet(file_path, engine="pyarrow")
         df = pl.scan_parquet(file_path).filter(pl.col("a").is_in([5])).collect()
         assert df["a"].to_list() == [5.0, 5.0]
 
@@ -158,15 +158,15 @@
         assert pl.scan_parquet(file_path).filter(
             pl.col("a").is_in([1, 2, 3, 4, 5])
         ).collect().shape == (8, 1)
 
 
 @pytest.mark.write_disk()
 def test_parquet_stats() -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "binary_stats.parquet"
 
         df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
         df1.to_parquet(file_path, engine="pyarrow")
         df = (
             pl.scan_parquet(file_path)
             .filter(pl.col("a").is_not_null() & (pl.col("a") > 4))
@@ -208,19 +208,19 @@
 
     df = pl.DataFrame({"idx": pl.arange(100, 200, eager=True)}).with_columns(
         (pl.col("idx") // 25).alias("part")
     )
     df = pl.concat(df.partition_by("part", as_dict=False), rechunk=False)
     assert df.n_chunks("all") == [4, 4]
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
         df.write_parquet(file_path, statistics=True, use_pyarrow=False)
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
         df.write_parquet(file_path, statistics=True, use_pyarrow=False)
 
         for pred in [
             pl.col("idx") == 50,
             pl.col("idx") == 150,
             pl.col("idx") == 210,
@@ -245,19 +245,19 @@
 
     df = pl.DataFrame({"idx": pl.arange(0, 100, eager=True)}).with_columns(
         (pl.col("idx") // 25).alias("part")
     )
     df = pl.concat(df.partition_by("part", as_dict=False), rechunk=False)
     assert df.n_chunks("all") == [4, 4]
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
         df.write_parquet(file_path, statistics=True, use_pyarrow=False)
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
         df.write_parquet(file_path, statistics=True, use_pyarrow=False)
 
         for pred in [
             pl.col("idx").is_in([150, 200, 300]),
             pl.col("idx").is_in([5, 250, 350]),
         ]:
@@ -281,15 +281,15 @@
 
     df = pl.DataFrame({"idx": pl.arange(0, 100, eager=True)}).with_columns(
         (pl.col("idx") // 25).alias("part")
     )
     df = pl.concat(df.partition_by("part", as_dict=False), rechunk=False)
     assert df.n_chunks("all") == [4, 4]
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "stats.parquet"
         df.write_parquet(file_path, statistics=True, use_pyarrow=False)
 
         for pred in [
             pl.col("idx") < 50,
             pl.col("idx") > 50,
             pl.col("idx").null_count() != 0,
@@ -315,15 +315,15 @@
     df = pl.DataFrame(
         [
             pl.Series("name", ["Bob", "Alice", "Bob"], pl.Categorical),
             pl.Series("amount", [100, 200, 300]),
         ]
     )
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "categorical.parquet"
         df.write_parquet(file_path)
 
         with pl.StringCache():
             result = (
                 pl.scan_parquet(file_path)
                 .groupby("name")
@@ -343,15 +343,15 @@
     df = pl.DataFrame(
         [
             pl.Series("a", ["bob"], pl.Categorical),
             pl.Series("b", ["foo"], pl.Categorical),
         ]
     )
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "categorical.parquet"
         df.write_parquet(file_path)
 
         with pl.StringCache():
             out = pl.read_parquet(file_path).select(pl.col("b").value_counts())
         assert out.to_dict(False) == {"b": [{"b": "foo", "counts": 1}]}
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_other.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_other.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_parquet.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_parquet.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from __future__ import annotations
 
 import io
-import tempfile
 import typing
 from pathlib import Path
 from typing import TYPE_CHECKING
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pyarrow.dataset as ds
 import pyarrow.parquet as pq
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_frame_equal_local_categoricals
+from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
     from polars.type_aliases import ParquetCompression
 
 COMPRESSIONS = [
     "lz4",
     "uncompressed",
@@ -66,24 +66,24 @@
     with pytest.raises(pl.ArrowError):
         _ = pl.read_parquet(buf)
 
 
 @pytest.mark.write_disk()
 @pytest.mark.parametrize("compression", COMPRESSIONS)
 def test_to_from_file(df: pl.DataFrame, compression: ParquetCompression) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.avro"
         df.write_parquet(file_path, compression=compression)
         read_df = pl.read_parquet(file_path)
         assert_frame_equal_local_categoricals(df, read_df)
 
 
 @pytest.mark.write_disk()
 def test_to_from_file_lzo(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.avro"
 
         # Writing lzo compressed parquet files is not supported for now.
         with pytest.raises(pl.ArrowError):
             df.write_parquet(file_path, compression="lzo", use_pyarrow=False)
         # Invalid parquet file as writing failed.
         with pytest.raises(pl.ArrowError):
@@ -158,26 +158,26 @@
     assert read.columns == ["a"]
     assert isinstance(read.dtypes[0], pl.datatypes.List)
     assert isinstance(read.dtypes[0].inner, pl.datatypes.Struct)
 
 
 @pytest.mark.write_disk()
 def test_glob_parquet(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.parquet"
         df.write_parquet(file_path)
 
         path_glob = Path(temp_dir) / "small*.parquet"
         assert pl.read_parquet(path_glob).shape == (3, 16)
         assert pl.scan_parquet(path_glob).collect().shape == (3, 16)
 
 
 @pytest.mark.write_disk()
 def test_streaming_parquet_glob_5900(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.parquet"
         df.write_parquet(file_path)
 
         path_glob = Path(temp_dir) / "small*.parquet"
         result = (
             pl.scan_parquet(path_glob).select(pl.all().first()).collect(streaming=True)
         )
@@ -204,15 +204,15 @@
     df.write_parquet(f)
     f.seek(0)
     assert_frame_equal(pl.read_parquet(f), df)
 
 
 @pytest.mark.write_disk()
 def test_lazy_self_join_file_cache_prop_3979(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.parquet"
         df.write_parquet(file_path)
 
         a = pl.scan_parquet(file_path)
         b = pl.DataFrame({"a": [1]}).lazy()
         assert a.join(b, how="cross").collect().shape == (3, 17)
         assert b.join(a, how="cross").collect().shape == (3, 17)
@@ -355,15 +355,15 @@
         assert_frame_equal(read, df)
 
 
 @pytest.mark.write_disk()
 def test_sink_parquet(io_files_path: Path) -> None:
     file = io_files_path / "small.parquet"
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "sink.parquet"
 
         df_scanned = pl.scan_parquet(file)
         df_scanned.sink_parquet(file_path)
 
         with pl.StringCache():
             result = pl.read_parquet(file_path)
@@ -371,15 +371,15 @@
             assert_frame_equal(result, df_read)
 
 
 @pytest.mark.write_disk()
 def test_sink_ipc(io_files_path: Path) -> None:
     file = io_files_path / "small.parquet"
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "sink.ipc"
 
         df_scanned = pl.scan_parquet(file)
         df_scanned.sink_ipc(file_path)
 
         with pl.StringCache():
             result = pl.read_ipc(file_path)
@@ -388,15 +388,15 @@
 
 
 @pytest.mark.write_disk()
 def test_fetch_union() -> None:
     df1 = pl.DataFrame({"a": [0, 1, 2], "b": [1, 2, 3]})
     df2 = pl.DataFrame({"a": [3, 4, 5], "b": [4, 5, 6]})
 
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path_1 = Path(temp_dir) / "df_fetch_1.parquet"
         file_path_2 = Path(temp_dir) / "df_fetch_2.parquet"
         file_path_glob = Path(temp_dir) / "df_fetch_*.parquet"
 
         df1.write_parquet(file_path_1)
         df2.write_parquet(file_path_2)
 
@@ -414,15 +414,15 @@
 @typing.no_type_check
 def test_struct_pyarrow_dataset_5796() -> None:
     num_rows = 2**17 + 1
 
     df = pl.from_records(
         [dict(id=i, nested=dict(a=i)) for i in range(num_rows)]  # noqa: C408
     )
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "out.parquet"
         df.write_parquet(file_path, use_pyarrow=True)
         tbl = ds.dataset(file_path).to_table()
         result = pl.from_arrow(tbl)
 
     assert_frame_equal(result, df)
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_pickle.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_pickle.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/io/test_pyarrow_dataset.py` & `polars_lts_cpu-0.17.3/tests/unit/io/test_pyarrow_dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 from __future__ import annotations
 
-import tempfile
 import typing
 from datetime import date, datetime, time
 from pathlib import Path
 
 import pyarrow.dataset as ds
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
+from polars.testing._tempdir import TemporaryDirectory
 
 
 @typing.no_type_check
 def helper_dataset_test(file_path: Path, query) -> None:
     dset = ds.dataset(file_path, format="ipc")
 
     expected = query(pl.scan_ipc(file_path))
     out = query(pl.scan_pyarrow_dataset(dset))
     assert_frame_equal(out, expected)
 
 
 @pytest.mark.write_disk()
 def test_dataset(df: pl.DataFrame) -> None:
-    with tempfile.TemporaryDirectory() as temp_dir:
+    with TemporaryDirectory() as temp_dir:
         file_path = Path(temp_dir) / "small.ipc"
         df.write_ipc(file_path)
 
         helper_dataset_test(
             file_path,
             lambda lf: lf.filter("bools").select(["bools", "floats", "date"]).collect(),
         )
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_binary.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_categorical.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_datetime.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_datetime.py`

 * *Files 0% similar despite different names*

```diff
@@ -62,15 +62,15 @@
 )
 def test_strptime_extract_times(
     unit_attr: str,
     expected: pl.Series,
     series_of_int_dates: pl.Series,
     series_of_str_dates: pl.Series,
 ) -> None:
-    s = series_of_str_dates.str.strptime(pl.Datetime, fmt="%Y-%m-%d %H:%M:%S.%9f")
+    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
     assert_series_equal(getattr(s.dt, unit_attr)(), expected)
 
 
 @pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu", "+03:00"])
 @pytest.mark.parametrize(
     ("attribute", "expected"),
@@ -128,21 +128,21 @@
     ],
 )
 def test_strptime_epoch(
     time_unit: TimeUnit,
     expected: pl.Series,
     series_of_str_dates: pl.Series,
 ) -> None:
-    s = series_of_str_dates.str.strptime(pl.Datetime, fmt="%Y-%m-%d %H:%M:%S.%9f")
+    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
     assert_series_equal(s.dt.epoch(time_unit=time_unit), expected)
 
 
 def test_strptime_fractional_seconds(series_of_str_dates: pl.Series) -> None:
-    s = series_of_str_dates.str.strptime(pl.Datetime, fmt="%Y-%m-%d %H:%M:%S.%9f")
+    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
     assert_series_equal(
         s.dt.second(fractional=True),
         pl.Series([0.0, 10.987654321], dtype=pl.Float64),
     )
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_list.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_list.py`

 * *Files 1% similar despite different names*

```diff
@@ -364,17 +364,17 @@
             "a": [100, 103, 105, 106, 105, 104, 103, 106, 100, 102],
             "group": [0, 0, 1, 1, 1, 1, 1, 1, 2, 2],
         }
     )
 
     assert df.groupby("group").agg(
         [
-            pl.col("a").list().arr.get(0).alias("get"),
-            pl.col("a").list().arr.take([0]).alias("take"),
-            pl.col("a").list().arr.slice(0, 3).alias("slice"),
+            pl.col("a").implode().arr.get(0).alias("get"),
+            pl.col("a").implode().arr.take([0]).alias("take"),
+            pl.col("a").implode().arr.slice(0, 3).alias("slice"),
         ]
     ).sort("group").to_dict(False) == {
         "group": [0, 1, 2],
         "get": [100, 105, 100],
         "take": [[100], [105], [100]],
         "slice": [[100, 103], [105, 106, 105], [100, 102]],
     }
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_meta.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_meta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_string.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_string.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_strptime.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_strptime.py`

 * *Files 2% similar despite different names*

```diff
@@ -40,19 +40,19 @@
     s = pl.Series(["00:00:00", "03:20:10"])
     expected = pl.Series([0, 12010000000000], dtype=pl.Time)
     assert_series_equal(s.str.strptime(pl.Time, "%H:%M:%S"), expected)
 
 
 def test_date_parse_omit_day() -> None:
     df = pl.DataFrame({"month": ["2022-01"]})
-    assert df.select(pl.col("month").str.strptime(pl.Date, fmt="%Y-%m")).item() == date(
-        2022, 1, 1
-    )
     assert df.select(
-        pl.col("month").str.strptime(pl.Datetime, fmt="%Y-%m")
+        pl.col("month").str.strptime(pl.Date, format="%Y-%m")
+    ).item() == date(2022, 1, 1)
+    assert df.select(
+        pl.col("month").str.strptime(pl.Datetime, format="%Y-%m")
     ).item() == datetime(2022, 1, 1)
 
 
 def test_strptime_precision() -> None:
     s = pl.Series(
         "date", ["2022-09-12 21:54:36.789321456", "2022-09-13 12:34:56.987456321"]
     )
@@ -77,20 +77,20 @@
         assert ds.dt.nanosecond().to_list() == expected_values
 
 
 @pytest.mark.parametrize(
     ("unit", "expected"),
     [("ms", "123000000"), ("us", "123456000"), ("ns", "123456789")],
 )
-@pytest.mark.parametrize("fmt", ["%Y-%m-%d %H:%M:%S.%f", None])
+@pytest.mark.parametrize("format", ["%Y-%m-%d %H:%M:%S%.f", None])
 def test_strptime_precision_with_time_unit(
-    unit: TimeUnit, expected: str, fmt: str
+    unit: TimeUnit, expected: str, format: str
 ) -> None:
     ser = pl.Series(["2020-01-01 00:00:00.123456789"])
-    result = ser.str.strptime(pl.Datetime(unit), fmt=fmt).dt.strftime("%f")[0]
+    result = ser.str.strptime(pl.Datetime(unit), format=format).dt.strftime("%f")[0]
     assert result == expected
 
 
 @pytest.mark.parametrize("fmt", ["%Y-%m-%dT%H:%M:%S", None])
 def test_utc_with_tz_naive(fmt: str | None) -> None:
     result = (
         pl.Series(["2020-01-01T00:00:00"])
@@ -112,15 +112,17 @@
                 "2021-12-05 06:00:00" + tz_string,
                 "2021-12-05 07:00:00" + tz_string,
                 "2021-12-05 08:00:00" + tz_string,
             ]
         }
     )
     assert times.with_columns(
-        pl.col("delivery_datetime").str.strptime(pl.Datetime, fmt="%Y-%m-%d %H:%M:%S%z")
+        pl.col("delivery_datetime").str.strptime(
+            pl.Datetime, format="%Y-%m-%d %H:%M:%S%z"
+        )
     ).to_dict(False) == {
         "delivery_datetime": [
             datetime(2021, 12, 5, 6, 0, tzinfo=timezone(timedelta)),
             datetime(2021, 12, 5, 7, 0, tzinfo=timezone(timedelta)),
             datetime(2021, 12, 5, 8, 0, tzinfo=timezone(timedelta)),
         ]
     }
@@ -248,15 +250,15 @@
             "2019-04-18T02:45:55.555000000",
             "2019-04-18T22:45:55.555123",
         ],
     ).to_frame()
     s = df.with_columns(
         [
             pl.col("date")
-            .str.strptime(pl.Datetime, fmt=None, strict=False)
+            .str.strptime(pl.Datetime, format=None, strict=False)
             .alias("parsed"),
         ]
     )["parsed"]
     assert s.null_count() == 1
     assert s[5] is None
 
 
@@ -276,50 +278,50 @@
             "2019-04-18T02:45:55.555000000",
             "2019-04-18T22:45:55.555123",
         ],
     ).to_frame()
     s = df.with_columns(
         [
             pl.col("date")
-            .str.strptime(pl.Datetime, fmt=None, strict=False)
+            .str.strptime(pl.Datetime, format=None, strict=False)
             .alias("parsed"),
         ]
     )["parsed"]
     assert s.null_count() == 8
     assert s[0] is not None
 
 
 @pytest.mark.parametrize(
     (
         "ts",
-        "fmt",
+        "format",
         "exp_year",
         "exp_month",
         "exp_day",
         "exp_hour",
         "exp_minute",
         "exp_second",
     ),
     [
         ("-0031-04-24 22:13:20", "%Y-%m-%d %H:%M:%S", -31, 4, 24, 22, 13, 20),
         ("-0031-04-24", "%Y-%m-%d", -31, 4, 24, 0, 0, 0),
     ],
 )
 def test_parse_negative_dates(
     ts: str,
-    fmt: str,
+    format: str,
     exp_year: int,
     exp_month: int,
     exp_day: int,
     exp_hour: int,
     exp_minute: int,
     exp_second: int,
 ) -> None:
     ser = pl.Series([ts])
-    result = ser.str.strptime(pl.Datetime("ms"), fmt=fmt)
+    result = ser.str.strptime(pl.Datetime("ms"), format=format)
     # Python datetime.datetime doesn't support negative dates, so comparing
     # with `result.item()` directly won't work.
     assert result.dt.year().item() == exp_year
     assert result.dt.month().item() == exp_month
     assert result.dt.day().item() == exp_day
     assert result.dt.hour().item() == exp_hour
     assert result.dt.minute().item() == exp_minute
@@ -328,15 +330,15 @@
 
 def test_short_formats() -> None:
     s = pl.Series(["20202020", "2020"])
     assert s.str.strptime(pl.Date, "%Y", strict=False).to_list() == [
         None,
         date(2020, 1, 1),
     ]
-    assert s.str.strptime(pl.Date, "%foo", strict=False).to_list() == [None, None]
+    assert s.str.strptime(pl.Date, "%bar", strict=False).to_list() == [None, None]
 
 
 @pytest.mark.parametrize(
     ("time_string", "fmt", "datatype", "expected"),
     [
         ("Jul/2020", "%b/%Y", pl.Date, date(2020, 7, 1)),
         ("Jan/2020", "%b/%Y", pl.Date, date(2020, 1, 1)),
@@ -375,23 +377,23 @@
 
 def test_invalid_date_parsing_4898() -> None:
     assert pl.Series(["2022-09-18", "2022-09-50"]).str.strptime(
         pl.Date, "%Y-%m-%d", strict=False
     ).to_list() == [date(2022, 9, 18), None]
 
 
-def test_replace_timezone_invalid_timezone() -> None:
+def test_strptime_invalid_timezone() -> None:
     ts = pl.Series(["2020-01-01 00:00:00+01:00"]).str.strptime(
         pl.Datetime, "%Y-%m-%d %H:%M:%S%z"
     )
     with pytest.raises(ComputeError, match=r"unable to parse time zone: 'foo'"):
         ts.dt.replace_time_zone("foo")
 
 
-def test_replace_time_zone_ambiguous_or_non_existent() -> None:
+def test_strptime_ambiguous_or_non_existent() -> None:
     with pytest.raises(
         ArrowError,
         match="datetime '2021-11-07 01:00:00' is ambiguous in time zone 'US/Central'",
     ):
         pl.Series(["2021-11-07 01:00"]).str.strptime(pl.Datetime("us", "US/Central"))
     with pytest.raises(
         ArrowError,
@@ -399,14 +401,15 @@
     ):
         pl.Series(["2021-03-28 02:30"]).str.strptime(pl.Datetime("us", "Europe/Warsaw"))
 
 
 @pytest.mark.parametrize(
     ("ts", "fmt", "expected"),
     [
+        ("2020-01-01T00:00:00Z", None, datetime(2020, 1, 1, tzinfo=timezone.utc)),
         ("2020-01-01T00:00:00Z", "%+", datetime(2020, 1, 1, tzinfo=timezone.utc)),
         (
             "2020-01-01T00:00:00+01:00",
             "%Y-%m-%dT%H:%M:%S%z",
             datetime(2020, 1, 1, tzinfo=timezone(timedelta(seconds=3600))),
         ),
         (
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/namespaces/test_struct.py` & `polars_lts_cpu-0.17.3/tests/unit/namespaces/test_struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_aggregations.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_aggregations.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 import typing
-from datetime import datetime, timedelta
+from datetime import date, datetime, timedelta
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
 
@@ -155,7 +155,50 @@
         pl.DataFrame(
             [
                 pl.Series("A", [1], dtype=pl.Int64),
                 pl.Series("B", [[1, 2, 2]], dtype=pl.List(pl.UInt32)),
             ]
         ),
     )
+
+
+def test_duration_function_literal() -> None:
+    df = pl.DataFrame(
+        {
+            "A": ["x", "x", "y", "y", "y"],
+            "T": [date(2022, m, 1) for m in range(1, 6)],
+            "S": [1, 2, 4, 8, 16],
+        }
+    ).with_columns(
+        [
+            pl.col("T").cast(pl.Datetime),
+        ]
+    )
+
+    # this checks if the `pl.duration` is flagged as AggState::Literal
+    assert df.groupby("A", maintain_order=True).agg(
+        [((pl.col("T").max() + pl.duration(seconds=1)) - pl.col("T"))]
+    ).to_dict(False) == {
+        "A": ["x", "y"],
+        "T": [
+            [timedelta(days=31, seconds=1), timedelta(seconds=1)],
+            [
+                timedelta(days=61, seconds=1),
+                timedelta(days=30, seconds=1),
+                timedelta(seconds=1),
+            ],
+        ],
+    }
+
+
+def test_string_par_materialize_8207() -> None:
+    df = pl.LazyFrame(
+        {
+            "a": ["a", "b", "d", "c", "e"],
+            "b": ["P", "L", "R", "T", "a long string"],
+        }
+    )
+
+    assert df.groupby(["a"]).agg(pl.min("b")).sort("a").collect().to_dict(False) == {
+        "a": ["a", "b", "c", "d", "e"],
+        "b": ["P", "L", "T", "R", "a long string"],
+    }
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_apply.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_apply.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_arithmetic.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_arithmetic.py`

 * *Files 14% similar despite different names*

```diff
@@ -124,7 +124,17 @@
 def test_unary_plus() -> None:
     data = [1, 2]
     df = pl.DataFrame({"x": data})
     assert df.select(+pl.col("x"))[:, 0].to_list() == data
 
     with pytest.raises(pl.exceptions.ComputeError):
         pl.select(+pl.lit(""))
+
+
+def test_series_expr_arithm() -> None:
+    s = pl.Series([1, 2, 3])
+    assert (s + pl.col("a")).meta == pl.lit(s) + pl.col("a")
+    assert (s - pl.col("a")).meta == pl.lit(s) - pl.col("a")
+    assert (s / pl.col("a")).meta == pl.lit(s) / pl.col("a")
+    assert (s // pl.col("a")).meta == pl.lit(s) // pl.col("a")
+    assert (s * pl.col("a")).meta == pl.lit(s) * pl.col("a")
+    assert (s % pl.col("a")).meta == pl.lit(s) % pl.col("a")
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_comparison.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_comparison.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_drop.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_drop.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_explode.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_explode.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_filter.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_filter.py`

 * *Files 5% similar despite different names*

```diff
@@ -28,26 +28,28 @@
         .collect()
     ).to_dict(False) == {"id": [1], "variable": ["asset_key_1"], "value": ["123"]}
 
 
 def test_filter_is_in_4572() -> None:
     df = pl.DataFrame({"id": [1, 2, 1, 2], "k": ["a"] * 2 + ["b"] * 2})
     expected = (
-        df.groupby("id").agg(pl.col("k").filter(pl.col("k") == "a").list()).sort("id")
+        df.groupby("id")
+        .agg(pl.col("k").filter(pl.col("k") == "a").implode())
+        .sort("id")
     )
     result = (
         df.groupby("id")
-        .agg(pl.col("k").filter(pl.col("k").is_in(["a"])).list())
+        .agg(pl.col("k").filter(pl.col("k").is_in(["a"])).implode())
         .sort("id")
     )
     assert_frame_equal(result, expected)
     result = (
         df.sort("id")
         .groupby("id")
-        .agg(pl.col("k").filter(pl.col("k").is_in(["a"])).list())
+        .agg(pl.col("k").filter(pl.col("k").is_in(["a"])).implode())
     )
     assert_frame_equal(result, expected)
 
 
 def test_filter_aggregation_any() -> None:
     assert pl.DataFrame(
         {
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_folds.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_folds.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_groupby.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_groupby.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_join.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_join.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_join_asof.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_join_asof.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_melt.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_melt.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_pivot.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_pivot.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_rolling.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_rolling.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_sort.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_sort.py`

 * *Files 0% similar despite different names*

```diff
@@ -337,15 +337,15 @@
         "foo": ["a"]
     }
 
 
 def test_explicit_list_agg_sort_in_groupby() -> None:
     df = pl.DataFrame({"A": ["a", "a", "a", "b", "b", "a"], "B": [1, 2, 3, 4, 5, 6]})
 
-    # this was col().list().sort() before we changed the logic
+    # this was col().implode().sort() before we changed the logic
     result = df.groupby("A").agg(pl.col("B").sort(descending=True)).sort("A")
     expected = df.groupby("A").agg(pl.col("B").sort(descending=True)).sort("A")
     assert_frame_equal(result, expected)
 
 
 def test_sorted_join_query_5406() -> None:
     df = (
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_statistics.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_statistics.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_transpose.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_transpose.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_unique.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_unique.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/operations/test_window.py` & `polars_lts_cpu-0.17.3/tests/unit/operations/test_window.py`

 * *Files 2% similar despite different names*

```diff
@@ -89,25 +89,25 @@
             "groups": ["A", "A", "B", "B", "B"],
             "groups_not_sorted": ["A", "B", "A", "B", "A"],
             "values": range(5),
         }
     ).with_columns(
         [
             pl.col("values")
-            .list()
+            .implode()
             .over("groups")
             .alias("values_list"),  # aggregation to list + join
             pl.col("values")
-            .list()
+            .implode()
             .over("groups")
             .flatten()
             .alias("values_flat"),  # aggregation to list + explode and concat back
             pl.col("values")
             .reverse()
-            .list()
+            .implode()
             .over("groups")
             .flatten()
             .alias("values_rev"),  # use flatten to reverse within a group
         ]
     )
 
     assert out["values_list"].to_list() == [
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_api.py` & `polars_lts_cpu-0.17.3/tests/unit/test_api.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_arity.py` & `polars_lts_cpu-0.17.3/tests/unit/test_arity.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_cfg.py` & `polars_lts_cpu-0.17.3/tests/unit/test_cfg.py`

 * *Files 0% similar despite different names*

```diff
@@ -159,15 +159,15 @@
         str(df) == "shape: (4, 3)\n"
         "\n"
         " a    b    c   \n"
         " ---  ---  --- \n"
         " i64  i64  i64 \n"
         "\n"
         " 1    5    9   \n"
-        "            \n"
+        " 2    6    10  \n"
         " 3    7    11  \n"
         " 4    8    12  \n"
         ""
     )
     assert (
         str(ser) == "shape: (5,)\n"
         "Series: 'ser' [i64]\n"
@@ -195,15 +195,15 @@
     )
     assert (
         str(ser) == "shape: (5,)\n"
         "Series: 'ser' [i64]\n"
         "[\n"
         "\t1\n"
         "\t2\n"
-        "\t\n"
+        "\t3\n"
         "\t4\n"
         "\t5\n"
         "]"
     )
 
     df = pl.DataFrame(
         {
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_constructors.py` & `polars_lts_cpu-0.17.3/tests/unit/test_exprs.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,988 +1,1052 @@
 from __future__ import annotations
 
+import random
 import sys
 import typing
-from datetime import date, datetime, timedelta, timezone
-from decimal import Decimal
-from random import shuffle
-from typing import Any
-
-import numpy as np
-import pandas as pd
-import pyarrow as pa
-import pytest
-
-import polars as pl
-from polars.dependencies import _ZONEINFO_AVAILABLE
-from polars.testing import assert_frame_equal, assert_series_equal
+from datetime import datetime, timedelta, timezone
+from itertools import permutations
+from typing import Any, cast
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
-elif _ZONEINFO_AVAILABLE:
+else:
     # Import from submodule due to typing issue with backports.zoneinfo package:
     # https://github.com/pganssle/zoneinfo/issues/125
     from backports.zoneinfo._zoneinfo import ZoneInfo
 
+import numpy as np
+import pytest
 
-def test_init_dict() -> None:
-    # Empty dictionary
-    df = pl.DataFrame({})
-    assert df.shape == (0, 0)
-
-    # Empty dictionary/values
-    df = pl.DataFrame({"a": [], "b": []})
-    assert df.shape == (0, 2)
-    assert df.schema == {"a": pl.Float32, "b": pl.Float32}
-
-    for df in (
-        pl.DataFrame({}, schema={"a": pl.Date, "b": pl.Utf8}),
-        pl.DataFrame({"a": [], "b": []}, schema={"a": pl.Date, "b": pl.Utf8}),
-    ):
-        assert df.shape == (0, 2)
-        assert df.schema == {"a": pl.Date, "b": pl.Utf8}
-
-    # List of empty list
-    df = pl.DataFrame({"a": [[]], "b": [[]]})
-    expected = {"a": pl.List(pl.Int32), "b": pl.List(pl.Int32)}
-    assert df.schema == expected
-    assert df.rows() == [([], [])]
-
-    # Mixed dtypes
-    df = pl.DataFrame({"a": [1, 2, 3], "b": [1.0, 2.0, 3.0]})
-    assert df.shape == (3, 2)
-    assert df.columns == ["a", "b"]
-    assert df.dtypes == [pl.Int64, pl.Float64]
-
-    df = pl.DataFrame(
-        data={"a": [1, 2, 3], "b": [1.0, 2.0, 3.0]},
-        schema=[("a", pl.Int8), ("b", pl.Float32)],
-    )
-    assert df.schema == {"a": pl.Int8, "b": pl.Float32}
+import polars as pl
+from polars.datatypes import (
+    DATETIME_DTYPES,
+    DURATION_DTYPES,
+    FLOAT_DTYPES,
+    INTEGER_DTYPES,
+    NUMERIC_DTYPES,
+    TEMPORAL_DTYPES,
+)
+from polars.testing import assert_frame_equal, assert_series_equal
 
-    # Values contained in tuples
-    df = pl.DataFrame({"a": (1, 2, 3), "b": [1.0, 2.0, 3.0]})
-    assert df.shape == (3, 2)
-
-    # Datetime/Date types (from both python and integer values)
-    py_datetimes = (
-        datetime(2022, 12, 31, 23, 59, 59),
-        datetime(2022, 12, 31, 23, 59, 59),
-    )
-    py_dates = (date(2022, 12, 31), date(2022, 12, 31))
-    int_datetimes = [1672531199000000, 1672531199000000]
-    int_dates = [19357, 19357]
-
-    for dates, datetimes, coldefs in (
-        # test inferred and explicit (given both py/polars dtypes)
-        (py_dates, py_datetimes, None),
-        (py_dates, py_datetimes, [("dt", date), ("dtm", datetime)]),
-        (py_dates, py_datetimes, [("dt", pl.Date), ("dtm", pl.Datetime)]),
-        (int_dates, int_datetimes, [("dt", date), ("dtm", datetime)]),
-        (int_dates, int_datetimes, [("dt", pl.Date), ("dtm", pl.Datetime)]),
-    ):
-        df = pl.DataFrame(
-            data={"dt": dates, "dtm": datetimes},
-            schema=coldefs,
-        )
-        assert df.schema == {"dt": pl.Date, "dtm": pl.Datetime}
-        assert df.rows() == list(zip(py_dates, py_datetimes))
 
-    # Overriding dict column names/types
-    df = pl.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]}, schema=["c", "d"])
-    assert df.columns == ["c", "d"]
+def test_arg_true() -> None:
+    df = pl.DataFrame({"a": [1, 1, 2, 1]})
+    res = df.select((pl.col("a") == 1).arg_true())
+    expected = pl.DataFrame([pl.Series("a", [0, 1, 3], dtype=pl.UInt32)])
+    assert_frame_equal(res, expected)
 
-    df = pl.DataFrame(
-        {"a": [1, 2, 3], "b": [4, 5, 6]},
-        schema=["c", ("d", pl.Int8)],
-    )  # partial type info (allowed, but mypy doesn't like it ;p)
-    assert df.schema == {"c": pl.Int64, "d": pl.Int8}
 
+def test_col_select() -> None:
     df = pl.DataFrame(
-        {"a": [1, 2, 3], "b": [4, 5, 6]}, schema=[("c", pl.Int8), ("d", pl.Int16)]
+        {
+            "ham": [1, 2, 3],
+            "hamburger": [11, 22, 33],
+            "foo": [3, 2, 1],
+            "bar": ["a", "b", "c"],
+        }
     )
-    assert df.schema == {"c": pl.Int8, "d": pl.Int16}
 
-    dfe = df.clear()
-    assert df.schema == dfe.schema
-    assert len(dfe) == 0
-
-    # empty nested objects
-    for empty_val in [None, "", {}, []]:  # type: ignore[var-annotated]
-        test = [{"field": {"sub_field": empty_val, "sub_field_2": 2}}]
-        df = pl.DataFrame(test, schema={"field": pl.Object})
-        assert df.to_dict(False)["field"][0] == test[0]["field"]
-
-
-def test_init_dataclasses_and_namedtuple(monkeypatch: Any) -> None:
-    from dataclasses import dataclass
-    from typing import NamedTuple
-
-    monkeypatch.setenv("POLARS_ACTIVATE_DECIMAL", "1")
-
-    from polars.utils._construction import dataclass_type_hints
-
-    @dataclass
-    class TradeDC:
-        timestamp: datetime
-        ticker: str
-        price: Decimal
-        size: int | None = None
-
-    class TradeNT(NamedTuple):
-        timestamp: datetime
-        ticker: str
-        price: Decimal
-        size: int | None = None
-
-    raw_data = [
-        (datetime(2022, 9, 8, 14, 30, 45), "AAPL", Decimal("157.5"), 125),
-        (datetime(2022, 9, 9, 10, 15, 12), "FLSY", Decimal("10.0"), 1500),
-        (datetime(2022, 9, 7, 15, 30), "MU", Decimal("55.5"), 400),
+    # Single column
+    assert df.select(pl.col("foo")).columns == ["foo"]
+    # Regex
+    assert df.select(pl.col("*")).columns == ["ham", "hamburger", "foo", "bar"]
+    assert df.select(pl.col("^ham.*$")).columns == ["ham", "hamburger"]
+    assert df.select(pl.col("*").exclude("ham")).columns == ["hamburger", "foo", "bar"]
+    # Multiple inputs
+    assert df.select(pl.col(["hamburger", "foo"])).columns == ["hamburger", "foo"]
+    assert df.select(pl.col("hamburger", "foo")).columns == ["hamburger", "foo"]
+    assert df.select(pl.col(pl.Series(["ham", "foo"]))).columns == ["ham", "foo"]
+    # Dtypes
+    assert df.select(pl.col(pl.Utf8)).columns == ["bar"]
+    assert df.select(pl.col(pl.Int64, pl.Float64)).columns == [
+        "ham",
+        "hamburger",
+        "foo",
     ]
 
-    for TradeClass in (TradeDC, TradeNT):
-        trades = [TradeClass(*values) for values in raw_data]
 
-        for DF in (pl.DataFrame, pl.from_records):
-            df = DF(data=trades)  # type: ignore[operator]
-            assert df.schema == {
-                "timestamp": pl.Datetime("us"),
-                "ticker": pl.Utf8,
-                "price": pl.Decimal(None, 1),
-                "size": pl.Int64,
-            }
-            assert df.rows() == raw_data
-
-            # partial dtypes override
-            df = DF(  # type: ignore[operator]
-                data=trades,
-                schema_overrides={"timestamp": pl.Datetime("ms"), "size": pl.Int32},
-            )
-            assert df.schema == {
-                "timestamp": pl.Datetime("ms"),
-                "ticker": pl.Utf8,
-                "price": pl.Decimal(None, 1),
-                "size": pl.Int32,
-            }
-
-        # in conjunction with full 'columns' override (rename/downcast)
-        df = pl.DataFrame(
-            data=trades,
-            schema=[
-                ("ts", pl.Datetime("ms")),
-                ("tk", pl.Categorical),
-                ("pc", pl.Decimal(None, 1)),
-                ("sz", pl.UInt16),
-            ],
-        )
-        assert df.schema == {
-            "ts": pl.Datetime("ms"),
-            "tk": pl.Categorical,
-            "pc": pl.Decimal(None, 1),
-            "sz": pl.UInt16,
-        }
-        assert df.rows() == raw_data
+def test_horizontal_agg(fruits_cars: pl.DataFrame) -> None:
+    df = fruits_cars
+    out = df.select(pl.max([pl.col("A"), pl.col("B")]))
+    assert out[:, 0].to_list() == [5, 4, 3, 4, 5]
 
-        # cover a miscellaneous edge-case when detecting the annotations
-        assert dataclass_type_hints(obj=type(None)) == {}
+    out = df.select(pl.min([pl.col("A"), pl.col("B")]))
+    assert out[:, 0].to_list() == [1, 2, 3, 2, 1]
 
 
-def test_init_ndarray(monkeypatch: Any) -> None:
-    # Empty array
-    df = pl.DataFrame(np.array([]))
-    assert_frame_equal(df, pl.DataFrame())
-
-    # 1D array
-    df = pl.DataFrame(np.array([1, 2, 3], dtype=np.int64), schema=["a"])
-    expected = pl.DataFrame({"a": [1, 2, 3]})
-    assert_frame_equal(df, expected)
-
-    df = pl.DataFrame(np.array([1, 2, 3]), schema=[("a", pl.Int32)])
-    expected = pl.DataFrame({"a": [1, 2, 3]}).with_columns(pl.col("a").cast(pl.Int32))
-    assert_frame_equal(df, expected)
-
-    # 2D array (or 2x 1D array) - should default to column orientation
-    for data in (
-        np.array([[1, 2], [3, 4]], dtype=np.int64),
-        [np.array([1, 2], dtype=np.int64), np.array([3, 4], dtype=np.int64)],
-    ):
-        df = pl.DataFrame(data, orient="col")
-        expected = pl.DataFrame({"column_0": [1, 2], "column_1": [3, 4]})
-        assert_frame_equal(df, expected)
+def test_suffix(fruits_cars: pl.DataFrame) -> None:
+    df = fruits_cars
+    out = df.select([pl.all().suffix("_reverse")])
+    assert out.columns == ["A_reverse", "fruits_reverse", "B_reverse", "cars_reverse"]
 
-    df = pl.DataFrame([[1, 2.0, "a"], [None, None, None]], orient="row")
-    expected = pl.DataFrame(
-        {"column_0": [1, None], "column_1": [2.0, None], "column_2": ["a", None]}
-    )
-    assert_frame_equal(df, expected)
 
-    df = pl.DataFrame(
-        data=[[1, 2.0, "a"], [None, None, None]],
-        schema=[("x", pl.Boolean), ("y", pl.Int32), "z"],
-        orient="row",
-    )
-    assert df.rows() == [(True, 2, "a"), (None, None, None)]
-    assert df.schema == {"x": pl.Boolean, "y": pl.Int32, "z": pl.Utf8}
-
-    # 2D array - default to column orientation
-    df = pl.DataFrame(np.array([[1, 2], [3, 4]], dtype=np.int64))
-    expected = pl.DataFrame({"column_0": [1, 3], "column_1": [2, 4]})
-    assert_frame_equal(df, expected)
-
-    # no orientation is numpy convention
-    df = pl.DataFrame(np.ones((3, 1), dtype=np.int64))
-    assert df.shape == (3, 1)
+def test_pipe() -> None:
+    df = pl.DataFrame({"foo": [1, 2, 3], "bar": [6, None, 8]})
 
-    # 2D array - row orientation inferred
-    df = pl.DataFrame(
-        np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int64), schema=["a", "b", "c"]
-    )
-    expected = pl.DataFrame({"a": [1, 4], "b": [2, 5], "c": [3, 6]})
-    assert_frame_equal(df, expected)
+    def _multiply(expr: pl.Expr, mul: int) -> pl.Expr:
+        return expr * mul
 
-    # 2D array - column orientation inferred
-    df = pl.DataFrame(
-        np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int64), schema=["a", "b"]
+    result = df.select(
+        pl.col("foo").pipe(_multiply, mul=2),
+        pl.col("bar").pipe(_multiply, mul=3),
     )
-    expected = pl.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
-    assert_frame_equal(df, expected)
 
-    # 2D array - orientation conflicts with columns
-    with pytest.raises(ValueError):
-        pl.DataFrame(np.array([[1, 2, 3], [4, 5, 6]]), schema=["a", "b"], orient="row")
-    with pytest.raises(ValueError):
-        pl.DataFrame(
-            np.array([[1, 2, 3], [4, 5, 6]]),
-            schema=[("a", pl.UInt32), ("b", pl.UInt32)],
-            orient="row",
-        )
+    expected = pl.DataFrame({"foo": [2, 4, 6], "bar": [18, None, 24]})
+    assert_frame_equal(result, expected)
 
-    # 3D array
-    with pytest.raises(ValueError):
-        _ = pl.DataFrame(np.random.randn(2, 2, 2))
-
-    # Wrong orient value
-    with pytest.raises(ValueError):
-        df = pl.DataFrame(
-            np.array([[1, 2, 3], [4, 5, 6]]),
-            orient="wrong",  # type: ignore[arg-type]
-        )
 
-    # Dimensions mismatch
-    with pytest.raises(ValueError):
-        _ = pl.DataFrame(np.array([1, 2, 3]), schema=[])
-    with pytest.raises(ValueError):
-        _ = pl.DataFrame(np.array([[1, 2], [3, 4]]), schema=["a"])
-
-    # NumPy not available
-    monkeypatch.setattr(pl.dataframe.frame, "_check_for_numpy", lambda x: False)
-    with pytest.raises(ValueError):
-        pl.DataFrame(np.array([1, 2, 3]), schema=["a"])
-
-    # 2D numpy arrays
-    df = pl.DataFrame({"a": np.arange(5, dtype=np.int64).reshape(1, -1)})
-    assert df.dtypes == [pl.List(pl.Int64)]
-    assert df.shape == (1, 1)
-
-    df = pl.DataFrame({"a": np.arange(10, dtype=np.int64).reshape(2, -1)})
-    assert df.dtypes == [pl.List(pl.Int64)]
-    assert df.shape == (2, 1)
-    assert df.rows() == [([0, 1, 2, 3, 4],), ([5, 6, 7, 8, 9],)]
+def test_prefix(fruits_cars: pl.DataFrame) -> None:
+    df = fruits_cars
+    out = df.select([pl.all().prefix("reverse_")])
+    assert out.columns == ["reverse_A", "reverse_fruits", "reverse_B", "reverse_cars"]
 
-    # numpy arrays containing NaN
-    df0 = pl.DataFrame(
-        data={"x": [1.0, 2.5, float("nan")], "y": [4.0, float("nan"), 6.5]},
+
+def test_cumcount() -> None:
+    df = pl.DataFrame([["a"], ["a"], ["a"], ["b"], ["b"], ["a"]], schema=["A"])
+
+    out = df.groupby("A", maintain_order=True).agg(
+        [pl.col("A").cumcount(reverse=False).alias("foo")]
     )
-    df1 = pl.DataFrame(
-        data={"x": np.array([1.0, 2.5, np.nan]), "y": np.array([4.0, np.nan, 6.5])},
+
+    assert out["foo"][0].to_list() == [0, 1, 2, 3]
+    assert out["foo"][1].to_list() == [0, 1]
+
+
+def test_filter_where() -> None:
+    df = pl.DataFrame({"a": [1, 2, 3, 1, 2, 3], "b": [4, 5, 6, 7, 8, 9]})
+    result_where = df.groupby("a", maintain_order=True).agg(
+        pl.col("b").where(pl.col("b") > 4).alias("c")
     )
-    df2 = pl.DataFrame(
-        data={"x": np.array([1.0, 2.5, np.nan]), "y": np.array([4.0, np.nan, 6.5])},
-        nan_to_null=True,
+    result_filter = df.groupby("a", maintain_order=True).agg(
+        pl.col("b").filter(pl.col("b") > 4).alias("c")
     )
-    assert_frame_equal(df0, df1, nans_compare_equal=True)
-    assert df2.rows() == [(1.0, 4.0), (2.5, None), (None, 6.5)]
+    expected = pl.DataFrame({"a": [1, 2, 3], "c": [[7], [5, 8], [6, 9]]})
+    assert_frame_equal(result_where, expected)
+    assert_frame_equal(result_filter, expected)
 
 
-def test_init_arrow() -> None:
-    # Handle unnamed column
-    df = pl.DataFrame(pa.table({"a": [1, 2], None: [3, 4]}))
-    expected = pl.DataFrame({"a": [1, 2], "None": [3, 4]})
-    assert_frame_equal(df, expected)
+def test_min_nulls_consistency() -> None:
+    df = pl.DataFrame({"a": [None, 2, 3], "b": [4, None, 6], "c": [7, 5, 0]})
+    out = df.select([pl.min(["a", "b", "c"])]).to_series()
+    expected = pl.Series("min", [4, 2, 0])
+    assert_series_equal(out, expected)
 
-    # Rename columns
-    df = pl.DataFrame(pa.table({"a": [1, 2], "b": [3, 4]}), schema=["c", "d"])
-    expected = pl.DataFrame({"c": [1, 2], "d": [3, 4]})
-    assert_frame_equal(df, expected)
+    out = df.select([pl.max(["a", "b", "c"])]).to_series()
+    expected = pl.Series("max", [7, 5, 6])
+    assert_series_equal(out, expected)
 
-    df = pl.DataFrame(
-        pa.table({"a": [1, 2], None: [3, 4]}),
-        schema=[("c", pl.Int32), ("d", pl.Float32)],
-    )
-    assert df.schema == {"c": pl.Int32, "d": pl.Float32}
-    assert df.rows() == [(1, 3.0), (2, 4.0)]
 
-    # Bad columns argument
-    with pytest.raises(ValueError):
-        pl.DataFrame(pa.table({"a": [1, 2, 3], "b": [4, 5, 6]}), schema=["c", "d", "e"])
-
-
-def test_init_series() -> None:
-    # List of Series
-    df = pl.DataFrame([pl.Series("a", [1, 2, 3]), pl.Series("b", [4, 5, 6])])
-    expected = pl.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
-    assert_frame_equal(df, expected)
-
-    # Tuple of Series
-    df = pl.DataFrame((pl.Series("a", (1, 2, 3)), pl.Series("b", (4, 5, 6))))
-    assert_frame_equal(df, expected)
+def test_list_join_strings() -> None:
+    s = pl.Series("a", [["ab", "c", "d"], ["e", "f"], ["g"], []])
+    expected = pl.Series("a", ["ab-c-d", "e-f", "g", ""])
+    assert_series_equal(s.arr.join("-"), expected)
 
-    df = pl.DataFrame(
-        (pl.Series("a", (1, 2, 3)), pl.Series("b", (4, 5, 6))),
-        schema=[("x", pl.Float64), ("y", pl.Float64)],
-    )
-    assert df.schema == {"x": pl.Float64, "y": pl.Float64}
-    assert df.rows() == [(1.0, 4.0), (2.0, 5.0), (3.0, 6.0)]
 
-    # List of unnamed Series
-    df = pl.DataFrame([pl.Series([1, 2, 3]), pl.Series([4, 5, 6])])
-    expected = pl.DataFrame(
-        [pl.Series("column_0", [1, 2, 3]), pl.Series("column_1", [4, 5, 6])]
-    )
-    assert_frame_equal(df, expected)
+def test_count_expr() -> None:
+    df = pl.DataFrame({"a": [1, 2, 3, 3, 3], "b": ["a", "a", "b", "a", "a"]})
 
-    df = pl.DataFrame([pl.Series([0.0]), pl.Series([1.0])])
-    assert df.schema == {"column_0": pl.Float64, "column_1": pl.Float64}
-    assert df.rows() == [(0.0, 1.0)]
+    out = df.select(pl.count())
+    assert out.shape == (1, 1)
+    assert cast(int, out.item()) == 5
 
-    df = pl.DataFrame(
-        [pl.Series([None]), pl.Series([1.0])],
-        schema=[("x", pl.Date), ("y", pl.Boolean)],
-    )
-    assert df.schema == {"x": pl.Date, "y": pl.Boolean}
-    assert df.rows() == [(None, True)]
+    out = df.groupby("b", maintain_order=True).agg(pl.count())
+    assert out["b"].to_list() == ["a", "b"]
+    assert out["count"].to_list() == [4, 1]
 
-    # Single Series
-    df = pl.DataFrame(pl.Series("a", [1, 2, 3]))
-    expected = pl.DataFrame({"a": [1, 2, 3]})
-    assert df.schema == {"a": pl.Int64}
-    assert_frame_equal(df, expected)
-
-    df = pl.DataFrame(pl.Series("a", [1, 2, 3]), schema=[("a", pl.UInt32)])
-    assert df.rows() == [(1,), (2,), (3,)]
-    assert df.schema == {"a": pl.UInt32}
-
-    # nested list, with/without explicit dtype
-    s1 = pl.Series([[[2, 2]]])
-    assert s1.dtype == pl.List(pl.List(pl.Int64))
-
-    s2 = pl.Series([[[2, 2]]], dtype=pl.List(pl.List(pl.UInt8)))
-    assert s2.dtype == pl.List(pl.List(pl.UInt8))
-
-    s3 = pl.Series(dtype=pl.List(pl.List(pl.UInt8)))
-    assert s3.dtype == pl.List(pl.List(pl.UInt8))
-
-    # numpy data containing NaN values
-    s0 = pl.Series("n", [1.0, 2.5, float("nan")])
-    s1 = pl.Series("n", np.array([1.0, 2.5, float("nan")]))
-    s2 = pl.Series("n", np.array([1.0, 2.5, float("nan")]), nan_to_null=True)
-
-    assert_series_equal(s0, s1, nans_compare_equal=True)
-    assert s2.to_list() == [1.0, 2.5, None]
-
-
-def test_init_seq_of_seq() -> None:
-    # List of lists
-    df = pl.DataFrame([[1, 2, 3], [4, 5, 6]], schema=["a", "b", "c"])
-    expected = pl.DataFrame({"a": [1, 4], "b": [2, 5], "c": [3, 6]})
-    assert_frame_equal(df, expected)
 
-    df = pl.DataFrame(
-        [[1, 2, 3], [4, 5, 6]],
-        schema=[("a", pl.Int8), ("b", pl.Int16), ("c", pl.Int32)],
-    )
-    assert df.schema == {"a": pl.Int8, "b": pl.Int16, "c": pl.Int32}
-    assert df.rows() == [(1, 2, 3), (4, 5, 6)]
+def test_shuffle() -> None:
+    # setting 'random.seed' should lead to reproducible results
+    s = pl.Series("a", range(20))
+    s_list = s.to_list()
 
-    # Tuple of tuples, default to column orientation
-    df = pl.DataFrame(((1, 2, 3), (4, 5, 6)))
-    expected = pl.DataFrame({"column_0": [1, 2, 3], "column_1": [4, 5, 6]})
-    assert_frame_equal(df, expected)
-
-    # Row orientation
-    df = pl.DataFrame(((1, 2), (3, 4)), schema=("a", "b"), orient="row")
-    expected = pl.DataFrame({"a": [1, 3], "b": [2, 4]})
-    assert_frame_equal(df, expected)
+    random.seed(1)
+    result1 = pl.select(pl.lit(s).shuffle()).to_series()
 
-    df = pl.DataFrame(
-        ((1, 2), (3, 4)), schema=(("a", pl.Float32), ("b", pl.Float32)), orient="row"
+    random.seed(1)
+    result2 = pl.select(a=pl.lit(s_list).shuffle()).to_series()
+    assert_series_equal(result1, result2)
+
+
+def test_sample() -> None:
+    a = pl.Series("a", range(0, 20))
+    out = pl.select(
+        pl.lit(a).sample(fraction=0.5, with_replacement=False, seed=1)
+    ).to_series()
+
+    assert out.shape == (10,)
+    assert out.to_list() != out.sort().to_list()
+    assert out.unique().shape == (10,)
+    assert set(out).issubset(set(a))
+
+    out = pl.select(pl.lit(a).sample(n=10, with_replacement=False, seed=1)).to_series()
+    assert out.shape == (10,)
+    assert out.to_list() != out.sort().to_list()
+    assert out.unique().shape == (10,)
+
+    # Setting random.seed should lead to reproducible results
+    random.seed(1)
+    result1 = pl.select(pl.lit(a).sample(n=10)).to_series()
+    random.seed(1)
+    result2 = pl.select(pl.lit(a).sample(n=10)).to_series()
+    assert_series_equal(result1, result2)
+
+
+def test_map_alias() -> None:
+    out = pl.DataFrame({"foo": [1, 2, 3]}).select(
+        (pl.col("foo") * 2).map_alias(lambda name: f"{name}{name}")
     )
-    assert df.schema == {"a": pl.Float32, "b": pl.Float32}
-    assert df.rows() == [(1.0, 2.0), (3.0, 4.0)]
+    expected = pl.DataFrame({"foofoo": [2, 4, 6]})
+    assert_frame_equal(out, expected)
+
+
+def test_unique_stable() -> None:
+    s = pl.Series("a", [1, 1, 1, 1, 2, 2, 2, 3, 3])
+    expected = pl.Series("a", [1, 2, 3])
+    assert_series_equal(s.unique(maintain_order=True), expected)
+
 
-    # Wrong orient value
-    with pytest.raises(ValueError):
-        df = pl.DataFrame(((1, 2), (3, 4)), orient="wrong")  # type: ignore[arg-type]
-
-
-def test_init_1d_sequence() -> None:
-    # Empty list
-    df = pl.DataFrame([])
-    assert_frame_equal(df, pl.DataFrame())
-
-    # List/array of strings
-    data = ["a", "b", "c"]
-    for a in (data, np.array(data)):
-        df = pl.DataFrame(a, schema=["s"])
-        expected = pl.DataFrame({"s": data})
-        assert_frame_equal(df, expected)
-
-    df = pl.DataFrame([None, True, False], schema=[("xx", pl.Int8)])
-    assert df.schema == {"xx": pl.Int8}
-    assert df.rows() == [(None,), (1,), (0,)]
-
-    # String sequence
-    assert pl.DataFrame("abc", schema=["s"]).to_dict(False) == {"s": ["a", "b", "c"]}
-
-    # datetimes sequence
-    df = pl.DataFrame([datetime(2020, 1, 1)], schema={"ts": pl.Datetime("ms")})
-    assert df.schema == {"ts": pl.Datetime("ms")}
+def test_unique_and_drop_stability() -> None:
+    # see: 2898
+    # the original cause was that we wrote:
+    # expr_a = a.unique()
+    # expr_a.filter(a.unique().is_not_null())
+    # meaning that the a.unique was executed twice, which is an unstable algorithm
+    df = pl.DataFrame({"a": [1, None, 1, None]})
+    assert df.select(pl.col("a").unique().drop_nulls()).to_series()[0] == 1
+
+
+def test_unique_counts() -> None:
+    s = pl.Series("id", ["a", "b", "b", "c", "c", "c"])
+    expected = pl.Series("id", [1, 2, 3], dtype=pl.UInt32)
+    assert_series_equal(s.unique_counts(), expected)
+
+
+def test_entropy() -> None:
     df = pl.DataFrame(
-        [datetime(2020, 1, 1, tzinfo=timezone.utc)], schema={"ts": pl.Datetime("ms")}
+        {
+            "group": ["A", "A", "A", "B", "B", "B", "B"],
+            "id": [1, 2, 1, 4, 5, 4, 6],
+        }
     )
-    assert df.schema == {"ts": pl.Datetime("ms", "UTC")}
-    df = pl.DataFrame(
-        [datetime(2020, 1, 1, tzinfo=timezone(timedelta(hours=1)))],
-        schema={"ts": pl.Datetime("ms")},
+    result = df.groupby("group", maintain_order=True).agg(
+        pl.col("id").entropy(normalize=True)
     )
-    assert df.schema == {"ts": pl.Datetime("ms", "+01:00")}
-    df = pl.DataFrame(
-        [datetime(2020, 1, 1, tzinfo=ZoneInfo("Asia/Kathmandu"))],
-        schema={"ts": pl.Datetime("ms")},
+    expected = pl.DataFrame(
+        {"group": ["A", "B"], "id": [1.0397207708399179, 1.371381017771811]}
     )
-    assert df.schema == {"ts": pl.Datetime("ms", "Asia/Kathmandu")}
-
+    assert_frame_equal(result, expected)
 
-def test_init_pandas(monkeypatch: Any) -> None:
-    pandas_df = pd.DataFrame([[1, 2], [3, 4]], columns=[1, 2])
-
-    # integer column names
-    df = pl.DataFrame(pandas_df)
-    expected = pl.DataFrame({"1": [1, 3], "2": [2, 4]})
-    assert_frame_equal(df, expected)
-    assert df.schema == {"1": pl.Int64, "2": pl.Int64}
-
-    # override column names, types
-    df = pl.DataFrame(pandas_df, schema=[("x", pl.Float64), ("y", pl.Float64)])
-    assert df.schema == {"x": pl.Float64, "y": pl.Float64}
-    assert df.rows() == [(1.0, 2.0), (3.0, 4.0)]
-
-    # subclassed pandas object, with/without data & overrides
-    class XSeries(pd.Series):
-        @property
-        def _constructor(self) -> type:
-            return XSeries
 
+def test_dot_in_groupby() -> None:
     df = pl.DataFrame(
-        data=[
-            XSeries(name="x", data=[], dtype=np.dtype("<M8[ns]")),
-            XSeries(name="y", data=[], dtype=np.dtype("f8")),
-            XSeries(name="z", data=[], dtype=np.dtype("?")),
-        ],
+        {
+            "group": ["a", "a", "a", "b", "b", "b"],
+            "x": [1, 1, 1, 1, 1, 1],
+            "y": [1, 2, 3, 4, 5, 6],
+        }
     )
-    assert df.schema == {"x": pl.Datetime("ns"), "y": pl.Float64, "z": pl.Boolean}
-    assert df.rows() == []
 
+    result = df.groupby("group", maintain_order=True).agg(
+        pl.col("x").dot("y").alias("dot")
+    )
+    expected = pl.DataFrame({"group": ["a", "b"], "dot": [6, 15]})
+    assert_frame_equal(result, expected)
+
+
+def test_dtype_col_selection() -> None:
     df = pl.DataFrame(
-        data=[
-            XSeries(
-                name="x",
-                data=[datetime(2022, 10, 31, 10, 30, 45, 123456)],
-                dtype=np.dtype("<M8[ns]"),
-            )
-        ],
-        schema={"colx": pl.Datetime("us")},
+        data=[],
+        schema={
+            "a1": pl.Datetime,
+            "a2": pl.Datetime("ms"),
+            "a3": pl.Datetime("ms"),
+            "a4": pl.Datetime("ns"),
+            "b": pl.Date,
+            "c": pl.Time,
+            "d1": pl.Duration,
+            "d2": pl.Duration("ms"),
+            "d3": pl.Duration("us"),
+            "d4": pl.Duration("ns"),
+            "e": pl.Int8,
+            "f": pl.Int16,
+            "g": pl.Int32,
+            "h": pl.Int64,
+            "i": pl.Float32,
+            "j": pl.Float64,
+            "k": pl.UInt8,
+            "l": pl.UInt16,
+            "m": pl.UInt32,
+            "n": pl.UInt64,
+        },
     )
-    assert df.schema == {"colx": pl.Datetime("us")}
-    assert df.rows() == [(datetime(2022, 10, 31, 10, 30, 45, 123456),)]
+    assert df.select(pl.col(INTEGER_DTYPES)).columns == [
+        "e",
+        "f",
+        "g",
+        "h",
+        "k",
+        "l",
+        "m",
+        "n",
+    ]
+    assert df.select(pl.col(FLOAT_DTYPES)).columns == ["i", "j"]
+    assert df.select(pl.col(NUMERIC_DTYPES)).columns == [
+        "e",
+        "f",
+        "g",
+        "h",
+        "i",
+        "j",
+        "k",
+        "l",
+        "m",
+        "n",
+    ]
+    assert df.select(pl.col(TEMPORAL_DTYPES)).columns == [
+        "a1",
+        "a2",
+        "a3",
+        "a4",
+        "b",
+        "c",
+        "d1",
+        "d2",
+        "d3",
+        "d4",
+    ]
+    assert df.select(pl.col(DATETIME_DTYPES)).columns == [
+        "a1",
+        "a2",
+        "a3",
+        "a4",
+    ]
+    assert df.select(pl.col(DURATION_DTYPES)).columns == [
+        "d1",
+        "d2",
+        "d3",
+        "d4",
+    ]
 
-    # pandas is not available
-    monkeypatch.setattr(pl.dataframe.frame, "_check_for_pandas", lambda x: False)
-    with pytest.raises(ValueError):
-        pl.DataFrame(pandas_df)
 
+def test_list_eval_expression() -> None:
+    df = pl.DataFrame({"a": [1, 8, 3], "b": [4, 5, 2]})
 
-def test_init_errors() -> None:
-    # Length mismatch
-    with pytest.raises(pl.ShapeError):
-        pl.DataFrame({"a": [1, 2, 3], "b": [1.0, 2.0, 3.0, 4.0]})
+    for parallel in [True, False]:
+        assert df.with_columns(
+            pl.concat_list(["a", "b"])
+            .arr.eval(pl.first().rank(), parallel=parallel)
+            .alias("rank")
+        ).to_dict(False) == {
+            "a": [1, 8, 3],
+            "b": [4, 5, 2],
+            "rank": [[1.0, 2.0], [2.0, 1.0], [2.0, 1.0]],
+        }
 
-    # Columns don't match data dimensions
-    with pytest.raises(pl.ShapeError):
-        pl.DataFrame([[1, 2], [3, 4]], schema=["a", "b", "c"])
+        assert df["a"].reshape((1, -1)).arr.eval(
+            pl.first(), parallel=parallel
+        ).to_list() == [[1, 8, 3]]
 
-    # Unmatched input
-    with pytest.raises(ValueError):
-        pl.DataFrame(0)
 
+def test_null_count_expr() -> None:
+    df = pl.DataFrame({"key": ["a", "b", "b", "a"], "val": [1, 2, None, 1]})
 
-def test_init_records() -> None:
-    dicts = [
-        {"a": 1, "b": 2},
-        {"b": 1, "a": 2},
-        {"a": 1, "b": 2},
-    ]
-    df = pl.DataFrame(dicts)
-    expected = pl.DataFrame({"a": [1, 2, 1], "b": [2, 1, 2]})
-    assert_frame_equal(df, expected)
-    assert df.to_dicts() == dicts
-
-    df_cd = pl.DataFrame(dicts, schema=["c", "d"])
-    expected = pl.DataFrame({"c": [1, 2, 1], "d": [2, 1, 2]})
-    assert_frame_equal(df_cd, expected)
-
-
-def test_init_records_schema_order() -> None:
-    cols: list[str] = ["a", "b", "c", "d"]
-    data: list[dict[str, int]] = [
-        {"c": 3, "b": 2, "a": 1},
-        {"b": 2, "d": 4},
-        {},
-        {"a": 1, "b": 2, "c": 3},
-        {"d": 4, "b": 2, "a": 1},
-        {"c": 3, "b": 2},
-    ]
-    lookup = {"a": 1, "b": 2, "c": 3, "d": 4, "e": None}
+    assert df.select([pl.all().null_count()]).to_dict(False) == {"key": [0], "val": [1]}
 
-    for constructor in (pl.from_dicts, pl.DataFrame):
-        # ensure field values are loaded according to the declared schema order
-        for _ in range(8):
-            shuffle(data)
-            shuffle(cols)
 
-            df = constructor(data, schema=cols)  # type: ignore[operator]
-            for col in df.columns:
-                assert all(value in (None, lookup[col]) for value in df[col].to_list())
+def test_power_by_expression() -> None:
+    out = pl.DataFrame(
+        {"a": [1, None, None, 4, 5, 6], "b": [1, 2, None, 4, None, 6]}
+    ).select(
+        [
+            pl.col("a").pow(pl.col("b")).alias("pow_expr"),
+            (pl.col("a") ** pl.col("b")).alias("pow_op"),
+            (2 ** pl.col("b")).alias("pow_op_left"),
+        ]
+    )
 
-        # have schema override inferred types, omit some columns, add a new one
-        schema = {"a": pl.Int8, "c": pl.Int16, "e": pl.Int32}
-        df = constructor(data, schema=schema)  # type: ignore[operator]
+    for pow_col in ("pow_expr", "pow_op"):
+        assert out[pow_col].to_list() == [
+            1.0,
+            None,
+            None,
+            256.0,
+            None,
+            46656.0,
+        ]
 
-        assert df.schema == schema
-        for col in df.columns:
-            assert all(value in (None, lookup[col]) for value in df[col].to_list())
+    assert out["pow_op_left"].to_list() == [
+        2.0,
+        4.0,
+        None,
+        16.0,
+        None,
+        64.0,
+    ]
 
 
-def test_init_only_columns() -> None:
-    df = pl.DataFrame(schema=["a", "b", "c"])
-    expected = pl.DataFrame({"a": [], "b": [], "c": []})
-    assert_frame_equal(df, expected)
+def test_expression_appends() -> None:
+    df = pl.DataFrame({"a": [1, 1, 2]})
 
-    # Validate construction with various flavours of no/empty data
-    no_data: Any
-    for no_data in (None, {}, []):
-        df = pl.DataFrame(
-            data=no_data,
-            schema=[
-                ("a", pl.Date),
-                ("b", pl.UInt64),
-                ("c", pl.Int8),
-                ("d", pl.List(pl.UInt8)),
-            ],
-        )
-        expected = pl.DataFrame({"a": [], "b": [], "c": []}).with_columns(
-            [
-                pl.col("a").cast(pl.Date),
-                pl.col("b").cast(pl.UInt64),
-                pl.col("c").cast(pl.Int8),
-            ]
-        )
-        expected.insert_at_idx(3, pl.Series("d", [], pl.List(pl.UInt8)))
+    assert df.select(pl.repeat(None, 3).append(pl.col("a"))).n_chunks() == 2
+
+    assert df.select(pl.repeat(None, 3).append(pl.col("a")).rechunk()).n_chunks() == 1
 
-        assert df.shape == (0, 4)
-        assert_frame_equal(df, expected)
-        assert df.dtypes == [pl.Date, pl.UInt64, pl.Int8, pl.List]
-        assert df.schema["d"].inner == pl.UInt8  # type: ignore[union-attr]
+    out = df.select(pl.concat([pl.repeat(None, 3), pl.col("a")]))
 
-        dfe = df.clear()
-        assert len(dfe) == 0
-        assert df.schema == dfe.schema
-        assert dfe.shape == df.shape
+    assert out.n_chunks() == 1
+    assert out.to_series().to_list() == [None, None, None, 1, 1, 2]
 
 
-def test_from_dicts_list_without_dtype() -> None:
-    assert pl.from_dicts(
-        [{"id": 1, "hint": ["some_text_here"]}, {"id": 2, "hint": [None]}]
-    ).to_dict(False) == {"id": [1, 2], "hint": [["some_text_here"], [None]]}
+def test_regex_in_filter() -> None:
+    df = pl.DataFrame(
+        {
+            "nrs": [1, 2, 3, None, 5],
+            "names": ["foo", "ham", "spam", "egg", None],
+            "flt": [1.0, None, 3.0, 1.0, None],
+        }
+    )
+
+    res = df.filter(
+        pl.fold(
+            acc=False, function=lambda acc, s: acc | s, exprs=(pl.col("^nrs|flt*$") < 3)
+        )
+    ).row(0)
+    expected = (1, "foo", 1.0)
+    assert res == expected
 
 
-def test_from_dicts_list_struct_without_inner_dtype() -> None:
-    assert pl.DataFrame(
+def test_arr_contains() -> None:
+    df_groups = pl.DataFrame(
         {
-            "users": [
-                [{"category": "A"}, {"category": "B"}],
-                [{"category": None}, {"category": None}],
+            "str_list": [
+                ["cat", "mouse", "dog"],
+                ["dog", "mouse", "cat"],
+                ["dog", "mouse", "aardvark"],
             ],
-            "days_of_week": [1, 2],
         }
-    ).to_dict(False) == {
-        "users": [
-            [{"category": "A"}, {"category": "B"}],
-            [{"category": None}, {"category": None}],
-        ],
-        "days_of_week": [1, 2],
+    )
+    assert df_groups.lazy().filter(
+        pl.col("str_list").arr.contains("cat")
+    ).collect().to_dict(False) == {
+        "str_list": [["cat", "mouse", "dog"], ["dog", "mouse", "cat"]]
     }
 
-    # 5611
-    df = pl.from_dicts(
+
+def test_rank_so_4109() -> None:
+    # also tests ranks null behavior
+    df = pl.from_dict(
+        {
+            "id": [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],
+            "rank": [None, 3, 2, 4, 1, 4, 3, 2, 1, None, 3, 4, 4, 1, None, 3],
+        }
+    ).sort(by=["id", "rank"])
+
+    assert df.groupby("id").agg(
         [
-            {"a": []},
-            {"a": [{"b": 1}]},
+            pl.col("rank").alias("original"),
+            pl.col("rank").rank(method="dense").alias("dense"),
+            pl.col("rank").rank(method="average").alias("average"),
         ]
+    ).to_dict(False) == {
+        "id": [1, 2, 3, 4],
+        "original": [[None, 2, 3, 4], [1, 2, 3, 4], [None, 1, 3, 4], [None, 1, 3, 4]],
+        "dense": [[None, 1, 2, 3], [1, 2, 3, 4], [None, 1, 2, 3], [None, 1, 2, 3]],
+        "average": [
+            [None, 1.0, 2.0, 3.0],
+            [1.0, 2.0, 3.0, 4.0],
+            [None, 1.0, 2.0, 3.0],
+            [None, 1.0, 2.0, 3.0],
+        ],
+    }
+
+
+def test_rank_random() -> None:
+    df = pl.from_dict(
+        {"a": [1] * 5, "b": [1, 2, 3, 4, 5], "c": [200, 100, 100, 50, 100]}
     )
-    assert df.to_dict(False) == {"a": [[], [{"b": 1}]]}
 
+    df_ranks1 = df.with_columns(
+        pl.col("c").rank(method="random", seed=1).over("a").alias("rank")
+    )
+    df_ranks2 = df.with_columns(
+        pl.col("c").rank(method="random", seed=1).over("a").alias("rank")
+    )
+    assert_frame_equal(df_ranks1, df_ranks2)
 
-def test_upcast_primitive_and_strings() -> None:
-    assert pl.Series([1, 1.0, 1]).dtype == pl.Float64
-    assert pl.Series([1, 1, "1.0"]).dtype == pl.Utf8
-    assert pl.Series([1, 1.0, "1.0"]).dtype == pl.Utf8
-    assert pl.Series([True, 1]).dtype == pl.Int64
-    assert pl.Series([True, 1.0]).dtype == pl.Float64
-    assert pl.Series([True, 1], dtype=pl.Boolean).dtype == pl.Boolean
-    assert pl.Series([False, 1.0], dtype=pl.Boolean).dtype == pl.Boolean
-    assert pl.Series([False, "1.0"]).dtype == pl.Utf8
-    assert pl.from_dict({"a": [1, 2.1, 3], "b": [4, 5, 6.4]}).dtypes == [
-        pl.Float64,
-        pl.Float64,
-    ]
 
+def test_unique_empty() -> None:
+    for dt in [pl.Utf8, pl.Boolean, pl.Int32, pl.UInt32]:
+        s = pl.Series([], dtype=dt)
+        assert_series_equal(s.unique(), s)
 
-def test_u64_lit_5031() -> None:
-    df = pl.DataFrame({"foo": [1, 2, 3]}).with_columns(pl.col("foo").cast(pl.UInt64))
-    assert df.filter(pl.col("foo") < (1 << 64) - 20).shape == (3, 1)
-    assert df["foo"].to_list() == [1, 2, 3]
 
+@typing.no_type_check
+def test_search_sorted() -> None:
+    for seed in [1, 2, 3]:
+        np.random.seed(seed)
+        a = np.sort(np.random.randn(10) * 100)
+        s = pl.Series(a)
 
-def test_from_dicts_missing_columns() -> None:
-    data = [
-        {"a": 1},
-        {"b": 2},
-    ]
+        for v in range(int(np.min(a)), int(np.max(a)), 20):
+            assert np.searchsorted(a, v) == s.search_sorted(v)
 
-    assert pl.from_dicts(data).to_dict(False) == {"a": [1, None], "b": [None, 2]}
+    a = pl.Series([1, 2, 3])
+    b = pl.Series([1, 2, 2, -1])
+    assert a.search_sorted(b).to_list() == [0, 1, 1, 0]
+    b = pl.Series([1, 2, 2, None, 3])
+    assert a.search_sorted(b).to_list() == [0, 1, 1, 0, 2]
 
+    a = pl.Series(["b", "b", "d", "d"])
+    b = pl.Series(["a", "b", "c", "d", "e"])
+    assert a.search_sorted(b, side="left").to_list() == [0, 0, 2, 2, 4]
+    assert a.search_sorted(b, side="right").to_list() == [0, 2, 2, 4, 4]
 
-@typing.no_type_check
-def test_from_rows_dtype() -> None:
-    # 50 is the default inference length
-    # 5182
-    df = pl.DataFrame(
-        data=[(None, None)] * 50 + [("1.23", None)],
-        schema=[("foo", pl.Utf8), ("bar", pl.Utf8)],
-        orient="row",
-    )
-    assert df.dtypes == [pl.Utf8, pl.Utf8]
-    assert df.null_count().row(0) == (50, 51)
-
-    type1 = [{"c1": 206, "c2": "type1", "c3": {"x1": "abcd", "x2": "jkl;"}}]
-    type2 = [
-        {"c1": 208, "c2": "type2", "c3": {"a1": "abcd", "a2": "jkl;", "a3": "qwerty"}}
-    ]
+    a = pl.Series([1, 1, 4, 4])
+    b = pl.Series([0, 1, 2, 4, 5])
+    assert a.search_sorted(b, side="left").to_list() == [0, 0, 2, 2, 4]
+    assert a.search_sorted(b, side="right").to_list() == [0, 2, 2, 4, 4]
 
-    df = pl.DataFrame(
-        data=type1 * 50 + type2,
-        schema=[("c1", pl.Int32), ("c2", pl.Object), ("c3", pl.Object)],
-    )
-    assert df.dtypes == [pl.Int32, pl.Object, pl.Object]
 
-    # 50 is the default inference length
-    # 5266
-    type1 = [{"c1": 206, "c2": "type1", "c3": {"x1": "abcd", "x2": "jkl;"}}]
-    type2 = [
-        {"c1": 208, "c2": "type2", "c3": {"a1": "abcd", "a2": "jkl;", "a3": "qwerty"}}
-    ]
+def test_abs_expr() -> None:
+    df = pl.DataFrame({"x": [-1, 0, 1]})
+    out = df.select(abs(pl.col("x")))
 
-    df = pl.DataFrame(
-        data=type1 * 50 + type2,
-        schema=[("c1", pl.Int32), ("c2", pl.Object), ("c3", pl.Object)],
-    )
-    assert df.dtypes == [pl.Int32, pl.Object, pl.Object]
-    assert df.null_count().row(0) == (0, 0, 0)
+    assert out["x"].to_list() == [1, 0, 1]
 
 
-def test_from_dicts_schema() -> None:
-    data = [{"a": 1, "b": 4}, {"a": 2, "b": 5}, {"a": 3, "b": 6}]
+def test_logical_boolean() -> None:
+    # note, cannot use expressions in logical
+    # boolean context (eg: and/or/not operators)
+    with pytest.raises(ValueError, match="ambiguous"):
+        pl.col("colx") and pl.col("coly")
 
-    # let polars infer the dtypes, but inform it about a 3rd column.
-    for schema, overrides in (
-        ({"a": pl.Unknown, "b": pl.Unknown, "c": pl.Int32}, None),
-        ({"a": None, "b": None, "c": None}, {"c": pl.Int32}),
-        (["a", "b", ("c", pl.Int32)], None),
-    ):
-        df = pl.from_dicts(
-            data,
-            schema=schema,  # type: ignore[arg-type]
-            schema_overrides=overrides,
-        )
-        assert df.dtypes == [pl.Int64, pl.Int64, pl.Int32]
-        assert df.to_dict(False) == {
-            "a": [1, 2, 3],
-            "b": [4, 5, 6],
-            "c": [None, None, None],
-        }
+    with pytest.raises(ValueError, match="ambiguous"):
+        pl.col("colx") or pl.col("coly")
+
+    df = pl.DataFrame({"a": [1, 2, 3, 4, 5], "b": [1, 2, 3, 4, 5]})
+
+    with pytest.raises(ValueError, match="ambiguous"):
+        df.select([(pl.col("a") > pl.col("b")) and (pl.col("b") > pl.col("b"))])
+
+    with pytest.raises(ValueError, match="ambiguous"):
+        df.select([(pl.col("a") > pl.col("b")) or (pl.col("b") > pl.col("b"))])
 
 
-def test_nested_read_dict_4143() -> None:
-    assert pl.from_dicts(
+# https://github.com/pola-rs/polars/issues/4951
+def test_ewm_with_multiple_chunks() -> None:
+    df0 = pl.DataFrame(
+        data=[
+            ("w", 6.0, 1.0),
+            ("x", 5.0, 2.0),
+            ("y", 4.0, 3.0),
+            ("z", 3.0, 4.0),
+        ],
+        schema=["a", "b", "c"],
+    ).with_columns(
         [
-            {
-                "id": 1,
-                "hint": [
-                    {"some_text_here": "text", "list_": [1, 2, 4]},
-                    {"some_text_here": "text", "list_": [1, 2, 4]},
-                ],
-            },
-            {
-                "id": 2,
-                "hint": [
-                    {"some_text_here": None, "list_": [1]},
-                    {"some_text_here": None, "list_": [2]},
-                ],
-            },
+            pl.col(pl.Float64).log().diff().prefix("ld_"),
         ]
-    ).to_dict(False) == {
-        "hint": [
-            [
-                {"some_text_here": "text", "list_": [1, 2, 4]},
-                {"some_text_here": "text", "list_": [1, 2, 4]},
-            ],
-            [
-                {"some_text_here": None, "list_": [1]},
-                {"some_text_here": None, "list_": [2]},
-            ],
-        ],
-        "id": [1, 2],
-    }
+    )
+    assert df0.n_chunks() == 1
+
+    # NOTE: We aren't testing whether `select` creates two chunks;
+    # we just need two chunks to properly test `ewm_mean`
+    df1 = df0.select(["ld_b", "ld_c"])
+    assert df1.n_chunks() == 2
 
-    out = pl.from_dicts(
+    ewm_std = df1.with_columns(
         [
-            {
-                "id": 1,
-                "hint": [
-                    {"some_text_here": "text", "list_": [1, 2, 4]},
-                    {"some_text_here": "text", "list_": [1, 2, 4]},
-                ],
-            },
-            {
-                "id": 2,
-                "hint": [
-                    {"some_text_here": "text", "list_": []},
-                    {"some_text_here": "text", "list_": []},
-                ],
-            },
+            pl.all().ewm_std(com=20).prefix("ewm_"),
         ]
     )
+    assert ewm_std.null_count().sum(axis=1)[0] == 4
 
-    assert out.dtypes == [
-        pl.Int64,
-        pl.List(pl.Struct({"some_text_here": pl.Utf8, "list_": pl.List(pl.Int64)})),
-    ]
-    assert out.to_dict(False) == {
-        "id": [1, 2],
-        "hint": [
+
+def test_map_dict() -> None:
+    country_code_dict = {
+        "CA": "Canada",
+        "DE": "Germany",
+        "FR": "France",
+        None: "Not specified",
+    }
+    df = pl.DataFrame(
+        [
+            pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+            pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+        ]
+    )
+
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("country_code")
+            .map_dict(country_code_dict, default=pl.first())
+            .alias("remapped")
+        ),
+        pl.DataFrame(
             [
-                {"some_text_here": "text", "list_": [1, 2, 4]},
-                {"some_text_here": "text", "list_": [1, 2, 4]},
-            ],
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series(
+                    "remapped",
+                    ["France", "Not specified", "ES", "Germany"],
+                    dtype=pl.Utf8,
+                ),
+            ]
+        ),
+    )
+
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("country_code")
+            .map_dict(country_code_dict, default=pl.col("country_code"))
+            .alias("remapped")
+        ),
+        pl.DataFrame(
             [
-                {"some_text_here": "text", "list_": []},
-                {"some_text_here": "text", "list_": []},
-            ],
-        ],
-    }
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series(
+                    "remapped",
+                    ["France", "Not specified", "ES", "Germany"],
+                    dtype=pl.Utf8,
+                ),
+            ]
+        ),
+    )
 
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("country_code").map_dict(country_code_dict).alias("remapped")
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series(
+                    "remapped",
+                    ["France", "Not specified", None, "Germany"],
+                    dtype=pl.Utf8,
+                ),
+            ]
+        ),
+    )
 
-@typing.no_type_check
-def test_from_records_nullable_structs() -> None:
-    records = [
-        {"id": 1, "items": [{"item_id": 100, "description": None}]},
-        {"id": 1, "items": [{"item_id": 100, "description": "hi"}]},
-    ]
+    assert_frame_equal(
+        df.with_row_count().with_columns(
+            pl.struct(pl.col(["country_code", "row_nr"]))
+            .map_dict(
+                country_code_dict,
+                default=pl.col("row_nr").cast(pl.Utf8),
+            )
+            .alias("remapped")
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("row_nr", [0, 1, 2, 3], dtype=pl.UInt32),
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series(
+                    "remapped",
+                    ["France", "Not specified", "2", "Germany"],
+                    dtype=pl.Utf8,
+                ),
+            ]
+        ),
+    )
 
-    schema = [
-        ("id", pl.UInt16),
-        (
-            "items",
-            pl.List(
-                pl.Struct(
-                    [pl.Field("item_id", pl.UInt32), pl.Field("description", pl.Utf8)]
-                )
+    with pl.StringCache():
+        assert_frame_equal(
+            df.with_columns(
+                pl.col("country_code")
+                .cast(pl.Categorical)
+                .map_dict(country_code_dict, default=pl.col("country_code"))
+                .alias("remapped")
+            ),
+            pl.DataFrame(
+                [
+                    pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                    pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                    pl.Series(
+                        "remapped",
+                        ["France", "Not specified", "ES", "Germany"],
+                        dtype=pl.Categorical,
+                    ),
+                ]
             ),
+        )
+
+    df_categorical_lazy = df.lazy().with_columns(
+        pl.col("country_code").cast(pl.Categorical)
+    )
+
+    with pl.StringCache():
+        assert_frame_equal(
+            df_categorical_lazy.with_columns(
+                pl.col("country_code")
+                .map_dict(country_code_dict, default=pl.col("country_code"))
+                .alias("remapped")
+            ).collect(),
+            pl.DataFrame(
+                [
+                    pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                    pl.Series(
+                        "country_code", ["FR", None, "ES", "DE"], dtype=pl.Categorical
+                    ),
+                    pl.Series(
+                        "remapped",
+                        ["France", "Not specified", "ES", "Germany"],
+                        dtype=pl.Categorical,
+                    ),
+                ]
+            ),
+        )
+
+    int_to_int_dict = {1: 5, 3: 7}
+
+    assert_frame_equal(
+        df.with_columns(pl.col("int").map_dict(int_to_int_dict).alias("remapped")),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", [None, 5, None, 7], dtype=pl.Int16),
+            ]
         ),
-    ]
+    )
 
-    for s in [schema, None]:
-        assert pl.DataFrame(records, schema=s, orient="row").to_dict(False) == {
-            "id": [1, 1],
-            "items": [
-                [{"item_id": 100, "description": None}],
-                [{"item_id": 100, "description": "hi"}],
-            ],
-        }
+    int_dict = {1: "b", 3: "d"}
 
-    # check initialisation without any records
-    df = pl.DataFrame(schema=schema)
-    dict_schema = dict(schema)
+    assert_frame_equal(
+        df.with_columns(pl.col("int").map_dict(int_dict).alias("remapped")),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", [None, "b", None, "d"], dtype=pl.Utf8),
+            ]
+        ),
+    )
 
-    assert df.to_dict(False) == {"id": [], "items": []}
-    assert df.schema == dict_schema
+    int_with_none_dict = {1: "b", 3: "d", None: "e"}
 
-    s = pl.Series("items", dtype=dict_schema["items"])
-    assert s.to_frame().to_dict(False) == {"items": []}
-    assert s.dtype == dict_schema["items"]
-    assert s.to_list() == []
+    assert_frame_equal(
+        df.with_columns(pl.col("int").map_dict(int_with_none_dict).alias("remapped")),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", ["e", "b", "e", "d"], dtype=pl.Utf8),
+            ]
+        ),
+    )
 
+    int_with_only_none_values_dict = {3: None}
 
-def test_from_categorical_in_struct_defined_by_schema() -> None:
-    df = pl.DataFrame(
-        {
-            "a": [
-                {"value": "foo", "counts": 1},
-                {"value": "bar", "counts": 2},
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("int")
+            .map_dict(int_with_only_none_values_dict, default=6)
+            .alias("remapped")
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", [6, 6, 6, None], dtype=pl.Int16),
             ]
-        },
-        schema={"a": pl.Struct({"value": pl.Categorical, "counts": pl.UInt32})},
+        ),
     )
-    out = df.unnest("a")
-    assert out.schema == {"value": pl.Categorical, "counts": pl.UInt32}
-    assert out.to_dict(False) == {"value": ["foo", "bar"], "counts": [1, 2]}
 
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("int")
+            .map_dict(int_with_only_none_values_dict, default=6, return_dtype=pl.Int32)
+            .alias("remapped")
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", [6, 6, 6, None], dtype=pl.Int32),
+            ]
+        ),
+    )
 
-def test_nested_schema_construction() -> None:
-    schema = {
-        "node_groups": pl.List(
-            pl.Struct(
-                [
-                    pl.Field("parent_node_group_id", pl.UInt8),
-                    pl.Field(
-                        "nodes",
-                        pl.List(
-                            pl.Struct(
-                                [
-                                    pl.Field("name", pl.Utf8),
-                                    pl.Field(
-                                        "sub_nodes",
-                                        pl.List(
-                                            pl.Struct(
-                                                [
-                                                    pl.Field("internal_id", pl.UInt64),
-                                                    pl.Field("value", pl.UInt32),
-                                                ]
-                                            )
-                                        ),
-                                    ),
-                                ]
-                            )
-                        ),
-                    ),
-                ]
-            )
-        )
-    }
-    df = pl.DataFrame(
-        {
-            "node_groups": [
-                [{"nodes": []}, {"nodes": [{"name": "", "sub_nodes": []}]}],
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("int").map_dict(int_with_only_none_values_dict).alias("remapped")
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", [None, None, None, None], dtype=pl.Int16),
             ]
-        },
-        schema=schema,
+        ),
     )
-    assert df.schema == schema
-    assert df.to_dict(False) == {
-        "node_groups": [
-            [
-                {"parent_node_group_id": None, "nodes": []},
-                {
-                    "parent_node_group_id": None,
-                    "nodes": [{"name": "", "sub_nodes": []}],
-                },
+
+    empty_dict: dict[Any, Any] = {}
+
+    assert_frame_equal(
+        df.with_columns(
+            pl.col("int").map_dict(empty_dict, default=pl.first()).alias("remapped")
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("int", [None, 1, None, 3], dtype=pl.Int16),
+                pl.Series("country_code", ["FR", None, "ES", "DE"], dtype=pl.Utf8),
+                pl.Series("remapped", [None, 1, None, 3], dtype=pl.Int16),
             ]
-        ]
-    }
+        ),
+    )
 
-    schema = {
-        "node_groups": pl.List(
-            pl.Struct(
-                [
-                    pl.Field(
-                        "nodes",
-                        pl.List(
-                            pl.Struct(
-                                [pl.Field("name", pl.Utf8), pl.Field("time", pl.UInt32)]
-                            )
-                        ),
-                    )
-                ]
-            )
-        )
-    }
-    df = pl.DataFrame(
-        [
-            {"node_groups": [{"nodes": [{"name": "a", "time": 0}]}]},
-            {"node_groups": [{"nodes": []}]},
-        ],
-        schema=schema,
+    float_dict = {1.0: "b", 3.0: "d"}
+
+    with pytest.raises(
+        pl.ComputeError,
+        match="Remapping keys for map_dict could not be converted to Int16: ",
+    ):
+        df.with_columns(pl.col("int").map_dict(float_dict))
+
+    df_int_as_str = df.with_columns(pl.col("int").cast(pl.Utf8))
+
+    with pytest.raises(
+        pl.ComputeError,
+        match="Remapping keys for map_dict could not be converted to Utf8 without losing values in the conversion.",
+    ):
+        df_int_as_str.with_columns(pl.col("int").map_dict(int_dict))
+
+    with pytest.raises(
+        pl.ComputeError,
+        match="Remapping keys for map_dict could not be converted to Utf8 without losing values in the conversion.",
+    ):
+        df_int_as_str.with_columns(pl.col("int").map_dict(int_with_none_dict))
+
+    # 7132
+    df = pl.DataFrame({"text": ["abc"]})
+    mapper = {"abc": "123"}
+    assert_frame_equal(
+        df.select(pl.col("text").map_dict(mapper).str.replace_all("1", "-")),
+        pl.DataFrame(
+            [
+                pl.Series("text", ["-23"], dtype=pl.Utf8),
+            ]
+        ),
+    )
+
+    assert_frame_equal(
+        pl.DataFrame(
+            [
+                pl.Series("float_to_boolean", [1.0, None]),
+                pl.Series("boolean_to_int", [True, False]),
+                pl.Series("boolean_to_str", [True, False]),
+            ]
+        ).with_columns(
+            pl.col("float_to_boolean").map_dict({1.0: True}),
+            pl.col("boolean_to_int").map_dict({True: 1, False: 0}),
+            pl.col("boolean_to_str").map_dict({True: "1", False: "0"}),
+        ),
+        pl.DataFrame(
+            [
+                pl.Series("float_to_boolean", [True, None], dtype=pl.Boolean),
+                pl.Series("boolean_to_int", [1, 0], dtype=pl.Int64),
+                pl.Series("boolean_to_str", ["1", "0"], dtype=pl.Utf8),
+            ]
+        ),
     )
-    assert df.schema == schema
-    assert df.to_dict(False) == {
-        "node_groups": [[{"nodes": [{"name": "a", "time": 0}]}], [{"nodes": []}]]
-    }
 
 
-def test_arrow_to_pyseries_with_one_chunk_does_not_copy_data() -> None:
-    from polars.utils._construction import arrow_to_pyseries
+def test_lit_dtypes() -> None:
+    def lit_series(value: Any, dtype: pl.PolarsDataType | None) -> pl.Series:
+        return pl.select(pl.lit(value, dtype=dtype)).to_series()
+
+    d = datetime(2049, 10, 5, 1, 2, 3, 987654)
+    d_ms = datetime(2049, 10, 5, 1, 2, 3, 987000)
+    d_tz = datetime(2049, 10, 5, 1, 2, 3, 987654, tzinfo=ZoneInfo("Asia/Kathmandu"))
 
-    original_array = pa.chunked_array([[1, 2, 3]], type=pa.int64())
-    pyseries = arrow_to_pyseries("", original_array)
-    assert (
-        pyseries.get_chunks()[0]._get_ptr()
-        == original_array.chunks[0].buffers()[1].address
+    td = timedelta(days=942, hours=6, microseconds=123456)
+    td_ms = timedelta(days=942, seconds=21600, microseconds=123000)
+
+    df = pl.DataFrame(
+        {
+            "dtm_ms": lit_series(d, pl.Datetime("ms")),
+            "dtm_us": lit_series(d, pl.Datetime("us")),
+            "dtm_ns": lit_series(d, pl.Datetime("ns")),
+            "dtm_aware_0": lit_series(d, pl.Datetime("us", "Asia/Kathmandu")),
+            "dtm_aware_1": lit_series(d_tz, pl.Datetime("us")),
+            "dtm_aware_2": lit_series(d_tz, None),
+            "dtm_aware_3": lit_series(d, pl.Datetime(None, "Asia/Kathmandu")),
+            "dur_ms": lit_series(td, pl.Duration("ms")),
+            "dur_us": lit_series(td, pl.Duration("us")),
+            "dur_ns": lit_series(td, pl.Duration("ns")),
+            "f32": lit_series(0, pl.Float32),
+            "u16": lit_series(0, pl.UInt16),
+            "i16": lit_series(0, pl.Int16),
+            "i64": lit_series([8], None),
+            "list_i64": lit_series([[1, 2, 3]], None),
+        }
+    )
+    assert df.dtypes == [
+        pl.Datetime("ms"),
+        pl.Datetime("us"),
+        pl.Datetime("ns"),
+        pl.Datetime("us", "Asia/Kathmandu"),
+        pl.Datetime("us", "Asia/Kathmandu"),
+        pl.Datetime("us", "Asia/Kathmandu"),
+        pl.Datetime("us", "Asia/Kathmandu"),
+        pl.Duration("ms"),
+        pl.Duration("us"),
+        pl.Duration("ns"),
+        pl.Float32,
+        pl.UInt16,
+        pl.Int16,
+        pl.Int64,
+        pl.List(pl.Int64),
+    ]
+    assert df.row(0) == (
+        d_ms,
+        d,
+        d,
+        d_tz,
+        d_tz,
+        d_tz,
+        d_tz,
+        td_ms,
+        td,
+        td,
+        0,
+        0,
+        0,
+        8,
+        [1, 2, 3],
     )
 
 
-def test_init_with_explicit_binary_schema() -> None:
-    df = pl.DataFrame({"a": [b"hello", b"world"]}, schema={"a": pl.Binary})
-    assert df.schema == {"a": pl.Binary}
-    assert df["a"].to_list() == [b"hello", b"world"]
+def test_incompatible_lit_dtype() -> None:
+    with pytest.raises(TypeError, match="Cannot cast tz-aware value to tz-aware dtype"):
+        pl.lit(
+            datetime(2020, 1, 1, tzinfo=timezone.utc),
+            dtype=pl.Datetime("us", "Asia/Kathmandu"),
+        )
+
 
-    s = pl.Series("a", [b"hello", b"world"], dtype=pl.Binary)
-    assert s.dtype == pl.Binary
-    assert s.to_list() == [b"hello", b"world"]
+@pytest.mark.parametrize(
+    ("input", "expected"),
+    [
+        (("a",), ["b", "c"]),
+        (("a", "b"), ["c"]),
+        ((["a", "b"],), ["c"]),
+        ((pl.Int64,), ["c"]),
+        ((pl.Utf8, pl.Float32), ["a", "b"]),
+        (([pl.Utf8, pl.Float32],), ["a", "b"]),
+    ],
+)
+def test_exclude(input: tuple[Any, ...], expected: list[str]) -> None:
+    df = pl.DataFrame(schema={"a": pl.Int64, "b": pl.Int64, "c": pl.Utf8})
+    assert df.select(pl.all().exclude(*input)).columns == expected
 
 
-def test_nested_categorical() -> None:
-    s = pl.Series([["a"]], dtype=pl.List(pl.Categorical))
-    assert s.to_list() == [["a"]]
-    assert s.dtype == pl.List(pl.Categorical)
+@pytest.mark.parametrize("input", [(5,), (["a"], "b"), (pl.Int64, "a")])
+def test_exclude_invalid_input(input: tuple[Any, ...]) -> None:
+    df = pl.DataFrame(schema=["a", "b", "c"])
+    with pytest.raises(TypeError):
+        df.select(pl.all().exclude(*input))
 
 
-def test_datetime_date_subclasses() -> None:
-    class FakeDate(date):
-        ...
+def test_operators_vs_expressions() -> None:
+    df = pl.DataFrame(
+        data={
+            "x": [5, 6, 7, 4, 8],
+            "y": [1.5, 2.5, 1.0, 4.0, -5.75],
+            "z": [-9, 2, -1, 4, 8],
+        }
+    )
+    for c1, c2 in permutations("xyz", r=2):
+        df_op = df.select(
+            a=pl.col(c1) == pl.col(c2),
+            b=pl.col(c1) // pl.col(c2),
+            c=pl.col(c1) > pl.col(c2),
+            d=pl.col(c1) >= pl.col(c2),
+            e=pl.col(c1) < pl.col(c2),
+            f=pl.col(c1) <= pl.col(c2),
+            g=pl.col(c1) % pl.col(c2),
+            h=pl.col(c1) != pl.col(c2),
+            i=pl.col(c1) - pl.col(c2),
+            j=pl.col(c1) / pl.col(c2),
+            k=pl.col(c1) * pl.col(c2),
+            l=pl.col(c1) + pl.col(c2),
+        )
+        df_expr = df.select(
+            a=pl.col(c1).eq(pl.col(c2)),
+            b=pl.col(c1).floordiv(pl.col(c2)),
+            c=pl.col(c1).gt(pl.col(c2)),
+            d=pl.col(c1).ge(pl.col(c2)),
+            e=pl.col(c1).lt(pl.col(c2)),
+            f=pl.col(c1).le(pl.col(c2)),
+            g=pl.col(c1).mod(pl.col(c2)),
+            h=pl.col(c1).ne(pl.col(c2)),
+            i=pl.col(c1).sub(pl.col(c2)),
+            j=pl.col(c1).truediv(pl.col(c2)),
+            k=pl.col(c1).mul(pl.col(c2)),
+            l=pl.col(c1).add(pl.col(c2)),
+        )
+        assert_frame_equal(df_op, df_expr)
+
+    # xor - only int cols
+    assert_frame_equal(
+        df.select(pl.col("x") ^ pl.col("z")),
+        df.select(pl.col("x").xor(pl.col("z"))),
+    )
+
+    # and (&) or (|) chains
+    assert_frame_equal(
+        df.select(
+            all=(pl.col("x") >= pl.col("z")).and_(
+                pl.col("y") >= pl.col("z"),
+                pl.col("y") == pl.col("y"),
+                pl.col("z") <= pl.col("x"),
+                pl.col("y") != pl.col("x"),
+            )
+        ),
+        df.select(
+            all=(
+                (pl.col("x") >= pl.col("z"))
+                & (pl.col("y") >= pl.col("z"))
+                & (pl.col("y") == pl.col("y"))
+                & (pl.col("z") <= pl.col("x"))
+                & (pl.col("y") != pl.col("x"))
+            )
+        ),
+    )
+
+    assert_frame_equal(
+        df.select(
+            any=(pl.col("x") == pl.col("y")).or_(
+                pl.col("x") == pl.col("y"),
+                pl.col("y") == pl.col("z"),
+                pl.col("y").cast(int) == pl.col("z"),
+            )
+        ),
+        df.select(
+            any=(pl.col("x") == pl.col("y"))
+            | (pl.col("x") == pl.col("y"))
+            | (pl.col("y") == pl.col("z"))
+            | (pl.col("y").cast(int) == pl.col("z"))
+        ),
+    )
 
-    class FakeDatetime(FakeDate, datetime):
-        ...
 
-    result = pl.Series([FakeDatetime(2020, 1, 1, 3)])
-    expected = pl.Series([datetime(2020, 1, 1, 3)])
-    assert_series_equal(result, expected)
-    result = pl.Series([FakeDate(2020, 1, 1)])
-    expected = pl.Series([date(2020, 1, 1)])
-    assert_series_equal(result, expected)
+def test_head() -> None:
+    df = pl.DataFrame({"a": [1, 2, 3, 4, 5]})
+    assert df.select(pl.col("a").head(0)).to_dict(False) == {"a": []}
+    assert df.select(pl.col("a").head(3)).to_dict(False) == {"a": [1, 2, 3]}
+    assert df.select(pl.col("a").head(10)).to_dict(False) == {"a": [1, 2, 3, 4, 5]}
+    assert df.select(pl.col("a").head(pl.count() / 2)).to_dict(False) == {"a": [1, 2]}
 
 
-def test_list_null_constructor() -> None:
-    s = pl.Series("a", [[None], [None]], dtype=pl.List(pl.Null))
-    assert s.dtype == pl.List(pl.Null)
-    assert s.to_list() == [None, None]
+def test_tail() -> None:
+    df = pl.DataFrame({"a": [1, 2, 3, 4, 5]})
+    assert df.select(pl.col("a").tail(0)).to_dict(False) == {"a": []}
+    assert df.select(pl.col("a").tail(3)).to_dict(False) == {"a": [3, 4, 5]}
+    assert df.select(pl.col("a").tail(10)).to_dict(False) == {"a": [1, 2, 3, 4, 5]}
+    assert df.select(pl.col("a").tail(pl.count() / 2)).to_dict(False) == {"a": [4, 5]}
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_cse.py` & `polars_lts_cpu-0.17.3/tests/unit/test_cse.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_datatypes.py` & `polars_lts_cpu-0.17.3/tests/unit/test_datatypes.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_df.py` & `polars_lts_cpu-0.17.3/tests/unit/test_df.py`

 * *Files 1% similar despite different names*

```diff
@@ -534,35 +534,35 @@
 def test_take_misc(fruits_cars: pl.DataFrame) -> None:
     df = fruits_cars
 
     # out of bounds error
     with pytest.raises(pl.ComputeError):
         (
             df.sort("fruits").select(
-                [pl.col("B").reverse().take([1, 2]).list().over("fruits"), "fruits"]
+                [pl.col("B").reverse().take([1, 2]).implode().over("fruits"), "fruits"]
             )
         )
 
     for index in [[0, 1], pl.Series([0, 1]), np.array([0, 1])]:
         out = df.sort("fruits").select(
             [
                 pl.col("B")
                 .reverse()
                 .take(index)  # type: ignore[arg-type]
-                .list()
+                .implode()
                 .over("fruits"),
                 "fruits",
             ]
         )
 
         assert out[0, "B"].to_list() == [2, 3]
         assert out[4, "B"].to_list() == [1, 4]
 
     out = df.sort("fruits").select(
-        [pl.col("B").reverse().take(pl.lit(1)).list().over("fruits"), "fruits"]
+        [pl.col("B").reverse().take(pl.lit(1)).implode().over("fruits"), "fruits"]
     )
     assert out[0, "B"] == 3
     assert out[4, "B"] == 4
 
 
 def test_slice() -> None:
     df = pl.DataFrame({"a": [1, 2, 3], "b": ["a", "b", "c"]})
@@ -1217,41 +1217,106 @@
             "e": ["usd", "eur", None],
             "f": [date(2020, 1, 1), date(2021, 1, 1), date(2022, 1, 1)],
         }
     )
     df = df.with_columns(pl.col("e").cast(pl.Categorical))
     expected = pl.DataFrame(
         {
-            "describe": ["count", "null_count", "mean", "std", "min", "max", "median"],
-            "a": [3.0, 0.0, 2.2666667, 1.101514, 1.0, 3.0, 2.8],
-            "b": [3.0, 1.0, 4.5, 0.7071067811865476, 4.0, 5.0, 4.5],
-            "c": [3.0, 0.0, 0.6666666666666666, 0.5773502588272095, 0.0, 1.0, 1.0],
-            "d": ["3", "1", None, None, "b", "c", None],
-            "e": ["3", "1", None, None, None, None, None],
-            "f": ["3", "0", None, None, "2020-01-01", "2022-01-01", None],
+            "describe": [
+                "count",
+                "null_count",
+                "mean",
+                "std",
+                "min",
+                "max",
+                "median",
+                "25%",
+                "75%",
+            ],
+            "a": [3.0, 0.0, 2.2666667, 1.101514, 1.0, 3.0, 2.8, 1.0, 3.0],
+            "b": [3.0, 1.0, 4.5, 0.7071067811865476, 4.0, 5.0, 4.5, 4.0, 5.0],
+            "c": [
+                3.0,
+                0.0,
+                0.6666666666666666,
+                0.5773502588272095,
+                0.0,
+                1.0,
+                1.0,
+                None,
+                None,
+            ],
+            "d": ["3", "1", None, None, "b", "c", None, None, None],
+            "e": ["3", "1", None, None, None, None, None, None, None],
+            "f": ["3", "0", None, None, "2020-01-01", "2022-01-01", None, None, None],
         }
     )
     assert_frame_equal(df.describe(), expected)
 
     # struct
     df = pl.DataFrame(
         {
             "numerical": [1, 2, 1, None],
             "struct": [{"x": 1, "y": 2}, {"x": 3, "y": 4}, {"x": 1, "y": 2}, None],
             "list": [[1, 2], [3, 4], [1, 2], None],
         }
     )
 
     assert df.describe().to_dict(False) == {
-        "describe": ["count", "null_count", "mean", "std", "min", "max", "median"],
-        "numerical": [4.0, 1.0, 1.3333333333333333, 0.5773502691896257, 1.0, 2.0, 1.0],
-        "struct": ["4", "1", None, None, None, None, None],
-        "list": ["4", "1", None, None, None, None, None],
+        "describe": [
+            "count",
+            "null_count",
+            "mean",
+            "std",
+            "min",
+            "max",
+            "median",
+            "25%",
+            "75%",
+        ],
+        "numerical": [
+            4.0,
+            1.0,
+            1.3333333333333333,
+            0.5773502691896257,
+            1.0,
+            2.0,
+            1.0,
+            1.0,
+            2.0,
+        ],
+        "struct": ["4", "1", None, None, None, None, None, None, None],
+        "list": ["4", "1", None, None, None, None, None, None, None],
     }
 
+    for pcts in (None, []):  # type:ignore[var-annotated]
+        assert df.describe(percentiles=pcts).rows() == [
+            ("count", 4.0, "4", "4"),
+            ("null_count", 1.0, "1", "1"),
+            ("mean", 1.3333333333333333, None, None),
+            ("std", 0.5773502691896257, None, None),
+            ("min", 1.0, None, None),
+            ("max", 2.0, None, None),
+            ("median", 1.0, None, None),
+        ]
+
+    assert df.describe(percentiles=(0.2, 0.4, 0.6, 0.8)).rows() == [
+        ("count", 4.0, "4", "4"),
+        ("null_count", 1.0, "1", "1"),
+        ("mean", 1.3333333333333333, None, None),
+        ("std", 0.5773502691896257, None, None),
+        ("min", 1.0, None, None),
+        ("max", 2.0, None, None),
+        ("median", 1.0, None, None),
+        ("20%", 1.0, None, None),
+        ("40%", 1.0, None, None),
+        ("60%", 1.0, None, None),
+        ("80%", 2.0, None, None),
+    ]
+
 
 def test_duration_arithmetic() -> None:
     df = pl.DataFrame(
         {"a": [datetime(2022, 1, 1, 0, 0, 0), datetime(2022, 1, 2, 0, 0, 0)]}
     )
     d1 = pl.duration(days=3, microseconds=987000)
     d2 = pl.duration(days=6, milliseconds=987)
@@ -1949,15 +2014,15 @@
     assert_frame_equal(result, expected)
 
 
 def test_partitioned_groupby_order() -> None:
     # check if group ordering is maintained.
     # we only have 30 groups, so this triggers a partitioned group by
     df = pl.DataFrame({"x": [chr(v) for v in range(33, 63)], "y": range(30)})
-    out = df.groupby("x", maintain_order=True).agg(pl.all().list())
+    out = df.groupby("x", maintain_order=True).agg(pl.all().implode())
     assert_series_equal(out["x"], df["x"])
 
 
 def test_schema() -> None:
     df = pl.DataFrame(
         {"foo": [1, 2, 3], "bar": [6.0, 7.0, 8.0], "ham": ["a", "b", "c"]}
     )
@@ -3710,10 +3775,10 @@
         }
     )
 
     df = df.select(
         [
             pl.col("*"),  # select all
             pl.col("random").sum().over("groups").alias("sum[random]/groups"),
-            pl.col("random").list().over("names").alias("random/name"),
+            pl.col("random").implode().over("names").alias("random/name"),
         ]
     )
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_empty.py` & `polars_lts_cpu-0.17.3/tests/unit/test_empty.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_errors.py` & `polars_lts_cpu-0.17.3/tests/unit/test_errors.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_expr_multi_cols.py` & `polars_lts_cpu-0.17.3/tests/unit/test_expr_multi_cols.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_fmt.py` & `polars_lts_cpu-0.17.3/tests/unit/test_fmt.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_functions.py` & `polars_lts_cpu-0.17.3/tests/unit/test_functions.py`

 * *Files 5% similar despite different names*

```diff
@@ -359,7 +359,26 @@
     result = df.select(pl.max("a", 3))
     assert_frame_equal(result, pl.DataFrame({"max": [3, 4]}))
 
 
 def test_abs_logical_type() -> None:
     s = pl.Series([timedelta(hours=1), timedelta(hours=-1)])
     assert s.abs().to_list() == [timedelta(hours=1), timedelta(hours=1)]
+
+
+def test_approx_unique() -> None:
+    df1 = pl.DataFrame({"a": [None, 1, 2], "b": [None, 2, 1]})
+
+    assert_frame_equal(
+        df1.select(pl.approx_unique("b")),
+        pl.DataFrame({"b": pl.Series(values=[3], dtype=pl.UInt32)}),
+    )
+
+    assert_frame_equal(
+        df1.select(pl.approx_unique(pl.col("b"))),
+        pl.DataFrame({"b": pl.Series(values=[3], dtype=pl.UInt32)}),
+    )
+
+    assert_frame_equal(
+        df1.select(pl.col("b").approx_unique()),
+        pl.DataFrame({"b": pl.Series(values=[3], dtype=pl.UInt32)}),
+    )
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_interchange.py` & `polars_lts_cpu-0.17.3/tests/unit/test_interchange.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_interop.py` & `polars_lts_cpu-0.17.3/tests/unit/test_interop.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_lazy.py` & `polars_lts_cpu-0.17.3/tests/unit/test_lazy.py`

 * *Files 4% similar despite different names*

```diff
@@ -33,19 +33,19 @@
 
     # test if it executes
     _ = ldf.with_columns(
         when(pl.col("a") > pl.lit(2)).then(pl.lit(10)).otherwise(pl.lit(1)).alias("new")
     ).collect()
 
     # test if pl.list is available, this is `to_list` re-exported as list
-    eager = ldf.groupby("a").agg(pl.list("b")).collect()
+    eager = ldf.groupby("a").agg(pl.implode("b")).collect()
     assert sorted(eager.rows()) == [(1, [[1.0]]), (2, [[2.0]]), (3, [[3.0]])]
 
     # profile lazyframe operation/plan
-    lazy = ldf.groupby("a").agg(pl.list("b"))
+    lazy = ldf.groupby("a").agg(pl.implode("b"))
     profiling_info = lazy.profile()
     # 
     #  node          start  end 
     #  ---           ---    --- 
     #  str           u64    u64 
     # 
     #  optimization  0      69  
@@ -665,41 +665,43 @@
     ldf = fruits_cars.lazy()
 
     # out of bounds error
     with pytest.raises(pl.ComputeError):
         (
             ldf.sort("fruits")
             .select(
-                [pl.col("B").reverse().take([1, 2]).list().over("fruits"), "fruits"]
+                [pl.col("B").reverse().take([1, 2]).implode().over("fruits"), "fruits"]
             )
             .collect()
         )
 
     for index in [[0, 1], pl.Series([0, 1]), np.array([0, 1])]:
         out = (
             ldf.sort("fruits")
             .select(
                 [
                     pl.col("B")
                     .reverse()
                     .take(index)  # type: ignore[arg-type]
-                    .list()
+                    .implode()
                     .over("fruits"),
                     "fruits",
                 ]
             )
             .collect()
         )
 
         assert out[0, "B"].to_list() == [2, 3]
         assert out[4, "B"].to_list() == [1, 4]
 
     out = (
         ldf.sort("fruits")
-        .select([pl.col("B").reverse().take(pl.lit(1)).list().over("fruits"), "fruits"])
+        .select(
+            [pl.col("B").reverse().take(pl.lit(1)).implode().over("fruits"), "fruits"]
+        )
         .collect()
     )
     assert out[0, "B"] == 3
     assert out[4, "B"] == 4
 
 
 def test_select_by_col_list(fruits_cars: pl.DataFrame) -> None:
@@ -785,22 +787,22 @@
 
 
 def test_arr_namespace(fruits_cars: pl.DataFrame) -> None:
     ldf = fruits_cars.lazy()
     out = ldf.select(
         [
             "fruits",
-            pl.col("B").list().over("fruits").arr.min().alias("B_by_fruits_min1"),
-            pl.col("B").min().list().over("fruits").alias("B_by_fruits_min2"),
-            pl.col("B").list().over("fruits").arr.max().alias("B_by_fruits_max1"),
-            pl.col("B").max().list().over("fruits").alias("B_by_fruits_max2"),
-            pl.col("B").list().over("fruits").arr.sum().alias("B_by_fruits_sum1"),
-            pl.col("B").sum().list().over("fruits").alias("B_by_fruits_sum2"),
-            pl.col("B").list().over("fruits").arr.mean().alias("B_by_fruits_mean1"),
-            pl.col("B").mean().list().over("fruits").alias("B_by_fruits_mean2"),
+            pl.col("B").implode().over("fruits").arr.min().alias("B_by_fruits_min1"),
+            pl.col("B").min().implode().over("fruits").alias("B_by_fruits_min2"),
+            pl.col("B").implode().over("fruits").arr.max().alias("B_by_fruits_max1"),
+            pl.col("B").max().implode().over("fruits").alias("B_by_fruits_max2"),
+            pl.col("B").implode().over("fruits").arr.sum().alias("B_by_fruits_sum1"),
+            pl.col("B").sum().implode().over("fruits").alias("B_by_fruits_sum2"),
+            pl.col("B").implode().over("fruits").arr.mean().alias("B_by_fruits_mean1"),
+            pl.col("B").mean().implode().over("fruits").alias("B_by_fruits_mean2"),
         ]
     )
     expected = pl.DataFrame(
         {
             "fruits": ["banana", "banana", "apple", "apple", "banana"],
             "B_by_fruits_min1": [1, 1, 2, 2, 1],
             "B_by_fruits_min2": [1, 1, 2, 2, 1],
@@ -1331,14 +1333,72 @@
         [(pl.col("a") - pl.col("a_mult")).alias("a"), pl.col("c")]
     ).collect().to_dict(False) == {"a": [0, 0, 0], "c": ["x", "y", "z"]}
 
     (out, _) = capfd.readouterr()
     assert "CACHE HIT" in out
 
 
+def test_lazy_cache_parallel() -> None:
+    df_evaluated = 0
+
+    def map_df(df: pl.DataFrame) -> pl.DataFrame:
+        nonlocal df_evaluated
+        df_evaluated += 1
+        return df
+
+    df = pl.LazyFrame({"a": [1]}).map(map_df).cache()
+
+    df = pl.concat(
+        [
+            df.select(pl.col("a") + 1),
+            df.select(pl.col("a") + 2),
+            df.select(pl.col("a") + 3),
+        ],
+        parallel=True,
+    )
+
+    assert df_evaluated == 0
+
+    df.collect()
+    assert df_evaluated == 1
+
+
+def test_lazy_cache_nested_parallel() -> None:
+    df_inner_evaluated = 0
+    df_outer_evaluated = 0
+
+    def map_df_inner(df: pl.DataFrame) -> pl.DataFrame:
+        nonlocal df_inner_evaluated
+        df_inner_evaluated += 1
+        return df
+
+    def map_df_outer(df: pl.DataFrame) -> pl.DataFrame:
+        nonlocal df_outer_evaluated
+        df_outer_evaluated += 1
+        return df
+
+    df_inner = pl.LazyFrame({"a": [1]}).map(map_df_inner).cache()
+    df_outer = df_inner.select(pl.col("a") + 1).map(map_df_outer).cache()
+
+    df = pl.concat(
+        [
+            df_outer.select(pl.col("a") + 2),
+            df_outer.select(pl.col("a") + 3),
+        ],
+        parallel=True,
+    )
+
+    assert df_inner_evaluated == 0
+    assert df_outer_evaluated == 0
+
+    df.collect()
+    assert df_inner_evaluated == 1
+    assert df_outer_evaluated == 1
+
+
 def test_quadratic_behavior_4736() -> None:
     # no assert; if this function does not stall our tests it has passed!
     ldf = pl.LazyFrame(schema=list(ascii_letters))
     ldf.select(reduce(add, (pl.col(fld) for fld in ldf.columns)))
 
 
 @pytest.mark.parametrize("input_dtype", [pl.Utf8, pl.Int64, pl.Float64])
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_polars_import.py` & `polars_lts_cpu-0.17.3/tests/unit/test_polars_import.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_predicates.py` & `polars_lts_cpu-0.17.3/tests/unit/test_predicates.py`

 * *Files 1% similar despite different names*

```diff
@@ -104,15 +104,15 @@
     assert out.dtypes == [pl.List(pl.Int64)]
 
 
 def test_predicate_strptime_6558() -> None:
     assert (
         pl.DataFrame({"date": ["2022-01-03", "2020-01-04", "2021-02-03", "2019-01-04"]})
         .lazy()
-        .select(pl.col("date").str.strptime(pl.Date, fmt="%F"))
+        .select(pl.col("date").str.strptime(pl.Date, format="%F"))
         .filter((pl.col("date").dt.year() == 2022) & (pl.col("date").dt.month() == 1))
         .collect()
     ).to_dict(False) == {"date": [date(2022, 1, 3)]}
 
 
 def test_predicate_arr_first_6573() -> None:
     df = pl.DataFrame(
@@ -120,15 +120,15 @@
             "a": [1, 2, 3, 4, 5, 6],
             "b": [6, 5, 4, 3, 2, 1],
         }
     )
 
     assert (
         df.lazy()
-        .with_columns(pl.col("a").list())
+        .with_columns(pl.col("a").implode())
         .with_columns(pl.col("a").arr.first())
         .filter(pl.col("a") == pl.col("b"))
         .collect()
     ).to_dict(False) == {"a": [1], "b": [1]}
 
 
 def test_fast_path_comparisons() -> None:
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_projections.py` & `polars_lts_cpu-0.17.3/tests/unit/test_projections.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_queries.py` & `polars_lts_cpu-0.17.3/tests/unit/test_queries.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_rows.py` & `polars_lts_cpu-0.17.3/tests/unit/test_rows.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_schema.py` & `polars_lts_cpu-0.17.3/tests/unit/test_schema.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_serde.py` & `polars_lts_cpu-0.17.3/tests/unit/test_serde.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 import pickle
 from datetime import datetime, timedelta
 
 import polars as pl
-from polars.testing import assert_series_equal
+from polars.testing import assert_frame_equal, assert_series_equal
 
 
 def test_pickling_simple_expression() -> None:
     e = pl.col("foo").sum()
     buf = pickle.dumps(e)
     assert str(pickle.loads(buf)) == str(e)
 
@@ -73,7 +73,14 @@
             b"@\xff\x95\xda\xff\xd2\x18",
         ],
     )
     assert_series_equal(
         data,
         pickle.loads(pickle.dumps(data)),
     )
+
+
+def test_pickle_lazyframe() -> None:
+    q = pl.LazyFrame({"a": [1, 4, 3]}).sort("a")
+
+    s = pickle.dumps(q)
+    assert_frame_equal(pickle.loads(s).collect(), pl.DataFrame({"a": [1, 3, 4]}))
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_series.py` & `polars_lts_cpu-0.17.3/tests/unit/test_series.py`

 * *Files 0% similar despite different names*

```diff
@@ -142,36 +142,45 @@
 
     # numpy not available
     monkeypatch.setattr(pl.series.series, "_check_for_numpy", lambda x: False)
     with pytest.raises(ValueError):
         pl.DataFrame(np.array([1, 2, 3]), schema=["a"])
 
 
-def test_init_dataclass_namedtuple() -> None:
-    from dataclasses import dataclass
+def test_init_structured_objects() -> None:
+    # validate init from dataclass, namedtuple, and pydantic model objects
     from typing import NamedTuple
 
-    @dataclass
+    from polars.dependencies import dataclasses, pydantic
+
+    @dataclasses.dataclass
     class TeaShipmentDC:
         exporter: str
         importer: str
         product: str
         tonnes: int | None
 
     class TeaShipmentNT(NamedTuple):
         exporter: str
         importer: str
         product: str
         tonnes: None | int
 
-    for Tea in (TeaShipmentDC, TeaShipmentNT):
+    class TeaShipmentPD(pydantic.BaseModel):
+        exporter: str
+        importer: str
+        product: str
+        tonnes: int
+
+    for Tea in (TeaShipmentDC, TeaShipmentNT, TeaShipmentPD):
         t0 = Tea(exporter="Sri Lanka", importer="USA", product="Ceylon", tonnes=10)
         t1 = Tea(exporter="India", importer="UK", product="Darjeeling", tonnes=25)
+        t2 = Tea(exporter="China", importer="UK", product="Keemum", tonnes=40)
 
-        s = pl.Series("t", [t0, t1])
+        s = pl.Series("t", [t0, t1, t2])
 
         assert isinstance(s, pl.Series)
         assert s.dtype.fields == [  # type: ignore[union-attr]
             Field("exporter", pl.Utf8),
             Field("importer", pl.Utf8),
             Field("product", pl.Utf8),
             Field("tonnes", pl.Int64),
@@ -185,16 +194,22 @@
             },
             {
                 "exporter": "India",
                 "importer": "UK",
                 "product": "Darjeeling",
                 "tonnes": 25,
             },
+            {
+                "exporter": "China",
+                "importer": "UK",
+                "product": "Keemum",
+                "tonnes": 40,
+            },
         ]
-        assert_frame_equal(s.to_frame(), pl.DataFrame({"t": [t0, t1]}))
+        assert_frame_equal(s.to_frame(), pl.DataFrame({"t": [t0, t1, t2]}))
 
 
 def test_concat() -> None:
     s = pl.Series("a", [2, 1, 3])
 
     assert pl.concat([s, s]).len() == 6
     # check if s remains unchanged
@@ -1127,23 +1142,27 @@
         "count": 3.0,
         "max": 3.0,
         "mean": 2.0,
         "min": 1.0,
         "null_count": 0.0,
         "std": 1.0,
         "median": 2.0,
+        "25%": 1.0,
+        "75%": 3.0,
     }
     assert dict(float_s.describe().rows()) == {  # type: ignore[arg-type]
         "count": 3.0,
         "max": 8.9,
         "mean": 4.933333333333334,
         "min": 1.3,
         "null_count": 0.0,
         "std": 3.8109491381194442,
         "median": 4.6,
+        "25%": 1.3,
+        "75%": 8.9,
     }
     assert dict(str_s.describe().rows()) == {  # type: ignore[arg-type]
         "count": 3,
         "null_count": 0,
         "unique": 3,
     }
     assert dict(bool_s.describe().rows()) == {  # type: ignore[arg-type]
@@ -1606,17 +1625,14 @@
     assert_series_equal(srs_int - 1.0, pl.Series([0.0, 1.0, 2.0, 3.0]))
     assert_series_equal(srs_int + 1.0, pl.Series([2.0, 3.0, 4.0, 5.0]))
     assert_series_equal(srs_int * 2.0, pl.Series([2.0, 4.0, 6.0, 8.0]))
     assert_series_equal(srs_int / 2.0, pl.Series([0.5, 1.0, 1.5, 2.0]))
     assert_series_equal(srs_int % 2.0, pl.Series([1.0, 0.0, 1.0, 0.0]))
     assert_series_equal(4.0 % srs_int, pl.Series([0.0, 0.0, 1.0, 0.0]))
 
-    assert_series_equal(srs_int - pl.lit(1.0), pl.Series([0.0, 1.0, 2.0, 3.0]))
-    assert_series_equal(srs_int + pl.lit(1.0), pl.Series([2.0, 3.0, 4.0, 5.0]))
-
     assert_series_equal(srs_int // 2.0, pl.Series([0.0, 1.0, 1.0, 2.0]))
     assert_series_equal(srs_int < 3.0, pl.Series([True, True, False, False]))
     assert_series_equal(srs_int <= 3.0, pl.Series([True, True, True, False]))
     assert_series_equal(srs_int > 3.0, pl.Series([False, False, False, True]))
     assert_series_equal(srs_int >= 3.0, pl.Series([False, False, True, True]))
     assert_series_equal(srs_int == 3.0, pl.Series([False, False, True, False]))
     assert_series_equal(srs_int - True, pl.Series([0, 1, 2, 3]))
@@ -1628,17 +1644,14 @@
     assert_series_equal(srs_float - 1, pl.Series([0.0, 1.0, 2.0, 3.0]))
     assert_series_equal(srs_float + 1, pl.Series([2.0, 3.0, 4.0, 5.0]))
     assert_series_equal(srs_float * 2, pl.Series([2.0, 4.0, 6.0, 8.0]))
     assert_series_equal(srs_float / 2, pl.Series([0.5, 1.0, 1.5, 2.0]))
     assert_series_equal(srs_float % 2, pl.Series([1.0, 0.0, 1.0, 0.0]))
     assert_series_equal(4 % srs_float, pl.Series([0.0, 0.0, 1.0, 0.0]))
 
-    assert_series_equal(srs_float - pl.lit(1), pl.Series([0.0, 1.0, 2.0, 3.0]))
-    assert_series_equal(srs_float + pl.lit(1), pl.Series([2.0, 3.0, 4.0, 5.0]))
-
     assert_series_equal(srs_float // 2, pl.Series([0.0, 1.0, 1.0, 2.0]))
     assert_series_equal(srs_float < 3, pl.Series([True, True, False, False]))
     assert_series_equal(srs_float <= 3, pl.Series([True, True, True, False]))
     assert_series_equal(srs_float > 3, pl.Series([False, False, False, True]))
     assert_series_equal(srs_float >= 3, pl.Series([False, False, True, True]))
     assert_series_equal(srs_float == 3, pl.Series([False, False, True, False]))
     assert_series_equal(srs_float - True, pl.Series([0.0, 1.0, 2.0, 3.0]))
@@ -1780,14 +1793,19 @@
     assert s.arg_max() == 4
     s = pl.Series("a", [5, 4, 3, 2, 1])
     s.sort(descending=True, in_place=True)  # set descing sorted flag
     assert s.flags == {"SORTED_ASC": False, "SORTED_DESC": True}
     assert s.arg_min() == 4
     assert s.arg_max() == 0
 
+    # test empty series
+    s = pl.Series("a", [])
+    assert s.arg_min() is None
+    assert s.arg_max() is None
+
 
 def test_is_null_is_not_null() -> None:
     s = pl.Series("a", [1.0, 2.0, 3.0, None])
     assert_series_equal(s.is_null(), pl.Series("a", [False, False, False, True]))
     assert_series_equal(s.is_not_null(), pl.Series("a", [True, True, True, False]))
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_sql.py` & `polars_lts_cpu-0.17.3/tests/unit/test_sql.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_streaming.py` & `polars_lts_cpu-0.17.3/tests/unit/test_streaming.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/tests/unit/test_testing.py` & `polars_lts_cpu-0.17.3/tests/unit/test_testing.py`

 * *Files 2% similar despite different names*

```diff
@@ -280,14 +280,24 @@
 
     for check_exact in (True, False):
         assert_series_equal(s0, s0, check_exact=check_exact)
         with pytest.raises(AssertionError):
             assert_series_equal(s1, s2, check_exact=check_exact)
 
 
+def test_assert_series_equal_uint_overflow() -> None:
+    # 'atol' is checked following "(left-right).abs()", which can overflow on uint
+    s1 = pl.Series([1, 2, 3], dtype=pl.UInt8)
+    s2 = pl.Series([2, 3, 4], dtype=pl.UInt8)
+
+    with pytest.raises(AssertionError):
+        assert_series_equal(s1, s2, atol=0)
+    assert_series_equal(s1, s2, atol=1)
+
+
 @pytest.mark.parametrize(
     ("data1", "data2"),
     [
         ([datetime(2022, 10, 2, 12)], [datetime(2022, 10, 2, 13)]),
         ([time(10, 0, 0)], [time(10, 0, 10)]),
         ([timedelta(10, 0, 0)], [timedelta(10, 0, 10)]),
     ],
```

### Comparing `polars_lts_cpu-0.17.2/tests/unit/utils/test_utils.py` & `polars_lts_cpu-0.17.3/tests/unit/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.17.2/Cargo.lock` & `polars_lts_cpu-0.17.3/Cargo.lock`

 * *Files 1% similar despite different names*

```diff
@@ -56,14 +56,23 @@
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "819e7219dbd41043ac279b19830f2efc897156490d7fd6ea916720117ee66311"
 dependencies = [
  "libc",
 ]
 
 [[package]]
+name = "argminmax"
+version = "0.6.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "202108b46429b765ef483f8a24d5c46f48c14acfdacc086dd4ab6dddf6bcdbd2"
+dependencies = [
+ "num-traits",
+]
+
+[[package]]
 name = "array-init-cursor"
 version = "0.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bf7d0a018de4f6aa429b9d33d69edf69072b1c5b1cb8d3e4a5f7ef898fc3eb76"
 
 [[package]]
 name = "arrow-format"
@@ -74,15 +83,15 @@
  "planus",
  "serde",
 ]
 
 [[package]]
 name = "arrow2"
 version = "0.17.0"
-source = "git+https://github.com/ritchie46/arrow2?branch=polars_2023-04-05#d0174d399dd635be6ca498f76a8d250bd9ccbb0a"
+source = "git+https://github.com/ritchie46/arrow2?rev=11933119612e072a6eefaa65abec8c16241073c6#11933119612e072a6eefaa65abec8c16241073c6"
 dependencies = [
  "ahash",
  "arrow-format",
  "avro-schema",
  "base64",
  "bytemuck",
  "chrono",
@@ -176,23 +185,14 @@
 [[package]]
 name = "base64"
 version = "0.21.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "a4a4ddaa51a5bc52a6948f74c06d20aaaddb71924eab79b8c97a8c556e942d6a"
 
 [[package]]
-name = "bincode"
-version = "1.3.3"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b1f45e9417d87227c7a56d22e471c6206462cba514c7590c09aff4cf6d1ddcad"
-dependencies = [
- "serde",
-]
-
-[[package]]
 name = "bitflags"
 version = "1.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"
 
 [[package]]
 name = "brotli"
@@ -326,14 +326,41 @@
 dependencies = [
  "parse-zoneinfo",
  "phf",
  "phf_codegen",
 ]
 
 [[package]]
+name = "ciborium"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "b0c137568cc60b904a7724001b35ce2630fd00d5d84805fbb608ab89509d788f"
+dependencies = [
+ "ciborium-io",
+ "ciborium-ll",
+ "serde",
+]
+
+[[package]]
+name = "ciborium-io"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "346de753af073cc87b52b2083a506b38ac176a44cfb05497b622e27be899b369"
+
+[[package]]
+name = "ciborium-ll"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "213030a2b5a4e0c0892b6652260cf6ccac84827b83a85a534e178e3906c4cf1b"
+dependencies = [
+ "ciborium-io",
+ "half",
+]
+
+[[package]]
 name = "codespan-reporting"
 version = "0.11.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "3538270d33cc669650c4b093848450d380def10c331d38c768e34cac80576e6e"
 dependencies = [
  "termcolor",
  "unicode-width",
@@ -737,14 +764,20 @@
 [[package]]
 name = "glob"
 version = "0.3.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d2fabcfbdc87f4758337ca535fb41a6d701b65693ce38287d856d1674551ec9b"
 
 [[package]]
+name = "half"
+version = "1.8.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "eabb4a44450da02c90444cf74558da904edde8fb4e9035a9a6a4e15445af0bd7"
+
+[[package]]
 name = "halfbrown"
 version = "0.1.18"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "9e2a3c70a9c00cc1ee87b54e89f9505f73bb17d63f1b25c9a462ba8ef885444f"
 dependencies = [
  "fxhash",
  "hashbrown 0.13.2",
@@ -1568,14 +1601,15 @@
 [[package]]
 name = "polars-lazy"
 version = "0.28.0"
 dependencies = [
  "ahash",
  "bitflags",
  "glob",
+ "once_cell",
  "polars-arrow",
  "polars-core",
  "polars-io",
  "polars-ops",
  "polars-pipe",
  "polars-plan",
  "polars-time",
@@ -1585,14 +1619,15 @@
  "smartstring",
 ]
 
 [[package]]
 name = "polars-ops"
 version = "0.28.0"
 dependencies = [
+ "argminmax",
  "arrow2",
  "base64",
  "either",
  "hex",
  "jsonpath_lib",
  "memchr",
  "polars-arrow",
@@ -1708,19 +1743,19 @@
 checksum = "1d0dd4be24fcdcfeaa12a432d588dc59bbad6cad3510c67e74a2b6b2fc950564"
 dependencies = [
  "unicode-ident",
 ]
 
 [[package]]
 name = "py-polars"
-version = "0.17.2"
+version = "0.17.3"
 dependencies = [
  "ahash",
- "bincode",
  "built",
+ "ciborium",
  "jemallocator",
  "lexical-core",
  "libc",
  "mimalloc",
  "ndarray",
  "numpy",
  "once_cell",
```

### Comparing `polars_lts_cpu-0.17.2/PKG-INFO` & `polars_lts_cpu-0.17.3/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: polars-lts-cpu
-Version: 0.17.2
+Version: 0.17.3
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
@@ -13,50 +13,50 @@
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Rust
 Classifier: Topic :: Scientific/Engineering
 Requires-Dist: typing_extensions >= 4.0.1; python_version < '3.11'
-Requires-Dist: sqlalchemy; extra == 'sqlalchemy'
-Requires-Dist: pandas; extra == 'sqlalchemy'
-Requires-Dist: backports.zoneinfo; (python_version < '3.9') and extra == 'timezone'
-Requires-Dist: tzdata; (platform_system == 'Windows') and extra == 'timezone'
-Requires-Dist: xlsxwriter; extra == 'xlsxwriter'
-Requires-Dist: deltalake >= 0.8.0; extra == 'deltalake'
 Requires-Dist: pyarrow>=7.0.0; extra == 'pyarrow'
 Requires-Dist: fsspec; extra == 'fsspec'
 Requires-Dist: xlsx2csv >= 0.8.0; extra == 'xlsx2csv'
+Requires-Dist: numpy >= 1.16.0; extra == 'numpy'
+Requires-Dist: deltalake >= 0.8.0; extra == 'deltalake'
+Requires-Dist: backports.zoneinfo; (python_version < '3.9') and extra == 'timezone'
+Requires-Dist: tzdata; (platform_system == 'Windows') and extra == 'timezone'
+Requires-Dist: xlsxwriter; extra == 'xlsxwriter'
+Requires-Dist: matplotlib; extra == 'matplotlib'
+Requires-Dist: polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter]; extra == 'all'
 Requires-Dist: pyarrow>=7.0.0; extra == 'pandas'
 Requires-Dist: pandas; extra == 'pandas'
+Requires-Dist: sqlalchemy; extra == 'sqlalchemy'
+Requires-Dist: pandas; extra == 'sqlalchemy'
 Requires-Dist: connectorx; extra == 'connectorx'
-Requires-Dist: polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter]; extra == 'all'
-Requires-Dist: numpy >= 1.16.0; extra == 'numpy'
-Requires-Dist: matplotlib; extra == 'matplotlib'
-Provides-Extra: sqlalchemy
-Provides-Extra: timezone
-Provides-Extra: xlsxwriter
-Provides-Extra: deltalake
 Provides-Extra: pyarrow
 Provides-Extra: fsspec
 Provides-Extra: xlsx2csv
-Provides-Extra: pandas
-Provides-Extra: connectorx
-Provides-Extra: all
 Provides-Extra: numpy
+Provides-Extra: deltalake
+Provides-Extra: timezone
+Provides-Extra: xlsxwriter
 Provides-Extra: matplotlib
+Provides-Extra: all
+Provides-Extra: pandas
+Provides-Extra: sqlalchemy
+Provides-Extra: connectorx
 License-File: LICENSE
 Summary: Blazingly fast DataFrame library
 Keywords: dataframe,arrow,out-of-core
 Author-email: Ritchie Vink <ritchie46@gmail.com>
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
+Project-URL: Repository, https://github.com/pola-rs/polars
 Project-URL: Homepage, https://www.pola.rs/
 Project-URL: Changelog, https://github.com/pola-rs/polars/releases
-Project-URL: Repository, https://github.com/pola-rs/polars
 Project-URL: Documentation, https://pola-rs.github.io/polars/py-polars/html/reference/index.html
 
 <h1 align="center">
   <img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg">
   <br>
 </h1>
```

#### html2text {}

```diff
@@ -1,41 +1,41 @@
-Metadata-Version: 2.1 Name: polars-lts-cpu Version: 0.17.2 Classifier:
+Metadata-Version: 2.1 Name: polars-lts-cpu Version: 0.17.3 Classifier:
 Development Status :: 5 - Production/Stable Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research Classifier: License :: OSI
 Approved :: MIT License Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python Classifier: Programming Language ::
 Python :: 3 Classifier: Programming Language :: Python :: 3 :: Only Classifier:
 Programming Language :: Python :: 3.7 Classifier: Programming Language ::
 Python :: 3.8 Classifier: Programming Language :: Python :: 3.9 Classifier:
 Programming Language :: Python :: 3.10 Classifier: Programming Language ::
 Python :: 3.11 Classifier: Programming Language :: Rust Classifier: Topic ::
 Scientific/Engineering Requires-Dist: typing_extensions >= 4.0.1;
-python_version < '3.11' Requires-Dist: sqlalchemy; extra == 'sqlalchemy'
-Requires-Dist: pandas; extra == 'sqlalchemy' Requires-Dist: backports.zoneinfo;
-(python_version < '3.9') and extra == 'timezone' Requires-Dist: tzdata;
-(platform_system == 'Windows') and extra == 'timezone' Requires-Dist:
-xlsxwriter; extra == 'xlsxwriter' Requires-Dist: deltalake >= 0.8.0; extra ==
-'deltalake' Requires-Dist: pyarrow>=7.0.0; extra == 'pyarrow' Requires-Dist:
-fsspec; extra == 'fsspec' Requires-Dist: xlsx2csv >= 0.8.0; extra == 'xlsx2csv'
-Requires-Dist: pyarrow>=7.0.0; extra == 'pandas' Requires-Dist: pandas; extra
-== 'pandas' Requires-Dist: connectorx; extra == 'connectorx' Requires-Dist:
-polars
+python_version < '3.11' Requires-Dist: pyarrow>=7.0.0; extra == 'pyarrow'
+Requires-Dist: fsspec; extra == 'fsspec' Requires-Dist: xlsx2csv >= 0.8.0;
+extra == 'xlsx2csv' Requires-Dist: numpy >= 1.16.0; extra == 'numpy' Requires-
+Dist: deltalake >= 0.8.0; extra == 'deltalake' Requires-Dist:
+backports.zoneinfo; (python_version < '3.9') and extra == 'timezone' Requires-
+Dist: tzdata; (platform_system == 'Windows') and extra == 'timezone' Requires-
+Dist: xlsxwriter; extra == 'xlsxwriter' Requires-Dist: matplotlib; extra ==
+'matplotlib' Requires-Dist: polars
 [pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter];
-extra == 'all' Requires-Dist: numpy >= 1.16.0; extra == 'numpy' Requires-Dist:
-matplotlib; extra == 'matplotlib' Provides-Extra: sqlalchemy Provides-Extra:
-timezone Provides-Extra: xlsxwriter Provides-Extra: deltalake Provides-Extra:
-pyarrow Provides-Extra: fsspec Provides-Extra: xlsx2csv Provides-Extra: pandas
-Provides-Extra: connectorx Provides-Extra: all Provides-Extra: numpy Provides-
-Extra: matplotlib License-File: LICENSE Summary: Blazingly fast DataFrame
-library Keywords: dataframe,arrow,out-of-core Author-email: Ritchie Vink
+extra == 'all' Requires-Dist: pyarrow>=7.0.0; extra == 'pandas' Requires-Dist:
+pandas; extra == 'pandas' Requires-Dist: sqlalchemy; extra == 'sqlalchemy'
+Requires-Dist: pandas; extra == 'sqlalchemy' Requires-Dist: connectorx; extra
+== 'connectorx' Provides-Extra: pyarrow Provides-Extra: fsspec Provides-Extra:
+xlsx2csv Provides-Extra: numpy Provides-Extra: deltalake Provides-Extra:
+timezone Provides-Extra: xlsxwriter Provides-Extra: matplotlib Provides-Extra:
+all Provides-Extra: pandas Provides-Extra: sqlalchemy Provides-Extra:
+connectorx License-File: LICENSE Summary: Blazingly fast DataFrame library
+Keywords: dataframe,arrow,out-of-core Author-email: Ritchie Vink
 gmail.com> Requires-Python: >=3.7 Description-Content-Type: text/markdown;
-charset=UTF-8; variant=GFM Project-URL: Homepage, https://www.pola.rs/ Project-
-URL: Changelog, https://github.com/pola-rs/polars/releases Project-URL:
-Repository, https://github.com/pola-rs/polars Project-URL: Documentation,
-https://pola-rs.github.io/polars/py-polars/html/reference/index.html
+charset=UTF-8; variant=GFM Project-URL: Repository, https://github.com/pola-rs/
+polars Project-URL: Homepage, https://www.pola.rs/ Project-URL: Changelog,
+https://github.com/pola-rs/polars/releases Project-URL: Documentation, https://
+pola-rs.github.io/polars/py-polars/html/reference/index.html
  ****** [https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/
                     polars_github_logo_rect_dark_name.svg]
                                      ******
 [rust_docs] [Build_and_test] [https://img.shields.io/crates/v/polars.svg] [PyPi
            Latest_Release] [NPM_Latest_Release] [DOI_Latest_Release]
 Documentation: Python - Rust - Node.js | StackOverflow: Python - Rust - Node.js
                             | User_Guide | Discord
```

