# Comparing `tmp/tmu-0.7.9-pp39-pypy39_pp73-win_amd64.whl.zip` & `tmp/tmu-0.8.0-pp39-pypy39_pp73-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,37 @@
-Zip file size: 63793 bytes, number of entries: 35
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 20:42 test/__init__.py
--rw-rw-rw-  2.0 fat      843 b- defN 23-Apr-07 20:42 test/test_datasets.py
--rw-rw-rw-  2.0 fat       54 b- defN 23-Apr-07 20:42 test/test_imports.py
--rw-rw-rw-  2.0 fat      515 b- defN 23-Apr-07 20:42 tmu/__init__.py
--rw-rw-rw-  2.0 fat    16730 b- defN 23-Apr-07 20:42 tmu/data.py
--rw-rw-rw-  2.0 fat      593 b- defN 23-Apr-07 20:42 tmu/logging_example.json
--rw-rw-rw-  2.0 fat    33280 b- defN 23-Apr-07 20:54 tmu/tmulib.pypy39-pp73-win_amd64.pyd
--rw-rw-rw-  2.0 fat     5120 b- defN 23-Apr-07 20:42 tmu/tools.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 20:42 tmu/clause_bank/__init__.py
--rw-rw-rw-  2.0 fat     3119 b- defN 23-Apr-07 20:42 tmu/clause_bank/base_clause_bank.py
--rw-rw-rw-  2.0 fat    12902 b- defN 23-Apr-07 20:42 tmu/clause_bank/clause_bank.py
--rw-rw-rw-  2.0 fat    11771 b- defN 23-Apr-07 20:42 tmu/clause_bank/clause_bank_cuda.py
--rw-rw-rw-  2.0 fat    11246 b- defN 23-Apr-07 20:42 tmu/clause_bank/clause_bank_sparse.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 20:42 tmu/models/__init__.py
--rw-rw-rw-  2.0 fat     3271 b- defN 23-Apr-07 20:42 tmu/models/attention.py
--rw-rw-rw-  2.0 fat     5678 b- defN 23-Apr-07 20:42 tmu/models/base.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 20:42 tmu/models/autoencoder/__init__.py
--rw-rw-rw-  2.0 fat    17062 b- defN 23-Apr-07 20:42 tmu/models/autoencoder/autoencoder.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 20:42 tmu/models/classification/__init__.py
--rw-rw-rw-  2.0 fat      940 b- defN 23-Apr-07 20:42 tmu/models/classification/base_classification.py
--rw-rw-rw-  2.0 fat    14745 b- defN 23-Apr-07 20:42 tmu/models/classification/coalesced_classifier.py
--rw-rw-rw-  2.0 fat    12333 b- defN 23-Apr-07 20:42 tmu/models/classification/multichannel_classifier.py
--rw-rw-rw-  2.0 fat    13464 b- defN 23-Apr-07 20:42 tmu/models/classification/multitask_classifier.py
--rw-rw-rw-  2.0 fat    11371 b- defN 23-Apr-07 20:42 tmu/models/classification/one_vs_one_classifier.py
--rw-rw-rw-  2.0 fat    20782 b- defN 23-Apr-07 20:42 tmu/models/classification/vanilla_classifier.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-07 20:42 tmu/models/regression/__init__.py
--rw-rw-rw-  2.0 fat     6590 b- defN 23-Apr-07 20:42 tmu/models/regression/vanilla_regressor.py
--rw-rw-rw-  2.0 fat       37 b- defN 23-Apr-07 20:42 tmu/weight_bank/__init__.py
--rw-rw-rw-  2.0 fat     2384 b- defN 23-Apr-07 20:42 tmu/weight_bank/weight_bank.py
--rw-rw-rw-  2.0 fat      593 b- defN 23-Apr-07 20:42 tmu-0.7.9.data/data/tmu/logging_example.json
--rw-rw-rw-  2.0 fat     1128 b- defN 23-Apr-07 20:54 tmu-0.7.9.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     1812 b- defN 23-Apr-07 20:54 tmu-0.7.9.dist-info/METADATA
--rw-rw-rw-  2.0 fat      107 b- defN 23-Apr-07 20:54 tmu-0.7.9.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        9 b- defN 23-Apr-07 20:54 tmu-0.7.9.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     3021 b- defN 23-Apr-07 20:54 tmu-0.7.9.dist-info/RECORD
-35 files, 211500 bytes uncompressed, 58911 bytes compressed:  72.1%
+Zip file size: 63888 bytes, number of entries: 35
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-15 08:22 test/__init__.py
+-rw-rw-rw-  2.0 fat      843 b- defN 23-Apr-15 08:22 test/test_datasets.py
+-rw-rw-rw-  2.0 fat       54 b- defN 23-Apr-15 08:22 test/test_imports.py
+-rw-rw-rw-  2.0 fat      515 b- defN 23-Apr-15 08:22 tmu/__init__.py
+-rw-rw-rw-  2.0 fat    16730 b- defN 23-Apr-15 08:22 tmu/data.py
+-rw-rw-rw-  2.0 fat      593 b- defN 23-Apr-15 08:22 tmu/logging_example.json
+-rw-rw-rw-  2.0 fat    33280 b- defN 23-Apr-15 08:32 tmu/tmulib.pypy39-pp73-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     5120 b- defN 23-Apr-15 08:22 tmu/tools.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-15 08:22 tmu/clause_bank/__init__.py
+-rw-rw-rw-  2.0 fat     3119 b- defN 23-Apr-15 08:22 tmu/clause_bank/base_clause_bank.py
+-rw-rw-rw-  2.0 fat    12902 b- defN 23-Apr-15 08:22 tmu/clause_bank/clause_bank.py
+-rw-rw-rw-  2.0 fat    11771 b- defN 23-Apr-15 08:22 tmu/clause_bank/clause_bank_cuda.py
+-rw-rw-rw-  2.0 fat    11246 b- defN 23-Apr-15 08:22 tmu/clause_bank/clause_bank_sparse.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-15 08:22 tmu/models/__init__.py
+-rw-rw-rw-  2.0 fat     3271 b- defN 23-Apr-15 08:22 tmu/models/attention.py
+-rw-rw-rw-  2.0 fat     5788 b- defN 23-Apr-15 08:22 tmu/models/base.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-15 08:22 tmu/models/autoencoder/__init__.py
+-rw-rw-rw-  2.0 fat    17528 b- defN 23-Apr-15 08:22 tmu/models/autoencoder/autoencoder.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-15 08:22 tmu/models/classification/__init__.py
+-rw-rw-rw-  2.0 fat      940 b- defN 23-Apr-15 08:22 tmu/models/classification/base_classification.py
+-rw-rw-rw-  2.0 fat    14745 b- defN 23-Apr-15 08:22 tmu/models/classification/coalesced_classifier.py
+-rw-rw-rw-  2.0 fat    12333 b- defN 23-Apr-15 08:22 tmu/models/classification/multichannel_classifier.py
+-rw-rw-rw-  2.0 fat    13464 b- defN 23-Apr-15 08:22 tmu/models/classification/multitask_classifier.py
+-rw-rw-rw-  2.0 fat    11371 b- defN 23-Apr-15 08:22 tmu/models/classification/one_vs_one_classifier.py
+-rw-rw-rw-  2.0 fat    20782 b- defN 23-Apr-15 08:22 tmu/models/classification/vanilla_classifier.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-15 08:22 tmu/models/regression/__init__.py
+-rw-rw-rw-  2.0 fat     6777 b- defN 23-Apr-15 08:22 tmu/models/regression/vanilla_regressor.py
+-rw-rw-rw-  2.0 fat       37 b- defN 23-Apr-15 08:22 tmu/weight_bank/__init__.py
+-rw-rw-rw-  2.0 fat     2384 b- defN 23-Apr-15 08:22 tmu/weight_bank/weight_bank.py
+-rw-rw-rw-  2.0 fat      593 b- defN 23-Apr-15 08:22 tmu-0.8.0.data/data/tmu/logging_example.json
+-rw-rw-rw-  2.0 fat     1128 b- defN 23-Apr-15 08:32 tmu-0.8.0.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     1812 b- defN 23-Apr-15 08:32 tmu-0.8.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      107 b- defN 23-Apr-15 08:32 tmu-0.8.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        9 b- defN 23-Apr-15 08:32 tmu-0.8.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     3021 b- defN 23-Apr-15 08:32 tmu-0.8.0.dist-info/RECORD
+35 files, 212263 bytes uncompressed, 59006 bytes compressed:  72.2%
```

## zipnote {}

```diff
@@ -81,26 +81,26 @@
 
 Filename: tmu/weight_bank/__init__.py
 Comment: 
 
 Filename: tmu/weight_bank/weight_bank.py
 Comment: 
 
-Filename: tmu-0.7.9.data/data/tmu/logging_example.json
+Filename: tmu-0.8.0.data/data/tmu/logging_example.json
 Comment: 
 
-Filename: tmu-0.7.9.dist-info/LICENSE
+Filename: tmu-0.8.0.dist-info/LICENSE
 Comment: 
 
-Filename: tmu-0.7.9.dist-info/METADATA
+Filename: tmu-0.8.0.dist-info/METADATA
 Comment: 
 
-Filename: tmu-0.7.9.dist-info/WHEEL
+Filename: tmu-0.8.0.dist-info/WHEEL
 Comment: 
 
-Filename: tmu-0.7.9.dist-info/top_level.txt
+Filename: tmu-0.8.0.dist-info/top_level.txt
 Comment: 
 
-Filename: tmu-0.7.9.dist-info/RECORD
+Filename: tmu-0.8.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tmu/__init__.py

```diff
@@ -11,8 +11,8 @@
 
 try:
     import tmu.tmulib
 except ImportError:
     raise ImportError("Could not import cffi compiled libraries. To fix this problem, run pip install -e .")
 
 
-__version__ = "0.7.9"
+__version__ = "0.8.0"
```

## tmu/models/base.py

```diff
@@ -57,15 +57,16 @@
             clause_drop_p=0.0,
             literal_drop_p=0.0,
             batch_size=100,
             incremental=True,
             absorbing=-1,
             literal_sampling=1.0,
             feedback_rate_excluded_literals=1,
-            literal_insertion_state = 0
+            literal_insertion_state = 0,
+            squared_weight_update_p = False
     ):
         self.number_of_clauses = number_of_clauses
         self.number_of_state_bits_ta = number_of_state_bits_ta
         self.number_of_state_bits_ind = number_of_state_bits_ind
         self.T = int(T)
         self.s = s
 
@@ -92,14 +93,15 @@
         self.literal_drop_p = literal_drop_p
         self.batch_size = batch_size
         self.incremental = incremental
         self.absorbing = absorbing
         self.literal_sampling = literal_sampling
         self.feedback_rate_excluded_literals = feedback_rate_excluded_literals
         self.literal_insertion_state = literal_insertion_state
+        self.squared_weight_update_p = squared_weight_update_p
         self.initialized = False
 
         # TODO - Change to checksum
         self.X_train = np.zeros(0, dtype=np.uint32)
         self.X_test = np.zeros(0, dtype=np.uint32)
 
         self.weight_banks = []
```

## tmu/models/autoencoder/autoencoder.py

```diff
@@ -26,25 +26,25 @@
 
 class TMAutoEncoder(TMBasis):
     def __init__(self, number_of_clauses, T, s, output_active, accumulation=1, type_i_ii_ratio=1.0,
                  type_iii_feedback=False, focused_negative_sampling=False, output_balancing=False, d=200.0,
                  platform='CPU', patch_dim=None, feature_negation=True, boost_true_positive_feedback=1,
                  max_included_literals=None, number_of_state_bits_ta=8, number_of_state_bits_ind=8,
                  weighted_clauses=False, clause_drop_p=0.0, literal_drop_p=0.0, absorbing=-1, literal_sampling=1.0, feedback_rate_excluded_literals=1,
-                 literal_insertion_state=-1):
+                 literal_insertion_state=-1, squared_weight_update_p=False):
         self.output_active = output_active
         self.accumulation = accumulation
         super().__init__(number_of_clauses, T, s, type_i_ii_ratio=type_i_ii_ratio, type_iii_feedback=type_iii_feedback,
                          focused_negative_sampling=focused_negative_sampling, output_balancing=output_balancing, d=d,
                          platform=platform, patch_dim=patch_dim, feature_negation=feature_negation,
                          boost_true_positive_feedback=boost_true_positive_feedback,
                          max_included_literals=max_included_literals, number_of_state_bits_ta=number_of_state_bits_ta,
                          number_of_state_bits_ind=number_of_state_bits_ind, weighted_clauses=weighted_clauses,
                          clause_drop_p=clause_drop_p, literal_drop_p=literal_drop_p, absorbing=absorbing, literal_sampling=literal_sampling,
-                         feedback_rate_excluded_literals=feedback_rate_excluded_literals, literal_insertion_state=literal_insertion_state)
+                         feedback_rate_excluded_literals=feedback_rate_excluded_literals, literal_insertion_state=literal_insertion_state, squared_weight_update_p=squared_weight_update_p)
 
     def initialize(self, X):
         self.number_of_classes = self.output_active.shape[0]
         if self.platform == 'CPU':
             self.clause_bank = ClauseBank(
                 X=X,
                 number_of_clauses=self.number_of_clauses,
@@ -57,19 +57,25 @@
                 X=X,
                 number_of_clauses=self.number_of_clauses,
                 number_of_states=2**self.number_of_state_bits_ta,
                 patch_dim=self.patch_dim,
                 absorbing=self.absorbing,
                 literal_sampling=self.literal_sampling,
                 feedback_rate_excluded_literals=self.feedback_rate_excluded_literals,
-                literal_insertion_state = self.literal_insertion_state
+                literal_insertion_state = self.literal_insertion_state,
+                squared_weight_update_p = self.squared_weight_update_p
             )
         elif self.platform == 'CUDA':
-            from clause_bank.clause_bank_cuda import ClauseBankCUDA
-            self.clause_bank = ClauseBankCUDA(X, self.number_of_clauses, self.number_of_state_bits_ta, self.patch_dim)
+            from tmu.clause_bank.clause_bank_cuda import ClauseBankCUDA
+            self.clause_bank = ClauseBankCUDA(
+                X=X,
+                number_of_clauses=self.number_of_clauses,
+                number_of_state_bits_ta=self.number_of_state_bits_ta,
+                patch_dim=self.patch_dim
+            )
         else:
             raise RuntimeError(f"Unknown platform of type: {self.platform}")
 
         self.weight_banks = []
         for i in range(self.number_of_classes):
             self.weight_banks.append(
                 WeightBank(np.random.choice([-1, 1], size=self.number_of_clauses).astype(np.int32)))
@@ -85,14 +91,16 @@
             np.int32)
         class_sum = np.clip(class_sum, -self.T, self.T)
 
         type_iii_feedback_selection = np.random.choice(2)
 
         if target_value == 1:
             update_p = (self.T - class_sum) / (2 * self.T)
+            if self.squared_weight_update_p:
+                update_p = update_p**2
 
             self.clause_bank.type_i_feedback(update_p * self.type_i_p, self.s, self.boost_true_positive_feedback,
                                              self.max_included_literals,
                                              clause_active * (self.weight_banks[target_output].get_weights() >= 0),
                                              literal_active, encoded_X, 0)
             self.clause_bank.type_ii_feedback(update_p * self.type_ii_p,
                                               clause_active * (self.weight_banks[target_output].get_weights() < 0),
@@ -102,14 +110,16 @@
                 self.clause_bank.type_iii_feedback(update_p, self.d, clause_active * (
                         self.weight_banks[target_output].get_weights() >= 0), literal_active, encoded_X, 0, 1)
                 self.clause_bank.type_iii_feedback(update_p, self.d,
                                                    clause_active * (self.weight_banks[target_output].get_weights() < 0),
                                                    literal_active, encoded_X, 0, 0)
         else:
             update_p = (self.T + class_sum) / (2 * self.T)
+            if self.squared_weight_update_p:
+                update_p = update_p**2
 
             self.clause_bank.type_i_feedback(update_p * self.type_i_p, self.s, self.boost_true_positive_feedback,
                                              self.max_included_literals,
                                              clause_active * (self.weight_banks[target_output].get_weights() < 0),
                                              literal_active, encoded_X, 0)
             self.clause_bank.type_ii_feedback(update_p * self.type_ii_p,
                                               clause_active * (self.weight_banks[target_output].get_weights() >= 0),
```

## tmu/models/regression/vanilla_regressor.py

```diff
@@ -13,15 +13,15 @@
 # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
-from tmu.clause_bank import ClauseBank
+from tmu.clause_bank.clause_bank import ClauseBank
 from tmu.models.base import TMBasis
 from tmu.weight_bank import WeightBank
 import numpy as np
 
 
 class TMRegressor(TMBasis):
     def __init__(self, number_of_clauses, T, s, platform='CPU', patch_dim=None, feature_negation=True,
@@ -33,19 +33,24 @@
                          weighted_clauses=weighted_clauses, clause_drop_p=clause_drop_p, literal_drop_p=literal_drop_p)
 
     def initialize(self, X, Y):
         self.max_y = np.max(Y)
         self.min_y = np.min(Y)
 
         if self.platform == 'CPU':
-            self.clause_bank = ClauseBank(X, self.number_of_clauses, self.number_of_state_bits_ta,
-                                          self.number_of_state_bits_ind, self.patch_dim)
+            self.clause_bank = ClauseBank(
+                X=X,
+                number_of_clauses=self.number_of_clauses,
+                number_of_state_bits_ind=self.number_of_state_bits_ind,
+                number_of_state_bits_ta=self.number_of_state_bits_ta,
+                patch_dim=self.patch_dim)
+
         elif self.platform == 'CUDA':
             from clause_bank.clause_bank_cuda import ClauseBankCUDA
-            self.clause_bank = ClauseBankCUDA(X, self.number_of_clauses, self.number_of_state_bits_ta, self.patch_dim)
+            self.clause_bank = ClauseBankCUDA(X=X, number_of_clauses=self.number_of_clauses, number_of_ta_bits_ta=self.number_of_state_bits_ta, patch_dim=self.patch_dim)
         else:
             print("Unknown Platform")
             sys.exit(-1)
 
         self.weight_bank = WeightBank(np.ones(self.number_of_clauses).astype(np.int32))
 
         if self.max_included_literals == None:
```

## Comparing `tmu-0.7.9.data/data/tmu/logging_example.json` & `tmu-0.8.0.data/data/tmu/logging_example.json`

 * *Files identical despite different names*

## Comparing `tmu-0.7.9.dist-info/LICENSE` & `tmu-0.8.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `tmu-0.7.9.dist-info/METADATA` & `tmu-0.8.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tmu
-Version: 0.7.9
+Version: 0.8.0
 Summary: Implements the Tsetlin Machine, Coalesced Tsetlin Machine, Convolutional Tsetlin Machine, Regression Tsetlin Machine, and Weighted Tsetlin Machine, with support for continuous features, drop clause, Type III Feedback, focused negative sampling, multi-task classifier, autoencoder, literal budget,incremental clause evaluation, sparse computation with absorbing exclude, and one-vs-one multi-class classifier. TMU is written in Python with wrappers for C and CUDA-based clause evaluation and updating.
 Home-page: https://github.com/cair/tmu/
 Author: Ole-Christoffer Granmo
 Author-email: ole.granmo@uia.no
 License: MIT
 License-File: LICENSE
 Requires-Dist: cffi (>=1.0.0)
```

## Comparing `tmu-0.7.9.dist-info/RECORD` & `tmu-0.8.0.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,35 +1,35 @@
 test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 test/test_datasets.py,sha256=Rbv3z35FJ8BHSS2F8W7iRJQqh28RNoAcUH53Lku9xGs,843
 test/test_imports.py,sha256=mgs50XEFMY8URJkJQcHXxJaUpsoARAI-cnG9nUbqusY,54
-tmu/__init__.py,sha256=gHiuGtMAOf_UQ-cQATf_XGP5PQM41llL8C38Q7Eh3Ho,515
+tmu/__init__.py,sha256=x2xPgBUfWSlmpvYEpCpI2PFjHS0qDNHigrEuIX2Zax4,515
 tmu/data.py,sha256=LFS0yL78DTiGcXuE-whkcPXj_MWlsZYb0vT0WqNpwI8,16730
 tmu/logging_example.json,sha256=TPtjbFQGS33rCHWMnbOV0-icQ-_sRZiUHj8xaXXEp6Q,593
-tmu/tmulib.pypy39-pp73-win_amd64.pyd,sha256=55VHObgOO8M020o1MpkWXXJeiSH93wUT6aqYMzT2VMQ,33280
+tmu/tmulib.pypy39-pp73-win_amd64.pyd,sha256=nQ6XuRTj3kIO6fHPUm93_drgFkP9ztruKi8lw_LEzko,33280
 tmu/tools.py,sha256=izJeiIRf6cj5mlm-i4kc-xPVszWfOiGYn3uux9DoeFw,5120
 tmu/clause_bank/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tmu/clause_bank/base_clause_bank.py,sha256=efqyYnVzFOMGguaON3h4wXrqOzGod0Haja3sXfDIcQY,3119
 tmu/clause_bank/clause_bank.py,sha256=mKfmFMGeS2poJ1jHnv8XAWWNzbVKUZc8YW3VDmLFdEo,12902
 tmu/clause_bank/clause_bank_cuda.py,sha256=If2KfgsC6-I_nxGvUrSSuII0sgHgkNy3Ocep1Vbia7g,11771
 tmu/clause_bank/clause_bank_sparse.py,sha256=uwslMGAobQVAXoEbjsZVd5F1JxmzI8AOx1Zm6EU5kyo,11246
 tmu/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tmu/models/attention.py,sha256=CC5vHT8hBlP5IuFS9i_CXYoWoqLO65f0fmWJgTwvFTU,3271
-tmu/models/base.py,sha256=ObQPPW1eRqqO4UnSGS-Xwex9JiyFKBtDG5mTA_Au2XY,5678
+tmu/models/base.py,sha256=j9f9s5XMHZJxX7LytyRNVa56P4b9zFt6J12Hl_lQZe0,5788
 tmu/models/autoencoder/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-tmu/models/autoencoder/autoencoder.py,sha256=IHizPcE5Tm8wq6mDeoPQRLhSC6HbuiffCvlkIPhTyis,17062
+tmu/models/autoencoder/autoencoder.py,sha256=jRGJtnbrUl3_CY8Lem-449ymZ_-6eNSf1jj2IqVnjDU,17528
 tmu/models/classification/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tmu/models/classification/base_classification.py,sha256=XHyfRiQrrxze_76KAomeLKoCwk6M5l3rwcEuZdlKqBY,940
 tmu/models/classification/coalesced_classifier.py,sha256=N2fXHtjEDSZeE7_VhkOyhBjfZa1TZR2gTG_UzOEgNBY,14745
 tmu/models/classification/multichannel_classifier.py,sha256=zhd6JWB9sOg35-u6CEduvSs6J2uqfNCKNUfNtZ33mZc,12333
 tmu/models/classification/multitask_classifier.py,sha256=axYPKEtzHD3NtybvjUfl7-ipVJ0a6IX-6e1GUmdjd8w,13464
 tmu/models/classification/one_vs_one_classifier.py,sha256=E0ITj6xXfH-xu8zOi34mI11GD81ECdOxSso0BzueBII,11371
 tmu/models/classification/vanilla_classifier.py,sha256=mmCaSI0MVQEMT31Z6ZJgbqRqzQZO3ShrtqBcMmfcF3Q,20782
 tmu/models/regression/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-tmu/models/regression/vanilla_regressor.py,sha256=n8-WPON1-DbD5B1hANXQsCsy146CcxJEPKR7qiW0pSQ,6590
+tmu/models/regression/vanilla_regressor.py,sha256=fLIjsPlXGf0ZyrgdSsDzXw0YNpjoSGjvgYrbVVx-rMM,6777
 tmu/weight_bank/__init__.py,sha256=3EAojTlrMl2ys3GZCaoim45dJyNapLXEIk7v6OY4uKo,37
 tmu/weight_bank/weight_bank.py,sha256=VDpJQEE6AhOWBkw37iNZi1ctLD2J6Yu3sdzIvvV9Mj0,2384
-tmu-0.7.9.data/data/tmu/logging_example.json,sha256=TPtjbFQGS33rCHWMnbOV0-icQ-_sRZiUHj8xaXXEp6Q,593
-tmu-0.7.9.dist-info/LICENSE,sha256=0sAZ3IbnshtS0nS5npAXKphpO34OQ6tSZmtytiVzNFY,1128
-tmu-0.7.9.dist-info/METADATA,sha256=Rur-1RC2ZlzVQhts-JIyjq9I_Vl-rUtubAmibYa4WMI,1812
-tmu-0.7.9.dist-info/WHEEL,sha256=QQY0XPJVcbNrDwRnZBTwtxGbMWJnHaWRpMJLfPEPCFM,107
-tmu-0.7.9.dist-info/top_level.txt,sha256=ybQL6qB--u7CBetG3wRX1hNbzYHVVJMnZVqICRjjZJc,9
-tmu-0.7.9.dist-info/RECORD,,
+tmu-0.8.0.data/data/tmu/logging_example.json,sha256=TPtjbFQGS33rCHWMnbOV0-icQ-_sRZiUHj8xaXXEp6Q,593
+tmu-0.8.0.dist-info/LICENSE,sha256=0sAZ3IbnshtS0nS5npAXKphpO34OQ6tSZmtytiVzNFY,1128
+tmu-0.8.0.dist-info/METADATA,sha256=C-WHsyamw5KZLqqMNod92ppfCS8PY8fkEyr7Nq8pqUo,1812
+tmu-0.8.0.dist-info/WHEEL,sha256=QQY0XPJVcbNrDwRnZBTwtxGbMWJnHaWRpMJLfPEPCFM,107
+tmu-0.8.0.dist-info/top_level.txt,sha256=ybQL6qB--u7CBetG3wRX1hNbzYHVVJMnZVqICRjjZJc,9
+tmu-0.8.0.dist-info/RECORD,,
```

